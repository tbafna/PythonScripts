{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import csv\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pywt\n",
    "import itertools\n",
    "from scipy import stats\n",
    "\n",
    "pd.options.mode.use_inf_as_na = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeDwellOrig = 100\n",
    "TimeFixation = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pupilTotal_Difficult = list()\n",
    "pupilTotal_Medium = list()\n",
    "pupilTotal_Easy = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FixUserKeys(UserKeys_Old):\n",
    "    # Fix the situation where comma has divided decimals into separate columns\n",
    "    \n",
    "    Column_beforeDecimal = [item[2] for item in UserKeys_Old]\n",
    "    Column_afterDecimal = [item[3] if len(item)>3 else '00' for item in UserKeys_Old]\n",
    "    \n",
    "    UserKeys_ProgressPercent = [float(Column_beforeDecimal[i]+'.'+ Column_afterDecimal[i]) for i in \n",
    "                                range(0, len(Column_beforeDecimal))]\n",
    "    UserKeys_Times = [item[0] for item in UserKeys_Old]\n",
    "    UserKeys_Keys = [item[1] for item in UserKeys_Old]\n",
    "    \n",
    "    UserKeys_New = [[UserKeys_Times[ind], UserKeys_Keys[ind], UserKeys_ProgressPercent[ind]] for ind in \n",
    "                    range(0, len(UserKeys_ProgressPercent))]\n",
    "    \n",
    "    #UserKeys_New = np.concatenate((UserKeys_Times, UserKeys_Keys, UserKeys_ProgressPercent), axis = 0)\n",
    "    \n",
    "    \n",
    "    return UserKeys_New\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeDwellTime(userKeys):\n",
    "    # modify userKeys to include a column of time instead of progress pct, which is dependent on the then dwell time\n",
    "    \n",
    "    timeDwell = TimeDwellOrig\n",
    "    nKey = -1\n",
    "    for key in userKeys:\n",
    "        nKey = nKey + 1\n",
    "        #print(key[1])\n",
    "        if key[1] == 'IncreaseDwellTime':\n",
    "            if float(key[2]) == 1:\n",
    "                timeDwell = timeDwell + 100\n",
    "        elif key[1] == 'DecreaseDwellTime':\n",
    "            #print(key[2])\n",
    "            if float(key[2]) == 1:\n",
    "                timeDwell = timeDwell - 100\n",
    "        else:\n",
    "            userKeys[nKey].append(str(float(key[2])*timeDwell))\n",
    "    \n",
    "    return userKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OptiKeyTypingTime(UserKeys):\n",
    "    \n",
    "    TimeTyping = dict()\n",
    "    \n",
    "    time1, t1, t2 = UserKeys[0][0].partition('+')\n",
    "    startTime = datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "    \n",
    "    time2, t1, t2 = UserKeys[-1][0].partition('+')\n",
    "    endTime = datetime.datetime.strptime(re.sub('[:.T]','-',time2[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "    \n",
    "    TimeTyping['startTime'] = startTime\n",
    "    TimeTyping['endTime'] = endTime\n",
    "    \n",
    "    return TimeTyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindTrialEndTimes(KeysSelected, timeTyping):\n",
    "    # function to find start and end of tasks in experiments\n",
    "    timeStartEnd = list() # format of this list will be: [startTime1, endTime1/startTime2, endTime2/startTime3, ..., endTimeN]\n",
    "    \n",
    "    timeStartEnd.append(timeTyping['startTime'])\n",
    "    \n",
    "    nTrial = 1\n",
    "    \n",
    "    for keys in KeysSelected:\n",
    "        \n",
    "        if keys[1] == 'NextPhrase':\n",
    "            time1, t1, t2 = keys[0].partition('+')\n",
    "            endTimeTrial = datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "            timeStartEnd.append(endTimeTrial)\n",
    "    \n",
    "    \n",
    "    timeStartEnd.append(timeTyping['endTime'])\n",
    "    \n",
    "    \n",
    "    return timeStartEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert list of date and time into datetime format list\n",
    "def timeConversion(timeStrList):\n",
    "    timeList = list()\n",
    "    for time in timeStrList:\n",
    "        time1, t1, t2 = time.partition('+')\n",
    "        timeList.append(datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\"))\n",
    "    return timeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will return the datetime in items which is the closest to the date pivot\n",
    "def nearestTimePoint(dates, date):\n",
    "    \n",
    "    for d in dates:\n",
    "        if d < date:\n",
    "            nearestTP = d\n",
    "        else:\n",
    "            continue\n",
    "    try: \n",
    "        nearestTP\n",
    "        nearestTPind = dates.index(nearestTP)\n",
    "    except:\n",
    "        nearestTP = 0\n",
    "        nearestTPind = -1\n",
    "        \n",
    "    return nearestTP, nearestTPind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateTimeEpochsOfTrials(TimeStartEndMixed, UserKeys):\n",
    "    # function to use list of mixed start and end times of trials and keys looked at by user to create trial epochs\n",
    "    \n",
    "    TimeEpochTrial = dict()\n",
    "    TimeEpochTrial['Start'] = list()\n",
    "    TimeEpochTrial['End'] = list()\n",
    "    \n",
    "    # Create list of times in userKeys to be able to use function 'nearestTimePoint'\n",
    "    UserKeysStrTimes = [item3[0] for item3 in UserKeys]\n",
    "    UserKeysTimes = timeConversion(UserKeysStrTimes)\n",
    "    \n",
    "    Flag_FoundSleepKey = 0 # Flag to indicate finding sleep key\n",
    "    \n",
    "    n = -1\n",
    "    for time in TimeStartEndMixed:\n",
    "        n = n + 1\n",
    "        Flag_FoundSleepKey = 0\n",
    "        \n",
    "        if n == 0: # first time is only start time for the first trial\n",
    "            TimeEpochTrial['Start'].append(time)\n",
    "            continue\n",
    "        elif n == len(TimeStartEndMixed)-1: # last time is only the end time for last trial\n",
    "            \n",
    "            TimeEpochTrial['End'].append(time)\n",
    "            \n",
    "        else: # the middle elements need to be divided into start and end\n",
    "            TimeEpochTrial['End'].append(time)\n",
    "            \n",
    "            # start time of trial is the time when 'Sleep' key is started in userKeys, after NextPhrase               \n",
    "            nearestToTrialStartTime, nearestToTrialStartInd = nearestTimePoint(UserKeysTimes, time)\n",
    "            indCheck = nearestToTrialStartInd + 2\n",
    "            TimeEpochTrial['Start'].append(UserKeysTimes[indCheck])\n",
    "            \n",
    "    return TimeEpochTrial      \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DwellTimeForBaseline(UserKeys_wDwellTime):\n",
    "    \n",
    "    DwellTime = list()\n",
    "    \n",
    "    for key in UserKeys_wDwellTime:\n",
    "        if key[1] == 'NextPhrase':\n",
    "            #print('NextPhrase found at ', key[2])\n",
    "            if key[2] == 1:\n",
    "                DwellTime.append(key[3])\n",
    "                \n",
    "    return DwellTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Combine2ColumnsTo1GazeLog(GazeLog, Column_1, Column_2):\n",
    "    \n",
    "    JoinedList = list()\n",
    "    \n",
    "    Column_beforeDecimal = [item4[Column_1] if 'Invalid' not in item4 else 'nan' for item4 in GazeLog]\n",
    "    Column_afterDecimal = [item4[Column_2] if 'Invalid' not in item4 else 'nan' for item4 in GazeLog]\n",
    "    \n",
    "    \n",
    "    for i in range(0, len(Column_beforeDecimal)):\n",
    "        if 'Valid' not in Column_beforeDecimal[i] and 'Valid' not in Column_afterDecimal[i]:\n",
    "            if 'nan' not in Column_beforeDecimal[i] and 'nan' not in Column_afterDecimal[i]:\n",
    "                JoinedList.append(float(Column_beforeDecimal[i]+'.'+ Column_afterDecimal[i]))\n",
    "            else:\n",
    "                JoinedList.append(np.nan)\n",
    "        else:\n",
    "            # Rarely, the pupil size is a whole number\n",
    "            JoinedList.append(np.nan) # we will ignore the row, since there is no way of automatically knowing which - \n",
    "            # right or left eye has whole number pupil size\n",
    "            \n",
    "    return JoinedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert2ColumnsToFormPupilSizes(GazeLog):\n",
    "    # function to convert pupilsizes from 2 columns for every pupil due to comma use instead of decimal, \n",
    "    # to proper pupil sizes\n",
    "    \n",
    "    PupilLogL = Combine2ColumnsTo1GazeLog(GazeLog, -5, -4)\n",
    "    PupilLogR = Combine2ColumnsTo1GazeLog(GazeLog, -2, -1)\n",
    "            \n",
    "    # if one of the pupils are nan, the other one is converted too\n",
    "    nPupil = -1\n",
    "    for pupilL in PupilLogL:\n",
    "        nPupil = nPupil + 1\n",
    "        if np.isnan(pupilL):\n",
    "            if nPupil < len(PupilLogR):\n",
    "                if not np.isnan(PupilLogR[nPupil]):\n",
    "                    PupilLogR[nPupil] = np.nan\n",
    "            else:\n",
    "                del PupilLogL[len(PupilLogR):]\n",
    "                \n",
    "    nPupil = -1\n",
    "    for pupilR in PupilLogR:\n",
    "        nPupil = nPupil + 1\n",
    "        if np.isnan(pupilR):\n",
    "            if nPupil < len(PupilLogL):\n",
    "                if not np.isnan(PupilLogL[nPupil]):\n",
    "                    PupilLogL[nPupil] = np.nan\n",
    "            else:\n",
    "                del PupilLogR[len(PupilLogL):]\n",
    "                \n",
    "    #print(len(PupilLogL), len(PupilLogR))\n",
    "    \n",
    "    return PupilLogL, PupilLogR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PupilSizeFromTrialTimes(TimeTrial, TimeGazeLog, TimeInternalGazeLog, PupilSizeLogL, PupilSizeLogR):\n",
    "    # find pupil sizes from the start and end time given\n",
    "    \n",
    "    # find start and end time in gazeLog\n",
    "    timeStart, timeStartInd = nearestTimePoint(TimeGazeLog, TimeTrial[0])\n",
    "    timeEnd, timeEndInd = nearestTimePoint(TimeGazeLog, TimeTrial[1])\n",
    "    \n",
    "    pupilSize_TrialL = PupilSizeLogL[timeStartInd: timeEndInd]\n",
    "    pupilSize_TrialR = PupilSizeLogR[timeStartInd: timeEndInd]\n",
    "    \n",
    "    TimeInternal_Trial = TimeInternalGazeLog[timeStartInd: timeEndInd]\n",
    "    \n",
    "    TimeGaze_Trial = TimeGazeLog[timeStartInd: timeEndInd]\n",
    "    \n",
    "    return pupilSize_TrialL, pupilSize_TrialR, TimeGaze_Trial, TimeInternal_Trial\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterBlinks(pupilData, timeListComplete):\n",
    "    # filter any blinks and nan values lasting around 250ms (on average)\n",
    "    # http://faculty.washington.edu/chudler/facts.html\n",
    "   \n",
    "    # blink is every nan value in the range of 100-400ms \n",
    "    # 250 ms (23 samples) before and after the blink will also be removed\n",
    "    extraBlinkSamples = 23    \n",
    "    \n",
    "    # remove single missing data, that are due to hardware error\n",
    "    missingVal_Single = np.argwhere(np.isnan(pupilData))\n",
    "    missingVal_Single = list(itertools.chain.from_iterable(missingVal_Single)) # flatten the list\n",
    "    missingVal_SingleDifference = [t - s for s, t in zip(missingVal_Single, missingVal_Single[1:])] # find difference \n",
    "    # between consecutive elements\n",
    "    \n",
    "    if len(missingVal_Single) > 0:\n",
    "        missingVal_SingleDifference.insert(0, missingVal_Single[0]) # insert the first blink index in the beginning of list\n",
    "    else:\n",
    "        return pupilData, timeListComplete, []\n",
    "    # the list missingVal_SingleDifference contains the index of the first blink, followed by the difference in the index to \n",
    "    # the next nan value\n",
    "    \n",
    "    # first remove the single nan values, which are missing data\n",
    "    eyeTracker_missingData = list() # list with index of single missing data  \n",
    "    valInd = -1\n",
    "\n",
    "    for val in missingVal_SingleDifference:\n",
    "        valInd = valInd + 1\n",
    "        if valInd == 0:\n",
    "            continue\n",
    "        if val != 1:\n",
    "            if missingVal_SingleDifference[valInd-1] !=1: # if there are 2 consecutive missing values (denoted by 2 consecutive\n",
    "                # non 1 numbers, they are added to the list of eyeTracker_missingData)\n",
    "                eyeTracker_missingData.append(sum(missingVal_SingleDifference[:valInd]))\n",
    "                \n",
    "    # remove single missing values from pupil data\n",
    "    pupilData_woSingleMissingData0 = [pupilData[ind] if ind not in eyeTracker_missingData else [] \n",
    "                                     for ind in range(0, len(pupilData))]\n",
    "    pupilData_woSingleMissingData = [x for x in pupilData_woSingleMissingData0 if x]\n",
    "    \n",
    "    # remove the times for single missing values in pupil data\n",
    "    timeList_woSingleMissingData0 = [timeListComplete[ind] if ind not in eyeTracker_missingData else [] \n",
    "                                     for ind in range(0, len(timeListComplete))]\n",
    "    timeList_woSingleMissingData = [x for x in timeList_woSingleMissingData0 if x]\n",
    "    \n",
    "#     print(len(timeList_woSingleMissingData))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # find the nan values again from pupilData_woSingleMissingData\n",
    "    missingVal_Rest = np.argwhere(np.isnan(pupilData_woSingleMissingData))\n",
    "    missingVal_Rest = list(itertools.chain.from_iterable(missingVal_Rest))\n",
    "    missingVal_RestDifference = [t - s for s, t in zip(missingVal_Rest, missingVal_Rest[1:])]\n",
    "    missingVal_RestDifference.insert(0, missingVal_Rest[0])\n",
    "    \n",
    "    \n",
    "    # compile and create list of start and end of blinks\n",
    "    blink_missingData = dict()\n",
    "    blink_missingData['Start'] = list()\n",
    "    blink_missingData['End'] = list()\n",
    "    \n",
    "    valInd = -1\n",
    "    for val in missingVal_RestDifference:\n",
    "        valInd = valInd + 1\n",
    "        if val > 1:\n",
    "            #print('value', val)\n",
    "            # instead of appending the actual index of blink start, since 250ms before and after the blink need to be\n",
    "            # removed, it is also appended here.\n",
    "            \n",
    "            # just make sure that the additional samples do not make the index of blink go in negative\n",
    "            if sum(missingVal_RestDifference[:valInd+1])-extraBlinkSamples > 0:\n",
    "                \n",
    "                blink_missingData['Start'].append(sum(missingVal_RestDifference[:valInd+1])-extraBlinkSamples)\n",
    "            else:\n",
    "                blink_missingData['Start'].append(0)\n",
    "            \n",
    "            if valInd == 0:\n",
    "                continue\n",
    "                \n",
    "            # make sure that the additional samples do not increase the index to more than the length of the pupilData\n",
    "            if sum(missingVal_RestDifference[:valInd])+extraBlinkSamples < len(pupilData_woSingleMissingData):\n",
    "                blink_missingData['End'].append(sum(missingVal_RestDifference[:valInd])+extraBlinkSamples)\n",
    "            else:\n",
    "                blink_missingData['End'].append(len(pupilData_woSingleMissingData)-1)\n",
    "            #print('end', sum(missingVal_RestDifference[:valInd]))\n",
    "      \n",
    "    # add the last blink index\n",
    "    # make sure that the additional samples do not increase the index to more than the length of the pupilData\n",
    "    if sum(missingVal_RestDifference)+extraBlinkSamples < len(pupilData_woSingleMissingData):\n",
    "        blink_missingData['End'].append(sum(missingVal_RestDifference)+extraBlinkSamples)\n",
    "    else:\n",
    "        blink_missingData['End'].append(len(pupilData_woSingleMissingData)-1)\n",
    "      \n",
    "    \n",
    "    # print start and end values\n",
    "    #for ind in range(0,len(blink_missingData['Start'])):\n",
    "    #    print(blink_missingData['Start'][ind]+23, blink_missingData['End'][ind]-23)\n",
    "        \n",
    "        \n",
    "        \n",
    "    # need to create a list containing indexes that are to be removed\n",
    "    blinkIndexList = list()\n",
    "    \n",
    "    #print(len(blink_missingData['Start']), len(blink_missingData['End']))\n",
    "    \n",
    "    \n",
    "    # remove blinks and additional data from pupil data to get filtered data\n",
    "    for indInd in range(0, len(blink_missingData['Start'])):\n",
    "        blinkIndexList.append(range(blink_missingData['Start'][indInd], blink_missingData['End'][indInd]+1))\n",
    "    # flatten the list\n",
    "    blinkIndexList = list(itertools.chain.from_iterable(blinkIndexList))\n",
    "    \n",
    "    \n",
    "    ##print(len(pupilData_woSingleMissingData))\n",
    "    \n",
    "    pupilData_woRestMissingData0 = [pupilData_woSingleMissingData[ind] if ind not in blinkIndexList else [] \n",
    "                                     for ind in range(0, len(pupilData_woSingleMissingData))]\n",
    "    #for i in enumerate(pupilData_woRestMissingData0):\n",
    "    #    print(i)\n",
    "    pupilData_filter = [x for x in pupilData_woRestMissingData0 if x]\n",
    "    \n",
    "    #for i in enumerate(pupilData_filter):\n",
    "    #    print(i)\n",
    "        \n",
    "    # remove the times for single missing values in pupil data\n",
    "    timeList_woRestMissingData0 = [timeList_woSingleMissingData[ind] if ind not in blinkIndexList else [] \n",
    "                                     for ind in range(0, len(timeList_woSingleMissingData))]\n",
    "    time_filter = [x for x in timeList_woRestMissingData0 if x]\n",
    "    \n",
    "    #print(len(pupilData_filter))\n",
    "        \n",
    "    if np.nan in pupilData_filter:\n",
    "        print('nan values still present in pupil data')\n",
    "        #for i in enumerate(pupilData_woSingleMissingData):\n",
    "        #    print(i)\n",
    "        \n",
    "    \n",
    "    return pupilData_filter, time_filter, blink_missingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hampel(vals_orig, k, sd):\n",
    "    '''\n",
    "    vals: pandas series of values from which to remove outliers\n",
    "    k: size of window (including the sample; 7 is equal to 3 on either side of value)\n",
    "    '''\n",
    "    # Obtained from: https://stackoverflow.com/questions/46819260/filtering-outliers-how-to-make-median-based-\n",
    "    # hampel-function-faster\n",
    "    \n",
    "    #plt.plot(vals_orig)\n",
    "    \n",
    "    #Make copy so original not edited\n",
    "    vals = pd.DataFrame(vals_orig)      \n",
    "    #print(vals.isnull().any())\n",
    "    vals0 = vals.replace([np.inf, -np.inf], np.nan)\n",
    "    #vals = vals0.astype(float).fillna(method = 'backfill') # linear interpolation instead \n",
    "    #print(vals)\n",
    "    vals = vals0.astype(float).interpolate('linear', limit_direction = 'both') # linear interpolation instead of \n",
    "    # simply copying the previous value --\\ linear interpolation than cubic to not add any patterns in the data, limit direction\n",
    "    # set to both, to interpolate the nan values occuring from the start of the series\n",
    "    \n",
    "    L= 1.4826\n",
    "    rolling_median = vals.rolling(window=k, min_periods=1, center=True).median()\n",
    "    \n",
    "    #print(rolling_median)\n",
    "    difference = np.abs(rolling_median-vals)\n",
    "    median_abs_deviation = difference.rolling(k).median()\n",
    "    threshold = sd * L * median_abs_deviation\n",
    "    outlier_idx = difference>threshold\n",
    "    vals[outlier_idx] = rolling_median[outlier_idx]\n",
    "    #print(vals)\n",
    "    #print('datatype', vals.dtypes)\n",
    "    #print(vals.isnull().any())\n",
    "    #vals.plot()\n",
    "    return(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPupilSize(pupilData, timeData, TrialNumber, scoreDifficulty):\n",
    "    \n",
    "    dataLenEqualizer = min(min(len(pupilData['Left']), len(pupilData['Right'])), len(timeData))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.plot(timeData[0:dataLenEqualizer], pupilData['Left'][0:dataLenEqualizer], 'b')\n",
    "    ax.plot(timeData[0:dataLenEqualizer], pupilData['Right'][0:dataLenEqualizer], 'r')\n",
    "    \n",
    "    ax.set_ylabel('Relative pupil size [in mm]')\n",
    "    ax.set_ylim([0.8, 1.2])\n",
    "    ax.set_title(scoreDifficulty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindAndPlotPupilSizeForEpoch(GazeLog, TimeEpochTrial, DwellTimes_ForBaseline):\n",
    "    # function that uses the list of start and end trial times to find the pupil sizes for those trials and plots them\n",
    "    \n",
    "    # first create a list of times in gaze log\n",
    "    timeStrGazeLog = [item3[0] for item3 in GazeLog]\n",
    "    # convert the list of strings to datetime formats\n",
    "    timeGazeLog = timeConversion(timeStrGazeLog)\n",
    "    \n",
    "    # internal time, to depict seconds\n",
    "    timeInternalGazeLog = [float(item3[1]) for item3 in GazeLog]\n",
    "    \n",
    "    # extract pupil sizes in decimals from the strange 2 columns for every pupil\n",
    "    pupilLogL, pupilLogR = Convert2ColumnsToFormPupilSizes(GazeLog)\n",
    "    \n",
    "    pupilRelative_avg = list()\n",
    "    pupilAbsolute_avg = list()\n",
    "    timeOfGaze_TrialList = list()\n",
    "    \n",
    "    #trialsToIgnore = [1, 2, 4, 6, 8, 10, 12]\n",
    "    trialsForBaseline = [2, 4, 6, 8, 10]\n",
    "    # for every epoch, plot the pupil size\n",
    "    for trialNr in range(0, len(timeEpochTrial['Start'])):\n",
    "        #if trialNr in trialsToIgnore:\n",
    "        #    continue\n",
    "        if trialNr == 1 or trialNr == 0:\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        # find pupil sizes for the trial\n",
    "        pupilSizeL_Trial, pupilSizeR_Trial, timeGaze_Trial, timeInternal_Trial = PupilSizeFromTrialTimes(\n",
    "            [TimeEpochTrial['Start'][trialNr], TimeEpochTrial['End'][trialNr]], timeGazeLog, \n",
    "                                timeInternalGazeLog, pupilLogL, pupilLogR)\n",
    "        \n",
    "        pupilSize_Trial = dict()\n",
    "        pupilSize_Filter = dict()\n",
    "        pupilSize_woBlink = dict()\n",
    "        \n",
    "        # find difference in consecutive elements of internal time\n",
    "        timeInternalDifference = [t - s for s, t in zip(timeInternal_Trial, timeInternal_Trial[1:])]\n",
    "        # divide by 1000 to make it s\n",
    "        timeOfGaze_Trial = [sum(timeInternalDifference[:i])/1000000 for i in range(1,len(timeInternalDifference))]\n",
    "\n",
    "        # some trials were skipped, because the sentence was written before. If the time of trial is less than\n",
    "        # 10s, the trial is skipped\n",
    "        if timeOfGaze_Trial[-1] < 20:\n",
    "            if trialNr != 3:\n",
    "                print(trialNr)\n",
    "                if trialNr not in trialsForBaseline:\n",
    "                    print('trial number ', trialNr, 'with', timeOfGaze_Trial[-1], 's will be skipped')\n",
    "                    continue\n",
    "        \n",
    "        pupilSize_Trial['Left'] = pupilSizeL_Trial\n",
    "        pupilSize_Trial['Right'] = pupilSizeR_Trial\n",
    "        \n",
    "        #if trialNr == 4:\n",
    "        #    for i in range(0, len(pupilSizeL_Trial)):\n",
    "        #        print(pupilSizeL_Trial[i], pupilSizeR_Trial[i])\n",
    "            \n",
    "        #print('Trial', len(pupilSizeL_Trial), len(pupilSizeR_Trial))\n",
    "        \n",
    "        # filter the blinks\n",
    "        pupilSizeL_woBlink, time_filter, missingPupilData = filterBlinks(\n",
    "            pupilSizeL_Trial, timeGaze_Trial)\n",
    "        \n",
    "        pupilSizeR_woBlink, time_filter, missingPupilData = filterBlinks(\n",
    "            pupilSizeR_Trial, timeGaze_Trial)\n",
    "        \n",
    "\n",
    "        \n",
    "        #print(index_blinkEndL)\n",
    "        #print(index_blinkEndR)\n",
    "        pupilSize_woBlink['Left'] = pupilSizeL_woBlink\n",
    "        pupilSize_woBlink['Right'] = pupilSizeR_woBlink\n",
    "        \n",
    "        #print('After blink', len(pupilSizeL_woBlink), len(pupilSizeR_woBlink))\n",
    "        # Hampel filter to remove the outliers\n",
    "        winSize = 25\n",
    "        pupilSizeL_filter = hampel(pupilSizeL_woBlink, winSize, 3)\n",
    "        pupilSizeR_filter = hampel(pupilSizeR_woBlink, winSize, 3)\n",
    "\n",
    "        pupilSize_Filter['Left'] = pupilSizeL_filter.values.tolist()\n",
    "        pupilSize_Filter['Right'] = pupilSizeR_filter.values.tolist()\n",
    "        \n",
    "        pupilSizeL_filterList = [i[0] for i in pupilSizeL_filter.values]\n",
    "        pupilSizeR_filterList = [i[0] for i in pupilSizeR_filter.values]\n",
    "        \n",
    "        #print('filter', len(pupilSizeL_filterList), len(pupilSizeR_filterList))\n",
    "        RLCorrelation = np.corrcoef(pupilSizeL_filterList, pupilSizeR_filterList)\n",
    "        \n",
    "        if RLCorrelation[0][1] < 0.8:\n",
    "            print(RLCorrelation[0][1])\n",
    "            print('CORRELATION BETWEEN RIGHT AND LEFT IS NOT GOOD. TRIAL MUST BE REMOVED')\n",
    "        \n",
    "        if trialNr in trialsForBaseline:\n",
    "            print(trialNr)\n",
    "            # baseline trial\n",
    "            # First find baseline pupil size, which is the time when looking at NextPhrase key\n",
    "            Samples_ForBaseline = int((int(DwellTimes_ForBaseline[trialNr][:-2])*90)/1000) # Number of samples of looking at key depend on\n",
    "        \n",
    "            # dwell time\n",
    "            pupilL_baseline = np.mean(pupilSizeL_filterList[0:Samples_ForBaseline])\n",
    "            pupilR_baseline = np.mean(pupilSizeR_filterList[0:Samples_ForBaseline])\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # Relative Pupil Size Calculation \n",
    "        \n",
    "        #print(DwellTimes_ForBaseline[trialNr-1])\n",
    "        \n",
    "        pupilL_Relative = [pupil/pupilL_baseline for pupil in pupilSizeL_filterList]\n",
    "        pupilR_Relative = [pupil/pupilR_baseline for pupil in pupilSizeR_filterList]\n",
    "        \n",
    "        # average of whole trial\n",
    "        pupilRelative_avg.append((np.mean(pupilL_Relative)+np.mean(pupilR_Relative))/2)\n",
    "        pupilAbsolute_avg.append((np.mean(pupilSizeL_filterList)+np.mean(pupilSizeR_filterList))/2)\n",
    "        \n",
    "        #print(np.mean(pupilL_Relative), np.mean(pupilR_Relative))\n",
    "        \n",
    "        \n",
    "    return pupilAbsolute_avg, pupilRelative_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\ait-pdfs.win.dtu.dk\\users\\homedir\\taba\\Documents\\Courses\\Credits\\2019January\\Principles of BCI\\Group Project\\EEG Data Grp Project\\Data_GazeTyping\\tb1_difficult_notCounting\n",
      "\\\\ait-pdfs.win.dtu.dk\\users\\homedir\\taba\\Documents\\Courses\\Credits\\2019January\\Principles of BCI\\Group Project\\EEG Data Grp Project\\Data_GazeTyping\\tb1_easy\\2019-1-17-13-12-54\n",
      "tb1_easy\n",
      "2\n",
      "0.7265572540426227\n",
      "CORRELATION BETWEEN RIGHT AND LEFT IS NOT GOOD. TRIAL MUST BE REMOVED\n",
      "2\n",
      "4\n",
      "6\n",
      "0.5710067552040098\n",
      "CORRELATION BETWEEN RIGHT AND LEFT IS NOT GOOD. TRIAL MUST BE REMOVED\n",
      "6\n",
      "8\n",
      "8\n",
      "10\n",
      "0.7347133191395835\n",
      "CORRELATION BETWEEN RIGHT AND LEFT IS NOT GOOD. TRIAL MUST BE REMOVED\n",
      "10\n",
      "12\n",
      "trial number  12 with 2.342759 s will be skipped\n",
      "13\n",
      "trial number  13 with 1.232447 s will be skipped\n",
      "\\\\ait-pdfs.win.dtu.dk\\users\\homedir\\taba\\Documents\\Courses\\Credits\\2019January\\Principles of BCI\\Group Project\\EEG Data Grp Project\\Data_GazeTyping\\tb2_difficult\\2019-1-17-13-26-43\n",
      "tb2_difficult\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "8\n",
      "8\n",
      "10\n",
      "10\n",
      "12\n",
      "trial number  12 with 1.4212 s will be skipped\n",
      "13\n",
      "trial number  13 with 2.253934 s will be skipped\n"
     ]
    }
   ],
   "source": [
    "inputFolderName = r'\\\\ait-pdfs.win.dtu.dk\\users\\homedir\\taba\\Documents\\Courses\\Credits\\2019January\\Principles of BCI\\Group Project\\EEG Data Grp Project\\Data_GazeTyping'\n",
    "\n",
    "pupilAbsolute_avgList = list()\n",
    "pupilRelative_avgList = list()\n",
    "\n",
    "for root, dirs, subfolder in os.walk(inputFolderName):\n",
    "    if not dirs:\n",
    "        print(root)\n",
    "        if 'notCounting' in root:\n",
    "            continue\n",
    "            \n",
    "        userKeys = None\n",
    "        gazeLog = None\n",
    "        keysSelected = None\n",
    "        \n",
    "        for file in subfolder:\n",
    "            if fnmatch.fnmatch(file, 'user_looks*'):\n",
    "                try:\n",
    "                    \n",
    "                    fUserKey = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerUserKey = csv.reader(fUserKey)\n",
    "                    userKeys = list(readerUserKey)\n",
    "                    \n",
    "                    userKeys.remove(userKeys[0])\n",
    "                except:\n",
    "                    if fUserKey is not None:\n",
    "                        \n",
    "                        fUserKey.close()\n",
    "                    else:\n",
    "                        print('error in opening the user looks at log file')\n",
    "            \n",
    "            elif fnmatch.fnmatch(file, 'KeySelection*'):\n",
    "                try:\n",
    "                    \n",
    "                    fKeysSelected = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerKeysSelected = csv.reader(fKeysSelected)\n",
    "                    keysSelected = list(readerKeysSelected)\n",
    "                    \n",
    "                    keysSelected.remove(keysSelected[0])\n",
    "                except:\n",
    "                    if fKeysSelected is not None:\n",
    "                        \n",
    "                        fKeysSelected.close()\n",
    "                    else:\n",
    "                        print('error in opening the KeySelection log file')\n",
    "            \n",
    "            elif fnmatch.fnmatch(file, 'tobiiGazeLog*'):\n",
    "                try:\n",
    "                    fGazeLog = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerGazeLog = csv.reader(fGazeLog)\n",
    "                    gazeLog = list(readerGazeLog)\n",
    "                    \n",
    "                    gazeLog.remove(gazeLog[0]) # would not matter much even if the first row was not labels\n",
    "                    gazeLog.remove(gazeLog[-1])\n",
    "\n",
    "                except:\n",
    "                    if fGazeLog is not None:\n",
    "                        fGazeLog.close()\n",
    "                    else:\n",
    "                        print('error in opening the gaze log file')\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "                # if all these lists exist\n",
    "            if userKeys is None or keysSelected is None or gazeLog is None:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                a = re.compile('(?<=Data_GazeTyping\\\\\\\\)(.*)(?=\\\\\\\\2019-1)')\n",
    "                subjName = a.findall(root)[0]\n",
    "                print(subjName)\n",
    "                \n",
    "                # fix userKeys due to comma related file changes\n",
    "                userKeys_new = FixUserKeys(userKeys)\n",
    "                \n",
    "                # find dwell time of typing\n",
    "                userKeys_wDwellTime = ComputeDwellTime(userKeys_new)\n",
    "                \n",
    "                # find start time of typing\n",
    "                timeTyping = OptiKeyTypingTime(userKeys_wDwellTime)\n",
    "                \n",
    "                # divide complete data into epochs of phrases\n",
    "                timeStartEndMixed = FindTrialEndTimes(keysSelected, timeTyping)\n",
    "                #print(timeStartEndMixed)\n",
    "                \n",
    "                # create trial time epoch using the list of start/end times of trial and userKeys, to make sure that \n",
    "                # Sleep is completely there in every trial, to allow for baseline\n",
    "                timeEpochTrial = CreateTimeEpochsOfTrials(timeStartEndMixed, userKeys_wDwellTime)\n",
    "                #print(timeEpochTrial)\n",
    "                \n",
    "                dwellTimes_ForBaseline = DwellTimeForBaseline(userKeys_wDwellTime)\n",
    "                \n",
    "                # find and plot pupil size for every trial\n",
    "                pupilAbsolute, pupilRelative = FindAndPlotPupilSizeForEpoch(gazeLog, timeEpochTrial, dwellTimes_ForBaseline)\n",
    "                \n",
    "                \n",
    "                \n",
    "                if 'easy' in root:\n",
    "                    pupilAbsolute[0] = np.nan\n",
    "                    pupilRelative[0] = np.nan\n",
    "                    \n",
    "                \n",
    "                pupilRelative_avgList.append(pupilRelative)\n",
    "                pupilAbsolute_avgList.append(pupilAbsolute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pupilAbsolute_avgList)\n",
    "plt.plot(pupilAbsolute_avgList[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[nan,\n",
       "  0.8244980417457839,\n",
       "  0.9297555049607051,\n",
       "  1.0552341189310543,\n",
       "  0.8759705994982582],\n",
       " [0.9165068388896602,\n",
       "  0.9775671053395556,\n",
       "  0.9227354512938861,\n",
       "  0.952379423266789,\n",
       "  0.9019541813131609]]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pupilRelative_avgList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x19c3cd28940>,\n",
       "  <matplotlib.axis.XTick at 0x19c3cd28278>,\n",
       "  <matplotlib.axis.XTick at 0x19c3cd28160>,\n",
       "  <matplotlib.axis.XTick at 0x19c3cd9ebe0>,\n",
       "  <matplotlib.axis.XTick at 0x19c39f90160>,\n",
       "  <matplotlib.axis.XTick at 0x19c39f905c0>,\n",
       "  <matplotlib.axis.XTick at 0x19c39f90a90>,\n",
       "  <matplotlib.axis.XTick at 0x19c39f90f60>,\n",
       "  <matplotlib.axis.XTick at 0x19c39fb3470>,\n",
       "  <matplotlib.axis.XTick at 0x19c39f90a58>],\n",
       " <a list of 10 Text xticklabel objects>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(flat_list, 'o')\n",
    "plt.xticks(np.arange(10), ('', 'Easy_trial2', 'Easy_trial3', 'Easy_trial4', 'Easy_trial5', 'Difficult_trial1', 'Difficult_trial2', 'Difficult_trial3', 'Difficult_trial4', 'Difficult_trial5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9213645662839504 0.9342286000206104\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(pupilRelative_avgList[0][1:]), np.mean(pupilRelative_avgList[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9165068388896602,\n",
       " 0.9775671053395556,\n",
       " 0.9227354512938861,\n",
       " 0.952379423266789,\n",
       " 0.9019541813131609]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pupilRelative_avgList[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pupilRelative_boxplot = [pupilRelative_avgList[0][1:], pupilRelative_avgList[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plot of pupil size\n",
    "\n",
    "#boxprops = dict(linewidth=3)\n",
    "#flierprops = dict(marker='o', markerfacecolor='green', markersize=12,\n",
    " #                 linestyle='none')\n",
    "#medianprops = dict(linewidth=2.5)\n",
    "#meanpointprops = dict(marker='s', markeredgecolor='black',\n",
    "#                      markerfacecolor='green', markersize = 8)\n",
    "\n",
    "boxprops = dict(markeredgecolor= 'c', color='blue')\n",
    "flierprops = dict(marker='o', markerfacecolor = 'white', markersize=12,linestyle='none', color='blue', markeredgecolor= 'blue')\n",
    "medianprops = dict(linewidth=2.5, color = 'red')\n",
    "meanpointprops = dict(marker='s', markerfacecolor = 'white', markeredgecolor = 'black', markersize = 8)\n",
    "whiskerprops = dict(linestyle = '--')\n",
    "\n",
    "#meanlineprops = dict(linestyle='--', linewidth=2.5, color='purple')\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "plt.boxplot(pupilRelative_boxplot, showmeans=True, notch=True, whiskerprops=whiskerprops, boxprops=boxprops, flierprops=flierprops, medianprops=medianprops, meanprops=meanpointprops)\n",
    "plt.xticks(np.arange(1, 3), ('Easy', 'Difficult'))\n",
    "plt.ylabel('Relative pupil size (mm)', fontsize = 14)\n",
    "plt.tight_layout()\n",
    "plt.xlim([0.5,2.5])\n",
    "plt.ylim([0.8, 1.1])\n",
    "plt.savefig('pupilSize1.png', format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x19c53d6fd30>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(pupilRelative_avgList[0], '*')\n",
    "plt.plot(pupilRelative_avgList[1], 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "resultFile = inputFolderName + '\\pupilData1.csv' \n",
    "\n",
    "with open(resultFile, 'w+') as myfile:\n",
    "    wr = csv.writer(myfile)\n",
    "    wr.writerow(pupilRelative_avgList[0])\n",
    "    wr.writerow(pupilRelative_avgList[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the MSD, with cost of 2 for substitution and 1 for insertion and deletion\n",
    "costSub = 2\n",
    "costIns = 1\n",
    "costDel = 1\n",
    "\n",
    "def levenshteinDist(phraseIn, phraseOut):\n",
    "    \n",
    "    lenStim = len(phraseIn)\n",
    "    lenUser = len(phraseOut)\n",
    "    costMatrix = np.zeros((lenStim+1, lenUser+1), dtype=int)\n",
    "    MSDoperation = np.empty([lenStim+1, lenUser+1], dtype=\"U4\")\n",
    "    costMatrix[0,0:] = range(0, lenUser+1)\n",
    "    costMatrix[0:,0] = range(0, lenStim+1)\n",
    "    MSDoperation[0,0:] = 'I'\n",
    "    MSDoperation[0:,0] = 'D'\n",
    "    \n",
    "    for i in range(1, len(phraseIn)+1):\n",
    "        iP = i - 1\n",
    "        for j in range(1, len(phraseOut)+1):\n",
    "            jP = j - 1\n",
    "            if phraseIn[iP].lower() == phraseOut[jP].lower():\n",
    "                # Define the possible cost array\n",
    "                costOptionArray = [costMatrix[i,j-1]+costDel, costMatrix[i-1,j]+costIns, costMatrix[i-1,j-1]] \n",
    "                flagSame = 1\n",
    "            else:\n",
    "                costOptionArray = [costMatrix[i,j-1]+costDel, costMatrix[i-1,j]+costIns, costMatrix[i-1,j-1]+costSub]\n",
    "                flagSame = 0\n",
    "            costMatrix[i,j], MSDoperation[i][j] = minValnInd(costOptionArray, flagSame)\n",
    "    #print(costMatrix)\n",
    "    return costMatrix[-1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find minimum cost and the operations that give rise to it\n",
    "def minValnInd(costOptions, flagSame):\n",
    "    operator = list()\n",
    "    unique_entries = set(costOptions)\n",
    "    valInd = { value : [ i for i, v in enumerate(costOptions) if v == value ] for value in unique_entries }\n",
    "    keyVal = list(valInd.keys())\n",
    "    min_value = min(keyVal)\n",
    "    \n",
    "    if 0 in valInd[min_value]:\n",
    "        operator.append('D')\n",
    "    if 1 in valInd[min_value]:\n",
    "        operator.append('I')\n",
    "    if 2 in valInd[min_value]:\n",
    "        if flagSame == 0:\n",
    "            operator.append('S')\n",
    "        else:\n",
    "            operator.append('N')   \n",
    "    flagSame = None    \n",
    "    return min_value, ''.join(operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03125\n",
      "0.27835051546391754\n",
      "0.0\n",
      "0.041666666666666664\n"
     ]
    }
   ],
   "source": [
    "# error rate for easy session:\n",
    "phraseLog_reduced = ['He wants humans to come to him freely,  rather than by coercion.', 'If in doubt about which level of course you think is appropriate,  please do not hesitate to ask.', 'This site uses frames - please update your browser.', 'He learned to rise early and work late at all times and in all weathers.', ]\n",
    "phraseUserEnd = ['he wants humans to come to him freely, rather than by  coercion.', 'if in doubt about which course is appropriate, do not hesitate to ask.', 'this site uses frames - please update your browser.', 'he learned to rise early and work late at all times and all weathers.']\n",
    "for n in range(0,len(phraseLog_reduced)):\n",
    "    #print(levenshteinDist(phraseLog_reduced[n], phraseUserEnd[n]), max(len(phraseLog_reduced[n]),len(phraseUserEnd[n])))\n",
    "    \n",
    "    print(levenshteinDist(phraseLog_reduced[n], phraseUserEnd[n])/max(len(phraseLog_reduced[n]),len(phraseUserEnd[n])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13471502590673576\n",
      "0.12637362637362637\n",
      "0.07627118644067797\n",
      "0.1282051282051282\n",
      "0.08743169398907104\n"
     ]
    }
   ],
   "source": [
    "# error rate for difficult session:\n",
    "phraseLog_reduced = ['Here, a group of thespians (and I use the term loosely): the director, producer, and a few crew members,head for an isolated island where they plan to make a film utilising an abandoned school.', 'Except for the Beginners tournaments ungraded players will be limited to 50kr of prize money unless the Congress organisers are able to satisfy themselves as to the player''s strength.', 'Further combinations may be possible and interested students are encouraged to contact the other Departments involved.', 'Environment Concern for Batley was established in 1986 as a voluntary organisation, registered as a company limited by guarantee in 1997 and granted registered charitable status in 1998.', 'The Blues were missing three key players with David Logan, Dave Goodchild and Keeper Stuart Dawson all suspended after last season''s bad tempered Presidents Cup Final against Trafford.']\n",
    "phraseUserEnd = ['a group of thespians (and i us the word loosely): the director, producer and a few crew members head to an isolated island where they plan to make a film in an abandoned school.', 'except the beginners tournament ungraded players will be limited to 50kr unless the Congress organisers are able to satisfy themselves so as to the player''s strength.', 'further combinations may be possible and interested students are asked to contact the other departments involved.', 'environmental concern for Batley was established in 1986 as a voluntary organisation, registered as a company with limited guarantee in 1997 and granted the registered charitable company in 1998.','the blues were missing three key players David Logan,Dave Goodchild and keeper Stuart Dawson all suspended after last season''s bad-tempered Presidents cup finals against trawthorn.']\n",
    "for n in range(0,len(phraseLog_reduced)):\n",
    "    #print(levenshteinDist(phraseLog_reduced[n], phraseUserEnd[n]), max(len(phraseLog_reduced[n]),len(phraseUserEnd[n])))\n",
    "    \n",
    "    print(levenshteinDist(phraseLog_reduced[n], phraseUserEnd[n])/max(len(phraseLog_reduced[n]),len(phraseUserEnd[n])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7999999999999999"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std([6,7,5,7,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreDifficulty = [[2,3,4,2], [6,7,5,7,7]]\n",
    "plt.boxplot(scoreDifficulty, showmeans=True, notch=True, whiskerprops=whiskerprops, boxprops=boxprops, flierprops=flierprops, medianprops=medianprops, meanprops=meanpointprops)\n",
    "plt.xticks(np.arange(1, 3), ('Easy', 'Difficult'))\n",
    "plt.ylabel('Subjective Difficulty Score', fontsize = 18)\n",
    "plt.tick_params(axis='both', which='major', labelsize=18)\n",
    "plt.tight_layout()\n",
    "plt.xlim([0.5,2.5])\n",
    "plt.ylim([1, 8])\n",
    "plt.savefig('scoreDifficulty.png', format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorRate = [[3.12, 27.84, 0.0, 4.16], [13.47, 13.26, 7.62, 12.82, 8.74]]\n",
    "plt.boxplot(errorRate, showmeans=True, notch=True, whiskerprops=whiskerprops, boxprops=boxprops, flierprops=flierprops, medianprops=medianprops, meanprops=meanpointprops)\n",
    "plt.xticks(np.arange(1, 3), ('Easy', 'Difficult'))\n",
    "plt.ylabel('Subjective Difficulty Score', fontsize = 18)\n",
    "plt.tick_params(axis='both', which='major', labelsize=18)\n",
    "plt.tight_layout()\n",
    "plt.xlim([0.5,2.5])\n",
    "#plt.ylim([1, 8])\n",
    "plt.savefig('errorRate.png', format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
