{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import csv\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pywt\n",
    "import itertools\n",
    "from scipy import stats\n",
    "\n",
    "pd.options.mode.use_inf_as_na = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeDwellOrig = 800\n",
    "TimeFixation = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pupilTotal_Difficult = list()\n",
    "pupilTotal_Medium = list()\n",
    "pupilTotal_Easy = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FixUserKeys(UserKeys_Old):\n",
    "    # Fix the situation where comma has divided decimals into separate columns\n",
    "    \n",
    "    Column_beforeDecimal = [item[2] for item in UserKeys_Old]\n",
    "    Column_afterDecimal = [item[3] if len(item)>3 else '00' for item in UserKeys_Old]\n",
    "    \n",
    "    UserKeys_ProgressPercent = [float(Column_beforeDecimal[i]+'.'+ Column_afterDecimal[i]) for i in \n",
    "                                range(0, len(Column_beforeDecimal))]\n",
    "    UserKeys_Times = [item[0] for item in UserKeys_Old]\n",
    "    UserKeys_Keys = [item[1] for item in UserKeys_Old]\n",
    "    \n",
    "    UserKeys_New = [[UserKeys_Times[ind], UserKeys_Keys[ind], UserKeys_ProgressPercent[ind]] for ind in \n",
    "                    range(0, len(UserKeys_ProgressPercent))]\n",
    "    \n",
    "    #UserKeys_New = np.concatenate((UserKeys_Times, UserKeys_Keys, UserKeys_ProgressPercent), axis = 0)\n",
    "    \n",
    "    \n",
    "    return UserKeys_New\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeDwellTime(userKeys):\n",
    "    # modify userKeys to include a column of time instead of progress pct, which is dependent on the then dwell time\n",
    "    \n",
    "    timeDwell = TimeDwellOrig\n",
    "    nKey = -1\n",
    "    for key in userKeys:\n",
    "        nKey = nKey + 1\n",
    "        #print(key[1])\n",
    "        if key[1] == 'IncreaseDwellTime':\n",
    "            if float(key[2]) == 1:\n",
    "                timeDwell = timeDwell + 100\n",
    "        elif key[1] == 'DecreaseDwellTime':\n",
    "            #print(key[2])\n",
    "            if float(key[2]) == 1:\n",
    "                timeDwell = timeDwell - 100\n",
    "        else:\n",
    "            userKeys[nKey].append(str(float(key[2])*timeDwell))\n",
    "    \n",
    "    return userKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OptiKeyTypingTime(UserKeys):\n",
    "    \n",
    "    TimeTyping = dict()\n",
    "    \n",
    "    time1, t1, t2 = UserKeys[0][0].partition('+')\n",
    "    startTime = datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "    \n",
    "    time2, t1, t2 = UserKeys[-1][0].partition('+')\n",
    "    endTime = datetime.datetime.strptime(re.sub('[:.T]','-',time2[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "    \n",
    "    TimeTyping['startTime'] = startTime\n",
    "    TimeTyping['endTime'] = endTime\n",
    "    \n",
    "    return TimeTyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindTrialEndTimes(KeysSelected, timeTyping):\n",
    "    # function to find start and end of tasks in experiments\n",
    "    timeStartEnd = list() # format of this list will be: [startTime1, endTime1/startTime2, endTime2/startTime3, ..., endTimeN]\n",
    "    \n",
    "    timeStartEnd.append(timeTyping['startTime'])\n",
    "    \n",
    "    nTrial = 1\n",
    "    \n",
    "    for keys in KeysSelected:\n",
    "        \n",
    "        if keys[1] == 'NextPhrase':\n",
    "            time1, t1, t2 = keys[0].partition('+')\n",
    "            endTimeTrial = datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "            timeStartEnd.append(endTimeTrial)\n",
    "    \n",
    "    \n",
    "    timeStartEnd.append(timeTyping['endTime'])\n",
    "    \n",
    "    \n",
    "    return timeStartEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert list of date and time into datetime format list\n",
    "def timeConversion(timeStrList):\n",
    "    timeList = list()\n",
    "    for time in timeStrList:\n",
    "        time1, t1, t2 = time.partition('+')\n",
    "        timeList.append(datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\"))\n",
    "    return timeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will return the datetime in items which is the closest to the date pivot\n",
    "def nearestTimePoint(dates, date):\n",
    "    \n",
    "    for d in dates:\n",
    "        if d < date:\n",
    "            nearestTP = d\n",
    "        else:\n",
    "            continue\n",
    "    try: \n",
    "        nearestTP\n",
    "        nearestTPind = dates.index(nearestTP)\n",
    "    except:\n",
    "        nearestTP = 0\n",
    "        nearestTPind = -1\n",
    "        \n",
    "    return nearestTP, nearestTPind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateTimeEpochsOfTrials(TimeStartEndMixed, UserKeys):\n",
    "    # function to use list of mixed start and end times of trials and keys looked at by user to create trial epochs\n",
    "    \n",
    "    TimeEpochTrial = dict()\n",
    "    TimeEpochTrial['Start'] = list()\n",
    "    TimeEpochTrial['End'] = list()\n",
    "    \n",
    "    # Create list of times in userKeys to be able to use function 'nearestTimePoint'\n",
    "    UserKeysStrTimes = [item3[0] for item3 in UserKeys]\n",
    "    UserKeysTimes = timeConversion(UserKeysStrTimes)\n",
    "    \n",
    "    Flag_FoundSleepKey = 0 # Flag to indicate finding sleep key\n",
    "    \n",
    "    n = -1\n",
    "    for time in TimeStartEndMixed:\n",
    "        n = n + 1\n",
    "        Flag_FoundSleepKey = 0\n",
    "        \n",
    "        if n == 0: # first time is only start time for the first trial\n",
    "            TimeEpochTrial['Start'].append(time)\n",
    "            continue\n",
    "        elif n == len(TimeStartEndMixed)-1: # last time is only the end time for last trial\n",
    "            \n",
    "            TimeEpochTrial['End'].append(time)\n",
    "            \n",
    "        else: # the middle elements need to be divided into start and end\n",
    "            TimeEpochTrial['End'].append(time)\n",
    "            \n",
    "            timeCheck = time\n",
    "            \n",
    "            # find the time in userkeys. Keep going to the previous element till you reach start of selection of\n",
    "            # nextPhrase key\n",
    "            while Flag_FoundSleepKey < 1:\n",
    "                \n",
    "                nearestToTrialStartTime, nearestToTrialStartInd = nearestTimePoint(UserKeysTimes, timeCheck)\n",
    "                indCheck = nearestToTrialStartInd\n",
    "                \n",
    "                if 'NextPhrase' not in UserKeys[indCheck][1]:\n",
    "                    TimeEpochTrial['Start'].append(nearestToTrialStartTime)\n",
    "                    Flag_FoundSleepKey = 1\n",
    "                    break\n",
    "                else:\n",
    "                    indCheck = indCheck - 2 # 2 added instead of 1, to allow nearestTimePoint to find the one before this\n",
    "                    timeCheck = UserKeysTimes[indCheck]\n",
    "                    \n",
    "                \n",
    "    return TimeEpochTrial      \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DwellTimeForBaseline(UserKeys_wDwellTime):\n",
    "    \n",
    "    DwellTime = list()\n",
    "    \n",
    "    for key in UserKeys_wDwellTime:\n",
    "        if key[1] == 'NextPhrase':\n",
    "            #print('NextPhrase found at ', key[2])\n",
    "            if key[2] == 1:\n",
    "                DwellTime.append(key[3])\n",
    "                \n",
    "    return DwellTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Combine2ColumnsTo1GazeLog(GazeLog, Column_1, Column_2):\n",
    "    \n",
    "    JoinedList = list()\n",
    "    \n",
    "    Column_beforeDecimal = [item4[Column_1] if 'Invalid' not in item4 else 'nan' for item4 in GazeLog]\n",
    "    Column_afterDecimal = [item4[Column_2] if 'Invalid' not in item4 else 'nan' for item4 in GazeLog]\n",
    "    \n",
    "    \n",
    "    for i in range(0, len(Column_beforeDecimal)):\n",
    "        if 'Valid' not in Column_beforeDecimal[i] and 'Valid' not in Column_afterDecimal[i]:\n",
    "            if 'nan' not in Column_beforeDecimal[i] and 'nan' not in Column_afterDecimal[i]:\n",
    "                JoinedList.append(float(Column_beforeDecimal[i]+'.'+ Column_afterDecimal[i]))\n",
    "            else:\n",
    "                JoinedList.append(np.nan)\n",
    "        else:\n",
    "            # Rarely, the pupil size is a whole number\n",
    "            JoinedList.append(np.nan) # we will ignore the row, since there is no way of automatically knowing which - \n",
    "            # right or left eye has whole number pupil size\n",
    "            \n",
    "    return JoinedList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert2ColumnsToFormPupilSizes(GazeLog):\n",
    "    # function to convert pupilsizes from 2 columns for every pupil due to comma use instead of decimal, \n",
    "    # to proper pupil sizes\n",
    "    \n",
    "    PupilLogL = Combine2ColumnsTo1GazeLog(GazeLog, -5, -4)\n",
    "    PupilLogR = Combine2ColumnsTo1GazeLog(GazeLog, -2, -1)\n",
    "            \n",
    "    # if one of the pupils are nan, the other one is converted too\n",
    "    nPupil = -1\n",
    "    for pupilL in PupilLogL:\n",
    "        nPupil = nPupil + 1\n",
    "        if np.isnan(pupilL):\n",
    "            if nPupil < len(PupilLogR):\n",
    "                if not np.isnan(PupilLogR[nPupil]):\n",
    "                    PupilLogR[nPupil] = np.nan\n",
    "            else:\n",
    "                del PupilLogL[len(PupilLogR):]\n",
    "                \n",
    "    nPupil = -1\n",
    "    for pupilR in PupilLogR:\n",
    "        nPupil = nPupil + 1\n",
    "        if np.isnan(pupilR):\n",
    "            if nPupil < len(PupilLogL):\n",
    "                if not np.isnan(PupilLogL[nPupil]):\n",
    "                    PupilLogL[nPupil] = np.nan\n",
    "            else:\n",
    "                del PupilLogR[len(PupilLogL):]\n",
    "                \n",
    "    #print(len(PupilLogL), len(PupilLogR))\n",
    "    \n",
    "    return PupilLogL, PupilLogR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PupilSizeFromTrialTimes(TimeTrial, TimeGazeLog, TimeInternalGazeLog, PupilSizeLogL, PupilSizeLogR):\n",
    "    # find pupil sizes from the start and end time given\n",
    "    \n",
    "    # find start and end time in gazeLog\n",
    "    timeStart, timeStartInd = nearestTimePoint(TimeGazeLog, TimeTrial[0])\n",
    "    timeEnd, timeEndInd = nearestTimePoint(TimeGazeLog, TimeTrial[1])\n",
    "    \n",
    "    pupilSize_TrialL = PupilSizeLogL[timeStartInd: timeEndInd]\n",
    "    pupilSize_TrialR = PupilSizeLogR[timeStartInd: timeEndInd]\n",
    "    \n",
    "    TimeInternal_Trial = TimeInternalGazeLog[timeStartInd: timeEndInd]\n",
    "    \n",
    "    TimeGaze_Trial = TimeGazeLog[timeStartInd: timeEndInd]\n",
    "    \n",
    "    return pupilSize_TrialL, pupilSize_TrialR, TimeGaze_Trial, TimeInternal_Trial\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterBlinks(pupilData, timeListComplete):\n",
    "    # filter any blinks and nan values lasting around 250ms (on average)\n",
    "    # http://faculty.washington.edu/chudler/facts.html\n",
    "   \n",
    "    # blink is every nan value in the range of 100-400ms \n",
    "    # 250 ms (23 samples) before and after the blink will also be removed\n",
    "    extraBlinkSamples = 23    \n",
    "    \n",
    "    # remove single missing data, that are due to hardware error\n",
    "    missingVal_Single = np.argwhere(np.isnan(pupilData))\n",
    "    missingVal_Single = list(itertools.chain.from_iterable(missingVal_Single)) # flatten the list\n",
    "    missingVal_SingleDifference = [t - s for s, t in zip(missingVal_Single, missingVal_Single[1:])] # find difference \n",
    "    # between consecutive elements\n",
    "    missingVal_SingleDifference.insert(0, missingVal_Single[0]) # insert the first blink index in the beginning of list\n",
    "    \n",
    "    # the list missingVal_SingleDifference contains the index of the first blink, followed by the difference in the index to \n",
    "    # the next nan value\n",
    "    \n",
    "    # first remove the single nan values, which are missing data\n",
    "    eyeTracker_missingData = list() # list with index of single missing data  \n",
    "    valInd = -1\n",
    "\n",
    "    for val in missingVal_SingleDifference:\n",
    "        valInd = valInd + 1\n",
    "        if valInd == 0:\n",
    "            continue\n",
    "        if val != 1:\n",
    "            if missingVal_SingleDifference[valInd-1] !=1: # if there are 2 consecutive missing values (denoted by 2 consecutive\n",
    "                # non 1 numbers, they are added to the list of eyeTracker_missingData)\n",
    "                eyeTracker_missingData.append(sum(missingVal_SingleDifference[:valInd]))\n",
    "                \n",
    "    # remove single missing values from pupil data\n",
    "    pupilData_woSingleMissingData0 = [pupilData[ind] if ind not in eyeTracker_missingData else [] \n",
    "                                     for ind in range(0, len(pupilData))]\n",
    "    pupilData_woSingleMissingData = [x for x in pupilData_woSingleMissingData0 if x]\n",
    "    \n",
    "    # remove the times for single missing values in pupil data\n",
    "    timeList_woSingleMissingData0 = [timeListComplete[ind] if ind not in eyeTracker_missingData else [] \n",
    "                                     for ind in range(0, len(timeListComplete))]\n",
    "    timeList_woSingleMissingData = [x for x in timeList_woSingleMissingData0 if x]\n",
    "    \n",
    "#     print(len(timeList_woSingleMissingData))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # find the nan values again from pupilData_woSingleMissingData\n",
    "    missingVal_Rest = np.argwhere(np.isnan(pupilData_woSingleMissingData))\n",
    "    missingVal_Rest = list(itertools.chain.from_iterable(missingVal_Rest))\n",
    "    missingVal_RestDifference = [t - s for s, t in zip(missingVal_Rest, missingVal_Rest[1:])]\n",
    "    missingVal_RestDifference.insert(0, missingVal_Rest[0])\n",
    "    \n",
    "    \n",
    "    # compile and create list of start and end of blinks\n",
    "    blink_missingData = dict()\n",
    "    blink_missingData['Start'] = list()\n",
    "    blink_missingData['End'] = list()\n",
    "    \n",
    "    valInd = -1\n",
    "    for val in missingVal_RestDifference:\n",
    "        valInd = valInd + 1\n",
    "        if val > 1:\n",
    "            #print('value', val)\n",
    "            # instead of appending the actual index of blink start, since 250ms before and after the blink need to be\n",
    "            # removed, it is also appended here.\n",
    "            \n",
    "            # just make sure that the additional samples do not make the index of blink go in negative\n",
    "            if sum(missingVal_RestDifference[:valInd+1])-extraBlinkSamples > 0:\n",
    "                \n",
    "                blink_missingData['Start'].append(sum(missingVal_RestDifference[:valInd+1])-extraBlinkSamples)\n",
    "            else:\n",
    "                blink_missingData['Start'].append(0)\n",
    "            \n",
    "            if valInd == 0:\n",
    "                continue\n",
    "                \n",
    "            # make sure that the additional samples do not increase the index to more than the length of the pupilData\n",
    "            if sum(missingVal_RestDifference[:valInd])+extraBlinkSamples < len(pupilData_woSingleMissingData):\n",
    "                blink_missingData['End'].append(sum(missingVal_RestDifference[:valInd])+extraBlinkSamples)\n",
    "            else:\n",
    "                blink_missingData['End'].append(len(pupilData_woSingleMissingData)-1)\n",
    "            #print('end', sum(missingVal_RestDifference[:valInd]))\n",
    "      \n",
    "    # add the last blink index\n",
    "    # make sure that the additional samples do not increase the index to more than the length of the pupilData\n",
    "    if sum(missingVal_RestDifference)+extraBlinkSamples < len(pupilData_woSingleMissingData):\n",
    "        blink_missingData['End'].append(sum(missingVal_RestDifference)+extraBlinkSamples)\n",
    "    else:\n",
    "        blink_missingData['End'].append(len(pupilData_woSingleMissingData)-1)\n",
    "      \n",
    "    \n",
    "    # print start and end values\n",
    "    #for ind in range(0,len(blink_missingData['Start'])):\n",
    "    #    print(blink_missingData['Start'][ind]+23, blink_missingData['End'][ind]-23)\n",
    "        \n",
    "        \n",
    "        \n",
    "    # need to create a list containing indexes that are to be removed\n",
    "    blinkIndexList = list()\n",
    "    \n",
    "    #print(len(blink_missingData['Start']), len(blink_missingData['End']))\n",
    "    \n",
    "    \n",
    "    # remove blinks and additional data from pupil data to get filtered data\n",
    "    for indInd in range(0, len(blink_missingData['Start'])):\n",
    "        blinkIndexList.append(range(blink_missingData['Start'][indInd], blink_missingData['End'][indInd]+1))\n",
    "    # flatten the list\n",
    "    blinkIndexList = list(itertools.chain.from_iterable(blinkIndexList))\n",
    "    \n",
    "    \n",
    "    ##print(len(pupilData_woSingleMissingData))\n",
    "    \n",
    "    pupilData_woRestMissingData0 = [pupilData_woSingleMissingData[ind] if ind not in blinkIndexList else [] \n",
    "                                     for ind in range(0, len(pupilData_woSingleMissingData))]\n",
    "    #for i in enumerate(pupilData_woRestMissingData0):\n",
    "    #    print(i)\n",
    "    pupilData_filter = [x for x in pupilData_woRestMissingData0 if x]\n",
    "    \n",
    "    #for i in enumerate(pupilData_filter):\n",
    "    #    print(i)\n",
    "        \n",
    "    # remove the times for single missing values in pupil data\n",
    "    timeList_woRestMissingData0 = [timeList_woSingleMissingData[ind] if ind not in blinkIndexList else [] \n",
    "                                     for ind in range(0, len(timeList_woSingleMissingData))]\n",
    "    time_filter = [x for x in timeList_woRestMissingData0 if x]\n",
    "    \n",
    "    #print(len(pupilData_filter))\n",
    "        \n",
    "    if np.nan in pupilData_filter:\n",
    "        print('nan values still present in pupil data')\n",
    "        #for i in enumerate(pupilData_woSingleMissingData):\n",
    "        #    print(i)\n",
    "        \n",
    "    \n",
    "    return pupilData_filter, time_filter, blink_missingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hampel(vals_orig, k, sd):\n",
    "    '''\n",
    "    vals: pandas series of values from which to remove outliers\n",
    "    k: size of window (including the sample; 7 is equal to 3 on either side of value)\n",
    "    '''\n",
    "    # Obtained from: https://stackoverflow.com/questions/46819260/filtering-outliers-how-to-make-median-based-\n",
    "    # hampel-function-faster\n",
    "    \n",
    "    #plt.plot(vals_orig)\n",
    "    \n",
    "    #Make copy so original not edited\n",
    "    vals = pd.DataFrame(vals_orig)      \n",
    "    #print(vals.isnull().any())\n",
    "    vals0 = vals.replace([np.inf, -np.inf], np.nan)\n",
    "    #vals = vals0.astype(float).fillna(method = 'backfill') # linear interpolation instead \n",
    "    #print(vals)\n",
    "    vals = vals0.astype(float).interpolate('linear', limit_direction = 'both') # linear interpolation instead of \n",
    "    # simply copying the previous value --\\ linear interpolation than cubic to not add any patterns in the data, limit direction\n",
    "    # set to both, to interpolate the nan values occuring from the start of the series\n",
    "    \n",
    "    L= 1.4826\n",
    "    rolling_median = vals.rolling(window=k, min_periods=1, center=True).median()\n",
    "    \n",
    "    #print(rolling_median)\n",
    "    difference = np.abs(rolling_median-vals)\n",
    "    median_abs_deviation = difference.rolling(k).median()\n",
    "    threshold = sd * L * median_abs_deviation\n",
    "    outlier_idx = difference>threshold\n",
    "    vals[outlier_idx] = rolling_median[outlier_idx]\n",
    "    #print(vals)\n",
    "    #print('datatype', vals.dtypes)\n",
    "    #print(vals.isnull().any())\n",
    "    #vals.plot()\n",
    "    return(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPupilSize(pupilData, timeData, TrialNumber):\n",
    "    \n",
    "    dataLenEqualizer = min(min(len(pupilData['Left']), len(pupilData['Right'])), len(timeData))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.plot(timeData[0:dataLenEqualizer], pupilData['Left'][0:dataLenEqualizer], 'b')\n",
    "    ax.plot(timeData[0:dataLenEqualizer], pupilData['Right'][0:dataLenEqualizer], 'r')\n",
    "    \n",
    "    ax.set_ylabel('Relative pupil size [in mm]')\n",
    "\n",
    "    ax.set_title(TrialNumber)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindAndPlotPupilSizeForEpoch(GazeLog, TimeEpochTrial, DwellTimes_ForBaseline):\n",
    "    # function that uses the list of start and end trial times to find the pupil sizes for those trials and plots them\n",
    "    \n",
    "    # first create a list of times in gaze log\n",
    "    timeStrGazeLog = [item3[0] for item3 in GazeLog]\n",
    "    # convert the list of strings to datetime formats\n",
    "    timeGazeLog = timeConversion(timeStrGazeLog)\n",
    "    \n",
    "    # internal time, to depict seconds\n",
    "    timeInternalGazeLog = [float(item3[1]) for item3 in GazeLog]\n",
    "    \n",
    "    # extract pupil sizes in decimals from the strange 2 columns for every pupil\n",
    "    pupilLogL, pupilLogR = Convert2ColumnsToFormPupilSizes(GazeLog)\n",
    "    \n",
    "    pupilL_avg = list()\n",
    "    pupilR_avg = list()\n",
    "    timeOfGaze_TrialList = list()\n",
    "    pupil_AvgPartsList = list()\n",
    "    \n",
    "    # for every epoch, plot the pupil size\n",
    "    for trialNr in range(0, len(timeEpochTrial['Start'])):\n",
    "        if trialNr == 0:\n",
    "            continue\n",
    "        print(trialNr)\n",
    "        # find pupil sizes for the trial\n",
    "        pupilSizeL_Trial, pupilSizeR_Trial, timeGaze_Trial, timeInternal_Trial = PupilSizeFromTrialTimes(\n",
    "            [TimeEpochTrial['Start'][trialNr], TimeEpochTrial['End'][trialNr]], timeGazeLog, \n",
    "                                timeInternalGazeLog, pupilLogL, pupilLogR)\n",
    "        \n",
    "        pupilSize_Trial = dict()\n",
    "        pupilSize_Filter = dict()\n",
    "        pupilSize_woBlink = dict()\n",
    "        \n",
    "        # find difference in consecutive elements of internal time\n",
    "        timeInternalDifference = [t - s for s, t in zip(timeInternal_Trial, timeInternal_Trial[1:])]\n",
    "        # divide by 1000 to make it s\n",
    "        timeOfGaze_Trial = [sum(timeInternalDifference[:i])/1000000 for i in range(1,len(timeInternalDifference))]\n",
    "\n",
    "        # some trials were skipped, because the sentence was written before. If the time of trial is less than\n",
    "        # 10s, the trial is skipped\n",
    "        if timeOfGaze_Trial[-1] < 20:\n",
    "            print('trial number ', trialNr+1, 'with', timeOfGaze_Trial[-1], 's will be skipped')\n",
    "            continue\n",
    "        \n",
    "        pupilSize_Trial['Left'] = pupilSizeL_Trial\n",
    "        pupilSize_Trial['Right'] = pupilSizeR_Trial\n",
    "        \n",
    "        #if trialNr == 4:\n",
    "        #    for i in range(0, len(pupilSizeL_Trial)):\n",
    "        #        print(pupilSizeL_Trial[i], pupilSizeR_Trial[i])\n",
    "            \n",
    "        #print('Trial', len(pupilSizeL_Trial), len(pupilSizeR_Trial))\n",
    "        \n",
    "        # filter the blinks\n",
    "        pupilSizeL_woBlink, time_filter, missingPupilData = filterBlinks(\n",
    "            pupilSizeL_Trial, timeGaze_Trial)\n",
    "        \n",
    "        pupilSizeR_woBlink, time_filter, missingPupilData = filterBlinks(\n",
    "            pupilSizeR_Trial, timeGaze_Trial)\n",
    "        \n",
    "\n",
    "        \n",
    "        #print(index_blinkEndL)\n",
    "        #print(index_blinkEndR)\n",
    "        pupilSize_woBlink['Left'] = pupilSizeL_woBlink\n",
    "        pupilSize_woBlink['Right'] = pupilSizeR_woBlink\n",
    "        \n",
    "        #print('After blink', len(pupilSizeL_woBlink), len(pupilSizeR_woBlink))\n",
    "        # Hampel filter to remove the outliers\n",
    "        winSize = 25\n",
    "        pupilSizeL_filter = hampel(pupilSizeL_woBlink, winSize, 3)\n",
    "        pupilSizeR_filter = hampel(pupilSizeR_woBlink, winSize, 3)\n",
    "\n",
    "        pupilSize_Filter['Left'] = pupilSizeL_filter.values.tolist()\n",
    "        pupilSize_Filter['Right'] = pupilSizeR_filter.values.tolist()\n",
    "        \n",
    "        pupilSizeL_filterList = [i[0] for i in pupilSizeL_filter.values]\n",
    "        pupilSizeR_filterList = [i[0] for i in pupilSizeR_filter.values]\n",
    "        \n",
    "        #print('filter', len(pupilSizeL_filterList), len(pupilSizeR_filterList))\n",
    "        RLCorrelation = np.corrcoef(pupilSizeL_filterList, pupilSizeR_filterList)\n",
    "        \n",
    "        if RLCorrelation[0][1] < 0.8:\n",
    "            print(RLCorrelation[0][1])\n",
    "            print('CORRELATION BETWEEN RIGHT AND LEFT IS NOT GOOD. TRIAL MUST BE REMOVED')\n",
    "        \n",
    "        # Relative Pupil Size Calculation \n",
    "        # First find baseline pupil size, which is the time when looking at NextPhrase key\n",
    "        Samples_ForBaseline = int((int(DwellTimes_ForBaseline[trialNr-1][:-2])*90)/1000) # Number of samples of looking at key depend on\n",
    "        \n",
    "        #print(DwellTimes_ForBaseline[trialNr-1])\n",
    "        \n",
    "        # dwell time\n",
    "        pupilL_baseline = np.mean(pupilSizeL_filterList[0:Samples_ForBaseline])\n",
    "        pupilR_baseline = np.mean(pupilSizeR_filterList[0:Samples_ForBaseline])\n",
    "        \n",
    "        pupilL_Relative = [pupil - pupilL_baseline for pupil in pupilSizeL_filterList]\n",
    "        pupilR_Relative = [pupil - pupilR_baseline for pupil in pupilSizeR_filterList]\n",
    "        \n",
    "        \n",
    "        # Divide Trial into 4 parts\n",
    "        samplesInOneQuarter = int(len(pupilL_Relative)/4)\n",
    "        \n",
    "        pupilL_AvgPart1 = np.mean(pupilL_Relative[0:samplesInOneQuarter-1])\n",
    "        pupilL_AvgPart2 = np.mean(pupilL_Relative[samplesInOneQuarter:int(2*samplesInOneQuarter)-1])\n",
    "        pupilL_AvgPart3 = np.mean(pupilL_Relative[int(2*samplesInOneQuarter):int(3*samplesInOneQuarter)-1])\n",
    "        pupilL_AvgPart4 = np.mean(pupilL_Relative[int(3*samplesInOneQuarter):])\n",
    "        \n",
    "        pupilR_AvgPart1 = np.mean(pupilR_Relative[0:samplesInOneQuarter-1])\n",
    "        pupilR_AvgPart2 = np.mean(pupilR_Relative[samplesInOneQuarter:int(2*samplesInOneQuarter)-1])\n",
    "        pupilR_AvgPart3 = np.mean(pupilR_Relative[int(2*samplesInOneQuarter):int(3*samplesInOneQuarter)-1])\n",
    "        pupilR_AvgPart4 = np.mean(pupilR_Relative[int(3*samplesInOneQuarter):])\n",
    "        \n",
    "        pupilL_AvgParts = [pupilL_AvgPart1, pupilL_AvgPart2, pupilL_AvgPart3, pupilL_AvgPart4]\n",
    "        pupilR_AvgParts = [pupilR_AvgPart1, pupilR_AvgPart2, pupilR_AvgPart3, pupilR_AvgPart4]\n",
    "        \n",
    "        pupilAvg_AvgParts = [(pupilL_AvgParts[ind] + pupilR_AvgParts[ind])/2 for ind in range(0, len(pupilL_AvgParts))]\n",
    "        \n",
    "        pupilSize_Relative = dict()\n",
    "        pupilSize_Relative['Left'] = pupilL_Relative\n",
    "        pupilSize_Relative['Right'] = pupilR_Relative\n",
    "        \n",
    "        #plotPupilSize(pupilSize_Relative, timeOfGaze_Trial, trialNr)\n",
    "        \n",
    "        pupil_AvgPartsList.append(pupilAvg_AvgParts)\n",
    "        \n",
    "    return pupil_AvgPartsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sa\\Test_wChinRest\n",
      "1     7\n",
      "2     5\n",
      "3     9\n",
      "4     7\n",
      "5    12\n",
      "6    12\n",
      "7    10\n",
      "8     8\n",
      "9    11\n",
      "Name: Test_wChinRest_SumOfScores, dtype: int64\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "subjName = r'C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data'\n",
    "j = 0\n",
    "flagFirstSubj = 0\n",
    "pupilData = dict()\n",
    "pupilData['RLCorrelation'] = []\n",
    "\n",
    "\n",
    "# extract self-reported scores list and LIX score of given sentence\n",
    "file_name = r'C:/DTU/Data/201812_ExptToCheckMovementEffect/Data/Scores.xlsx'\n",
    "\n",
    "testNr = 'Test_wChinRest'\n",
    "for root, dirs, subfolder in os.walk(subjName):\n",
    "    if not dirs and testNr in root and 'sa' in root:\n",
    "        \n",
    "        if 'tb' in root or 'trial' in root:\n",
    "            continue\n",
    "            \n",
    "        userKeys = None\n",
    "        gazeLog = None\n",
    "        keysSelected = None\n",
    "        \n",
    "        for file in subfolder:\n",
    "            if fnmatch.fnmatch(file, 'user_looks*'):\n",
    "                try:\n",
    "                    \n",
    "                    fUserKey = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerUserKey = csv.reader(fUserKey)\n",
    "                    userKeys = list(readerUserKey)\n",
    "                    \n",
    "                    userKeys.remove(userKeys[0])\n",
    "                except:\n",
    "                    if fUserKey is not None:\n",
    "                        \n",
    "                        fUserKey.close()\n",
    "                    else:\n",
    "                        print('error in opening the user looks at log file')\n",
    "            \n",
    "            elif fnmatch.fnmatch(file, 'KeySelection*'):\n",
    "                try:\n",
    "                    \n",
    "                    fKeysSelected = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerKeysSelected = csv.reader(fKeysSelected)\n",
    "                    keysSelected = list(readerKeysSelected)\n",
    "                    \n",
    "                    keysSelected.remove(keysSelected[0])\n",
    "                except:\n",
    "                    if fKeysSelected is not None:\n",
    "                        \n",
    "                        fKeysSelected.close()\n",
    "                    else:\n",
    "                        print('error in opening the KeySelection log file')\n",
    "            \n",
    "            elif fnmatch.fnmatch(file, 'tobiiGazeLog*'):\n",
    "                try:\n",
    "                    fGazeLog = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerGazeLog = csv.reader(fGazeLog)\n",
    "                    gazeLog = list(readerGazeLog)\n",
    "                    \n",
    "                    gazeLog.remove(gazeLog[0]) # would not matter much even if the first row was not labels\n",
    "                    gazeLog.remove(gazeLog[-1])\n",
    "\n",
    "                except:\n",
    "                    if fGazeLog is not None:\n",
    "                        fGazeLog.close()\n",
    "                    else:\n",
    "                        print('error in opening the gaze log file')\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "                # if all these lists exist\n",
    "            if userKeys is None or keysSelected is None or gazeLog is None:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                a = re.compile('(?<=ExptToCheckMovementEffect\\\\\\\\Data\\\\\\\\)(.*)(?=\\\\\\\\2018-1)')\n",
    "                subjName = a.findall(root)[0]\n",
    "                print(subjName)\n",
    "                \n",
    "                if subjName == 'sa\\Test_woChinRest\\p2':\n",
    "                    userKeys = userKeys[:-1]\n",
    "                \n",
    "                sheet_to_df_map = pd.read_excel(file_name, sheet_name=subjName[0:2])\n",
    "                columnName = testNr + '_SumOfScores'\n",
    "                \n",
    "                # find total of difficulty score\n",
    "                scoresDifficulty = sheet_to_df_map[columnName]\n",
    "                scoresDifficulty = scoresDifficulty[1:]\n",
    "                \n",
    "                print(scoresDifficulty)\n",
    "                \n",
    "                # fix userKeys due to comma related file changes\n",
    "                userKeys_new = FixUserKeys(userKeys)\n",
    "                \n",
    "                # find dwell time of typing\n",
    "                userKeys_wDwellTime = ComputeDwellTime(userKeys_new)\n",
    "                \n",
    "                # find start time of typing\n",
    "                timeTyping = OptiKeyTypingTime(userKeys_wDwellTime)\n",
    "                \n",
    "                # for some of the subjects, the data was not completely collected\n",
    "                if subjName == 'sa\\Test_woChinRest\\p1' or subjName == 'rh\\Test_wChinRest\\p1':\n",
    "                    del keysSelected[-1]\n",
    "                \n",
    "                # divide complete data into epochs of phrases\n",
    "                timeStartEndMixed = FindTrialEndTimes(keysSelected, timeTyping)\n",
    "                \n",
    "                # create trial time epoch using the list of start/end times of trial and userKeys, to make sure that \n",
    "                # Sleep is completely there in every trial, to allow for baseline\n",
    "                timeEpochTrial = CreateTimeEpochsOfTrials(timeStartEndMixed, userKeys_wDwellTime)\n",
    "                #print(timeEpochTrial)\n",
    "                \n",
    "                dwellTimes_ForBaseline = DwellTimeForBaseline(userKeys_wDwellTime)\n",
    "                \n",
    "                # find and plot pupil size for every trial\n",
    "                pupilAvg_AvgPartsList = FindAndPlotPupilSizeForEpoch(gazeLog, timeEpochTrial, dwellTimes_ForBaseline)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                if 'sa\\Test_woChinRest' in subjName or 'rh\\Test_wChinRest' in subjName:\n",
    "                    if 'p1' in root:\n",
    "                        pupilAvg_AvgPartsList1 = pupilAvg_AvgPartsList\n",
    "                        \n",
    "                    else:\n",
    "                        if 'sa\\Test_woChinRest' in subjName:\n",
    "                            pupilAvg_AvgPartsList2 = pupilAvg_AvgPartsList[1:]\n",
    "                            \n",
    "\n",
    "                        else:\n",
    "                            pupilAvg_AvgPartsList2 = pupilAvg_AvgPartsList\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sa\\Test_woChinRest' in subjName or 'rh\\Test_wChinRest' in subjName:\n",
    "    print('Addition of lists')\n",
    "    pupilAvg_AvgPartsList = pupilAvg_AvgPartsList1 + pupilAvg_AvgPartsList2\n",
    "    \n",
    "\n",
    "pupil_Part1 = [item[0] for item in pupilAvg_AvgPartsList]\n",
    "pupil_Part2 = [item[1] for item in pupilAvg_AvgPartsList]\n",
    "pupil_Part3 = [item[2] for item in pupilAvg_AvgPartsList]\n",
    "pupil_Part4 = [item[3] for item in pupilAvg_AvgPartsList]\n",
    "    \n",
    "    \n",
    "pupil_Difficult_Part1 = list()\n",
    "pupil_Medium_Part1 = list()\n",
    "pupil_Easy_Part1 = list()\n",
    "\n",
    "pupil_Difficult_Part2 = list()\n",
    "pupil_Medium_Part2 = list()\n",
    "pupil_Easy_Part2 = list()\n",
    "\n",
    "pupil_Difficult_Part3 = list()\n",
    "pupil_Medium_Part3 = list()\n",
    "pupil_Easy_Part3 = list()\n",
    "\n",
    "pupil_Difficult_Part4 = list()\n",
    "pupil_Medium_Part4 = list()\n",
    "pupil_Easy_Part4 = list()\n",
    "\n",
    "\n",
    "for ind in range(0, len(scoresDifficulty)):\n",
    "    #print(scoresDifficulty.values[ind])\n",
    "    if scoresDifficulty.values[ind] > 12:\n",
    "        pupil_Difficult_Part1.append(pupil_Part1[ind])\n",
    "        pupilTotal_Difficult_Part1.append(pupil_Part1[ind])\n",
    "        pupil_Difficult_Part2.append(pupil_Part2[ind])\n",
    "        pupilTotal_Difficult_Part2.append(pupil_Part2[ind])\n",
    "        pupil_Difficult_Part3.append(pupil_Part3[ind])\n",
    "        pupilTotal_Difficult_Part3.append(pupil_Part3[ind])\n",
    "        pupil_Difficult_Part4.append(pupil_Part4[ind])\n",
    "        pupilTotal_Difficult_Part4.append(pupil_Part4[ind])\n",
    "        \n",
    "        \n",
    "    elif scoresDifficulty.values[ind] > 7:\n",
    "        pupil_Medium_Part1.append(pupil_Part1[ind])\n",
    "        pupilTotal_Medium_Part1.append(pupil_Part1[ind])\n",
    "        pupil_Medium_Part2.append(pupil_Part2[ind])\n",
    "        pupilTotal_Medium_Part2.append(pupil_Part2[ind])\n",
    "        pupil_Medium_Part3.append(pupil_Part3[ind])\n",
    "        pupilTotal_Medium_Part3.append(pupil_Part3[ind])\n",
    "        pupil_Medium_Part4.append(pupil_Part4[ind])\n",
    "        pupilTotal_Medium_Part4.append(pupil_Part4[ind])\n",
    "        \n",
    "    else:\n",
    "        pupil_Easy_Part1.append(pupil_Part1[ind])\n",
    "        pupilTotal_Easy_Part1.append(pupil_Part1[ind])\n",
    "        pupil_Easy_Part2.append(pupil_Part2[ind])\n",
    "        pupilTotal_Easy_Part2.append(pupil_Part2[ind])\n",
    "        pupil_Easy_Part3.append(pupil_Part3[ind])\n",
    "        pupilTotal_Easy_Part3.append(pupil_Part3[ind])\n",
    "        pupil_Easy_Part4.append(pupil_Part4[ind])\n",
    "        pupilTotal_Easy_Part4.append(pupil_Part4[ind])\n",
    "\n",
    "#fig = plt.figure()\n",
    "#ax = fig.add_subplot(1,1,1)\n",
    "#ax.plot(pupilAvg)\n",
    "#ax.plot(range(1,len(pupil_Difficult)+1), pupil_Difficult, 'r', marker = 'o', linestyle = '-', label = 'difficult')\n",
    "#ax.plot(range(1,len(pupil_Medium)+1), pupil_Medium, 'b', marker = 's', linestyle = '-', label = 'medium')\n",
    "#ax.plot(range(1,len(pupil_Easy)+1), pupil_Easy, 'c', marker = 'd', linestyle = '-', label = 'easy')\n",
    "\n",
    "\n",
    "#ax.plot(range(1,len(scoresDifficulty)+1), scoresDifficulty/100, 'b', label = 'difficulty')\n",
    "#ax.plot(range(1, len(timeOfTrialList)+1), timeOfTrialListPlot, 'c', label = 'time' )\n",
    "#ax.set_title(subjName)\n",
    "#ax.legend()\n",
    "             \n",
    "#print(ipaList)\n",
    "#print(scoresDifficulty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=0.5950996582177246, pvalue=0.5649994869607455)\n",
      "Ttest_indResult(statistic=2.016995595396921, pvalue=0.0713371592961708)\n",
      "Ttest_indResult(statistic=-0.41729265646520425, pvalue=0.6852817328789658)\n"
     ]
    }
   ],
   "source": [
    "print(stats.ttest_ind(pupilTotal_Difficult,pupilTotal_Medium))\n",
    "print(stats.ttest_ind(pupilTotal_Difficult,pupilTotal_Easy))\n",
    "print(stats.ttest_ind(pupilTotal_Easy,pupilTotal_Medium))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Ttest_indResult(statistic=-1.0696403057017287, pvalue=0.28921262865813135)\n",
      "2 Ttest_indResult(statistic=0.044449822205945996, pvalue=0.9647302539565396)\n",
      "3 Ttest_indResult(statistic=-1.231538985966445, pvalue=0.2223634647575932)\n",
      "4 Ttest_indResult(statistic=-0.8344306596878612, pvalue=0.4074620949781256)\n",
      "5 Ttest_indResult(statistic=-0.7562252867819801, pvalue=0.45320975139779984)\n",
      "6 Ttest_indResult(statistic=-0.09953408804485739, pvalue=0.921007079909333)\n",
      "7 Ttest_indResult(statistic=-0.28602804755113254, pvalue=0.7758757731750251)\n",
      "8 Ttest_indResult(statistic=-0.0825502957293609, pvalue=0.9345524139005935)\n",
      "9 Ttest_indResult(statistic=-0.2202583053584867, pvalue=0.826329925051366)\n",
      "10 Ttest_indResult(statistic=-1.2867630161383408, pvalue=0.20328908531097506)\n",
      "11 Ttest_indResult(statistic=-0.514082103706411, pvalue=0.609553346681668)\n",
      "12 Ttest_indResult(statistic=-0.792642396133211, pvalue=0.4307429990021252)\n",
      "13 Ttest_indResult(statistic=-0.2810237449585898, pvalue=0.7796922872358806)\n",
      "14 Ttest_indResult(statistic=0.6361930605370442, pvalue=0.5271532836115864)\n",
      "15 Ttest_indResult(statistic=1.4604670947925882, pvalue=0.149557822666253)\n",
      "16 Ttest_indResult(statistic=0.8263482842570116, pvalue=0.41199305694158184)\n",
      "17 Ttest_indResult(statistic=1.5621596622615077, pvalue=0.12369071447093646)\n",
      "18 Ttest_indResult(statistic=0.7195730032481025, pvalue=0.4746775410386206)\n",
      "19 Ttest_indResult(statistic=0.7516690000133944, pvalue=0.4545122610222725)\n",
      "20 Ttest_indResult(statistic=1.5528483300421143, pvalue=0.12450768572592708)\n",
      "21 Ttest_indResult(statistic=2.0024881136294046, pvalue=0.04870752196056943)\n",
      "22 Ttest_indResult(statistic=0.7534490253704612, pvalue=0.4534484429281649)\n",
      "23 Ttest_indResult(statistic=1.0849185288391054, pvalue=0.28129964721210854)\n",
      "24 Ttest_indResult(statistic=0.2614081627120062, pvalue=0.7944667791307837)\n",
      "25 Ttest_indResult(statistic=0.6501086383896083, pvalue=0.5195332636007923)\n",
      "26 Ttest_indResult(statistic=0.8190866062471611, pvalue=0.41784454982410113)\n",
      "27 Ttest_indResult(statistic=2.05519154005562, pvalue=0.04678106633913233)\n",
      "28 Ttest_indResult(statistic=0.17943709405808447, pvalue=0.8585478964688137)\n",
      "29 Ttest_indResult(statistic=1.4382802846972045, pvalue=0.1585400423840949)\n",
      "30 Ttest_indResult(statistic=1.2464659671262814, pvalue=0.22022268257149613)\n"
     ]
    }
   ],
   "source": [
    "#part1\n",
    "print('1', stats.ttest_ind(pupilTotal_Difficult_Part1,pupilTotal_Medium_Part1))\n",
    "print('2', stats.ttest_ind(pupilTotal_Difficult_Part1,pupilTotal_Easy_Part1))\n",
    "print('3', stats.ttest_ind(pupilTotal_Easy_Part1,pupilTotal_Medium_Part1))\n",
    "\n",
    "#part2\n",
    "print('4', stats.ttest_ind(pupilTotal_Difficult_Part2,pupilTotal_Medium_Part2))\n",
    "print('5', stats.ttest_ind(pupilTotal_Difficult_Part2,pupilTotal_Easy_Part2))\n",
    "print('6', stats.ttest_ind(pupilTotal_Easy_Part2,pupilTotal_Medium_Part2))\n",
    "\n",
    "#part3\n",
    "print('7', stats.ttest_ind(pupilTotal_Difficult_Part3,pupilTotal_Medium_Part3))\n",
    "print('8', stats.ttest_ind(pupilTotal_Difficult_Part3,pupilTotal_Easy_Part3))\n",
    "print('9', stats.ttest_ind(pupilTotal_Easy_Part3,pupilTotal_Medium_Part3))\n",
    "\n",
    "\n",
    "#part4\n",
    "print('10', stats.ttest_ind(pupilTotal_Difficult_Part4,pupilTotal_Medium_Part4))\n",
    "print('11', stats.ttest_ind(pupilTotal_Difficult_Part4,pupilTotal_Easy_Part4))\n",
    "print('12', stats.ttest_ind(pupilTotal_Easy_Part4,pupilTotal_Medium_Part4))\n",
    "\n",
    "\n",
    "# easy\n",
    "print('13', stats.ttest_ind(pupilTotal_Easy_Part1,pupilTotal_Easy_Part2))\n",
    "print('14', stats.ttest_ind(pupilTotal_Easy_Part1,pupilTotal_Easy_Part3))\n",
    "print('15', stats.ttest_ind(pupilTotal_Easy_Part1,pupilTotal_Easy_Part4))\n",
    "print('16', stats.ttest_ind(pupilTotal_Easy_Part2,pupilTotal_Easy_Part3))\n",
    "print('17', stats.ttest_ind(pupilTotal_Easy_Part2,pupilTotal_Easy_Part4))\n",
    "print('18', stats.ttest_ind(pupilTotal_Easy_Part3,pupilTotal_Easy_Part4))\n",
    "\n",
    "# medium\n",
    "print('19', stats.ttest_ind(pupilTotal_Medium_Part1,pupilTotal_Medium_Part2))\n",
    "print('20', stats.ttest_ind(pupilTotal_Medium_Part1,pupilTotal_Medium_Part3))\n",
    "print('21', stats.ttest_ind(pupilTotal_Medium_Part1,pupilTotal_Medium_Part4))\n",
    "print('22', stats.ttest_ind(pupilTotal_Medium_Part2,pupilTotal_Medium_Part3))\n",
    "print('23', stats.ttest_ind(pupilTotal_Medium_Part2,pupilTotal_Medium_Part4))\n",
    "print('24', stats.ttest_ind(pupilTotal_Medium_Part3,pupilTotal_Medium_Part4))\n",
    "\n",
    "\n",
    "# difficult\n",
    "print('25', stats.ttest_ind(pupilTotal_Difficult_Part1,pupilTotal_Difficult_Part2))\n",
    "print('26', stats.ttest_ind(pupilTotal_Difficult_Part1,pupilTotal_Difficult_Part3))\n",
    "print('27', stats.ttest_ind(pupilTotal_Difficult_Part1,pupilTotal_Difficult_Part4))\n",
    "print('28', stats.ttest_ind(pupilTotal_Difficult_Part2,pupilTotal_Difficult_Part3))\n",
    "print('29', stats.ttest_ind(pupilTotal_Difficult_Part2,pupilTotal_Difficult_Part4))\n",
    "print('30', stats.ttest_ind(pupilTotal_Difficult_Part3,pupilTotal_Difficult_Part4))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.2083060431552143 0.22390721948270248\n",
      "2 0.16124979254545543 0.22228326594993914\n",
      "3 0.14810910290462365 0.22910282270814505\n",
      "4 0.05275096774599053 0.24230720797797184\n",
      "1 0.29355221149267413 0.312614547340028\n",
      "2 0.2360379060074025 0.3613892679834723\n",
      "3 0.17407881649725532 0.3648729587345165\n",
      "4 0.15426326263088508 0.30160590284738154\n",
      "1 0.20503701312088835 0.26537754788858653\n",
      "2 0.22746305733573255 0.3380143060914249\n",
      "3 0.15521826799415114 0.3277270761050492\n",
      "4 0.09539992614635055 0.3049653570680041\n"
     ]
    }
   ],
   "source": [
    "print('1', np.mean(pupilTotal_Difficult_Part1), np.std(pupilTotal_Difficult_Part1))\n",
    "print('2', np.mean(pupilTotal_Difficult_Part2), np.std(pupilTotal_Difficult_Part2))\n",
    "print('3', np.mean(pupilTotal_Difficult_Part3), np.std(pupilTotal_Difficult_Part3))\n",
    "print('4', np.mean(pupilTotal_Difficult_Part4),np.std(pupilTotal_Difficult_Part4))\n",
    "\n",
    "print('1', np.mean(pupilTotal_Medium_Part1), np.std(pupilTotal_Medium_Part1))\n",
    "print('2', np.mean(pupilTotal_Medium_Part2), np.std(pupilTotal_Medium_Part2))\n",
    "print('3', np.mean(pupilTotal_Medium_Part3), np.std(pupilTotal_Medium_Part3))\n",
    "print('4', np.mean(pupilTotal_Medium_Part4),np.std(pupilTotal_Medium_Part4))\n",
    "\n",
    "\n",
    "print('1', np.mean(pupilTotal_Easy_Part1), np.std(pupilTotal_Easy_Part1))\n",
    "print('2', np.mean(pupilTotal_Easy_Part2), np.std(pupilTotal_Easy_Part2))\n",
    "print('3', np.mean(pupilTotal_Easy_Part3), np.std(pupilTotal_Easy_Part3))\n",
    "print('4', np.mean(pupilTotal_Easy_Part4),np.std(pupilTotal_Easy_Part4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2083060431552143 0.22390721948270248\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(pupilTotal_Difficult_Part1), np.std(pupilTotal_Difficult_Part1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x1aca3ec0208>,\n",
       "  <matplotlib.axis.XTick at 0x1aca3eb6550>,\n",
       "  <matplotlib.axis.XTick at 0x1aca3eb63c8>],\n",
       " <a list of 3 Text xticklabel objects>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pupilMean = [ np.mean(pupilTotal_Easy), np.mean(pupilTotal_Medium) , np.mean(pupilTotal_Difficult)]\n",
    "pupilStd = [ np.std(pupilTotal_Easy), np.std(pupilTotal_Medium) , np.std(pupilTotal_Difficult)]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.errorbar([1, 2, 3], pupilMean, pupilStd, marker = 'o', capsize=4)\n",
    "plt.xticks([1,2,3], ['Easy', 'Medium', 'Difficult'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pupilTotal_Difficult_Part1 = list()\n",
    "pupilTotal_Medium_Part1 = list()\n",
    "pupilTotal_Easy_Part1 = list()\n",
    "\n",
    "pupilTotal_Difficult_Part2 = list()\n",
    "pupilTotal_Medium_Part2 = list()\n",
    "pupilTotal_Easy_Part2 = list()\n",
    "\n",
    "pupilTotal_Difficult_Part3 = list()\n",
    "pupilTotal_Medium_Part3 = list()\n",
    "pupilTotal_Easy_Part3 = list()\n",
    "\n",
    "pupilTotal_Difficult_Part4 = list()\n",
    "pupilTotal_Medium_Part4 = list()\n",
    "pupilTotal_Easy_Part4 = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.22915668],\n",
       "       [0.22915668, 1.        ]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(pupilAvg, scoresDifficulty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresDifficultyPlot = [i/100 for i in scoresDifficulty]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "ax.plot(range(1,len(pupilAvg)+1), pupilR_Avg, 'b')\n",
    "\n",
    "ax.plot(range(1, len(scoresDifficulty)+1), scoresDifficultyPlot, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipaMean = [ np.mean(ipaEasy), np.mean(ipaMedium) , np.mean(ipaDifficult)]\n",
    "ipaStd = [ np.std(ipaEasy), np.std(ipaMedium) , np.std(ipaDifficult)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.errorbar([1, 2, 3], ipaMean, ipaStd, marker = 'o', capsize=4)\n",
    "ax.set_title(subjName)\n",
    "plt.xticks([1,2,3], ['Easy', 'Medium', 'Difficult'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ipaEasy), len(ipaMedium), len(ipaDifficult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Difficult', np.mean(ipaDifficult), np.std(ipaDifficult))\n",
    "print('Medium', np.mean(ipaMedium), np.std(ipaMedium))\n",
    "print('Easy', np.mean(ipaEasy), np.std(ipaEasy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.errorbar([1, 2, 3], ipaMean, ipaStd, marker = 'o', capsize=4)\n",
    "plt.xticks([1,2,3], ['Easy', 'Medium', 'Difficult'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5367295633713159, 0.17908971232473003]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pupil_Difficult_Part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
