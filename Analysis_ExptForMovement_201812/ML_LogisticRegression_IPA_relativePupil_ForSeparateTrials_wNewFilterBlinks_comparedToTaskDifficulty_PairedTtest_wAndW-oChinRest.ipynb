{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import csv\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pywt\n",
    "import itertools\n",
    "from scipy import stats\n",
    "\n",
    "pd.options.mode.use_inf_as_na = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeDwellOrig = 800\n",
    "TimeFixation = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipaDifficult = list()\n",
    "ipaMedium = list()\n",
    "ipaEasy = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FixUserKeys(UserKeys_Old):\n",
    "    # Fix the situation where comma has divided decimals into separate columns\n",
    "    \n",
    "    Column_beforeDecimal = [item[2] for item in UserKeys_Old]\n",
    "    Column_afterDecimal = [item[3] if len(item)>3 else '00' for item in UserKeys_Old]\n",
    "    \n",
    "    UserKeys_ProgressPercent = [float(Column_beforeDecimal[i]+'.'+ Column_afterDecimal[i]) for i in \n",
    "                                range(0, len(Column_beforeDecimal))]\n",
    "    UserKeys_Times = [item[0] for item in UserKeys_Old]\n",
    "    UserKeys_Keys = [item[1] for item in UserKeys_Old]\n",
    "    \n",
    "    UserKeys_New = [[UserKeys_Times[ind], UserKeys_Keys[ind], UserKeys_ProgressPercent[ind]] for ind in \n",
    "                    range(0, len(UserKeys_ProgressPercent))]\n",
    "    \n",
    "    #UserKeys_New = np.concatenate((UserKeys_Times, UserKeys_Keys, UserKeys_ProgressPercent), axis = 0)\n",
    "    \n",
    "    \n",
    "    return UserKeys_New\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeDwellTime(userKeys):\n",
    "    # modify userKeys to include a column of time instead of progress pct, which is dependent on the then dwell time\n",
    "    \n",
    "    timeDwell = TimeDwellOrig\n",
    "    nKey = -1\n",
    "    for key in userKeys:\n",
    "        nKey = nKey + 1\n",
    "        #print(key[1])\n",
    "        if key[1] == 'IncreaseDwellTime':\n",
    "            if float(key[2]) == 1:\n",
    "                timeDwell = timeDwell + 100\n",
    "        elif key[1] == 'DecreaseDwellTime':\n",
    "            #print(key[2])\n",
    "            if float(key[2]) == 1:\n",
    "                timeDwell = timeDwell - 100\n",
    "        else:\n",
    "            userKeys[nKey].append(str(float(key[2])*timeDwell))\n",
    "    \n",
    "    return userKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OptiKeyTypingTime(UserKeys):\n",
    "    \n",
    "    TimeTyping = dict()\n",
    "    \n",
    "    time1, t1, t2 = UserKeys[0][0].partition('+')\n",
    "    startTime = datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "    \n",
    "    time2, t1, t2 = UserKeys[-1][0].partition('+')\n",
    "    endTime = datetime.datetime.strptime(re.sub('[:.T]','-',time2[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "    \n",
    "    TimeTyping['startTime'] = startTime\n",
    "    TimeTyping['endTime'] = endTime\n",
    "    \n",
    "    return TimeTyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindTrialEndTimes(KeysSelected, timeTyping):\n",
    "    # function to find start and end of tasks in experiments\n",
    "    timeStartEnd = list() # format of this list will be: [startTime1, endTime1/startTime2, endTime2/startTime3, ..., endTimeN]\n",
    "    \n",
    "    timeStartEnd.append(timeTyping['startTime'])\n",
    "    \n",
    "    nTrial = 1\n",
    "    \n",
    "    for keys in KeysSelected:\n",
    "        \n",
    "        if keys[1] == 'NextPhrase':\n",
    "            time1, t1, t2 = keys[0].partition('+')\n",
    "            endTimeTrial = datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "            timeStartEnd.append(endTimeTrial)\n",
    "    \n",
    "    \n",
    "    timeStartEnd.append(timeTyping['endTime'])\n",
    "    \n",
    "    \n",
    "    return timeStartEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DwellTimeForBaseline(UserKeys_wDwellTime):\n",
    "    \n",
    "    DwellTime = list()\n",
    "    \n",
    "    for key in UserKeys_wDwellTime:\n",
    "        if key[1] == 'NextPhrase':\n",
    "            #print('NextPhrase found at ', key[2])\n",
    "            if key[2] == 1:\n",
    "                DwellTime.append(key[3])\n",
    "                \n",
    "    return DwellTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert list of date and time into datetime format list\n",
    "def timeConversion(timeStrList):\n",
    "    timeList = list()\n",
    "    for time in timeStrList:\n",
    "        time1, t1, t2 = time.partition('+')\n",
    "        timeList.append(datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\"))\n",
    "    return timeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will return the datetime in items which is the closest to the date pivot\n",
    "def nearestTimePoint(dates, date):\n",
    "    \n",
    "    for d in dates:\n",
    "        if d < date:\n",
    "            nearestTP = d\n",
    "        else:\n",
    "            continue\n",
    "    try: \n",
    "        nearestTP\n",
    "        nearestTPind = dates.index(nearestTP)\n",
    "    except:\n",
    "        nearestTP = 0\n",
    "        nearestTPind = -1\n",
    "        \n",
    "    return nearestTP, nearestTPind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateTimeEpochsOfTrials(TimeStartEndMixed, UserKeys):\n",
    "    # function to use list of mixed start and end times of trials and keys looked at by user to create trial epochs\n",
    "    \n",
    "    TimeEpochTrial = dict()\n",
    "    TimeEpochTrial['Start'] = list()\n",
    "    TimeEpochTrial['End'] = list()\n",
    "    \n",
    "    # Create list of times in userKeys to be able to use function 'nearestTimePoint'\n",
    "    UserKeysStrTimes = [item3[0] for item3 in UserKeys]\n",
    "    UserKeysTimes = timeConversion(UserKeysStrTimes)\n",
    "    \n",
    "    Flag_FoundSleepKey = 0 # Flag to indicate finding sleep key\n",
    "    \n",
    "    n = -1\n",
    "    for time in TimeStartEndMixed:\n",
    "        n = n + 1\n",
    "        Flag_FoundSleepKey = 0\n",
    "        \n",
    "        if n == 0: # first time is only start time for the first trial\n",
    "            TimeEpochTrial['Start'].append(time)\n",
    "            continue\n",
    "        elif n == len(TimeStartEndMixed)-1: # last time is only the end time for last trial\n",
    "            \n",
    "            TimeEpochTrial['End'].append(time)\n",
    "            \n",
    "        else: # the middle elements need to be divided into start and end\n",
    "            TimeEpochTrial['End'].append(time)\n",
    "            \n",
    "            timeCheck = time\n",
    "            \n",
    "            # find the time in userkeys. Keep going to the previous element till you reach start of selection of\n",
    "            # nextPhrase key\n",
    "            while Flag_FoundSleepKey < 1:\n",
    "                \n",
    "                nearestToTrialStartTime, nearestToTrialStartInd = nearestTimePoint(UserKeysTimes, timeCheck)\n",
    "                indCheck = nearestToTrialStartInd\n",
    "                \n",
    "                if 'NextPhrase' not in UserKeys[indCheck][1]:\n",
    "                    TimeEpochTrial['Start'].append(nearestToTrialStartTime)\n",
    "                    Flag_FoundSleepKey = 1\n",
    "                    break\n",
    "                else:\n",
    "                    indCheck = indCheck - 2 # 2 added instead of 1, to allow nearestTimePoint to find the one before this\n",
    "                    timeCheck = UserKeysTimes[indCheck]\n",
    "                    \n",
    "                \n",
    "    return TimeEpochTrial      \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert2ColumnSizesTo1(GazeLog):\n",
    "    # function to convert pupilsizes from 2 columns for every pupil due to comma use instead of decimal, \n",
    "    # to proper pupil sizes\n",
    "    \n",
    "    PupilLogL = list()\n",
    "    PupilLogR = list()\n",
    "    \n",
    "    PupilLogL_beforeDecimal = [item4[-5] if 'Invalid' not in item4 else 'nan' for item4 in GazeLog]\n",
    "    PupilLogL_afterDecimal = [item4[-4] if 'Invalid' not in item4 else 'nan' for item4 in GazeLog]\n",
    "    PupilLogR_beforeDecimal = [item4[-2] if 'Invalid' not in item4 else 'nan' for item4 in GazeLog]\n",
    "    PupilLogR_afterDecimal = [item4[-1] if 'Invalid' not in item4 else 'nan' for item4 in GazeLog]\n",
    "    \n",
    "    for i in range(0, len(PupilLogL_beforeDecimal)):\n",
    "        if 'Valid' not in PupilLogL_beforeDecimal[i] and 'Valid' not in PupilLogL_afterDecimal[i]:\n",
    "            if 'nan' not in PupilLogL_beforeDecimal[i] and 'nan' not in PupilLogL_afterDecimal[i]:\n",
    "                PupilLogL.append(float(PupilLogL_beforeDecimal[i]+'.'+PupilLogL_afterDecimal[i]))\n",
    "            else:\n",
    "                PupilLogL.append(np.nan)\n",
    "        else:\n",
    "            # Rarely, the pupil size is a whole number\n",
    "            PupilLogL.append(np.nan) # we will ignore the row, since there is no way of automatically knowing which - \n",
    "            # right or left eye has whole number pupil size\n",
    "    \n",
    "    for i in range(0, len(PupilLogR_beforeDecimal)):\n",
    "        if 'Valid' not in PupilLogR_beforeDecimal[i] and 'Valid' not in PupilLogR_afterDecimal[i]:\n",
    "            if 'nan' not in PupilLogR_beforeDecimal[i] and 'nan' not in PupilLogR_afterDecimal[i]:\n",
    "                PupilLogR.append(float(PupilLogR_beforeDecimal[i]+'.'+PupilLogR_afterDecimal[i]))\n",
    "            else:\n",
    "                PupilLogR.append(np.nan)\n",
    "        else:\n",
    "            # Rarely, the pupil size is a whole number\n",
    "            PupilLogL.append(np.nan) # we will ignore the row, since there is no way of automatically knowing which - \n",
    "            # right or left eye has whole number pupil size\n",
    "            \n",
    "    # if one of the pupils are nan, the other one is converted too\n",
    "    nPupil = -1\n",
    "    for pupilL in PupilLogL:\n",
    "        nPupil = nPupil + 1\n",
    "        if np.isnan(pupilL):\n",
    "            if nPupil < len(PupilLogR):\n",
    "                if not np.isnan(PupilLogR[nPupil]):\n",
    "                    PupilLogR[nPupil] = np.nan\n",
    "            else:\n",
    "                del PupilLogL[len(PupilLogR):]\n",
    "                \n",
    "    nPupil = -1\n",
    "    for pupilR in PupilLogR:\n",
    "        nPupil = nPupil + 1\n",
    "        if np.isnan(pupilR):\n",
    "            if nPupil < len(PupilLogL):\n",
    "                if not np.isnan(PupilLogL[nPupil]):\n",
    "                    PupilLogL[nPupil] = np.nan\n",
    "            else:\n",
    "                del PupilLogR[len(PupilLogL):]\n",
    "                \n",
    "    #print(len(PupilLogL), len(PupilLogR))\n",
    "    \n",
    "    return PupilLogL, PupilLogR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PupilSizeFromTrialTimes(TimeTrial, TimeGazeLog, TimeInternalGazeLog, PupilSizeLogL, PupilSizeLogR):\n",
    "    # find pupil sizes from the start and end time given\n",
    "    \n",
    "    # find start and end time in gazeLog\n",
    "    timeStart, timeStartInd = nearestTimePoint(TimeGazeLog, TimeTrial[0])\n",
    "    timeEnd, timeEndInd = nearestTimePoint(TimeGazeLog, TimeTrial[1])\n",
    "    \n",
    "    pupilSize_TrialL = PupilSizeLogL[timeStartInd: timeEndInd]\n",
    "    pupilSize_TrialR = PupilSizeLogR[timeStartInd: timeEndInd]\n",
    "    \n",
    "    TimeInternal_Trial = TimeInternalGazeLog[timeStartInd: timeEndInd]\n",
    "    \n",
    "    TimeGaze_Trial = TimeGazeLog[timeStartInd: timeEndInd]\n",
    "    \n",
    "    return pupilSize_TrialL, pupilSize_TrialR, TimeGaze_Trial, TimeInternal_Trial\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterBlinks(pupilData, timeInDatetime_trial, timeInS_Trial):\n",
    "    # filter any blinks and nan values lasting around 250ms (on average)\n",
    "    # http://faculty.washington.edu/chudler/facts.html\n",
    "   \n",
    "    # recording extra blink information - duration and frequency\n",
    "    blinkDurationList = list()\n",
    "    blinkTimeList = list()\n",
    "    blinkCount = 0\n",
    "    nonBlinkCount = 0\n",
    "    nonBlinkTimeList = list()\n",
    "    timeRemove = 0\n",
    "    \n",
    "    # blink is every nan value in the range of 100-400ms \n",
    "    # 250 ms (23 samples) before and after the blink will also be removed\n",
    "    extraBlinkSamples = 23    \n",
    "    \n",
    "    # remove single missing data, that are due to hardware error\n",
    "    missingVal_Single = np.argwhere(np.isnan(pupilData))\n",
    "    missingVal_Single = list(itertools.chain.from_iterable(missingVal_Single)) # flatten the list\n",
    "    missingVal_SingleDifference = [t - s for s, t in zip(missingVal_Single, missingVal_Single[1:])] # find difference \n",
    "    # between consecutive elements\n",
    "    missingVal_SingleDifference.insert(0, missingVal_Single[0]) # insert the first blink index in the beginning of list\n",
    "    \n",
    "    # the list missingVal_SingleDifference contains the index of the first blink, followed by the difference in the index to \n",
    "    # the next nan value\n",
    "    \n",
    "    # first remove the single nan values, which are missing data\n",
    "    eyeTracker_missingData = list() # list with index of single missing data  \n",
    "    valInd = -1\n",
    "\n",
    "    for val in missingVal_SingleDifference:\n",
    "        valInd = valInd + 1\n",
    "        if valInd == 0:\n",
    "            continue\n",
    "        if val != 1:\n",
    "            if missingVal_SingleDifference[valInd-1] !=1: # if there are 2 consecutive missing values (denoted by 2 consecutive\n",
    "                # non 1 numbers, they are added to the list of eyeTracker_missingData)\n",
    "                eyeTracker_missingData.append(sum(missingVal_SingleDifference[:valInd]))\n",
    "                \n",
    "    # remove single missing values from pupil data\n",
    "    pupilData_woSingleMissingData0 = [pupilData[ind] if ind not in eyeTracker_missingData else [] \n",
    "                                     for ind in range(0, len(pupilData))]\n",
    "    pupilData_woSingleMissingData = [x for x in pupilData_woSingleMissingData0 if x]\n",
    "    \n",
    "    # remove the times for single missing values in pupil data\n",
    "    timeList_woSingleMissingData0 = [timeInDatetime_trial[ind] if ind not in eyeTracker_missingData else [] \n",
    "                                     for ind in range(0, len(timeInDatetime_trial))]\n",
    "    timeList_woSingleMissingData = [x for x in timeList_woSingleMissingData0 if x]\n",
    "    \n",
    "#     print(len(timeList_woSingleMissingData))\n",
    "    \n",
    "    \n",
    "    timeInS_woSingleMissingData = timeInS_Trial[-1]-(len(timeList_woSingleMissingData)-len(timeInDatetime_trial))/90\n",
    "    #print(timeInS_woSingleMissingData, timeInS_Trial[-1])\n",
    "    \n",
    "    # find the nan values again from pupilData_woSingleMissingData\n",
    "    missingVal_Rest = np.argwhere(np.isnan(pupilData_woSingleMissingData))\n",
    "    missingVal_Rest = list(itertools.chain.from_iterable(missingVal_Rest))\n",
    "    missingVal_RestDifference = [t - s for s, t in zip(missingVal_Rest, missingVal_Rest[1:])]\n",
    "    missingVal_RestDifference.insert(0, missingVal_Rest[0])\n",
    "    #print(missingVal_RestDifference)\n",
    "    \n",
    "    # compile and create list of start and end of blinks\n",
    "    blink_missingData = dict()\n",
    "    blink_missingData['Start'] = list()\n",
    "    blink_missingData['End'] = list()\n",
    "    \n",
    "    valInd = -1\n",
    "    for val in missingVal_RestDifference:\n",
    "        valInd = valInd + 1\n",
    "        if val > 1:\n",
    "            \n",
    "            \n",
    "            #print('value', val)\n",
    "            # instead of appending the actual index of blink start, since 250ms before and after the blink need to be\n",
    "            # removed, it is also appended here.\n",
    "            \n",
    "            # just make sure that the additional samples do not make the index of blink go in negative\n",
    "            if sum(missingVal_RestDifference[:valInd+1])-extraBlinkSamples > 0:\n",
    "                \n",
    "                blink_missingData['Start'].append(sum(missingVal_RestDifference[:valInd+1])-extraBlinkSamples)\n",
    "            else:\n",
    "                blink_missingData['Start'].append(0)\n",
    "            \n",
    "            if valInd == 0:\n",
    "                lastBlinkStart = valInd\n",
    "                continue\n",
    "                \n",
    "            # append blink duration list\n",
    "            blinkDurationCurrent = valInd-lastBlinkStart\n",
    "            # if blink duration is greater than 1s, it is not considered to be blink anymore\n",
    "            if blinkDurationCurrent < 90: # since tobii sampling frequency is 90Hz\n",
    "                blinkCount = blinkCount + 1\n",
    "                blinkDurationList.append(blinkDurationCurrent/90)\n",
    "                blinkTimeList.append(timeList_woSingleMissingData[sum(missingVal_RestDifference[:valInd+1])])\n",
    "                lastBlinkStart = valInd\n",
    "            else:\n",
    "                # collect the time of non-blinks, that will need to be removed from trial time, to calculate \n",
    "                # blink frequency\n",
    "                #print('current blink duration', valInd, lastBlinkStart, blinkDurationCurrent)\n",
    "                timeRemove = timeRemove + blinkDurationCurrent\n",
    "                nonBlinkCount = nonBlinkCount + 1\n",
    "                nonBlinkTimeList.append(timeList_woSingleMissingData[sum(missingVal_RestDifference[:valInd+1])])\n",
    "                lastBlinkStart = valInd\n",
    "            \n",
    "            # make sure that the additional samples do not increase the index to more than the length of the pupilData\n",
    "            if sum(missingVal_RestDifference[:valInd])+extraBlinkSamples < len(pupilData_woSingleMissingData):\n",
    "                blink_missingData['End'].append(sum(missingVal_RestDifference[:valInd])+extraBlinkSamples)\n",
    "            else:\n",
    "                blink_missingData['End'].append(len(pupilData_woSingleMissingData)-1)\n",
    "#         else:\n",
    "#             # val is 1\n",
    "#             if valInd-2 > 0 and valInd+3 < len(missingVal_RestDifference):\n",
    "#                 if missingVal_RestDifference[valInd-1] > 1:\n",
    "#                     if missingVal_RestDifference[valInd+1] == 1:\n",
    "#                         if missingVal_RestDifference[valInd+2] > 1:\n",
    "#                             print(timeList_woSingleMissingData[sum(missingVal_RestDifference[:valInd+1])], \n",
    "#                                 missingVal_RestDifference[valInd-2:valInd+3])\n",
    "#                             if missingVal_RestDifference[valInd+2] > missingVal_RestDifference[valInd-1]:\n",
    "#                                 if valInd-6>0:\n",
    "#                                     print(missingVal_RestDifference[valInd-6:valInd+3])\n",
    "#                     elif missingVal_RestDifference[valInd+1] > 1:\n",
    "#                         print(timeList_woSingleMissingData[sum(missingVal_RestDifference[:valInd+1])], \n",
    "#                               missingVal_RestDifference[valInd-2:valInd+3])\n",
    "#                         if missingVal_RestDifference[valInd+2] > missingVal_RestDifference[valInd-1]:\n",
    "#                                 if valInd-6>0:\n",
    "#                                     print(missingVal_RestDifference[valInd-6:valInd+3])\n",
    "                        \n",
    "                        \n",
    "    # add the last blink index\n",
    "    # make sure that the additional samples do not increase the index to more than the length of the pupilData\n",
    "    if sum(missingVal_RestDifference)+extraBlinkSamples < len(pupilData_woSingleMissingData):\n",
    "        blink_missingData['End'].append(sum(missingVal_RestDifference)+extraBlinkSamples)\n",
    "    else:\n",
    "        blink_missingData['End'].append(len(pupilData_woSingleMissingData)-1)\n",
    "                \n",
    "    # need to create a list containing indexes that are to be removed\n",
    "    blinkIndexList = list()\n",
    "    \n",
    "#     print(len(blink_missingData['Start']), len(blink_missingData['End']))\n",
    "    \n",
    "    # remove blinks and additional data from pupil data to get filtered data\n",
    "    for indInd in range(0, len(blink_missingData['Start'])):\n",
    "        blinkIndexList.append(range(blink_missingData['Start'][indInd], blink_missingData['End'][indInd]+1))\n",
    "    # flatten the list\n",
    "    blinkIndexList = list(itertools.chain.from_iterable(blinkIndexList))\n",
    "    \n",
    "    pupilData_woRestMissingData0 = [pupilData_woSingleMissingData[ind] if ind not in blinkIndexList else [] \n",
    "                                     for ind in range(0, len(pupilData_woSingleMissingData))]\n",
    "    pupilData_filter = [x for x in pupilData_woRestMissingData0 if x]\n",
    "    \n",
    "    # remove the times for single missing values in pupil data\n",
    "    timeList_woRestMissingData0 = [timeList_woSingleMissingData[ind] if ind not in blinkIndexList else [] \n",
    "                                     for ind in range(0, len(timeList_woSingleMissingData))]\n",
    "    time_filter = [x for x in timeList_woRestMissingData0 if x]\n",
    "    \n",
    "    timeInS_Trial_filter = timeInS_woSingleMissingData-timeRemove/90\n",
    "    \n",
    "    blinkFrequency = blinkCount/timeInS_Trial_filter\n",
    "    #print('freq', blinkFrequency, timeInS_woSingleMissingData, timeRemove)\n",
    "    #print('time difference', len(timeInDatetime_trial), len(time_filter))\n",
    "    if np.nan in pupilData_filter:\n",
    "        print('nan values in filtered data')\n",
    "#         for i in enumerate(pupilData_filter):\n",
    "#             print(i)\n",
    "        \n",
    "    #print(nonBlinkCount, blinkCount, nonBlinkTimeList)\n",
    "    return pupilData_filter, time_filter, blink_missingData, blinkDurationList, blinkFrequency, blinkTimeList, timeInS_Trial_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modmax(d):\n",
    "    # modulus maxima detection\n",
    "    \n",
    "    # compute signal modulus\n",
    "    m = [0.0]*len(d)\n",
    "    for i in range(0, len(d)):\n",
    "        m[i] = math.fabs(d[i])\n",
    "    \n",
    "    # if value is larger than both neighbours , and strictly\n",
    "    # larger than either , then it is a local maximum\n",
    "    t = [0.0]*len(d)\n",
    "    for i in range(0, len(d)):\n",
    "        ll = m[i-1] if i >= 1 else m[i]\n",
    "        oo = m[i]\n",
    "        rr = m[i+1] if i < len(d)-2 else m[i]\n",
    "        if (ll <= oo and oo >= rr) and (ll < oo or oo > rr):\n",
    "            # compute magnitude\n",
    "            t[i] = math.sqrt(d[i]**2)\n",
    "        else:\n",
    "            t[i] = 0.0\n",
    "    #print(len(t))\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPupilSize(pupilData, timeData, TrialNumber):\n",
    "    \n",
    "    dataLenEqualizer = min(min(len(pupilData['Left']), len(pupilData['Right'])), len(timeData))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.plot(timeData[0:dataLenEqualizer], pupilData['Left'][0:dataLenEqualizer], 'b')\n",
    "    ax.plot(timeData[0:dataLenEqualizer], pupilData['Right'][0:dataLenEqualizer], 'r')\n",
    "    \n",
    "    ax.set_ylabel('Absolute pupil size [in mm]')\n",
    "\n",
    "    ax.set_title(TrialNumber)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hampel(vals_orig, k, sd):\n",
    "    '''\n",
    "    vals: pandas series of values from which to remove outliers\n",
    "    k: size of window (including the sample; 7 is equal to 3 on either side of value)\n",
    "    '''\n",
    "    # Obtained from: https://stackoverflow.com/questions/46819260/filtering-outliers-how-to-make-median-based-\n",
    "    # hampel-function-faster\n",
    "    \n",
    "    #plt.plot(vals_orig)\n",
    "    \n",
    "    #Make copy so original not edited\n",
    "    vals = pd.DataFrame(vals_orig)      \n",
    "    #print(vals.isnull().any())\n",
    "    vals0 = vals.replace([np.inf, -np.inf], np.nan)\n",
    "    #vals = vals0.astype(float).fillna(method = 'backfill') # linear interpolation instead \n",
    "    #print(vals)\n",
    "    vals = vals0.astype(float).interpolate('linear', limit_direction = 'both') # linear interpolation instead of \n",
    "    # simply copying the previous value --\\ linear interpolation than cubic to not add any patterns in the data, limit direction\n",
    "    # set to both, to interpolate the nan values occuring from the start of the series\n",
    "    \n",
    "    L= 1.4826\n",
    "    rolling_median = vals.rolling(window=k, min_periods=1, center=True).median()\n",
    "    \n",
    "    #print(rolling_median)\n",
    "    difference = np.abs(rolling_median-vals)\n",
    "    median_abs_deviation = difference.rolling(k).median()\n",
    "    threshold = sd * L * median_abs_deviation\n",
    "    outlier_idx = difference>threshold\n",
    "    vals[outlier_idx] = rolling_median[outlier_idx]\n",
    "    #print(vals)\n",
    "    #print('datatype', vals.dtypes)\n",
    "    #print(vals.isnull().any())\n",
    "    #vals.plot()\n",
    "    return(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipaFunc(d):\n",
    "    # compute ipa value of pupil diameter\n",
    "    IPA = list()\n",
    "    #print(len(d.pupildata.values))\n",
    "    # obtain 2-level DWT of pupil diameter signal d\n",
    "    \n",
    "    # get signal duration (in seconds)\n",
    "    tt = ((d.timestamp.values[-1] - d.timestamp.values[0]).item())/1000000000\n",
    "\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        (cA2,cD2,cD1) = pywt.wavedec(d.pupildata.values,'sym12','symmetric', 2)\n",
    "    except ValueError:\n",
    "        print('value error in wavedec')\n",
    "        return\n",
    "        \n",
    "    # normalize by 1=2j , j = 2 for 2-level DWT\n",
    "    cA2[:] = [x / math.sqrt(4.0) for x in cA2]\n",
    "    cD1[:] = [x / math.sqrt(2.0) for x in cD1]\n",
    "    cD2[:] = [x / math.sqrt(4.0) for x in cD2]\n",
    "    \n",
    "    # detect modulus maxima , see Listing 2\n",
    "    cD2m = modmax(cD2)\n",
    "    #print(len(cD2m))\n",
    "    \n",
    "    # threshold using universal threshold l_univ = s*sqrt(2logn)\n",
    "    # where s is the standard deviation of the noise\n",
    "    luniv = np.std(cD2m) * math.sqrt(2.0*np.log2(len(cD2m)))\n",
    "    cD2t = pywt.threshold(cD2m ,luniv,mode=\"hard\")\n",
    "        \n",
    "    # compute IPA\n",
    "    ctr = 0\n",
    "    for i in range(0, len(cD2t)):\n",
    "        if math.fabs(cD2t[i]) > 0: ctr += 1\n",
    "        #IPA = float(ctr)/tt\n",
    "        # maybe each pupil data has an IPA?\n",
    "    IPA = (float(ctr)/tt)\n",
    "    \n",
    "    return IPA, cD2m, cD2t, cD2, cD1, cA2, tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindAndPlotPupilSizeForEpoch(GazeLog, TimeEpochTrial, ScoresDifficulty, DwellTimes_ForBaseline):\n",
    "    # function that uses the list of start and end trial times to find the pupil sizes for those trials and plots them\n",
    "    \n",
    "    # first create a list of times in gaze log\n",
    "    timeStrGazeLog = [item3[0] for item3 in GazeLog]\n",
    "    # convert the list of strings to datetime formats\n",
    "    timeGazeLog = timeConversion(timeStrGazeLog)\n",
    "    \n",
    "    # internal time, to depict seconds\n",
    "    timeInternalGazeLog = [float(item3[1]) for item3 in GazeLog]\n",
    "    \n",
    "    # extract pupil sizes in decimals from the strange 2 columns for every pupil\n",
    "    pupilLogL, pupilLogR = Convert2ColumnSizesTo1(GazeLog)\n",
    "    \n",
    "    ipaList = list()\n",
    "    timeOfGaze_TrialList = list()\n",
    "    \n",
    "    \n",
    "    blinkDurationList = list()\n",
    "    blinkDurationAverageList = list()\n",
    "    blinkTimeList = list()\n",
    "    blinkFrequencyList = list()\n",
    "    timeInS_List = list()\n",
    "    pupilMean = list()\n",
    "    \n",
    "    # for every epoch, plot the pupil size\n",
    "    for trialNr in range(0, len(timeEpochTrial['Start'])):\n",
    "        if trialNr == 0:\n",
    "            continue\n",
    "        # find pupil sizes for the trial\n",
    "        pupilSizeL_Trial, pupilSizeR_Trial, timeGaze_Trial, timeInternal_Trial = PupilSizeFromTrialTimes(\n",
    "            [TimeEpochTrial['Start'][trialNr], TimeEpochTrial['End'][trialNr]], timeGazeLog, \n",
    "                                timeInternalGazeLog, pupilLogL, pupilLogR)\n",
    "        \n",
    "        pupilSize_Trial = dict()\n",
    "        pupilSize_Filter = dict()\n",
    "        pupilSize_woBlink = dict()\n",
    "        \n",
    "        # find difference in consecutive elements of internal time\n",
    "        timeInternalDifference = [t - s for s, t in zip(timeInternal_Trial, timeInternal_Trial[1:])]\n",
    "        # divide by 1000 to make it s\n",
    "        timeOfGaze_Trial = [sum(timeInternalDifference[:i])/1000000 for i in range(1,len(timeInternalDifference))]\n",
    "\n",
    "        # some trials were skipped, because the sentence was written before. If the time of trial is less than\n",
    "        # 10s, the trial is skipped\n",
    "        if timeOfGaze_Trial[-1] < 20:\n",
    "            print('trial number ', trialNr+1, 'with', timeOfGaze_Trial[-1], 's will be skipped')\n",
    "            continue\n",
    "        \n",
    "        pupilSize_Trial['Left'] = pupilSizeL_Trial\n",
    "        pupilSize_Trial['Right'] = pupilSizeR_Trial\n",
    "        \n",
    "        #if trialNr == 4:\n",
    "        #    for i in range(0, len(pupilSizeL_Trial)):\n",
    "        #        print(pupilSizeL_Trial[i], pupilSizeR_Trial[i])\n",
    "            \n",
    "        #print('Trial', len(pupilSizeL_Trial), len(pupilSizeR_Trial))\n",
    "        \n",
    "        # filter the blinks\n",
    "        pupilSizeL_woBlink, time_filter, missingPupilData, blinkDuration, blinkFrequency, blinkTimeList, timeInS_filter = filterBlinks(pupilSizeL_Trial, timeGaze_Trial, timeOfGaze_Trial)\n",
    "        pupilSizeR_woBlink, time_filter, missingPupilData, blinkDuration, blinkFrequency, blinkTimeList, timeInS_filter = filterBlinks(pupilSizeR_Trial, timeGaze_Trial, timeOfGaze_Trial)\n",
    "        \n",
    "#         print(trialNr, blinkFrequency)\n",
    "        #print(trialNr, blinkDuration)\n",
    "\n",
    "        # time of trial\n",
    "        timeInS_List.append(timeInS_filter)\n",
    "        #print(trialNr, timeInS_filter)\n",
    "        \n",
    "        #print(index_blinkEndL)\n",
    "        #print(index_blinkEndR)\n",
    "        pupilSize_woBlink['Left'] = pupilSizeL_woBlink\n",
    "        pupilSize_woBlink['Right'] = pupilSizeR_woBlink\n",
    "        \n",
    "        #print('After blink', len(pupilSizeL_woBlink), len(pupilSizeR_woBlink))\n",
    "        # Hampel filter to remove the outliers\n",
    "        winSize = 25\n",
    "        pupilSizeL_filter = hampel(pupilSizeL_woBlink, winSize, 3)\n",
    "        pupilSizeR_filter = hampel(pupilSizeR_woBlink, winSize, 3)\n",
    "\n",
    "        pupilSize_Filter['Left'] = pupilSizeL_filter.values.tolist()\n",
    "        pupilSize_Filter['Right'] = pupilSizeR_filter.values.tolist()\n",
    "        \n",
    "        pupilSizeL_filterList = [i[0] for i in pupilSizeL_filter.values]\n",
    "        pupilSizeR_filterList = [i[0] for i in pupilSizeR_filter.values]\n",
    "        \n",
    "        #print('filter', len(pupilSizeL_filterList), len(pupilSizeR_filterList))\n",
    "        RLCorrelation = np.corrcoef(pupilSizeL_filterList, pupilSizeR_filterList)\n",
    "        #print(RLCorrelation)\n",
    "        \n",
    "        pupilAvg = [((pupilSizeL_filterList[i] + pupilSizeR_filterList[i])/2) for i in range(0, min(len(pupilSizeL_filterList), len(pupilSizeR_filterList)))]\n",
    "        \n",
    "        # First find baseline pupil size, which is the time when looking at NextPhrase key\n",
    "        Samples_ForBaseline = int((int(DwellTimes_ForBaseline[trialNr-1][:-2])*90)/1000)+int((TimeFixation*900)/1000) # Number of samples of looking at key depend on\n",
    "        \n",
    "        #print(DwellTimes_ForBaseline[trialNr-1])\n",
    "        \n",
    "        # dwell time\n",
    "        pupilL_baseline = np.mean(pupilSizeL_filterList[0:Samples_ForBaseline])\n",
    "        pupilR_baseline = np.mean(pupilSizeR_filterList[0:Samples_ForBaseline])\n",
    "        \n",
    "        pupilL_Relative = [pupil - pupilL_baseline for pupil in pupilSizeL_filterList]\n",
    "        pupilR_Relative = [pupil - pupilR_baseline for pupil in pupilSizeR_filterList]\n",
    "        \n",
    "        pupilRelativeAvg = [((pupilL_Relative[i] + pupilR_Relative[i])/2) for i in range(0, min(len(pupilL_Relative), len(pupilR_Relative)))]\n",
    "        \n",
    "        \n",
    "        pupilLog_filter_wTime_Tuple = list(zip(time_filter, pupilAvg))\n",
    "        pupilAndTimeDf =  pd.DataFrame(pupilLog_filter_wTime_Tuple, columns=['timestamp','pupildata'])\n",
    "        \n",
    "        # compute IPA for the trial\n",
    "        ipaVal, coeff_modmax, coeff_hard, coeff_D2, coeff_D1, coeff_A, timePeriodTrial = ipaFunc(pupilAndTimeDf)\n",
    "        \n",
    "        #print(trialNr+1, ipaVal, timeOfGaze_Trial[-1])\n",
    "        \n",
    "        ipaList.append(ipaVal)\n",
    "        timeOfGaze_TrialList.append(timeOfGaze_Trial[-1])\n",
    "        \n",
    "        \n",
    "        blinkDurationList.append(blinkDuration)\n",
    "        blinkFrequencyList.append(blinkFrequency)\n",
    "        \n",
    "        \n",
    "        if len(blinkDuration)>0:\n",
    "            blinkDurationAverageList.append(np.mean(blinkDuration))\n",
    "        else:\n",
    "            blinkDurationAverageList.append(0)\n",
    "         \n",
    "        pupilMean.append(np.mean(pupilRelativeAvg))\n",
    "        \n",
    "    return ipaList, pupilMean, timeOfGaze_TrialList, blinkDurationList, blinkDurationAverageList, blinkFrequencyList, timeInS_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject bh\\Test_wChinRest\n",
      "Test_wChinRest\n",
      "trial number  11 with 4.596693 s will be skipped\n",
      "subject bh\\Test_woChinRest\n",
      "Test_woChinRest\n",
      "trial number  11 with 7.339166 s will be skipped\n",
      "subject ph\\Test_wChinRest\n",
      "Test_wChinRest\n",
      "trial number  11 with 18.00399 s will be skipped\n",
      "subject ph\\Test_woChinRest\n",
      "Test_woChinRest\n",
      "subject pt\\Test_wChinRest\n",
      "Test_wChinRest\n",
      "subject pt\\Test_woChinRest\n",
      "Test_woChinRest\n",
      "trial number  11 with 17.47867 s will be skipped\n",
      "subject rh\\Test_wChinRest\\p1\n",
      "Test_wChinRest\n",
      "subject rh\\Test_wChinRest\\p2\n",
      "Test_wChinRest\n",
      "trial number  4 with 10.770031 s will be skipped\n",
      "trial number  10 with 14.989218 s will be skipped\n",
      "subject rh\\Test_woChinRest\n",
      "Test_woChinRest\n",
      "trial number  11 with 10.476645 s will be skipped\n",
      "subject sa\\Test_wChinRest\n",
      "Test_wChinRest\n",
      "subject sa\\Test_woChinRest\\p1\n",
      "Test_woChinRest\n",
      "subject sa\\Test_woChinRest\\p2\n",
      "Test_woChinRest\n",
      "trial number  3 with 8.449478 s will be skipped\n",
      "trial number  5 with 8.926912 s will be skipped\n"
     ]
    }
   ],
   "source": [
    "blink_wChinRestFrequency = list()\n",
    "blink_wChinRestDurationAverage = list()\n",
    "\n",
    "time_wChinRestTrial = list()\n",
    "blink_wChinRestDuration = list()\n",
    "ipa_wChinRest = list()\n",
    "pupilMean_wChinRest = list()\n",
    "\n",
    "score_wChinRestLIX = list()\n",
    "score_wChinRestComplexity = list()\n",
    "score_wChinRestDifficulty = list()\n",
    "score_wChinRestSumOfScores = list()\n",
    "score_wChinRestAfinn = list()\n",
    "\n",
    "blink_woChinRestFrequency = list()\n",
    "blink_woChinRestDurationAverage = list()\n",
    "\n",
    "time_woChinRestTrial = list()\n",
    "blink_woChinRestDuration = list()\n",
    "ipa_woChinRest = list()\n",
    "pupilMean_woChinRest = list()\n",
    "\n",
    "score_woChinRestLIX = list()\n",
    "score_woChinRestComplexity = list()\n",
    "score_woChinRestDifficulty = list()\n",
    "score_woChinRestSumOfScores = list()\n",
    "score_woChinRestAfinn = list()\n",
    "\n",
    "subjName = r'C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data'\n",
    "j = 0\n",
    "flagFirstSubj = 0\n",
    "pupilData = dict()\n",
    "pupilData['RLCorrelation'] = []\n",
    "\n",
    "# extract self-reported scores list and LIX score of given sentence\n",
    "file_name = r'C:/DTU/Data/201812_ExptToCheckMovementEffect/Data/Scores.xlsx'\n",
    "\n",
    "\n",
    "#testNr = 'Test_wChinRest'\n",
    "for root, dirs, subfolder in os.walk(subjName):\n",
    "    scoreDifficult = list()\n",
    "    scoreMedium = list()\n",
    "    scoreEasy = list()\n",
    "    # Semantic modeling score from afinn\n",
    "    afinnDifficult = list()\n",
    "    afinnMedium = list()\n",
    "    afinnEasy = list()\n",
    "\n",
    "    if not dirs:\n",
    "        \n",
    "        if 'tb' in root or 'trial' in root:\n",
    "            continue\n",
    "            \n",
    "        userKeys = None\n",
    "        gazeLog = None\n",
    "        keysSelected = None\n",
    "        \n",
    "       \n",
    "        \n",
    "        for file in subfolder:\n",
    "            if fnmatch.fnmatch(file, 'user_looks*'):\n",
    "                try:\n",
    "                    \n",
    "                    fUserKey = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerUserKey = csv.reader(fUserKey)\n",
    "                    userKeys = list(readerUserKey)\n",
    "                    \n",
    "                    userKeys.remove(userKeys[0])\n",
    "                except:\n",
    "                    if fUserKey is not None:\n",
    "                        \n",
    "                        fUserKey.close()\n",
    "                    else:\n",
    "                        print('error in opening the user looks at log file')\n",
    "            \n",
    "            elif fnmatch.fnmatch(file, 'KeySelection*'):\n",
    "                try:\n",
    "                    \n",
    "                    fKeysSelected = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerKeysSelected = csv.reader(fKeysSelected)\n",
    "                    keysSelected = list(readerKeysSelected)\n",
    "                    \n",
    "                    keysSelected.remove(keysSelected[0])\n",
    "                except:\n",
    "                    if fKeysSelected is not None:\n",
    "                        \n",
    "                        fKeysSelected.close()\n",
    "                    else:\n",
    "                        print('error in opening the KeySelection log file')\n",
    "            \n",
    "            elif fnmatch.fnmatch(file, 'tobiiGazeLog*'):\n",
    "                try:\n",
    "                    fGazeLog = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerGazeLog = csv.reader(fGazeLog)\n",
    "                    gazeLog = list(readerGazeLog)\n",
    "                    \n",
    "                    gazeLog.remove(gazeLog[0]) # would not matter much even if the first row was not labels\n",
    "                    gazeLog.remove(gazeLog[-1])\n",
    "\n",
    "                except:\n",
    "                    if fGazeLog is not None:\n",
    "                        fGazeLog.close()\n",
    "                    else:\n",
    "                        print('error in opening the gaze log file')\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "                # if all these lists exist\n",
    "            if userKeys is None or keysSelected is None or gazeLog is None:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                a = re.compile('(?<=ExptToCheckMovementEffect\\\\\\\\Data\\\\\\\\)(.*)(?=\\\\\\\\2018-1)')\n",
    "                subjName = a.findall(root)[0]\n",
    "                print('subject', subjName)\n",
    "                \n",
    "                sheet_to_df_map = pd.read_excel(file_name, sheet_name=subjName[0:2])\n",
    "                \n",
    "                testNr_re = re.compile('(?<=\\\\\\Test)(.*)')\n",
    "                testNr = 'Test' + testNr_re.findall(subjName)[0]\n",
    "                if 'rh\\Test_wChinRest' in subjName or 'sa\\Test_woChinRest' in subjName:\n",
    "                    testNr = 'Test' + testNr_re.findall(subjName)[0][:-3]\n",
    "                print(testNr)\n",
    "                columnName1 = testNr + '_SumOfScores'\n",
    "                columnName2 = testNr + '_LIX'\n",
    "                columnName3 = testNr + '_Complexity'\n",
    "                columnName4 = testNr + '_Difficulty'\n",
    "                columnName5 = testNr + '_AfinnScore'\n",
    "                \n",
    "                \n",
    "                # find _wChinRest of difficulty score\n",
    "                scoresSumOfScores = sheet_to_df_map[columnName1]\n",
    "                scoresSumOfScores = scoresSumOfScores[1:]\n",
    "\n",
    "                # find _wChinRest of SumOfScores score\n",
    "                scoresLIX = sheet_to_df_map[columnName2]\n",
    "                scoresLIX = scoresLIX[1:]\n",
    "                \n",
    "                # find _wChinRest of SumOfScores score\n",
    "                scoresComplexity = sheet_to_df_map[columnName3]\n",
    "                scoresComplexity = scoresComplexity[1:]\n",
    "                \n",
    "                # find _wChinRest of SumOfScores score\n",
    "                scoresDifficulty = sheet_to_df_map[columnName4]\n",
    "                scoresDifficulty = scoresDifficulty[1:]\n",
    "                \n",
    "                # find affin score\n",
    "                scoresAfinn = sheet_to_df_map[columnName5]\n",
    "                scoresAfinn = scoresAfinn[1:]\n",
    "                \n",
    "                if subjName == 'sa\\Test_woChinRest\\p2':\n",
    "                    userKeys = userKeys[:-1]\n",
    "                    \n",
    "                # fix userKeys due to comma related file changes\n",
    "                userKeys_new = FixUserKeys(userKeys)\n",
    "                \n",
    "                # find dwell time of typing\n",
    "                userKeys_wDwellTime = ComputeDwellTime(userKeys_new)\n",
    "                \n",
    "                # find start time of typing\n",
    "                timeTyping = OptiKeyTypingTime(userKeys_new)\n",
    "                \n",
    "                # for some of the subjects, the data was not completely collected\n",
    "                if subjName == 'sa\\Test_woChinRest\\p1' or subjName == 'rh\\Test_wChinRest\\p1':\n",
    "                    del keysSelected[-1]\n",
    "                \n",
    "                # divide complete data into epochs of phrases\n",
    "                timeStartEndMixed = FindTrialEndTimes(keysSelected, timeTyping)\n",
    "                \n",
    "                # create trial time epoch using the list of start/end times of trial and userKeys, to make sure that \n",
    "                # Sleep is completely there in every trial, to allow for baseline\n",
    "                timeEpochTrial = CreateTimeEpochsOfTrials(timeStartEndMixed, userKeys_new)\n",
    "                #print(timeEpochTrial)\n",
    "                \n",
    "                dwellTimes_ForBaseline = DwellTimeForBaseline(userKeys_wDwellTime)\n",
    "                \n",
    "                # find and plot pupil size for every trial\n",
    "                ipaList, pupilMean, timeOfTrialList, blinkDuration, blinkDurationAverage, blinkFrequency, time_trialList = FindAndPlotPupilSizeForEpoch(gazeLog, timeEpochTrial, scoresSumOfScores, dwellTimes_ForBaseline)\n",
    "                \n",
    "                if 'sa\\Test_woChinRest' in subjName or 'rh\\Test_wChinRest' in subjName:\n",
    "                    if 'p1' in root:\n",
    "                        ipaList1 = ipaList\n",
    "                        pupilMean1 = pupilMean\n",
    "                        timeOfTrialList1 = timeOfTrialList\n",
    "                        blinkDurationAverage1 = blinkDurationAverage\n",
    "                        blinkFrequency1 = blinkFrequency\n",
    "                        time1 = time_trialList\n",
    "                        blinkDuration1 = blinkDuration\n",
    "                        continue\n",
    "                        \n",
    "                        #print('1', ipaList1)\n",
    "                    else:\n",
    "                        if 'sa\\Test_woChinRest' in subjName:\n",
    "                            ipaList2 = ipaList[1:]\n",
    "                            pupilMean2 = pupilMean[1:]\n",
    "                            timeOfTrialList2 = timeOfTrialList[1:]\n",
    "                            blinkDurationAverage2 = blinkDurationAverage[1:]\n",
    "                            blinkFrequency2 = blinkFrequency[1:]\n",
    "                            time2 = time_trialList[1:]\n",
    "                            blinkDuration2 = blinkDuration[1:]\n",
    "                        else:\n",
    "                            ipaList2 = ipaList\n",
    "                            pupilMean2 = pupilMean\n",
    "                            timeOfTrialList2 = timeOfTrialList\n",
    "                            blinkDurationAverage2 = blinkDurationAverage\n",
    "                            blinkFrequency2 = blinkFrequency\n",
    "                            time2 = time_trialList\n",
    "                            blinkDuration2 = blinkDuration\n",
    "                            \n",
    "                    blinkFrequency = blinkFrequency1 + blinkFrequency2\n",
    "                    blinkDurationAverage = blinkDurationAverage1 + blinkDurationAverage2\n",
    "                    time_trialList = time1 + time2\n",
    "                    blinkDuration = blinkDuration1 + blinkDuration2\n",
    "                    ipaList = ipaList1 + ipaList2\n",
    "                    timeOfTrialList = timeOfTrialList1 + timeOfTrialList2\n",
    "                    pupilMean = pupilMean1 + pupilMean2\n",
    "                    \n",
    "                timeOfTrialListPlot = [i/1000 for i in timeOfTrialList]\n",
    "\n",
    "\n",
    "                if 'Test_wChinRest' in subjName:\n",
    "                    blink_wChinRestFrequency.append(blinkFrequency)\n",
    "                    blink_wChinRestDurationAverage.append(blinkDurationAverage)\n",
    "                    time_wChinRestTrial.append(time_trialList)\n",
    "                    blink_wChinRestDuration.append(blinkDuration)\n",
    "                    ipa_wChinRest.append(ipaList)\n",
    "                    pupilMean_wChinRest.append(pupilMean)\n",
    "                    \n",
    "                    score_wChinRestLIX.append(scoresLIX)\n",
    "                    score_wChinRestComplexity.append(scoresComplexity)\n",
    "                    score_wChinRestDifficulty.append(scoresDifficulty)\n",
    "                    score_wChinRestSumOfScores.append(scoresSumOfScores)\n",
    "                    score_wChinRestAfinn.append(scoresAfinn)\n",
    "                else:\n",
    "                    blink_woChinRestFrequency.append(blinkFrequency)\n",
    "                    blink_woChinRestDurationAverage.append(blinkDurationAverage)\n",
    "                    time_woChinRestTrial.append(time_trialList)\n",
    "                    blink_woChinRestDuration.append(blinkDuration)\n",
    "                    ipa_woChinRest.append(ipaList)\n",
    "                    pupilMean_woChinRest.append(pupilMean)\n",
    "                    \n",
    "                    score_woChinRestLIX.append(scoresLIX)\n",
    "                    score_woChinRestComplexity.append(scoresComplexity)\n",
    "                    score_woChinRestDifficulty.append(scoresDifficulty)\n",
    "                    score_woChinRestSumOfScores.append(scoresSumOfScores)\n",
    "                    score_woChinRestAfinn.append(scoresAfinn)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreComplexity_wChinRest_difficult = list()\n",
    "scoreDifficulty_wChinRest_difficult = list()\n",
    "scoreAfinn_wChinRest_difficult = list()\n",
    "scoreLIX_wChinRest_difficult = list()\n",
    "            \n",
    "blinkFrequency_wChinRest_difficult = list()\n",
    "blinkDurationAverage_wChinRest_difficult = list()\n",
    "            \n",
    "ipa_wChinRest_difficult = list()\n",
    "pupilMean_wChinRest_difficult = list()\n",
    "            \n",
    "scoreComplexity_wChinRest_easy = list()\n",
    "scoreDifficulty_wChinRest_easy = list()\n",
    "scoreAfinn_wChinRest_easy = list()\n",
    "scoreLIX_wChinRest_easy = list()\n",
    "            \n",
    "blinkFrequency_wChinRest_easy = list()\n",
    "blinkDurationAverage_wChinRest_easy = list()\n",
    "            \n",
    "ipa_wChinRest_easy = list()\n",
    "pupilMean_wChinRest_easy = list()\n",
    "\n",
    "\n",
    "subjInd = -1\n",
    "for subjScores in score_wChinRestLIX:\n",
    "    subjInd = subjInd + 1\n",
    "    \n",
    "    scoreComplexity_subj_diffiult = list()\n",
    "    scoreDifficulty_subj_difficult = list()\n",
    "    scoreAfinn_subj_difficult = list()\n",
    "    scoreLIX_subj_difficult = list()\n",
    "    blinkFrequency_subj_difficult = list()\n",
    "    blinkDurationAverage_subj_difficult = list()\n",
    "    ipa_subj_difficult = list()\n",
    "    pupilMean_subj_difficult = list()\n",
    "    \n",
    "    scoreComplexity_subj_easy = list()\n",
    "    scoreDifficulty_subj_easy = list()\n",
    "    scoreAfinn_subj_easy = list()\n",
    "    scoreLIX_subj_easy = list()\n",
    "    blinkFrequency_subj_easy = list()\n",
    "    blinkDurationAverage_subj_easy = list()\n",
    "    ipa_subj_easy = list()\n",
    "    pupilMean_subj_easy = list()\n",
    "    \n",
    "    scoreInd = -1\n",
    "    blinkDurationList = list()\n",
    "    for score in subjScores:\n",
    "        scoreInd = scoreInd + 1\n",
    "        if score > 2:\n",
    "            \n",
    "            scoreComplexity_subj_diffiult.append(score_wChinRestComplexity[subjInd][scoreInd+1])\n",
    "            scoreDifficulty_subj_difficult.append(score_wChinRestDifficulty[subjInd][scoreInd+1])\n",
    "            scoreAfinn_subj_difficult.append(score_wChinRestAfinn[subjInd][scoreInd+1])\n",
    "            scoreLIX_subj_difficult.append(score_wChinRestLIX[subjInd][scoreInd+1])\n",
    "            \n",
    "            blinkFrequency_subj_difficult.append(blink_wChinRestFrequency[subjInd][scoreInd])\n",
    "            blinkDurationAverage_subj_difficult.append(blink_wChinRestDurationAverage[subjInd][scoreInd])\n",
    "            \n",
    "            ipa_subj_difficult.append(ipa_wChinRest[subjInd][scoreInd])\n",
    "            pupilMean_subj_difficult.append(pupilMean_wChinRest[subjInd][scoreInd])\n",
    "            \n",
    "        elif score < 2:\n",
    "            scoreComplexity_subj_easy.append(score_wChinRestComplexity[subjInd][scoreInd+1])\n",
    "            scoreDifficulty_subj_easy.append(score_wChinRestDifficulty[subjInd][scoreInd+1])\n",
    "            scoreAfinn_subj_easy.append(score_wChinRestAfinn[subjInd][scoreInd+1])\n",
    "            scoreLIX_subj_easy.append(score_wChinRestLIX[subjInd][scoreInd+1])\n",
    "            \n",
    "            blinkFrequency_subj_easy.append(blink_wChinRestFrequency[subjInd][scoreInd])\n",
    "            blinkDurationAverage_subj_easy.append(blink_wChinRestDurationAverage[subjInd][scoreInd])\n",
    "            \n",
    "            ipa_subj_easy.append(ipa_wChinRest[subjInd][scoreInd])\n",
    "            pupilMean_subj_easy.append(pupilMean_wChinRest[subjInd][scoreInd])\n",
    "        \n",
    "        if scoreInd == len(subjScores)-1:\n",
    "            scoreComplexity_wChinRest_difficult.append(np.mean(scoreComplexity_subj_diffiult))\n",
    "            scoreDifficulty_wChinRest_difficult.append(np.mean(scoreDifficulty_subj_difficult))\n",
    "            scoreAfinn_wChinRest_difficult.append(np.mean(scoreAfinn_subj_difficult))\n",
    "            scoreLIX_wChinRest_difficult.append(np.mean(scoreLIX_subj_difficult))\n",
    "            \n",
    "            blinkFrequency_wChinRest_difficult.append(np.mean(blinkFrequency_subj_difficult))\n",
    "            blinkDurationAverage_wChinRest_difficult.append(np.mean(blinkDurationAverage_subj_difficult))\n",
    "            \n",
    "            ipa_wChinRest_difficult.append(np.mean(ipa_subj_difficult))\n",
    "            pupilMean_wChinRest_difficult.append(np.mean(pupilMean_subj_difficult))\n",
    "            \n",
    "            scoreComplexity_wChinRest_easy.append(np.mean(scoreComplexity_subj_easy))\n",
    "            scoreDifficulty_wChinRest_easy.append(np.mean(scoreDifficulty_subj_easy))\n",
    "            scoreAfinn_wChinRest_easy.append(np.mean(scoreAfinn_subj_easy))\n",
    "            scoreLIX_wChinRest_easy.append(np.mean(scoreLIX_subj_easy))\n",
    "            \n",
    "            blinkFrequency_wChinRest_easy.append(np.mean(blinkFrequency_subj_easy))\n",
    "            blinkDurationAverage_wChinRest_easy.append(np.mean(blinkDurationAverage_subj_easy))\n",
    "            \n",
    "            ipa_wChinRest_easy.append(np.mean(ipa_subj_easy))\n",
    "            pupilMean_wChinRest_easy.append(np.mean(pupilMean_subj_easy))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=1.49071198499986, pvalue=0.21029538311834686)\n",
      "Ttest_relResult(statistic=2.502022303445038, pvalue=0.06662242870964402)\n",
      "Ttest_relResult(statistic=-0.30151134457776363, pvalue=0.7780495489000209)\n",
      "Ttest_relResult(statistic=0.4423763690161807, pvalue=0.681084280142571)\n",
      "Ttest_relResult(statistic=0.24252793658836114, pvalue=0.8202991413081696)\n",
      "Ttest_relResult(statistic=-0.5457914377870493, pvalue=0.6142206418288512)\n",
      "Ttest_relResult(statistic=1.5815734814207545, pvalue=0.18890684090763923)\n"
     ]
    }
   ],
   "source": [
    "print(stats.ttest_rel(scoreComplexity_wChinRest_difficult, scoreComplexity_wChinRest_easy))\n",
    "print(stats.ttest_rel(scoreDifficulty_wChinRest_difficult, scoreDifficulty_wChinRest_easy))\n",
    "print(stats.ttest_rel(scoreAfinn_wChinRest_difficult, scoreAfinn_wChinRest_easy))\n",
    "\n",
    "print(stats.ttest_rel(blinkFrequency_wChinRest_difficult, blinkFrequency_wChinRest_easy))\n",
    "print(stats.ttest_rel(blinkDurationAverage_wChinRest_difficult, blinkDurationAverage_wChinRest_easy))\n",
    "\n",
    "print(stats.ttest_rel(ipa_wChinRest_difficult, ipa_wChinRest_easy))\n",
    "print(stats.ttest_rel(pupilMean_wChinRest_difficult, pupilMean_wChinRest_easy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreComplexity_woChinRest_difficult = list()\n",
    "scoreDifficulty_woChinRest_difficult = list()\n",
    "scoreAfinn_woChinRest_difficult = list()\n",
    "scoreLIX_woChinRest_difficult = list()\n",
    "\n",
    "blinkFrequency_woChinRest_difficult = list()\n",
    "blinkDurationAverage_woChinRest_difficult = list()\n",
    "            \n",
    "ipa_woChinRest_difficult = list()\n",
    "pupilMean_woChinRest_difficult = list()\n",
    "            \n",
    "scoreComplexity_woChinRest_easy = list()\n",
    "scoreDifficulty_woChinRest_easy = list()\n",
    "scoreAfinn_woChinRest_easy = list()\n",
    "scoreLIX_woChinRest_easy = list()\n",
    "\n",
    "blinkFrequency_woChinRest_easy = list()\n",
    "blinkDurationAverage_woChinRest_easy = list()\n",
    "            \n",
    "ipa_woChinRest_easy = list()\n",
    "pupilMean_woChinRest_easy = list()\n",
    "\n",
    "\n",
    "subjInd = -1\n",
    "for subjScores in score_woChinRestLIX:\n",
    "    subjInd = subjInd + 1\n",
    "    \n",
    "    scoreComplexity_subj_diffiult = list()\n",
    "    scoreDifficulty_subj_difficult = list()\n",
    "    scoreAfinn_subj_difficult = list()\n",
    "    scoreLIX_subj_difficult = list()\n",
    "    blinkFrequency_subj_difficult = list()\n",
    "    blinkDurationAverage_subj_difficult = list()\n",
    "    ipa_subj_difficult = list()\n",
    "    pupilMean_subj_difficult = list()\n",
    "    \n",
    "    scoreComplexity_subj_easy = list()\n",
    "    scoreDifficulty_subj_easy = list()\n",
    "    scoreAfinn_subj_easy = list()\n",
    "    scoreLIX_subj_easy = list()\n",
    "    blinkFrequency_subj_easy = list()\n",
    "    blinkDurationAverage_subj_easy = list()\n",
    "    ipa_subj_easy = list()\n",
    "    pupilMean_subj_easy = list()\n",
    "    \n",
    "    scoreInd = -1\n",
    "    blinkDurationList = list()\n",
    "    for score in subjScores:\n",
    "        scoreInd = scoreInd + 1\n",
    "        if score > 2:\n",
    "            \n",
    "            scoreComplexity_subj_diffiult.append(score_woChinRestComplexity[subjInd][scoreInd+1])\n",
    "            scoreDifficulty_subj_difficult.append(score_woChinRestDifficulty[subjInd][scoreInd+1])\n",
    "            scoreAfinn_subj_difficult.append(score_woChinRestAfinn[subjInd][scoreInd+1])\n",
    "            scoreLIX_subj_difficult.append(score_woChinRestLIX[subjInd][scoreInd+1])\n",
    "            \n",
    "            blinkFrequency_subj_difficult.append(blink_woChinRestFrequency[subjInd][scoreInd])\n",
    "            blinkDurationAverage_subj_difficult.append(blink_woChinRestDurationAverage[subjInd][scoreInd])\n",
    "            \n",
    "            ipa_subj_difficult.append(ipa_woChinRest[subjInd][scoreInd])\n",
    "            pupilMean_subj_difficult.append(pupilMean_woChinRest[subjInd][scoreInd])\n",
    "            \n",
    "        elif score < 2:\n",
    "            scoreComplexity_subj_easy.append(score_woChinRestComplexity[subjInd][scoreInd+1])\n",
    "            scoreDifficulty_subj_easy.append(score_woChinRestDifficulty[subjInd][scoreInd+1])\n",
    "            scoreAfinn_subj_easy.append(score_woChinRestAfinn[subjInd][scoreInd+1])\n",
    "            scoreLIX_subj_easy.append(score_woChinRestLIX[subjInd][scoreInd+1])\n",
    "            \n",
    "            blinkFrequency_subj_easy.append(blink_woChinRestFrequency[subjInd][scoreInd])\n",
    "            blinkDurationAverage_subj_easy.append(blink_woChinRestDurationAverage[subjInd][scoreInd])\n",
    "            \n",
    "            ipa_subj_easy.append(ipa_woChinRest[subjInd][scoreInd])\n",
    "            pupilMean_subj_easy.append(pupilMean_woChinRest[subjInd][scoreInd])\n",
    "        \n",
    "        if scoreInd == len(subjScores)-1:\n",
    "            scoreComplexity_woChinRest_difficult.append(np.mean(scoreComplexity_subj_diffiult))\n",
    "            scoreDifficulty_woChinRest_difficult.append(np.mean(scoreDifficulty_subj_difficult))\n",
    "            scoreAfinn_woChinRest_difficult.append(np.mean(scoreAfinn_subj_difficult))\n",
    "            scoreLIX_woChinRest_difficult.append(np.mean(scoreLIX_subj_difficult))\n",
    "            \n",
    "            blinkFrequency_woChinRest_difficult.append(np.mean(blinkFrequency_subj_difficult))\n",
    "            blinkDurationAverage_woChinRest_difficult.append(np.mean(blinkDurationAverage_subj_difficult))\n",
    "            \n",
    "            ipa_woChinRest_difficult.append(np.mean(ipa_subj_difficult))\n",
    "            pupilMean_woChinRest_difficult.append(np.mean(pupilMean_subj_difficult))\n",
    "            \n",
    "            scoreComplexity_woChinRest_easy.append(np.mean(scoreComplexity_subj_easy))\n",
    "            scoreDifficulty_woChinRest_easy.append(np.mean(scoreDifficulty_subj_easy))\n",
    "            scoreAfinn_woChinRest_easy.append(np.mean(scoreAfinn_subj_easy))\n",
    "            scoreLIX_woChinRest_easy.append(np.mean(scoreLIX_subj_easy))\n",
    "            \n",
    "            blinkFrequency_woChinRest_easy.append(np.mean(blinkFrequency_subj_easy))\n",
    "            blinkDurationAverage_woChinRest_easy.append(np.mean(blinkDurationAverage_subj_easy))\n",
    "            \n",
    "            ipa_woChinRest_easy.append(np.mean(ipa_subj_easy))\n",
    "            pupilMean_woChinRest_easy.append(np.mean(pupilMean_subj_easy))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=10.06230589874906, pvalue=0.0005486474801839636)\n",
      "Ttest_relResult(statistic=9.130087106158284, pvalue=0.0007985330691842276)\n",
      "Ttest_relResult(statistic=2.2499999999999996, pvalue=0.08764517650339469)\n",
      "Ttest_relResult(statistic=2.8772898324005354, pvalue=0.045136030336156444)\n",
      "Ttest_relResult(statistic=1.0745675745448307, pvalue=0.3430680792342676)\n",
      "Ttest_relResult(statistic=-3.313182009310074, pvalue=0.029566315355539524)\n",
      "Ttest_relResult(statistic=2.1219812269714295, pvalue=0.10111623933265561)\n"
     ]
    }
   ],
   "source": [
    "print(stats.ttest_rel(scoreComplexity_woChinRest_difficult, scoreComplexity_woChinRest_easy))\n",
    "print(stats.ttest_rel(scoreDifficulty_woChinRest_difficult, scoreDifficulty_woChinRest_easy))\n",
    "print(stats.ttest_rel(scoreAfinn_woChinRest_difficult, scoreAfinn_woChinRest_easy))\n",
    "\n",
    "print(stats.ttest_rel(blinkFrequency_woChinRest_difficult, blinkFrequency_woChinRest_easy))\n",
    "print(stats.ttest_rel(blinkDurationAverage_woChinRest_difficult, blinkDurationAverage_woChinRest_easy))\n",
    "\n",
    "print(stats.ttest_rel(ipa_woChinRest_difficult, ipa_woChinRest_easy))\n",
    "print(stats.ttest_rel(pupilMean_woChinRest_difficult, pupilMean_woChinRest_easy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreComplexity_difficult = scoreComplexity_woChinRest_difficult + scoreComplexity_wChinRest_difficult\n",
    "scoreDifficulty_difficult = scoreDifficulty_woChinRest_difficult + scoreDifficulty_wChinRest_difficult\n",
    "scoreAfinn_difficult = scoreAfinn_woChinRest_difficult + scoreAfinn_wChinRest_difficult\n",
    "scoreLIX_difficult = scoreLIX_wChinRest_difficult + scoreLIX_woChinRest_difficult\n",
    "blinkFrequency_difficult = blinkFrequency_woChinRest_difficult + blinkFrequency_wChinRest_difficult\n",
    "blinkDurationAverage_difficult = blinkDurationAverage_woChinRest_difficult + blinkDurationAverage_wChinRest_difficult\n",
    "ipa_difficult = ipa_woChinRest_difficult + ipa_wChinRest_difficult\n",
    "pupilMean_difficult = pupilMean_woChinRest_difficult + pupilMean_wChinRest_difficult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreComplexity_easy = scoreComplexity_woChinRest_easy + scoreComplexity_wChinRest_easy\n",
    "scoreDifficulty_easy = scoreDifficulty_woChinRest_easy + scoreDifficulty_wChinRest_easy\n",
    "scoreAfinn_easy = scoreAfinn_woChinRest_easy + scoreAfinn_wChinRest_easy\n",
    "scoreLIX_easy = scoreLIX_woChinRest_easy + scoreLIX_wChinRest_easy\n",
    "\n",
    "blinkFrequency_easy = blinkFrequency_woChinRest_easy + blinkFrequency_wChinRest_easy\n",
    "blinkDurationAverage_easy = blinkDurationAverage_woChinRest_easy + blinkDurationAverage_wChinRest_easy\n",
    "ipa_easy = ipa_woChinRest_easy + ipa_wChinRest_easy\n",
    "pupilMean_easy = pupilMean_woChinRest_easy + pupilMean_wChinRest_easy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=4.133991732024803, pvalue=0.0025443073595036274)\n",
      "Ttest_relResult(statistic=5.676263889047659, pvalue=0.0003033015559492453)\n",
      "Ttest_relResult(statistic=0.5518254055364693, pvalue=0.594502686775326)\n",
      "Ttest_relResult(statistic=1.6833457357225243, pvalue=0.12659779923829523)\n",
      "Ttest_relResult(statistic=1.0725247044177222, pvalue=0.3113994960516582)\n",
      "Ttest_relResult(statistic=-2.0667311720247867, pvalue=0.06872696101507828)\n",
      "Ttest_relResult(statistic=2.2519398408807096, pvalue=0.05084186464959069)\n"
     ]
    }
   ],
   "source": [
    "print(stats.ttest_rel(scoreComplexity_difficult, scoreComplexity_easy))\n",
    "print(stats.ttest_rel(scoreDifficulty_difficult, scoreDifficulty_easy))\n",
    "print(stats.ttest_rel(scoreAfinn_difficult, scoreAfinn_easy))\n",
    "\n",
    "print(stats.ttest_rel(blinkFrequency_difficult, blinkFrequency_easy))\n",
    "print(stats.ttest_rel(blinkDurationAverage_difficult, blinkDurationAverage_easy))\n",
    "\n",
    "print(stats.ttest_rel(ipa_difficult, ipa_easy))\n",
    "print(stats.ttest_rel(pupilMean_difficult, pupilMean_easy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipa = ipa_difficult + ipa_easy\n",
    "pupilMean = pupilMean_difficult + pupilMean_easy\n",
    "\n",
    "blinkFrequency = blinkFrequency_difficult + blinkFrequency_easy\n",
    "blinkDurationAverage = blinkDurationAverage_difficult + blinkDurationAverage_easy\n",
    "\n",
    "scoreComplexity = scoreComplexity_difficult + scoreComplexity_easy\n",
    "scoreDifficulty = scoreDifficulty_difficult + scoreDifficulty_easy\n",
    "scoreAfinn = scoreAfinn_difficult + scoreAfinn_easy\n",
    "\n",
    "scoreLIX = scoreLIX_difficult + scoreLIX_easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipa_wChinRest = ipa_wChinRest_difficult + ipa_wChinRest_easy\n",
    "pupilMean_wChinRest = pupilMean_wChinRest_difficult + pupilMean_wChinRest_easy\n",
    "\n",
    "blinkFrequency_wChinRest = blinkFrequency_wChinRest_difficult + blinkFrequency_wChinRest_easy\n",
    "blinkDurationAverage_wChinRest = blinkDurationAverage_wChinRest_difficult + blinkDurationAverage_wChinRest_easy\n",
    "\n",
    "scoreComplexity_wChinRest = scoreComplexity_wChinRest_difficult + scoreComplexity_wChinRest_easy\n",
    "scoreDifficulty_wChinRest = scoreDifficulty_wChinRest_difficult + scoreDifficulty_wChinRest_easy\n",
    "scoreAfinn_wChinRest = scoreAfinn_wChinRest_difficult + scoreAfinn_wChinRest_easy\n",
    "\n",
    "scoreLIX_wChinRest = scoreLIX_wChinRest_difficult + scoreLIX_wChinRest_easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipa_woChinRest = ipa_woChinRest_difficult + ipa_woChinRest_easy\n",
    "pupilMean_woChinRest = pupilMean_woChinRest_difficult + pupilMean_woChinRest_easy\n",
    "\n",
    "blinkFrequency_woChinRest = blinkFrequency_woChinRest_difficult + blinkFrequency_woChinRest_easy\n",
    "blinkDurationAverage_woChinRest = blinkDurationAverage_woChinRest_difficult + blinkDurationAverage_woChinRest_easy\n",
    "\n",
    "scoreComplexity_woChinRest = scoreComplexity_woChinRest_difficult + scoreComplexity_woChinRest_easy\n",
    "scoreDifficulty_woChinRest = scoreDifficulty_woChinRest_difficult + scoreDifficulty_woChinRest_easy\n",
    "scoreAfinn_woChinRest = scoreAfinn_woChinRest_difficult + scoreAfinn_woChinRest_easy\n",
    "\n",
    "scoreLIX_woChinRest = scoreLIX_woChinRest_difficult + scoreLIX_woChinRest_easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 10 20\n"
     ]
    }
   ],
   "source": [
    "print(len(pupilMean), len(ipa), len(blinkFrequency), len(y), len(blinkDurationAverage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.676699\n",
      "         Iterations: 5\n",
      "         Function evaluations: 8\n",
      "         Gradient evaluations: 8\n",
      "                        Results: Logit\n",
      "==============================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.024  \n",
      "Dependent Variable: y                AIC:              29.0680\n",
      "Date:               2018-12-22 14:10 BIC:              30.0637\n",
      "No. Observations:   20               Log-Likelihood:   -13.534\n",
      "Df Model:           0                LL-Null:          -13.863\n",
      "Df Residuals:       19               Scale:            1.0000 \n",
      "Converged:          1.0000                                    \n",
      "---------------------------------------------------------------\n",
      "              Coef.   Std.Err.    z     P>|z|    [0.025  0.975]\n",
      "---------------------------------------------------------------\n",
      "pupilMean     1.8157    2.3189  0.7830  0.4336  -2.7292  6.3607\n",
      "==============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "y = [0 if score == 1 else 1 for score in scoreLIX]\n",
    "\n",
    "X = pd.DataFrame(\n",
    "    {#'blinkFrequency': blinkFrequency,\n",
    "     #'blinkDuration': blinkDurationAverage,\n",
    "     #'scoreComplexity': scoreComplexity,\n",
    "     #'scoreDifficulty': scoreDifficulty,\n",
    "     #'scoreAfin' : scoreAfinn,\n",
    "     #'ipa' : ipa,\n",
    "     'pupilMean' : pupilMean\n",
    "        \n",
    "     \n",
    "    })\n",
    "\n",
    "\n",
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit(method='bfgs')\n",
    "\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: inf\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1214: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1264: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-90ba936e8ed0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mlogit_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLogit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mresult\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m   1375\u001b[0m         bnryfit = super(Logit, self).fit(start_params=start_params,\n\u001b[0;32m   1376\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1377\u001b[1;33m                 disp=disp, callback=callback, **kwargs)\n\u001b[0m\u001b[0;32m   1378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m         \u001b[0mdiscretefit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogitResults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbnryfit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m         mlefit = super(DiscreteModel, self).fit(start_params=start_params,\n\u001b[0;32m    203\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                 disp=disp, callback=callback, **kwargs)\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmlefit\u001b[0m \u001b[1;31m# up to subclasses to wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mHinv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcov_params_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'newton'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mHinv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mretvals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Hessian'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mskip_hessian\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m             \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhessian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    526\u001b[0m     \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D->D'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'd->d'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m     \u001b[0mainv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Singular matrix\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "y = [0 if score == 1 else 1 for score in scoreLIX_wChinRest]\n",
    "\n",
    "X = pd.DataFrame(\n",
    "    {'blinkFrequency': blinkFrequency_wChinRest,\n",
    "     'blinkDuration': blinkDurationAverage_wChinRest,\n",
    "     'scoreComplexity': scoreComplexity_wChinRest,\n",
    "     'scoreDifficulty': scoreDifficulty_wChinRest,\n",
    "     'scoreAfin' : scoreAfinn_wChinRest,\n",
    "     'ipa' : ipa_wChinRest,\n",
    "     'pupilMean' : pupilMean_wChinRest\n",
    "        \n",
    "     \n",
    "    })\n",
    "\n",
    "\n",
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=109) # 70% training and 30% test\n",
    "\n",
    "#Import svm model\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X.pupilMean,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.269275\n",
       "1    0.135525\n",
       "2    0.050791\n",
       "3    0.160896\n",
       "4    0.248927\n",
       "5   -0.604614\n",
       "6    0.003908\n",
       "7    0.044167\n",
       "8    0.168720\n",
       "9    0.212247\n",
       "Name: pupilMean, dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.pupilMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
