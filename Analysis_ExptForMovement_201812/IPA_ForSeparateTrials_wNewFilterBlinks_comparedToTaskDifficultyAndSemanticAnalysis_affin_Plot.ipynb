{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import csv\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "import pywt\n",
    "import itertools\n",
    "from afinn import Afinn\n",
    "from scipy import stats\n",
    "\n",
    "pd.options.mode.use_inf_as_na = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipaDifficult = list()\n",
    "ipaMedium = list()\n",
    "ipaEasy = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FixUserKeys(UserKeys_Old):\n",
    "    # Fix the situation where comma has divided decimals into separate columns\n",
    "    \n",
    "    Column_beforeDecimal = [item[2] for item in UserKeys_Old]\n",
    "    Column_afterDecimal = [item[3] if len(item)>3 else '00' for item in UserKeys_Old]\n",
    "    \n",
    "    UserKeys_ProgressPercent = [float(Column_beforeDecimal[i]+'.'+ Column_afterDecimal[i]) for i in \n",
    "                                range(0, len(Column_beforeDecimal))]\n",
    "    UserKeys_Times = [item[0] for item in UserKeys_Old]\n",
    "    UserKeys_Keys = [item[1] for item in UserKeys_Old]\n",
    "    \n",
    "    UserKeys_New = [[UserKeys_Times[ind], UserKeys_Keys[ind], UserKeys_ProgressPercent[ind]] for ind in \n",
    "                    range(0, len(UserKeys_ProgressPercent))]\n",
    "    \n",
    "    #UserKeys_New = np.concatenate((UserKeys_Times, UserKeys_Keys, UserKeys_ProgressPercent), axis = 0)\n",
    "    \n",
    "    \n",
    "    return UserKeys_New\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OptiKeyTypingTime(UserKeys):\n",
    "    \n",
    "    TimeTyping = dict()\n",
    "    \n",
    "    time1, t1, t2 = UserKeys[0][0].partition('+')\n",
    "    startTime = datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "    \n",
    "    time2, t1, t2 = UserKeys[-1][0].partition('+')\n",
    "    endTime = datetime.datetime.strptime(re.sub('[:.T]','-',time2[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "    \n",
    "    TimeTyping['startTime'] = startTime\n",
    "    TimeTyping['endTime'] = endTime\n",
    "    \n",
    "    return TimeTyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindTrialEndTimes(KeysSelected, timeTyping):\n",
    "    # function to find start and end of tasks in experiments\n",
    "    timeStartEnd = list() # format of this list will be: [startTime1, endTime1/startTime2, endTime2/startTime3, ..., endTimeN]\n",
    "    \n",
    "    timeStartEnd.append(timeTyping['startTime'])\n",
    "    \n",
    "    nTrial = 1\n",
    "    \n",
    "    for keys in KeysSelected:\n",
    "        \n",
    "        if keys[1] == 'NextPhrase':\n",
    "            time1, t1, t2 = keys[0].partition('+')\n",
    "            endTimeTrial = datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "            timeStartEnd.append(endTimeTrial)\n",
    "    \n",
    "    \n",
    "    timeStartEnd.append(timeTyping['endTime'])\n",
    "    \n",
    "    \n",
    "    return timeStartEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert list of date and time into datetime format list\n",
    "def timeConversion(timeStrList):\n",
    "    timeList = list()\n",
    "    for time in timeStrList:\n",
    "        time1, t1, t2 = time.partition('+')\n",
    "        timeList.append(datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\"))\n",
    "    return timeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will return the datetime in items which is the closest to the date pivot\n",
    "def nearestTimePoint(dates, date):\n",
    "    \n",
    "    for d in dates:\n",
    "        if d < date:\n",
    "            nearestTP = d\n",
    "        else:\n",
    "            continue\n",
    "    try: \n",
    "        nearestTP\n",
    "        nearestTPind = dates.index(nearestTP)\n",
    "    except:\n",
    "        nearestTP = 0\n",
    "        nearestTPind = -1\n",
    "        \n",
    "    return nearestTP, nearestTPind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateTimeEpochsOfTrials(TimeStartEndMixed, UserKeys):\n",
    "    # function to use list of mixed start and end times of trials and keys looked at by user to create trial epochs\n",
    "    \n",
    "    TimeEpochTrial = dict()\n",
    "    TimeEpochTrial['Start'] = list()\n",
    "    TimeEpochTrial['End'] = list()\n",
    "    \n",
    "    # Create list of times in userKeys to be able to use function 'nearestTimePoint'\n",
    "    UserKeysStrTimes = [item3[0] for item3 in UserKeys]\n",
    "    UserKeysTimes = timeConversion(UserKeysStrTimes)\n",
    "    \n",
    "    Flag_FoundSleepKey = 0 # Flag to indicate finding sleep key\n",
    "    \n",
    "    n = -1\n",
    "    for time in TimeStartEndMixed:\n",
    "        n = n + 1\n",
    "        Flag_FoundSleepKey = 0\n",
    "        \n",
    "        if n == 0: # first time is only start time for the first trial\n",
    "            TimeEpochTrial['Start'].append(time)\n",
    "            continue\n",
    "        elif n == len(TimeStartEndMixed)-1: # last time is only the end time for last trial\n",
    "            \n",
    "            TimeEpochTrial['End'].append(time)\n",
    "            \n",
    "        else: # the middle elements need to be divided into start and end\n",
    "            TimeEpochTrial['End'].append(time)\n",
    "            \n",
    "            timeCheck = time\n",
    "            \n",
    "            # find the time in userkeys. Keep going to the previous element till you reach start of selection of\n",
    "            # nextPhrase key\n",
    "            while Flag_FoundSleepKey < 1:\n",
    "                \n",
    "                nearestToTrialStartTime, nearestToTrialStartInd = nearestTimePoint(UserKeysTimes, timeCheck)\n",
    "                indCheck = nearestToTrialStartInd\n",
    "                \n",
    "                if 'NextPhrase' not in UserKeys[indCheck][1]:\n",
    "                    TimeEpochTrial['Start'].append(nearestToTrialStartTime)\n",
    "                    Flag_FoundSleepKey = 1\n",
    "                    break\n",
    "                else:\n",
    "                    indCheck = indCheck - 2 # 2 added instead of 1, to allow nearestTimePoint to find the one before this\n",
    "                    timeCheck = UserKeysTimes[indCheck]\n",
    "                    \n",
    "                \n",
    "    return TimeEpochTrial      \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert2ColumnSizesTo1(GazeLog):\n",
    "    # function to convert pupilsizes from 2 columns for every pupil due to comma use instead of decimal, \n",
    "    # to proper pupil sizes\n",
    "    \n",
    "    PupilLogL = list()\n",
    "    PupilLogR = list()\n",
    "    \n",
    "    PupilLogL_beforeDecimal = [item4[-5] if 'Invalid' not in item4 else 'nan' for item4 in GazeLog]\n",
    "    PupilLogL_afterDecimal = [item4[-4] if 'Invalid' not in item4 else 'nan' for item4 in GazeLog]\n",
    "    PupilLogR_beforeDecimal = [item4[-2] if 'Invalid' not in item4 else 'nan' for item4 in GazeLog]\n",
    "    PupilLogR_afterDecimal = [item4[-1] if 'Invalid' not in item4 else 'nan' for item4 in GazeLog]\n",
    "    \n",
    "    for i in range(0, len(PupilLogL_beforeDecimal)):\n",
    "        if 'Valid' not in PupilLogL_beforeDecimal[i] and 'Valid' not in PupilLogL_afterDecimal[i]:\n",
    "            if 'nan' not in PupilLogL_beforeDecimal[i] and 'nan' not in PupilLogL_afterDecimal[i]:\n",
    "                PupilLogL.append(float(PupilLogL_beforeDecimal[i]+'.'+PupilLogL_afterDecimal[i]))\n",
    "            else:\n",
    "                PupilLogL.append(np.nan)\n",
    "        else:\n",
    "            # Rarely, the pupil size is a whole number\n",
    "            PupilLogL.append(np.nan) # we will ignore the row, since there is no way of automatically knowing which - \n",
    "            # right or left eye has whole number pupil size\n",
    "    \n",
    "    for i in range(0, len(PupilLogR_beforeDecimal)):\n",
    "        if 'Valid' not in PupilLogR_beforeDecimal[i] and 'Valid' not in PupilLogR_afterDecimal[i]:\n",
    "            if 'nan' not in PupilLogR_beforeDecimal[i] and 'nan' not in PupilLogR_afterDecimal[i]:\n",
    "                PupilLogR.append(float(PupilLogR_beforeDecimal[i]+'.'+PupilLogR_afterDecimal[i]))\n",
    "            else:\n",
    "                PupilLogR.append(np.nan)\n",
    "        else:\n",
    "            # Rarely, the pupil size is a whole number\n",
    "            PupilLogL.append(np.nan) # we will ignore the row, since there is no way of automatically knowing which - \n",
    "            # right or left eye has whole number pupil size\n",
    "            \n",
    "    # if one of the pupils are nan, the other one is converted too\n",
    "    nPupil = -1\n",
    "    for pupilL in PupilLogL:\n",
    "        nPupil = nPupil + 1\n",
    "        if np.isnan(pupilL):\n",
    "            if nPupil < len(PupilLogR):\n",
    "                if not np.isnan(PupilLogR[nPupil]):\n",
    "                    PupilLogR[nPupil] = np.nan\n",
    "            else:\n",
    "                del PupilLogL[len(PupilLogR):]\n",
    "                \n",
    "    nPupil = -1\n",
    "    for pupilR in PupilLogR:\n",
    "        nPupil = nPupil + 1\n",
    "        if np.isnan(pupilR):\n",
    "            if nPupil < len(PupilLogL):\n",
    "                if not np.isnan(PupilLogL[nPupil]):\n",
    "                    PupilLogL[nPupil] = np.nan\n",
    "            else:\n",
    "                del PupilLogR[len(PupilLogL):]\n",
    "                \n",
    "    #print(len(PupilLogL), len(PupilLogR))\n",
    "    \n",
    "    return PupilLogL, PupilLogR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PupilSizeFromTrialTimes(TimeTrial, TimeGazeLog, TimeInternalGazeLog, PupilSizeLogL, PupilSizeLogR):\n",
    "    # find pupil sizes from the start and end time given\n",
    "    \n",
    "    # find start and end time in gazeLog\n",
    "    timeStart, timeStartInd = nearestTimePoint(TimeGazeLog, TimeTrial[0])\n",
    "    timeEnd, timeEndInd = nearestTimePoint(TimeGazeLog, TimeTrial[1])\n",
    "    \n",
    "    pupilSize_TrialL = PupilSizeLogL[timeStartInd: timeEndInd]\n",
    "    pupilSize_TrialR = PupilSizeLogR[timeStartInd: timeEndInd]\n",
    "    \n",
    "    TimeInternal_Trial = TimeInternalGazeLog[timeStartInd: timeEndInd]\n",
    "    \n",
    "    TimeGaze_Trial = TimeGazeLog[timeStartInd: timeEndInd]\n",
    "    \n",
    "    return pupilSize_TrialL, pupilSize_TrialR, TimeGaze_Trial, TimeInternal_Trial\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterBlinks(pupilData, timeInDatetime_trial, timeInS_Trial):\n",
    "    # filter any blinks and nan values lasting around 250ms (on average)\n",
    "    # http://faculty.washington.edu/chudler/facts.html\n",
    "   \n",
    "    # recording extra blink information - duration and frequency\n",
    "    blinkDurationList = list()\n",
    "    blinkTimeList = list()\n",
    "    blinkCount = 0\n",
    "    nonBlinkCount = 0\n",
    "    nonBlinkTimeList = list()\n",
    "    timeRemove = 0\n",
    "    \n",
    "    # blink is every nan value in the range of 100-400ms \n",
    "    # 250 ms (23 samples) before and after the blink will also be removed\n",
    "    extraBlinkSamples = 23    \n",
    "    \n",
    "    # remove single missing data, that are due to hardware error\n",
    "    missingVal_Single = np.argwhere(np.isnan(pupilData))\n",
    "    missingVal_Single = list(itertools.chain.from_iterable(missingVal_Single)) # flatten the list\n",
    "    missingVal_SingleDifference = [t - s for s, t in zip(missingVal_Single, missingVal_Single[1:])] # find difference \n",
    "    # between consecutive elements\n",
    "    missingVal_SingleDifference.insert(0, missingVal_Single[0]) # insert the first blink index in the beginning of list\n",
    "    \n",
    "    # the list missingVal_SingleDifference contains the index of the first blink, followed by the difference in the index to \n",
    "    # the next nan value\n",
    "    \n",
    "    # first remove the single nan values, which are missing data\n",
    "    eyeTracker_missingData = list() # list with index of single missing data  \n",
    "    valInd = -1\n",
    "\n",
    "    for val in missingVal_SingleDifference:\n",
    "        valInd = valInd + 1\n",
    "        if valInd == 0:\n",
    "            continue\n",
    "        if val != 1:\n",
    "            if missingVal_SingleDifference[valInd-1] !=1: # if there are 2 consecutive missing values (denoted by 2 consecutive\n",
    "                # non 1 numbers, they are added to the list of eyeTracker_missingData)\n",
    "                eyeTracker_missingData.append(sum(missingVal_SingleDifference[:valInd]))\n",
    "                \n",
    "    # remove single missing values from pupil data\n",
    "    pupilData_woSingleMissingData0 = [pupilData[ind] if ind not in eyeTracker_missingData else [] \n",
    "                                     for ind in range(0, len(pupilData))]\n",
    "    pupilData_woSingleMissingData = [x for x in pupilData_woSingleMissingData0 if x]\n",
    "    \n",
    "    # remove the times for single missing values in pupil data\n",
    "    timeList_woSingleMissingData0 = [timeInDatetime_trial[ind] if ind not in eyeTracker_missingData else [] \n",
    "                                     for ind in range(0, len(timeInDatetime_trial))]\n",
    "    timeList_woSingleMissingData = [x for x in timeList_woSingleMissingData0 if x]\n",
    "    \n",
    "#     print(len(timeList_woSingleMissingData))\n",
    "    \n",
    "    \n",
    "    timeInS_woSingleMissingData = timeInS_Trial[-1]-(len(timeList_woSingleMissingData)-len(timeInDatetime_trial))/90\n",
    "    #print(timeInS_woSingleMissingData, timeInS_Trial[-1])\n",
    "    \n",
    "    # find the nan values again from pupilData_woSingleMissingData\n",
    "    missingVal_Rest = np.argwhere(np.isnan(pupilData_woSingleMissingData))\n",
    "    missingVal_Rest = list(itertools.chain.from_iterable(missingVal_Rest))\n",
    "    missingVal_RestDifference = [t - s for s, t in zip(missingVal_Rest, missingVal_Rest[1:])]\n",
    "    missingVal_RestDifference.insert(0, missingVal_Rest[0])\n",
    "    #print(missingVal_RestDifference)\n",
    "    \n",
    "    # compile and create list of start and end of blinks\n",
    "    blink_missingData = dict()\n",
    "    blink_missingData['Start'] = list()\n",
    "    blink_missingData['End'] = list()\n",
    "    \n",
    "    valInd = -1\n",
    "    for val in missingVal_RestDifference:\n",
    "        valInd = valInd + 1\n",
    "        if val > 1:\n",
    "            \n",
    "            \n",
    "            #print('value', val)\n",
    "            # instead of appending the actual index of blink start, since 250ms before and after the blink need to be\n",
    "            # removed, it is also appended here.\n",
    "            \n",
    "            # just make sure that the additional samples do not make the index of blink go in negative\n",
    "            if sum(missingVal_RestDifference[:valInd+1])-extraBlinkSamples > 0:\n",
    "                \n",
    "                blink_missingData['Start'].append(sum(missingVal_RestDifference[:valInd+1])-extraBlinkSamples)\n",
    "            else:\n",
    "                blink_missingData['Start'].append(0)\n",
    "            \n",
    "            if valInd == 0:\n",
    "                lastBlinkStart = valInd\n",
    "                continue\n",
    "                \n",
    "            # append blink duration list\n",
    "            blinkDurationCurrent = valInd-lastBlinkStart\n",
    "            # if blink duration is greater than 1s, it is not considered to be blink anymore\n",
    "            if blinkDurationCurrent < 90: # since tobii sampling frequency is 90Hz\n",
    "                blinkCount = blinkCount + 1\n",
    "                blinkDurationList.append(blinkDurationCurrent/90)\n",
    "                blinkTimeList.append(timeList_woSingleMissingData[sum(missingVal_RestDifference[:valInd+1])])\n",
    "                lastBlinkStart = valInd\n",
    "            else:\n",
    "                # collect the time of non-blinks, that will need to be removed from trial time, to calculate \n",
    "                # blink frequency\n",
    "                #print('current blink duration', valInd, lastBlinkStart, blinkDurationCurrent)\n",
    "                timeRemove = timeRemove + blinkDurationCurrent\n",
    "                nonBlinkCount = nonBlinkCount + 1\n",
    "                nonBlinkTimeList.append(timeList_woSingleMissingData[sum(missingVal_RestDifference[:valInd+1])])\n",
    "                lastBlinkStart = valInd\n",
    "            \n",
    "            # make sure that the additional samples do not increase the index to more than the length of the pupilData\n",
    "            if sum(missingVal_RestDifference[:valInd])+extraBlinkSamples < len(pupilData_woSingleMissingData):\n",
    "                blink_missingData['End'].append(sum(missingVal_RestDifference[:valInd])+extraBlinkSamples)\n",
    "            else:\n",
    "                blink_missingData['End'].append(len(pupilData_woSingleMissingData)-1)\n",
    "#         else:\n",
    "#             # val is 1\n",
    "#             if valInd-2 > 0 and valInd+3 < len(missingVal_RestDifference):\n",
    "#                 if missingVal_RestDifference[valInd-1] > 1:\n",
    "#                     if missingVal_RestDifference[valInd+1] == 1:\n",
    "#                         if missingVal_RestDifference[valInd+2] > 1:\n",
    "#                             print(timeList_woSingleMissingData[sum(missingVal_RestDifference[:valInd+1])], \n",
    "#                                 missingVal_RestDifference[valInd-2:valInd+3])\n",
    "#                             if missingVal_RestDifference[valInd+2] > missingVal_RestDifference[valInd-1]:\n",
    "#                                 if valInd-6>0:\n",
    "#                                     print(missingVal_RestDifference[valInd-6:valInd+3])\n",
    "#                     elif missingVal_RestDifference[valInd+1] > 1:\n",
    "#                         print(timeList_woSingleMissingData[sum(missingVal_RestDifference[:valInd+1])], \n",
    "#                               missingVal_RestDifference[valInd-2:valInd+3])\n",
    "#                         if missingVal_RestDifference[valInd+2] > missingVal_RestDifference[valInd-1]:\n",
    "#                                 if valInd-6>0:\n",
    "#                                     print(missingVal_RestDifference[valInd-6:valInd+3])\n",
    "                        \n",
    "                        \n",
    "    # add the last blink index\n",
    "    # make sure that the additional samples do not increase the index to more than the length of the pupilData\n",
    "    if sum(missingVal_RestDifference)+extraBlinkSamples < len(pupilData_woSingleMissingData):\n",
    "        blink_missingData['End'].append(sum(missingVal_RestDifference)+extraBlinkSamples)\n",
    "    else:\n",
    "        blink_missingData['End'].append(len(pupilData_woSingleMissingData)-1)\n",
    "                \n",
    "    # need to create a list containing indexes that are to be removed\n",
    "    blinkIndexList = list()\n",
    "    \n",
    "#     print(len(blink_missingData['Start']), len(blink_missingData['End']))\n",
    "    \n",
    "    # remove blinks and additional data from pupil data to get filtered data\n",
    "    for indInd in range(0, len(blink_missingData['Start'])):\n",
    "        blinkIndexList.append(range(blink_missingData['Start'][indInd], blink_missingData['End'][indInd]+1))\n",
    "    # flatten the list\n",
    "    blinkIndexList = list(itertools.chain.from_iterable(blinkIndexList))\n",
    "    \n",
    "    pupilData_woRestMissingData0 = [pupilData_woSingleMissingData[ind] if ind not in blinkIndexList else [] \n",
    "                                     for ind in range(0, len(pupilData_woSingleMissingData))]\n",
    "    pupilData_filter = [x for x in pupilData_woRestMissingData0 if x]\n",
    "    \n",
    "    # remove the times for single missing values in pupil data\n",
    "    timeList_woRestMissingData0 = [timeList_woSingleMissingData[ind] if ind not in blinkIndexList else [] \n",
    "                                     for ind in range(0, len(timeList_woSingleMissingData))]\n",
    "    time_filter = [x for x in timeList_woRestMissingData0 if x]\n",
    "    \n",
    "    timeInS_Trial_filter = timeInS_woSingleMissingData-timeRemove/90\n",
    "    \n",
    "    blinkFrequency = blinkCount/timeInS_Trial_filter\n",
    "    #print('freq', blinkFrequency, timeInS_woSingleMissingData, timeRemove)\n",
    "    #print('time difference', len(timeInDatetime_trial), len(time_filter))\n",
    "    if np.nan in pupilData_filter:\n",
    "        print('nan values in filtered data')\n",
    "#         for i in enumerate(pupilData_filter):\n",
    "#             print(i)\n",
    "        \n",
    "    #print(nonBlinkCount, blinkCount, nonBlinkTimeList)\n",
    "    return pupilData_filter, time_filter, blink_missingData, blinkDurationList, blinkFrequency, blinkTimeList, timeInS_Trial_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modmax(d):\n",
    "    # modulus maxima detection\n",
    "    \n",
    "    # compute signal modulus\n",
    "    m = [0.0]*len(d)\n",
    "    for i in range(0, len(d)):\n",
    "        m[i] = math.fabs(d[i])\n",
    "    \n",
    "    # if value is larger than both neighbours , and strictly\n",
    "    # larger than either , then it is a local maximum\n",
    "    t = [0.0]*len(d)\n",
    "    for i in range(0, len(d)):\n",
    "        ll = m[i-1] if i >= 1 else m[i]\n",
    "        oo = m[i]\n",
    "        rr = m[i+1] if i < len(d)-2 else m[i]\n",
    "        if (ll <= oo and oo >= rr) and (ll < oo or oo > rr):\n",
    "            # compute magnitude\n",
    "            t[i] = math.sqrt(d[i]**2)\n",
    "        else:\n",
    "            t[i] = 0.0\n",
    "    #print(len(t))\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPupilSize(pupilData, timeData, TrialNumber):\n",
    "    \n",
    "    dataLenEqualizer = min(min(len(pupilData['Left']), len(pupilData['Right'])), len(timeData))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.plot(timeData[0:dataLenEqualizer], pupilData['Left'][0:dataLenEqualizer], 'b')\n",
    "    ax.plot(timeData[0:dataLenEqualizer], pupilData['Right'][0:dataLenEqualizer], 'r')\n",
    "    \n",
    "    ax.set_ylabel('Absolute pupil size [in mm]')\n",
    "\n",
    "    ax.set_title(TrialNumber)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hampel(vals_orig, k, sd):\n",
    "    '''\n",
    "    vals: pandas series of values from which to remove outliers\n",
    "    k: size of window (including the sample; 7 is equal to 3 on either side of value)\n",
    "    '''\n",
    "    # Obtained from: https://stackoverflow.com/questions/46819260/filtering-outliers-how-to-make-median-based-\n",
    "    # hampel-function-faster\n",
    "    \n",
    "    #plt.plot(vals_orig)\n",
    "    \n",
    "    #Make copy so original not edited\n",
    "    vals = pd.DataFrame(vals_orig)      \n",
    "    #print(vals.isnull().any())\n",
    "    vals0 = vals.replace([np.inf, -np.inf], np.nan)\n",
    "    #vals = vals0.astype(float).fillna(method = 'backfill') # linear interpolation instead \n",
    "    #print(vals)\n",
    "    vals = vals0.astype(float).interpolate('linear', limit_direction = 'both') # linear interpolation instead of \n",
    "    # simply copying the previous value --\\ linear interpolation than cubic to not add any patterns in the data, limit direction\n",
    "    # set to both, to interpolate the nan values occuring from the start of the series\n",
    "    \n",
    "    L= 1.4826\n",
    "    rolling_median = vals.rolling(window=k, min_periods=1, center=True).median()\n",
    "    \n",
    "    #print(rolling_median)\n",
    "    difference = np.abs(rolling_median-vals)\n",
    "    median_abs_deviation = difference.rolling(k).median()\n",
    "    threshold = sd * L * median_abs_deviation\n",
    "    outlier_idx = difference>threshold\n",
    "    vals[outlier_idx] = rolling_median[outlier_idx]\n",
    "    #print(vals)\n",
    "    #print('datatype', vals.dtypes)\n",
    "    #print(vals.isnull().any())\n",
    "    #vals.plot()\n",
    "    return(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipaFunc(d):\n",
    "    # compute ipa value of pupil diameter\n",
    "    IPA = list()\n",
    "    #print(len(d.pupildata.values))\n",
    "    # obtain 2-level DWT of pupil diameter signal d\n",
    "    \n",
    "    # get signal duration (in seconds)\n",
    "    tt = ((d.timestamp.values[-1] - d.timestamp.values[0]).item())/1000000000\n",
    "\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        (cA2,cD2,cD1) = pywt.wavedec(d.pupildata.values,'sym12','symmetric', 2)\n",
    "    except ValueError:\n",
    "        print('value error in wavedec')\n",
    "        return\n",
    "        \n",
    "    # normalize by 1=2j , j = 2 for 2-level DWT\n",
    "    cA2[:] = [x / math.sqrt(4.0) for x in cA2]\n",
    "    cD1[:] = [x / math.sqrt(2.0) for x in cD1]\n",
    "    cD2[:] = [x / math.sqrt(4.0) for x in cD2]\n",
    "    \n",
    "    # detect modulus maxima , see Listing 2\n",
    "    cD2m = modmax(cD2)\n",
    "    #print(len(cD2m))\n",
    "    \n",
    "    # threshold using universal threshold l_univ = s*sqrt(2logn)\n",
    "    # where s is the standard deviation of the noise\n",
    "    luniv = np.std(cD2m) * math.sqrt(2.0*np.log2(len(cD2m)))\n",
    "    cD2t = pywt.threshold(cD2m ,luniv,mode=\"hard\")\n",
    "        \n",
    "    # compute IPA\n",
    "    ctr = 0\n",
    "    for i in range(0, len(cD2t)):\n",
    "        if math.fabs(cD2t[i]) > 0: ctr += 1\n",
    "        #IPA = float(ctr)/tt\n",
    "        # maybe each pupil data has an IPA?\n",
    "    IPA = (float(ctr)/tt)\n",
    "    \n",
    "    return IPA, cD2m, cD2t, cD2, cD1, cA2, tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindAndPlotPupilSizeForEpoch(GazeLog, TimeEpochTrial, ScoresDifficulty):\n",
    "    # function that uses the list of start and end trial times to find the pupil sizes for those trials and plots them\n",
    "    \n",
    "    # first create a list of times in gaze log\n",
    "    timeStrGazeLog = [item3[0] for item3 in GazeLog]\n",
    "    # convert the list of strings to datetime formats\n",
    "    timeGazeLog = timeConversion(timeStrGazeLog)\n",
    "    \n",
    "    # internal time, to depict seconds\n",
    "    timeInternalGazeLog = [float(item3[1]) for item3 in GazeLog]\n",
    "    \n",
    "    # extract pupil sizes in decimals from the strange 2 columns for every pupil\n",
    "    pupilLogL, pupilLogR = Convert2ColumnSizesTo1(GazeLog)\n",
    "    \n",
    "    ipaList = list()\n",
    "    timeOfGaze_TrialList = list()\n",
    "    \n",
    "    \n",
    "    blinkDurationList = list()\n",
    "    blinkDurationAverageList = list()\n",
    "    blinkTimeList = list()\n",
    "    blinkFrequencyList = list()\n",
    "    timeInS_List = list()\n",
    "    pupilMean = list()\n",
    "    \n",
    "    \n",
    "    # for every epoch, plot the pupil size\n",
    "    for trialNr in range(0, len(timeEpochTrial['Start'])):\n",
    "        if trialNr == 0:\n",
    "            continue\n",
    "        # find pupil sizes for the trial\n",
    "        pupilSizeL_Trial, pupilSizeR_Trial, timeGaze_Trial, timeInternal_Trial = PupilSizeFromTrialTimes(\n",
    "            [TimeEpochTrial['Start'][trialNr], TimeEpochTrial['End'][trialNr]], timeGazeLog, \n",
    "                                timeInternalGazeLog, pupilLogL, pupilLogR)\n",
    "        \n",
    "        pupilSize_Trial = dict()\n",
    "        pupilSize_Filter = dict()\n",
    "        pupilSize_woBlink = dict()\n",
    "        \n",
    "        # find difference in consecutive elements of internal time\n",
    "        timeInternalDifference = [t - s for s, t in zip(timeInternal_Trial, timeInternal_Trial[1:])]\n",
    "        # divide by 1000 to make it s\n",
    "        timeOfGaze_Trial = [sum(timeInternalDifference[:i])/1000000 for i in range(1,len(timeInternalDifference))]\n",
    "\n",
    "        # some trials were skipped, because the sentence was written before. If the time of trial is less than\n",
    "        # 10s, the trial is skipped\n",
    "        if timeOfGaze_Trial[-1] < 20:\n",
    "            print('trial number ', trialNr+1, 'with', timeOfGaze_Trial[-1], 's will be skipped')\n",
    "            continue\n",
    "        \n",
    "        pupilSize_Trial['Left'] = pupilSizeL_Trial\n",
    "        pupilSize_Trial['Right'] = pupilSizeR_Trial\n",
    "        \n",
    "        #if trialNr == 4:\n",
    "        #    for i in range(0, len(pupilSizeL_Trial)):\n",
    "        #        print(pupilSizeL_Trial[i], pupilSizeR_Trial[i])\n",
    "            \n",
    "        #print('Trial', len(pupilSizeL_Trial), len(pupilSizeR_Trial))\n",
    "        \n",
    "        # filter the blinks\n",
    "        pupilSizeL_woBlink, time_filter, missingPupilData, blinkDuration, blinkFrequency, blinkTimeList, timeInS_filter = filterBlinks(pupilSizeL_Trial, timeGaze_Trial, timeOfGaze_Trial)\n",
    "        pupilSizeR_woBlink, time_filter, missingPupilData, blinkDuration, blinkFrequency, blinkTimeList, timeInS_filter = filterBlinks(pupilSizeR_Trial, timeGaze_Trial, timeOfGaze_Trial)\n",
    "        \n",
    "#         print(trialNr, blinkFrequency)\n",
    "        #print(trialNr, blinkDuration)\n",
    "\n",
    "        # time of trial\n",
    "        timeInS_List.append(timeInS_filter)\n",
    "        #print(trialNr, timeInS_filter)\n",
    "        \n",
    "        #print(index_blinkEndL)\n",
    "        #print(index_blinkEndR)\n",
    "        pupilSize_woBlink['Left'] = pupilSizeL_woBlink\n",
    "        pupilSize_woBlink['Right'] = pupilSizeR_woBlink\n",
    "        \n",
    "        #print('After blink', len(pupilSizeL_woBlink), len(pupilSizeR_woBlink))\n",
    "        # Hampel filter to remove the outliers\n",
    "        winSize = 25\n",
    "        pupilSizeL_filter = hampel(pupilSizeL_woBlink, winSize, 3)\n",
    "        pupilSizeR_filter = hampel(pupilSizeR_woBlink, winSize, 3)\n",
    "\n",
    "        pupilSize_Filter['Left'] = pupilSizeL_filter.values.tolist()\n",
    "        pupilSize_Filter['Right'] = pupilSizeR_filter.values.tolist()\n",
    "        \n",
    "        pupilSizeL_filterList = [i[0] for i in pupilSizeL_filter.values]\n",
    "        pupilSizeR_filterList = [i[0] for i in pupilSizeR_filter.values]\n",
    "        \n",
    "        #print('filter', len(pupilSizeL_filterList), len(pupilSizeR_filterList))\n",
    "        RLCorrelation = np.corrcoef(pupilSizeL_filterList, pupilSizeR_filterList)\n",
    "        #print(RLCorrelation)\n",
    "        \n",
    "        pupilAvg = [((pupilSizeL_filterList[i] + pupilSizeR_filterList[i])/2) for i in range(0, min(len(pupilSizeL_filterList), len(pupilSizeR_filterList)))]\n",
    "        \n",
    "        pupilMean.append(np.mean(pupilAvg))\n",
    "        \n",
    "        pupilLog_filter_wTime_Tuple = list(zip(time_filter, pupilAvg))\n",
    "        pupilAndTimeDf =  pd.DataFrame(pupilLog_filter_wTime_Tuple, columns=['timestamp','pupildata'])\n",
    "        \n",
    "        # compute IPA for the trial\n",
    "        ipaVal, coeff_modmax, coeff_hard, coeff_D2, coeff_D1, coeff_A, timePeriodTrial = ipaFunc(pupilAndTimeDf)\n",
    "        \n",
    "        #print(trialNr+1, ipaVal, timeOfGaze_Trial[-1])\n",
    "        \n",
    "        ipaList.append(ipaVal)\n",
    "        timeOfGaze_TrialList.append(timeOfGaze_Trial[-1])\n",
    "        \n",
    "        \n",
    "        blinkDurationList.append(blinkDuration)\n",
    "        blinkFrequencyList.append(blinkFrequency)\n",
    "        \n",
    "        \n",
    "        if len(blinkDuration)>0:\n",
    "            blinkDurationAverageList.append(np.mean(blinkDuration))\n",
    "        else:\n",
    "            blinkDurationAverageList.append(0)\n",
    "            \n",
    "        \n",
    "    return ipaList, pupilMean, timeOfGaze_TrialList, blinkDurationList, blinkDurationAverageList, blinkFrequencyList, timeInS_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject bh\\Test_wChinRest\n",
      "Test_wChinRest\n",
      "trial number  11 with 4.596693 s will be skipped\n",
      "subject bh\\Test_woChinRest\n",
      "Test_woChinRest\n",
      "trial number  11 with 7.339166 s will be skipped\n",
      "subject ph\\Test_wChinRest\n",
      "Test_wChinRest\n",
      "trial number  11 with 18.00399 s will be skipped\n",
      "subject ph\\Test_woChinRest\n",
      "Test_woChinRest\n",
      "subject pt\\Test_wChinRest\n",
      "Test_wChinRest\n",
      "subject pt\\Test_woChinRest\n",
      "Test_woChinRest\n",
      "trial number  11 with 17.47867 s will be skipped\n",
      "subject rh\\Test_wChinRest\\p1\n",
      "Test_wChinRest\n",
      "subject rh\\Test_wChinRest\\p2\n",
      "Test_wChinRest\n",
      "trial number  4 with 10.770031 s will be skipped\n",
      "trial number  10 with 14.989218 s will be skipped\n",
      "subject rh\\Test_woChinRest\n",
      "Test_woChinRest\n",
      "trial number  11 with 10.476645 s will be skipped\n",
      "subject sa\\Test_wChinRest\n",
      "Test_wChinRest\n",
      "subject sa\\Test_woChinRest\\p1\n",
      "Test_woChinRest\n",
      "subject sa\\Test_woChinRest\\p2\n",
      "Test_woChinRest\n",
      "trial number  3 with 8.449478 s will be skipped\n",
      "trial number  5 with 8.926912 s will be skipped\n"
     ]
    }
   ],
   "source": [
    "blinkTotalFrequency = list()\n",
    "blinkTotalDurationAverage = list()\n",
    "\n",
    "timeTotalTrial = list()\n",
    "blinkTotalDuration = list()\n",
    "ipaTotal = list()\n",
    "pupilMeanTotal = list()\n",
    "\n",
    "scoreTotalLIX = list()\n",
    "scoreTotalComplexity = list()\n",
    "scoreTotalDifficulty = list()\n",
    "scoreTotalSumOfScores = list()\n",
    "scoreTotalAfinn = list()\n",
    "\n",
    "subjName = r'C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data'\n",
    "j = 0\n",
    "flagFirstSubj = 0\n",
    "pupilData = dict()\n",
    "pupilData['RLCorrelation'] = []\n",
    "\n",
    "# extract self-reported scores list and LIX score of given sentence\n",
    "file_name = r'C:/DTU/Data/201812_ExptToCheckMovementEffect/Data/Scores.xlsx'\n",
    "\n",
    "\n",
    "#testNr = 'Test_wChinRest'\n",
    "for root, dirs, subfolder in os.walk(subjName):\n",
    "    scoreDifficult = list()\n",
    "    scoreMedium = list()\n",
    "    scoreEasy = list()\n",
    "    # Semantic modeling score from afinn\n",
    "    afinnDifficult = list()\n",
    "    afinnMedium = list()\n",
    "    afinnEasy = list()\n",
    "\n",
    "    if not dirs:\n",
    "        \n",
    "        if 'tb' in root or 'trial' in root:\n",
    "            continue\n",
    "            \n",
    "        userKeys = None\n",
    "        gazeLog = None\n",
    "        keysSelected = None\n",
    "        \n",
    "        if 'Test_wChinRest' in root:\n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_subplot(111)\n",
    "        \n",
    "        for file in subfolder:\n",
    "            if fnmatch.fnmatch(file, 'user_looks*'):\n",
    "                try:\n",
    "                    \n",
    "                    fUserKey = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerUserKey = csv.reader(fUserKey)\n",
    "                    userKeys = list(readerUserKey)\n",
    "                    \n",
    "                    userKeys.remove(userKeys[0])\n",
    "                except:\n",
    "                    if fUserKey is not None:\n",
    "                        \n",
    "                        fUserKey.close()\n",
    "                    else:\n",
    "                        print('error in opening the user looks at log file')\n",
    "            \n",
    "            elif fnmatch.fnmatch(file, 'KeySelection*'):\n",
    "                try:\n",
    "                    \n",
    "                    fKeysSelected = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerKeysSelected = csv.reader(fKeysSelected)\n",
    "                    keysSelected = list(readerKeysSelected)\n",
    "                    \n",
    "                    keysSelected.remove(keysSelected[0])\n",
    "                except:\n",
    "                    if fKeysSelected is not None:\n",
    "                        \n",
    "                        fKeysSelected.close()\n",
    "                    else:\n",
    "                        print('error in opening the KeySelection log file')\n",
    "            \n",
    "            elif fnmatch.fnmatch(file, 'tobiiGazeLog*'):\n",
    "                try:\n",
    "                    fGazeLog = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerGazeLog = csv.reader(fGazeLog)\n",
    "                    gazeLog = list(readerGazeLog)\n",
    "                    \n",
    "                    gazeLog.remove(gazeLog[0]) # would not matter much even if the first row was not labels\n",
    "                    gazeLog.remove(gazeLog[-1])\n",
    "\n",
    "                except:\n",
    "                    if fGazeLog is not None:\n",
    "                        fGazeLog.close()\n",
    "                    else:\n",
    "                        print('error in opening the gaze log file')\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "                # if all these lists exist\n",
    "            if userKeys is None or keysSelected is None or gazeLog is None:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                a = re.compile('(?<=ExptToCheckMovementEffect\\\\\\\\Data\\\\\\\\)(.*)(?=\\\\\\\\2018-1)')\n",
    "                subjName = a.findall(root)[0]\n",
    "                print('subject', subjName)\n",
    "                \n",
    "                sheet_to_df_map = pd.read_excel(file_name, sheet_name=subjName[0:2])\n",
    "                \n",
    "                testNr_re = re.compile('(?<=\\\\\\Test)(.*)')\n",
    "                testNr = 'Test' + testNr_re.findall(subjName)[0]\n",
    "                if 'rh\\Test_wChinRest' in subjName or 'sa\\Test_woChinRest' in subjName:\n",
    "                    testNr = 'Test' + testNr_re.findall(subjName)[0][:-3]\n",
    "                print(testNr)\n",
    "                columnName1 = testNr + '_SumOfScores'\n",
    "                columnName2 = testNr + '_LIX'\n",
    "                columnName3 = testNr + '_Complexity'\n",
    "                columnName4 = testNr + '_Difficulty'\n",
    "                columnName5 = testNr + '_AfinnScore'\n",
    "                \n",
    "                \n",
    "                # find total of difficulty score\n",
    "                scoresSumOfScores = sheet_to_df_map[columnName1]\n",
    "                scoresSumOfScores = scoresSumOfScores[1:]\n",
    "\n",
    "                # find total of SumOfScores score\n",
    "                scoresLIX = sheet_to_df_map[columnName2]\n",
    "                scoresLIX = scoresLIX[1:]\n",
    "                \n",
    "                # find total of SumOfScores score\n",
    "                scoresComplexity = sheet_to_df_map[columnName3]\n",
    "                scoresComplexity = scoresComplexity[1:]\n",
    "                \n",
    "                # find total of SumOfScores score\n",
    "                scoresDifficulty = sheet_to_df_map[columnName4]\n",
    "                scoresDifficulty = scoresDifficulty[1:]\n",
    "                \n",
    "                # find affin score\n",
    "                scoresAfinn = sheet_to_df_map[columnName5]\n",
    "                scoresAfinn = scoresAfinn[1:]\n",
    "                \n",
    "                if subjName == 'sa\\Test_woChinRest\\p2':\n",
    "                    userKeys = userKeys[:-1]\n",
    "                \n",
    "                # fix userKeys due to comma related file changes\n",
    "                userKeys_new = FixUserKeys(userKeys)\n",
    "                \n",
    "                # find start time of typing\n",
    "                timeTyping = OptiKeyTypingTime(userKeys_new)\n",
    "                \n",
    "                # for some of the subjects, the data was not completely collected\n",
    "                if subjName == 'sa\\Test_woChinRest\\p1' or subjName == 'rh\\Test_wChinRest\\p1':\n",
    "                    del keysSelected[-1]\n",
    "                \n",
    "                # divide complete data into epochs of phrases\n",
    "                timeStartEndMixed = FindTrialEndTimes(keysSelected, timeTyping)\n",
    "                \n",
    "                # create trial time epoch using the list of start/end times of trial and userKeys, to make sure that \n",
    "                # Sleep is completely there in every trial, to allow for baseline\n",
    "                timeEpochTrial = CreateTimeEpochsOfTrials(timeStartEndMixed, userKeys_new)\n",
    "                #print(timeEpochTrial)\n",
    "                \n",
    "                # find and plot pupil size for every trial\n",
    "                ipaList, pupilMean, timeOfTrialList, blinkDuration, blinkDurationAverage, blinkFrequency, time_trialList = FindAndPlotPupilSizeForEpoch(gazeLog, timeEpochTrial, scoresSumOfScores)\n",
    "                \n",
    "                if 'sa\\Test_woChinRest' in subjName or 'rh\\Test_wChinRest' in subjName:\n",
    "                    if 'p1' in root:\n",
    "                        ipaList1 = ipaList\n",
    "                        pupilMean1 = pupilMean\n",
    "                        timeOfTrialList1 = timeOfTrialList\n",
    "                        blinkDurationAverage1 = blinkDurationAverage\n",
    "                        blinkFrequency1 = blinkFrequency\n",
    "                        time1 = time_trialList\n",
    "                        blinkDuration1 = blinkDuration\n",
    "                        continue\n",
    "\n",
    "                    else:\n",
    "                        if 'sa\\Test_woChinRest' in subjName:\n",
    "                            ipaList2 = ipaList[1:]\n",
    "                            pupilMean2 = pupilMean[1:]\n",
    "                            timeOfTrialList2 = timeOfTrialList[1:]\n",
    "                            blinkDurationAverage2 = blinkDurationAverage[1:]\n",
    "                            blinkFrequency2 = blinkFrequency[1:]\n",
    "                            time2 = time_trialList[1:]\n",
    "                            blinkDuration2 = blinkDuration[1:]\n",
    "                        else:\n",
    "                            ipaList2 = ipaList\n",
    "                            pupilMean2 = pupilMean\n",
    "                            timeOfTrialList2 = timeOfTrialList\n",
    "                            blinkDurationAverage2 = blinkDurationAverage\n",
    "                            blinkFrequency2 = blinkFrequency\n",
    "                            time2 = time_trialList\n",
    "                            blinkDuration2 = blinkDuration\n",
    "                            \n",
    "                    blinkFrequency = blinkFrequency1 + blinkFrequency2\n",
    "                    blinkDurationAverage = blinkDurationAverage1 + blinkDurationAverage2\n",
    "                    time_trialList = time1 + time2\n",
    "                    blinkDuration = blinkDuration1 + blinkDuration2\n",
    "                    ipaList = ipaList1 + ipaList2\n",
    "                    timeOfTrialList = timeOfTrialList1 + timeOfTrialList2\n",
    "                    pupilMean = pupilMean1 + pupilMean2\n",
    "                    \n",
    "                timeOfTrialListPlot = [i/1000 for i in timeOfTrialList]\n",
    "\n",
    "\n",
    "                blinkTotalFrequency.append(blinkFrequency)\n",
    "                blinkTotalDurationAverage.append(blinkDurationAverage)\n",
    "                timeTotalTrial.append(time_trialList)\n",
    "                blinkTotalDuration.append(blinkDuration)\n",
    "                \n",
    "                ipaTotal.append(ipaList)\n",
    "                pupilMeanTotal.append(pupilMean)\n",
    "                \n",
    "                scoreTotalLIX.append(scoresLIX)\n",
    "                scoreTotalComplexity.append(scoresComplexity)\n",
    "                scoreTotalDifficulty.append(scoresDifficulty)\n",
    "                scoreTotalSumOfScores.append(scoresSumOfScores)\n",
    "                scoreTotalAfinn.append(scoresAfinn)\n",
    "\n",
    "                #if 'Test_wChinRest' in testNr:\n",
    "                #    xAxisPlot = 1\n",
    "                #else:\n",
    "                #    xAxisPlot = 2\n",
    "                #fig = plt.figure()\n",
    "                #ax = fig.add_subplot(111)\n",
    "                ## 3d plot between afinn score, difficulty and ipa values\n",
    "                #ax.plot(afinnDifficult, scoreDifficult, 'ro', label = 'difficult')\n",
    "                #ax.plot(afinnMedium, scoreMedium, 'bs', label = 'medium')\n",
    "                #ax.plot(afinnEasy, scoreEasy, 'cd', label = 'easy')\n",
    "\n",
    "                #ax.set_title(subjName[0:2])\n",
    "                #ax.legend()\n",
    "             \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_duration_wChinRest = [item for sublist in blink_wChinRestDurationAverage for item in sublist]\n",
    "flat_frequency_wChinRest = [item for sublist in blink_wChinRestFrequency for item in sublist]\n",
    "flat_time_wChinRest = [item for sublist in time_wChinRestTrial for item in sublist]\n",
    "flat_scoreDifficulty_wChinRest = [item for sublist in score_wChinRestDifficulty for item in sublist]\n",
    "flat_scoreComplexity_wChinRest = [item for sublist in score_wChinRestComplexity for item in sublist]\n",
    "flat_scoreLIX_wChinRest = [item for sublist in score_wChinRestLIX for item in sublist]\n",
    "flat_scoreSumOfScores_wChinRest = [item for sublist in score_wChinRestSumOfScores for item in sublist]\n",
    "flat_scoreAfinn_wChinRest = [item for sublist in score_wChinRestAfinn for item in sublist]\n",
    "flat_ipa_wChinRest = [item for sublist in ipa_wChinRest for item in sublist]\n",
    "flat_pupilMean_wChinRest = [item for sublist in pupilMean_wChinRest for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blink_woChinRestDurationAverage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-b762fb5d61b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mflat_duration_woChinRest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblink_woChinRestDurationAverage\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mflat_frequency_woChinRest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblink_woChinRestFrequency\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mflat_time_woChinRest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtime_woChinRestTrial\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mflat_scoreDifficulty_woChinRest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscore_woChinRestDifficulty\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mflat_scoreComplexity_woChinRest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mscore_woChinRestComplexity\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'blink_woChinRestDurationAverage' is not defined"
     ]
    }
   ],
   "source": [
    "flat_duration_woChinRest = [item for sublist in blink_woChinRestDurationAverage for item in sublist]\n",
    "flat_frequency_woChinRest = [item for sublist in blink_woChinRestFrequency for item in sublist]\n",
    "flat_time_woChinRest = [item for sublist in time_woChinRestTrial for item in sublist]\n",
    "flat_scoreDifficulty_woChinRest = [item for sublist in score_woChinRestDifficulty for item in sublist]\n",
    "flat_scoreComplexity_woChinRest = [item for sublist in score_woChinRestComplexity for item in sublist]\n",
    "flat_scoreLIX_woChinRest = [item for sublist in score_woChinRestLIX for item in sublist]\n",
    "flat_scoreSumOfScores_woChinRest = [item for sublist in score_woChinRestSumOfScores for item in sublist]\n",
    "flat_scoreAfinn_woChinRest = [item for sublist in score_woChinRestAfinn for item in sublist]\n",
    "flat_ipa_woChinRest = [item for sublist in ipa_woChinRest for item in sublist]\n",
    "flat_pupilMean_woChinRest = [item for sublist in pupilMean_woChinRest for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "blinkFrequencyLR = list()\n",
    "blinkDurationLR = list()\n",
    "scoreComplexityLR = list()\n",
    "scoreDifficultyLR = list()\n",
    "scoreLIXLR = list()\n",
    "scoreAfinnLR = list()\n",
    "ipaLR = list()\n",
    "pupilMeanLR = list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = -1\n",
    "for score in flat_scoreLIX:\n",
    "    ind = ind + 1\n",
    "    if score != 2:\n",
    "        blinkFrequencyLR.append(flat_frequency[ind])\n",
    "        blinkDurationLR.append(flat_duration[ind])\n",
    "        scoreComplexityLR.append(flat_scoreComplexity[ind])\n",
    "        scoreDifficultyLR.append(flat_scoreDifficulty[ind])\n",
    "        scoreLIXLR.append(flat_scoreLIX[ind])\n",
    "        scoreAfinnLR.append(flat_scoreAfinn[ind])\n",
    "        ipaLR.append(flat_ipa[ind])\n",
    "        pupilMeanLR.append(flat_pupilMean[ind])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0 if score == 1 else 1 for score in scoreLIXLR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: inf\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1214: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:1264: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-4d9050e5f43d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mlogit_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLogit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mresult\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m   1375\u001b[0m         bnryfit = super(Logit, self).fit(start_params=start_params,\n\u001b[0;32m   1376\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1377\u001b[1;33m                 disp=disp, callback=callback, **kwargs)\n\u001b[0m\u001b[0;32m   1378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m         \u001b[0mdiscretefit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogitResults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbnryfit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m         mlefit = super(DiscreteModel, self).fit(start_params=start_params,\n\u001b[0;32m    203\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                 disp=disp, callback=callback, **kwargs)\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmlefit\u001b[0m \u001b[1;31m# up to subclasses to wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mHinv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcov_params_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'newton'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mHinv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mretvals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Hessian'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mskip_hessian\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m             \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhessian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    526\u001b[0m     \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D->D'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'd->d'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m     \u001b[0mainv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Singular matrix\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "y = [0 if score == 1 else 1 for score in scoreLIXLR]\n",
    "\n",
    "X = pd.DataFrame(\n",
    "    {'blinkFrequency': blinkFrequencyLR,\n",
    "     'blinkDuration': blinkDurationLR,\n",
    "     'scoreComplexity': scoreComplexityLR,\n",
    "     'scoreDifficulty': scoreDifficultyLR,\n",
    "     'scoreAfin' : scoreAfinnLR\n",
    "     \n",
    "    })\n",
    "\n",
    "\n",
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 1, 1]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'sa\\Test_woChinRest' in subjName or 'rh\\Test_wChinRest' in subjName:\n",
    "    print('Addition of lists')\n",
    "    ipaList = ipaList1 + ipaList2\n",
    "    timeOfTrialList = timeOfTrialList1 + timeOfTrialList2\n",
    "\n",
    "timeOfTrialListPlot = [i/1000 for i in timeOfTrialList]\n",
    "\n",
    "#print(ipaList)\n",
    "#print(scoresDifficulty)\n",
    "# divide scores as per difficulty\n",
    "\n",
    "scoreDifficult = list()\n",
    "scoreMedium = list()\n",
    "scoreEasy = list()\n",
    "\n",
    "\n",
    "\n",
    "for ind in range(0, len(scoresDifficulty)):\n",
    "    #print(scoresDifficulty.values[ind])\n",
    "    if scoresDifficulty.values[ind] > 2:\n",
    "        scoreDifficult.append(ipaList[ind])\n",
    "        ipaDifficult.append(ipaList[ind])\n",
    "    elif scoresDifficulty.values[ind] > 1:\n",
    "        scoreMedium.append(ipaList[ind])\n",
    "        ipaMedium.append(ipaList[ind])\n",
    "    else:\n",
    "        scoreEasy.append(ipaList[ind])\n",
    "        ipaEasy.append(ipaList[ind])\n",
    "        \n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(1,1,1)\n",
    "# ax.plot(range(1,len(scoreDifficult)+1), scoreDifficult, 'r', marker = 'o', linestyle = '-', label = 'difficult')\n",
    "# ax.plot(range(1,len(scoreMedium)+1), scoreMedium, 'b', marker = 's', linestyle = '-', label = 'medium')\n",
    "# ax.plot(range(1,len(scoreEasy)+1), scoreEasy, 'c', marker = 'd', linestyle = '-', label = 'easy')\n",
    "\n",
    "#ax.plot(range(1,len(scoresDifficulty)+1), scoresDifficulty/100, 'b', label = 'difficulty')\n",
    "#ax.plot(range(1, len(timeOfTrialList)+1), timeOfTrialListPlot, 'c', label = 'time' )\n",
    "# ax.set_title(subjName)\n",
    "# ax.legend()\n",
    "             \n",
    "#print(ipaList)\n",
    "#print(scoresDifficulty)\n",
    "print(subjName)\n",
    "print('Correlation:', np.corrcoef(ipaList,scoresDifficulty))\n",
    "print('Correlation between time and ipa', np.corrcoef(ipaList, timeOfTrialList))\n",
    "print('Correlation between time and difficulty', np.corrcoef(timeOfTrialList, scoresDifficulty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipaMean = [ np.mean(ipaEasy), np.mean(ipaMedium) , np.mean(ipaDifficult)]\n",
    "ipaStd = [ np.std(ipaEasy), np.std(ipaMedium) , np.std(ipaDifficult)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.errorbar([1, 2, 3], ipaMean, ipaStd, marker = 'o', capsize=4)\n",
    "ax.set_title(subjName)\n",
    "plt.xticks([1,2,3], ['Easy', 'Medium', 'Difficult'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ipaEasy), len(ipaMedium), len(ipaDifficult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipaDifficult = list()\n",
    "ipaMedium = list()\n",
    "ipaEasy = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Difficult', np.mean(ipaDifficult), np.std(ipaDifficult))\n",
    "print('Medium', np.mean(ipaMedium), np.std(ipaMedium))\n",
    "print('Easy', np.mean(ipaEasy), np.std(ipaEasy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.errorbar([1, 2, 3], ipaMean, ipaStd, marker = 'o', capsize=4)\n",
    "plt.xticks([1,2,3], ['Easy', 'Medium', 'Difficult'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 'bh\\Test_woChinRest'\n",
    "c = re.compile('(?<=\\\\\\Test)(.*)')\n",
    "d = c.findall(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipaDifficult = list()\n",
    "ipaMedium = list()\n",
    "ipaEasy = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.set_xticklabels([1,2], ['With_chinRest', 'Without_chinRest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresAfinn.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
