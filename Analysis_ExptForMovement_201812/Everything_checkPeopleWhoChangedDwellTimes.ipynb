{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import csv\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pywt\n",
    "import itertools\n",
    "from scipy import stats\n",
    "import statsmodels\n",
    "\n",
    "pd.options.mode.use_inf_as_na = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipaDifficult = list()\n",
    "ipaMedium = list()\n",
    "ipaEasy = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeDwellOrig = 800\n",
    "TimeFixation = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FixUserKeys(UserKeys_Old):\n",
    "    # Fix the situation where comma has divided decimals into separate columns\n",
    "    \n",
    "    Column_beforeDecimal = [item[2] for item in UserKeys_Old]\n",
    "    Column_afterDecimal = [item[3] if len(item)>3 else '00' for item in UserKeys_Old]\n",
    "    \n",
    "    UserKeys_ProgressPercent = [float(Column_beforeDecimal[i]+'.'+ Column_afterDecimal[i]) for i in \n",
    "                                range(0, len(Column_beforeDecimal))]\n",
    "    UserKeys_Times = [item[0] for item in UserKeys_Old]\n",
    "    UserKeys_Keys = [item[1] for item in UserKeys_Old]\n",
    "    \n",
    "    UserKeys_New = [[UserKeys_Times[ind], UserKeys_Keys[ind], UserKeys_ProgressPercent[ind]] for ind in \n",
    "                    range(0, len(UserKeys_ProgressPercent))]\n",
    "    \n",
    "    #UserKeys_New = np.concatenate((UserKeys_Times, UserKeys_Keys, UserKeys_ProgressPercent), axis = 0)\n",
    "    \n",
    "    \n",
    "    return UserKeys_New\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FixScratchPad(ScratchPad_Old):\n",
    "    # Fix the situation where comma has divided decimals into separate columns\n",
    "    \n",
    "    ScratchPad_Times = [item[0] for item in ScratchPad_Old]\n",
    "    \n",
    "    ScratchPad_Phrases = list()\n",
    "    \n",
    "    # loop to combine phrases divided by commas\n",
    "    ScratchPadInd = -1 \n",
    "    while ScratchPadInd < len(ScratchPad_Old)-1:\n",
    "        ScratchPadInd = ScratchPadInd + 1\n",
    "        commasInPhrase = len(ScratchPad_Old[ScratchPadInd])-2\n",
    "        if commasInPhrase < 1:\n",
    "            #print(ScratchPad_Old[ScratchPadInd][1])\n",
    "            ScratchPad_Phrases.append(ScratchPad_Old[ScratchPadInd][1])\n",
    "            continue\n",
    "        scratchPadPhrase = ScratchPad_Old[ScratchPadInd][1]\n",
    "        for phraseJoinNr in range(1, commasInPhrase+1):\n",
    "            scratchPadPhrase = scratchPadPhrase + ', ' + ScratchPad_Old[ScratchPadInd][1+phraseJoinNr]\n",
    "        \n",
    "        ScratchPad_Phrases.append(scratchPadPhrase)\n",
    "            \n",
    "        \n",
    "    ScratchPad_New = [[ScratchPad_Times[ind], ScratchPad_Phrases[ind]] for ind in \n",
    "                    range(0, len(ScratchPad_Times))]\n",
    "    \n",
    "    #UserKeys_New = np.concatenate((UserKeys_Times, UserKeys_Keys, UserKeys_ProgressPercent), axis = 0)\n",
    "    \n",
    "    #print(ScratchPad_New)\n",
    "    return ScratchPad_New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stimPhrasesEdit(PhraseLog, subjName):\n",
    "    \n",
    "    # Now extract phrases from the phrase file\n",
    "    phraseStim_Phrases = [item[1] for item in PhraseLog]\n",
    "    phraseStim_PhrasesReduced = sorted(set(phraseStim_Phrases), key=phraseStim_Phrases.index)\n",
    "    \n",
    "    PhraseLogReduced= list()\n",
    "    ind = -1\n",
    "    \n",
    "    for i in phraseStim_PhrasesReduced:\n",
    "        ind = ind + 1\n",
    "\n",
    "        if ind == len(phraseStim_PhrasesReduced)-1:\n",
    "            if subjName == 'sa\\Test_woChinRest\\p1':\n",
    "                PhraseLogReduced.append([phraseLog[phraseStim_Phrases.index(i)][0], i[0:31]])\n",
    "                \n",
    "            elif subjName == 'rh\\Test_wChinRest\\p1':\n",
    "                PhraseLogReduced.append([phraseLog[phraseStim_Phrases.index(i)][0], i[0:-9]])\n",
    "            else:\n",
    "                PhraseLogReduced.append([phraseLog[phraseStim_Phrases.index(i)][0], i])\n",
    "        else:\n",
    "            PhraseLogReduced.append([phraseLog[phraseStim_Phrases.index(i)][0], i])\n",
    "            \n",
    "    del PhraseLogReduced[0]\n",
    "    del PhraseLogReduced[0]\n",
    "    \n",
    "\n",
    "    \n",
    "    if PhraseLogReduced[-1][1] == 'THE EXPERIMENT IS NOW DONE':\n",
    "        del PhraseLogReduced[-1]\n",
    "        \n",
    "    if subjName == 'rh\\Test_wChinRest\\p2':\n",
    "        #print(PhraseLogReduced[2])\n",
    "        del PhraseLogReduced[2]\n",
    "        #print(PhraseLogReduced[-1])\n",
    "        del PhraseLogReduced[-1]\n",
    "        \n",
    "    #if subjName == 'sa\\Test_woChinRest\\p1' or subjName == 'rh\\Test_wChinRest\\p1':\n",
    "    #    del PhraseLogReduced[-1]\n",
    "        \n",
    "    if subjName == 'sa\\Test_woChinRest\\p2':\n",
    "        del PhraseLogReduced[3]\n",
    "        del PhraseLogReduced[1]\n",
    "        del PhraseLogReduced[0]\n",
    "        \n",
    "    return PhraseLogReduced\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scratchPadPhraseEdit(phraseUser, subjName):\n",
    "    phraseUserEnd = list()\n",
    "    \n",
    "    \n",
    "    #print(phraseUser)\n",
    "    for row_ind in range(0, len(phraseUser)):\n",
    "        if row_ind!= 0 and phraseUser[row_ind][1] == '':\n",
    "            if len(phraseUser[row_ind-1][1])>10:\n",
    "                phraseUserEnd.append(phraseUser[row_ind-1])\n",
    "                #print(phraseUser[row_ind-1])\n",
    "    \n",
    "    if subjName == 'sa\\Test_woChinRest\\p1':\n",
    "        phraseUserEnd.append([phraseUser[-1][0], phraseUser[-1][1][0:35]])\n",
    "    \n",
    "    if subjName == 'rh\\Test_wChinRest\\p1':\n",
    "        phraseUserEnd.append(phraseUser[-1])\n",
    "        \n",
    "    # remove first trial of text composition\n",
    "    del phraseUserEnd[0]\n",
    "        \n",
    "    if subjName == 'rh\\Test_wChinRest\\p2':\n",
    "        #print(phraseUserEnd[-2])\n",
    "        del phraseUserEnd[-2]\n",
    "        \n",
    "    return phraseUserEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find minimum cost and the operations that give rise to it\n",
    "def minValnInd(costOptions, flagSame):\n",
    "    operator = list()\n",
    "    unique_entries = set(costOptions)\n",
    "    valInd = { value : [ i for i, v in enumerate(costOptions) if v == value ] for value in unique_entries }\n",
    "    keyVal = list(valInd.keys())\n",
    "    min_value = min(keyVal)\n",
    "    \n",
    "    if 0 in valInd[min_value]:\n",
    "        operator.append('D')\n",
    "    if 1 in valInd[min_value]:\n",
    "        operator.append('I')\n",
    "    if 2 in valInd[min_value]:\n",
    "        if flagSame == 0:\n",
    "            operator.append('S')\n",
    "        else:\n",
    "            operator.append('N')   \n",
    "    flagSame = None    \n",
    "    return min_value, ''.join(operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the MSD, with cost of 2 for substitution and 1 for insertion and deletion\n",
    "costSub = 2\n",
    "costIns = 1\n",
    "costDel = 1\n",
    "\n",
    "def levenshteinDist(phraseIn, phraseOut):\n",
    "    \n",
    "    lenStim = len(phraseIn)\n",
    "    lenUser = len(phraseOut)\n",
    "    costMatrix = np.zeros((lenStim+1, lenUser+1), dtype=int)\n",
    "    MSDoperation = np.empty([lenStim+1, lenUser+1], dtype=\"U4\")\n",
    "    costMatrix[0,0:] = range(0, lenUser+1)\n",
    "    costMatrix[0:,0] = range(0, lenStim+1)\n",
    "    MSDoperation[0,0:] = 'I'\n",
    "    MSDoperation[0:,0] = 'D'\n",
    "    \n",
    "    for i in range(1, len(phraseIn)+1):\n",
    "        iP = i - 1\n",
    "        for j in range(1, len(phraseOut)+1):\n",
    "            jP = j - 1\n",
    "            if phraseIn[iP].lower() == phraseOut[jP].lower():\n",
    "                # Define the possible cost array\n",
    "                costOptionArray = [costMatrix[i,j-1]+costDel, costMatrix[i-1,j]+costIns, costMatrix[i-1,j-1]] \n",
    "                flagSame = 1\n",
    "            else:\n",
    "                costOptionArray = [costMatrix[i,j-1]+costDel, costMatrix[i-1,j]+costIns, costMatrix[i-1,j-1]+costSub]\n",
    "                flagSame = 0\n",
    "            costMatrix[i,j], MSDoperation[i][j] = minValnInd(costOptionArray, flagSame)\n",
    "    #print(costMatrix)\n",
    "    return costMatrix[-1,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeDwellTime(userKeys):\n",
    "    # modify userKeys to include a column of time instead of progress pct, which is dependent on the then dwell time\n",
    "    \n",
    "    timeDwell = TimeDwellOrig\n",
    "    nKey = -1\n",
    "    for key in userKeys:\n",
    "        nKey = nKey + 1\n",
    "        #print(key[1])\n",
    "        if key[1] == 'IncreaseDwellTime':\n",
    "            if float(key[2]) == 1:\n",
    "                timeDwell = timeDwell + 100\n",
    "                #print(key, timeDwell)\n",
    "        elif key[1] == 'DecreaseDwellTime':\n",
    "            #print(key[2])\n",
    "            if float(key[2]) == 1:\n",
    "                timeDwell = timeDwell - 100\n",
    "                #print(key, timeDwell)\n",
    "        else:\n",
    "            userKeys[nKey].append(str(float(key[2])*timeDwell))\n",
    "    \n",
    "    return userKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeTypingStart(userKeys):\n",
    "    # From the user keys, find when the user actually starts typing, after having looked at the phrase and all the other \n",
    "    # function keys\n",
    "    \n",
    "    timeTypingStartInd = 0\n",
    "    \n",
    "    timeTypingStartIndList = list()\n",
    "            \n",
    "    timeUserTimeInd = 0\n",
    "    \n",
    "    ind = 0\n",
    "    # Get start time of first trial\n",
    "    \n",
    "    while ind < len(userKeys):\n",
    "        #print(len(userKeys[ind][1]))\n",
    "        if len(userKeys[ind][1]) > 1:\n",
    "            ind = ind + 1\n",
    "        else:\n",
    "            timeTypingStartInd = ind\n",
    "            timeTypingStartIndList.append(ind)\n",
    "            break\n",
    "    \n",
    "    #print(timeTypingStartInd)\n",
    "    # Get every next phrase start timings\n",
    "    while ind < len(userKeys):\n",
    "        \n",
    "        if userKeys[ind][1] == 'NextPhrase' and float(userKeys[ind][2]) == 1:\n",
    "            \n",
    "            #timeTypingStartIndList.append(ind+1)\n",
    "            for ind2 in range(ind+1, len(userKeys)):\n",
    "                if len(userKeys[ind2][1]) > 1:\n",
    "                    ind = ind + 1\n",
    "                    continue\n",
    "                elif userKeys[ind2][1] == 'NextPhrase' and float(userKeys[ind][2]) == 1:\n",
    "                    ind = ind + 1\n",
    "                    continue\n",
    "                else:\n",
    "                    ind = ind2\n",
    "                    timeTypingStartIndList.append(ind)\n",
    "                    break\n",
    "                    \n",
    "        else:\n",
    "            ind = ind + 1\n",
    "            \n",
    "    #print(timeTypingStartIndList)\n",
    "    \n",
    "    return timeTypingStartIndList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phrasesTyped(your_list, timeList, userKeys, stimPhraseList, SubjName):\n",
    "    # Find entries in scratchpad (end of each trial)\n",
    "    \n",
    "    IndexNotInclude = list()\n",
    "    PhraseList = list()\n",
    "    TypingSpeed = list()\n",
    "\n",
    "    # After every complete phrase, the next phrase is empyty ''\n",
    "    for row_ind in range(0, len(your_list)):\n",
    "        if 'sa\\Test_woChinRest\\p1' in SubjName or 'rh\\Test_wChinRest\\p1' in SubjName:\n",
    "            if row_ind == len(your_list)-1:\n",
    "                IndexNotInclude.append(row_ind)\n",
    "                #print([your_list[row_ind-1][1]])\n",
    "                #print(your_list[row_ind-1][1])\n",
    "        if your_list[row_ind][1] == '':\n",
    "            if row_ind == 1:# first empty phrase needs to be not considered , at least for most of the subjects\n",
    "                #print(your_list[row_ind-1][1])\n",
    "                continue\n",
    "            if your_list[row_ind][1] == your_list[row_ind-1][1]:\n",
    "                continue\n",
    "            IndexNotInclude.append(row_ind)\n",
    "            #print([your_list[row_ind-1][1]])\n",
    "    \n",
    "    #print(len(IndexNotInclude))\n",
    "    #print('IndexNotInclude', IndexNotInclude)\n",
    "    \n",
    "    firstTrial = IndexNotInclude[0]\n",
    "    # Find the time taken for each phrase  \n",
    "    # remove the indices that are due to deleting phrase written to make the scrathpad empty\n",
    "    IndexNotInclude_Difference = [t - s for s, t in zip(IndexNotInclude, IndexNotInclude[1:])]\n",
    "    #print('IndexNotInclude_Difference', IndexNotInclude_Difference)\n",
    "    IndexNotInclude = [IndexNotInclude[ind+1] for ind in range(0,len(IndexNotInclude_Difference)) if IndexNotInclude_Difference[ind]>12]\n",
    "    IndexNotInclude_DifferenceLeft = [IndexNotInclude_Difference[ind] for ind in range(0,len(IndexNotInclude_Difference)) if IndexNotInclude_Difference[ind]>12]\n",
    "\n",
    "    #print(len(IndexNotInclude_DifferenceLeft))\n",
    "    #print('IndexNotInclude_DifferenceLeft', IndexNotInclude_DifferenceLeft)\n",
    "    \n",
    "    if 'sa\\Test_woChinRest\\p1' in SubjName:\n",
    "        IndexNotInclude = IndexNotInclude[1:]\n",
    "    if 'rh\\Test_wChinRest\\p2' in SubjName:\n",
    "        del IndexNotInclude[-2]\n",
    "        IndexNotInclude.insert(0, firstTrial)\n",
    "        \n",
    "    if 'sa\\Test_woChinRest\\p2' in SubjName:\n",
    "        IndexNotInclude.insert(0, firstTrial)\n",
    "        \n",
    "    #print('length', len(userKeys[1]))\n",
    "    \n",
    "    for indPhrase in range(0, len(IndexNotInclude)):\n",
    "        #print(indPhrase)\n",
    "        startPhrase = timeList[indPhrase]    \n",
    " \n",
    "        endPhrase = IndexNotInclude[indPhrase]-1\n",
    "        headStartPhrase,sep,tail = userKeys[startPhrase][0].partition('+')\n",
    "        headEndPhrase,sep,tail = your_list[endPhrase][0].partition('+')\n",
    "        timeTaken = datetime.datetime.strptime(re.sub('[:.T]','-',headEndPhrase[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\") - datetime.datetime.strptime(re.sub('[:.T]', '-', headStartPhrase[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\") + datetime.timedelta(0, 0, float(userKeys[startPhrase][3]))\n",
    "        phraseTyped = your_list[endPhrase][1]\n",
    "        #print(userKeys[startPhrase][0], ' to ', your_list[endPhrase][0], phraseTyped)\n",
    "        PhraseList.append([timeTaken, phraseTyped])\n",
    "            \n",
    "\n",
    "    \n",
    "    # Compute the total time for the phrase and the total number of words typed during that time (1 word = 5 characters, including space)\n",
    "    timeAdd = datetime.datetime.strptime('1000-1-1-0-00-00-000000',\"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "    characterLen = 0\n",
    "    \n",
    "    #print(IndexNotInclude)\n",
    "    timeTrial_list = list()\n",
    "    characters = list()\n",
    "    for indPhrase in range(0, len(IndexNotInclude)):\n",
    "        timeAdd += PhraseList[indPhrase][0]\n",
    "        timeTrial_list.append(PhraseList[indPhrase][0])\n",
    "        characters.append(len(PhraseList[indPhrase][1]))\n",
    "        \n",
    "    TimeTaken = (timeAdd.microsecond/1000000 + timeAdd.second)/60 + timeAdd.minute\n",
    "    \n",
    "    return characters, timeTrial_list, TimeTaken\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OptiKeyTypingTime(UserKeys):\n",
    "    \n",
    "    TimeTyping = dict()\n",
    "    \n",
    "    time1, t1, t2 = UserKeys[0][0].partition('+')\n",
    "    startTime = datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "    \n",
    "    time2, t1, t2 = UserKeys[-1][0].partition('+')\n",
    "    endTime = datetime.datetime.strptime(re.sub('[:.T]','-',time2[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "    \n",
    "    TimeTyping['startTime'] = startTime\n",
    "    TimeTyping['endTime'] = endTime\n",
    "    \n",
    "    return TimeTyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindTrialEndTimes(KeysSelected, timeTyping):\n",
    "    # function to find start and end of tasks in experiments\n",
    "    timeStartEnd = list() # format of this list will be: [startTime1, endTime1/startTime2, endTime2/startTime3, ..., endTimeN]\n",
    "    \n",
    "    timeStartEnd.append(timeTyping['startTime'])\n",
    "    \n",
    "    nTrial = 1\n",
    "    \n",
    "    for keys in KeysSelected:\n",
    "        \n",
    "        if keys[1] == 'NextPhrase':\n",
    "            time1, t1, t2 = keys[0].partition('+')\n",
    "            endTimeTrial = datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "            timeStartEnd.append(endTimeTrial)\n",
    "    \n",
    "    \n",
    "    timeStartEnd.append(timeTyping['endTime'])\n",
    "    \n",
    "    \n",
    "    return timeStartEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert list of date and time into datetime format list\n",
    "def timeConversion(timeStrList):\n",
    "    timeList = list()\n",
    "    for time in timeStrList:\n",
    "        time1, t1, t2 = time.partition('+')\n",
    "        timeList.append(datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\"))\n",
    "    return timeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will return the datetime in items which is the closest to the date pivot\n",
    "def nearestTimePoint(dates, date):\n",
    "    \n",
    "    for d in dates:\n",
    "        if d < date:\n",
    "            nearestTP = d\n",
    "        else:\n",
    "            continue\n",
    "    try: \n",
    "        nearestTP\n",
    "        nearestTPind = dates.index(nearestTP)\n",
    "    except:\n",
    "        nearestTP = 0\n",
    "        nearestTPind = -1\n",
    "        \n",
    "    return nearestTP, nearestTPind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateTimeEpochsOfTrials(TimeStartEndMixed, UserKeys):\n",
    "    # function to use list of mixed start and end times of trials and keys looked at by user to create trial epochs\n",
    "    \n",
    "    TimeEpochTrial = dict()\n",
    "    TimeEpochTrial['Start'] = list()\n",
    "    TimeEpochTrial['End'] = list()\n",
    "    \n",
    "    # Create list of times in userKeys to be able to use function 'nearestTimePoint'\n",
    "    UserKeysStrTimes = [item3[0] for item3 in UserKeys]\n",
    "    UserKeysTimes = timeConversion(UserKeysStrTimes)\n",
    "    \n",
    "    Flag_FoundSleepKey = 0 # Flag to indicate finding sleep key\n",
    "    \n",
    "    n = -1\n",
    "    for time in TimeStartEndMixed:\n",
    "        n = n + 1\n",
    "        Flag_FoundSleepKey = 0\n",
    "        \n",
    "        if n == 0: # first time is only start time for the first trial\n",
    "            TimeEpochTrial['Start'].append(time)\n",
    "            continue\n",
    "        elif n == len(TimeStartEndMixed)-1: # last time is only the end time for last trial\n",
    "            \n",
    "            TimeEpochTrial['End'].append(time)\n",
    "            \n",
    "        else: # the middle elements need to be divided into start and end\n",
    "            TimeEpochTrial['End'].append(time)\n",
    "            \n",
    "            timeCheck = time\n",
    "            \n",
    "            # find the time in userkeys. Keep going to the previous element till you reach start of selection of\n",
    "            # nextPhrase key\n",
    "            while Flag_FoundSleepKey < 1:\n",
    "                \n",
    "                nearestToTrialStartTime, nearestToTrialStartInd = nearestTimePoint(UserKeysTimes, timeCheck)\n",
    "                indCheck = nearestToTrialStartInd\n",
    "                \n",
    "                if 'NextPhrase' not in UserKeys[indCheck][1]:\n",
    "                    TimeEpochTrial['Start'].append(nearestToTrialStartTime)\n",
    "                    Flag_FoundSleepKey = 1\n",
    "                    break\n",
    "                else:\n",
    "                    indCheck = indCheck - 2 # 2 added instead of 1, to allow nearestTimePoint to find the one before this\n",
    "                    timeCheck = UserKeysTimes[indCheck]\n",
    "                    \n",
    "                \n",
    "    return TimeEpochTrial      \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DwellTimeForBaseline(UserKeys_wDwellTime):\n",
    "    \n",
    "    DwellTime = list()\n",
    "    \n",
    "    for key in UserKeys_wDwellTime:\n",
    "        if key[1] == 'NextPhrase':\n",
    "            #print('NextPhrase found at ', key[2])\n",
    "            if key[2] == 1:\n",
    "                DwellTime.append(key[3])\n",
    "                \n",
    "    return DwellTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert2ColumnSizesTo1(GazeLog):\n",
    "    # function to convert pupilsizes from 2 columns for every pupil due to comma use instead of decimal, \n",
    "    # to proper pupil sizes\n",
    "    \n",
    "    PupilLogL = list()\n",
    "    PupilLogR = list()\n",
    "    \n",
    "    PupilLogL_beforeDecimal = [item4[-5] if 'Invalid' not in item4 else 'nan' for item4 in GazeLog]\n",
    "    PupilLogL_afterDecimal = [item4[-4] if 'Invalid' not in item4 else 'nan' for item4 in GazeLog]\n",
    "    PupilLogR_beforeDecimal = [item4[-2] if 'Invalid' not in item4 else 'nan' for item4 in GazeLog]\n",
    "    PupilLogR_afterDecimal = [item4[-1] if 'Invalid' not in item4 else 'nan' for item4 in GazeLog]\n",
    "    \n",
    "    for i in range(0, len(PupilLogL_beforeDecimal)):\n",
    "        if 'Valid' not in PupilLogL_beforeDecimal[i] and 'Valid' not in PupilLogL_afterDecimal[i]:\n",
    "            if 'nan' not in PupilLogL_beforeDecimal[i] and 'nan' not in PupilLogL_afterDecimal[i]:\n",
    "                PupilLogL.append(float(PupilLogL_beforeDecimal[i]+'.'+PupilLogL_afterDecimal[i]))\n",
    "            else:\n",
    "                PupilLogL.append(np.nan)\n",
    "        else:\n",
    "            # Rarely, the pupil size is a whole number\n",
    "            PupilLogL.append(np.nan) # we will ignore the row, since there is no way of automatically knowing which - \n",
    "            # right or left eye has whole number pupil size\n",
    "    \n",
    "    for i in range(0, len(PupilLogR_beforeDecimal)):\n",
    "        if 'Valid' not in PupilLogR_beforeDecimal[i] and 'Valid' not in PupilLogR_afterDecimal[i]:\n",
    "            if 'nan' not in PupilLogR_beforeDecimal[i] and 'nan' not in PupilLogR_afterDecimal[i]:\n",
    "                PupilLogR.append(float(PupilLogR_beforeDecimal[i]+'.'+PupilLogR_afterDecimal[i]))\n",
    "            else:\n",
    "                PupilLogR.append(np.nan)\n",
    "        else:\n",
    "            # Rarely, the pupil size is a whole number\n",
    "            PupilLogL.append(np.nan) # we will ignore the row, since there is no way of automatically knowing which - \n",
    "            # right or left eye has whole number pupil size\n",
    "            \n",
    "    # if one of the pupils are nan, the other one is converted too\n",
    "    nPupil = -1\n",
    "    for pupilL in PupilLogL:\n",
    "        nPupil = nPupil + 1\n",
    "        if np.isnan(pupilL):\n",
    "            if nPupil < len(PupilLogR):\n",
    "                if not np.isnan(PupilLogR[nPupil]):\n",
    "                    PupilLogR[nPupil] = np.nan\n",
    "            else:\n",
    "                del PupilLogL[len(PupilLogR):]\n",
    "                \n",
    "    nPupil = -1\n",
    "    for pupilR in PupilLogR:\n",
    "        nPupil = nPupil + 1\n",
    "        if np.isnan(pupilR):\n",
    "            if nPupil < len(PupilLogL):\n",
    "                if not np.isnan(PupilLogL[nPupil]):\n",
    "                    PupilLogL[nPupil] = np.nan\n",
    "            else:\n",
    "                del PupilLogR[len(PupilLogL):]\n",
    "                \n",
    "    #print(len(PupilLogL), len(PupilLogR))\n",
    "    \n",
    "    return PupilLogL, PupilLogR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PupilSizeFromTrialTimes(TimeTrial, TimeGazeLog, TimeInternalGazeLog, PupilSizeLogL, PupilSizeLogR):\n",
    "    # find pupil sizes from the start and end time given\n",
    "    \n",
    "    # find start and end time in gazeLog\n",
    "    timeStart, timeStartInd = nearestTimePoint(TimeGazeLog, TimeTrial[0])\n",
    "    timeEnd, timeEndInd = nearestTimePoint(TimeGazeLog, TimeTrial[1])\n",
    "    \n",
    "    pupilSize_TrialL = PupilSizeLogL[timeStartInd: timeEndInd]\n",
    "    pupilSize_TrialR = PupilSizeLogR[timeStartInd: timeEndInd]\n",
    "    \n",
    "    TimeInternal_Trial = TimeInternalGazeLog[timeStartInd: timeEndInd]\n",
    "    \n",
    "    TimeGaze_Trial = TimeGazeLog[timeStartInd: timeEndInd]\n",
    "    \n",
    "    return pupilSize_TrialL, pupilSize_TrialR, TimeGaze_Trial, TimeInternal_Trial\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterBlinks(pupilData, timeInDatetime_trial, timeInS_Trial):\n",
    "    # filter any blinks and nan values lasting around 250ms (on average)\n",
    "    # http://faculty.washington.edu/chudler/facts.html\n",
    "   \n",
    "    # recording extra blink information - duration and frequency\n",
    "    blinkDurationList = list()\n",
    "    blinkTimeList = list()\n",
    "    blinkCount = 0\n",
    "    nonBlinkCount = 0\n",
    "    nonBlinkTimeList = list()\n",
    "    timeRemove = 0\n",
    "    \n",
    "    # blink is every nan value in the range of 100-400ms \n",
    "    # 250 ms (23 samples) before and after the blink will also be removed\n",
    "    extraBlinkSamples = 23    \n",
    "    \n",
    "    # remove single missing data, that are due to hardware error\n",
    "    missingVal_Single = np.argwhere(np.isnan(pupilData))\n",
    "    missingVal_Single = list(itertools.chain.from_iterable(missingVal_Single)) # flatten the list\n",
    "    missingVal_SingleDifference = [t - s for s, t in zip(missingVal_Single, missingVal_Single[1:])] # find difference \n",
    "    # between consecutive elements\n",
    "    missingVal_SingleDifference.insert(0, missingVal_Single[0]) # insert the first blink index in the beginning of list\n",
    "    \n",
    "    # the list missingVal_SingleDifference contains the index of the first blink, followed by the difference in the index to \n",
    "    # the next nan value\n",
    "    \n",
    "    # first remove the single nan values, which are missing data\n",
    "    eyeTracker_missingData = list() # list with index of single missing data  \n",
    "    valInd = -1\n",
    "\n",
    "    for val in missingVal_SingleDifference:\n",
    "        valInd = valInd + 1\n",
    "        if valInd == 0:\n",
    "            continue\n",
    "        if val != 1:\n",
    "            if missingVal_SingleDifference[valInd-1] !=1: # if there are 2 consecutive missing values (denoted by 2 consecutive\n",
    "                # non 1 numbers, they are added to the list of eyeTracker_missingData)\n",
    "                eyeTracker_missingData.append(sum(missingVal_SingleDifference[:valInd]))\n",
    "                \n",
    "    # remove single missing values from pupil data\n",
    "    pupilData_woSingleMissingData0 = [pupilData[ind] if ind not in eyeTracker_missingData else [] \n",
    "                                     for ind in range(0, len(pupilData))]\n",
    "    pupilData_woSingleMissingData = [x for x in pupilData_woSingleMissingData0 if x]\n",
    "    \n",
    "    # remove the times for single missing values in pupil data\n",
    "    timeList_woSingleMissingData0 = [timeInDatetime_trial[ind] if ind not in eyeTracker_missingData else [] \n",
    "                                     for ind in range(0, len(timeInDatetime_trial))]\n",
    "    timeList_woSingleMissingData = [x for x in timeList_woSingleMissingData0 if x]\n",
    "    \n",
    "#     print(len(timeList_woSingleMissingData))\n",
    "    \n",
    "    \n",
    "    timeInS_woSingleMissingData = timeInS_Trial[-1]-(len(timeList_woSingleMissingData)-len(timeInDatetime_trial))/90\n",
    "    #print(timeInS_woSingleMissingData, timeInS_Trial[-1])\n",
    "    \n",
    "    # find the nan values again from pupilData_woSingleMissingData\n",
    "    missingVal_Rest = np.argwhere(np.isnan(pupilData_woSingleMissingData))\n",
    "    missingVal_Rest = list(itertools.chain.from_iterable(missingVal_Rest))\n",
    "    missingVal_RestDifference = [t - s for s, t in zip(missingVal_Rest, missingVal_Rest[1:])]\n",
    "    missingVal_RestDifference.insert(0, missingVal_Rest[0])\n",
    "    #print(missingVal_RestDifference)\n",
    "    \n",
    "    # compile and create list of start and end of blinks\n",
    "    blink_missingData = dict()\n",
    "    blink_missingData['Start'] = list()\n",
    "    blink_missingData['End'] = list()\n",
    "    \n",
    "    valInd = -1\n",
    "    for val in missingVal_RestDifference:\n",
    "        valInd = valInd + 1\n",
    "        if val > 1:\n",
    "            \n",
    "            \n",
    "            #print('value', val)\n",
    "            # instead of appending the actual index of blink start, since 250ms before and after the blink need to be\n",
    "            # removed, it is also appended here.\n",
    "            \n",
    "            # just make sure that the additional samples do not make the index of blink go in negative\n",
    "            if sum(missingVal_RestDifference[:valInd+1])-extraBlinkSamples > 0:\n",
    "                \n",
    "                blink_missingData['Start'].append(sum(missingVal_RestDifference[:valInd+1])-extraBlinkSamples)\n",
    "            else:\n",
    "                blink_missingData['Start'].append(0)\n",
    "            \n",
    "            if valInd == 0:\n",
    "                lastBlinkStart = valInd\n",
    "                continue\n",
    "                \n",
    "            # append blink duration list\n",
    "            blinkDurationCurrent = valInd-lastBlinkStart\n",
    "            # if blink duration is greater than 1s, it is not considered to be blink anymore\n",
    "            if blinkDurationCurrent < 90: # since tobii sampling frequency is 90Hz\n",
    "                blinkCount = blinkCount + 1\n",
    "                blinkDurationList.append(blinkDurationCurrent/90)\n",
    "                blinkTimeList.append(timeList_woSingleMissingData[sum(missingVal_RestDifference[:valInd+1])])\n",
    "                lastBlinkStart = valInd\n",
    "            else:\n",
    "                # collect the time of non-blinks, that will need to be removed from trial time, to calculate \n",
    "                # blink frequency\n",
    "                #print('current blink duration', valInd, lastBlinkStart, blinkDurationCurrent)\n",
    "                timeRemove = timeRemove + blinkDurationCurrent\n",
    "                nonBlinkCount = nonBlinkCount + 1\n",
    "                nonBlinkTimeList.append(timeList_woSingleMissingData[sum(missingVal_RestDifference[:valInd+1])])\n",
    "                lastBlinkStart = valInd\n",
    "            \n",
    "            # make sure that the additional samples do not increase the index to more than the length of the pupilData\n",
    "            if sum(missingVal_RestDifference[:valInd])+extraBlinkSamples < len(pupilData_woSingleMissingData):\n",
    "                blink_missingData['End'].append(sum(missingVal_RestDifference[:valInd])+extraBlinkSamples)\n",
    "            else:\n",
    "                blink_missingData['End'].append(len(pupilData_woSingleMissingData)-1)\n",
    "#         else:\n",
    "#             # val is 1\n",
    "#             if valInd-2 > 0 and valInd+3 < len(missingVal_RestDifference):\n",
    "#                 if missingVal_RestDifference[valInd-1] > 1:\n",
    "#                     if missingVal_RestDifference[valInd+1] == 1:\n",
    "#                         if missingVal_RestDifference[valInd+2] > 1:\n",
    "#                             print(timeList_woSingleMissingData[sum(missingVal_RestDifference[:valInd+1])], \n",
    "#                                 missingVal_RestDifference[valInd-2:valInd+3])\n",
    "#                             if missingVal_RestDifference[valInd+2] > missingVal_RestDifference[valInd-1]:\n",
    "#                                 if valInd-6>0:\n",
    "#                                     print(missingVal_RestDifference[valInd-6:valInd+3])\n",
    "#                     elif missingVal_RestDifference[valInd+1] > 1:\n",
    "#                         print(timeList_woSingleMissingData[sum(missingVal_RestDifference[:valInd+1])], \n",
    "#                               missingVal_RestDifference[valInd-2:valInd+3])\n",
    "#                         if missingVal_RestDifference[valInd+2] > missingVal_RestDifference[valInd-1]:\n",
    "#                                 if valInd-6>0:\n",
    "#                                     print(missingVal_RestDifference[valInd-6:valInd+3])\n",
    "                        \n",
    "                        \n",
    "    # add the last blink index\n",
    "    # make sure that the additional samples do not increase the index to more than the length of the pupilData\n",
    "    if sum(missingVal_RestDifference)+extraBlinkSamples < len(pupilData_woSingleMissingData):\n",
    "        blink_missingData['End'].append(sum(missingVal_RestDifference)+extraBlinkSamples)\n",
    "    else:\n",
    "        blink_missingData['End'].append(len(pupilData_woSingleMissingData)-1)\n",
    "                \n",
    "    # need to create a list containing indexes that are to be removed\n",
    "    blinkIndexList = list()\n",
    "    \n",
    "#     print(len(blink_missingData['Start']), len(blink_missingData['End']))\n",
    "    \n",
    "    # remove blinks and additional data from pupil data to get filtered data\n",
    "    for indInd in range(0, len(blink_missingData['Start'])):\n",
    "        blinkIndexList.append(range(blink_missingData['Start'][indInd], blink_missingData['End'][indInd]+1))\n",
    "    # flatten the list\n",
    "    blinkIndexList = list(itertools.chain.from_iterable(blinkIndexList))\n",
    "    \n",
    "    pupilData_woRestMissingData0 = [pupilData_woSingleMissingData[ind] if ind not in blinkIndexList else [] \n",
    "                                     for ind in range(0, len(pupilData_woSingleMissingData))]\n",
    "    pupilData_filter = [x for x in pupilData_woRestMissingData0 if x]\n",
    "    \n",
    "    # remove the times for single missing values in pupil data\n",
    "    timeList_woRestMissingData0 = [timeList_woSingleMissingData[ind] if ind not in blinkIndexList else [] \n",
    "                                     for ind in range(0, len(timeList_woSingleMissingData))]\n",
    "    time_filter = [x for x in timeList_woRestMissingData0 if x]\n",
    "    \n",
    "    timeInS_Trial_filter = timeInS_woSingleMissingData-timeRemove/90\n",
    "    \n",
    "    blinkFrequency = blinkCount/timeInS_Trial_filter\n",
    "    #print('freq', blinkFrequency, timeInS_woSingleMissingData, timeRemove)\n",
    "    #print('time difference', len(timeInDatetime_trial), len(time_filter))\n",
    "    if np.nan in pupilData_filter:\n",
    "        print('nan values in filtered data')\n",
    "#         for i in enumerate(pupilData_filter):\n",
    "#             print(i)\n",
    "        \n",
    "    #print(nonBlinkCount, blinkCount, nonBlinkTimeList)\n",
    "    return pupilData_filter, time_filter, blink_missingData, blinkDurationList, blinkFrequency, blinkTimeList, timeInS_Trial_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modmax(d):\n",
    "    # modulus maxima detection\n",
    "    \n",
    "    # compute signal modulus\n",
    "    m = [0.0]*len(d)\n",
    "    for i in range(0, len(d)):\n",
    "        m[i] = math.fabs(d[i])\n",
    "    \n",
    "    # if value is larger than both neighbours , and strictly\n",
    "    # larger than either , then it is a local maximum\n",
    "    t = [0.0]*len(d)\n",
    "    for i in range(0, len(d)):\n",
    "        ll = m[i-1] if i >= 1 else m[i]\n",
    "        oo = m[i]\n",
    "        rr = m[i+1] if i < len(d)-2 else m[i]\n",
    "        if (ll <= oo and oo >= rr) and (ll < oo or oo > rr):\n",
    "            # compute magnitude\n",
    "            t[i] = math.sqrt(d[i]**2)\n",
    "        else:\n",
    "            t[i] = 0.0\n",
    "    #print(len(t))\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPupilSize(pupilData, timeData, TrialNumber):\n",
    "    \n",
    "    dataLenEqualizer = min(min(len(pupilData['Left']), len(pupilData['Right'])), len(timeData))\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.plot(timeData[0:dataLenEqualizer], pupilData['Left'][0:dataLenEqualizer], 'b')\n",
    "    ax.plot(timeData[0:dataLenEqualizer], pupilData['Right'][0:dataLenEqualizer], 'r')\n",
    "    \n",
    "    ax.set_ylabel('Absolute pupil size [in mm]')\n",
    "\n",
    "    ax.set_title(TrialNumber)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hampel(vals_orig, k, sd):\n",
    "    '''\n",
    "    vals: pandas series of values from which to remove outliers\n",
    "    k: size of window (including the sample; 7 is equal to 3 on either side of value)\n",
    "    '''\n",
    "    # Obtained from: https://stackoverflow.com/questions/46819260/filtering-outliers-how-to-make-median-based-\n",
    "    # hampel-function-faster\n",
    "    \n",
    "    #plt.plot(vals_orig)\n",
    "    \n",
    "    #Make copy so original not edited\n",
    "    vals = pd.DataFrame(vals_orig)      \n",
    "    #print(vals.isnull().any())\n",
    "    vals0 = vals.replace([np.inf, -np.inf], np.nan)\n",
    "    #vals = vals0.astype(float).fillna(method = 'backfill') # linear interpolation instead \n",
    "    #print(vals)\n",
    "    vals = vals0.astype(float).interpolate('linear', limit_direction = 'both') # linear interpolation instead of \n",
    "    # simply copying the previous value --\\ linear interpolation than cubic to not add any patterns in the data, limit direction\n",
    "    # set to both, to interpolate the nan values occuring from the start of the series\n",
    "    \n",
    "    L= 1.4826\n",
    "    rolling_median = vals.rolling(window=k, min_periods=1, center=True).median()\n",
    "    \n",
    "    #print(rolling_median)\n",
    "    difference = np.abs(rolling_median-vals)\n",
    "    median_abs_deviation = difference.rolling(k).median()\n",
    "    threshold = sd * L * median_abs_deviation\n",
    "    outlier_idx = difference>threshold\n",
    "    vals[outlier_idx] = rolling_median[outlier_idx]\n",
    "    #print(vals)\n",
    "    #print('datatype', vals.dtypes)\n",
    "    #print(vals.isnull().any())\n",
    "    #vals.plot()\n",
    "    return(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipaFunc(d):\n",
    "    # compute ipa value of pupil diameter\n",
    "    IPA = list()\n",
    "    #print(len(d.pupildata.values))\n",
    "    # obtain 2-level DWT of pupil diameter signal d\n",
    "    \n",
    "    # get signal duration (in seconds)\n",
    "    tt = ((d.timestamp.values[-1] - d.timestamp.values[0]).item())/1000000000\n",
    "\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        (cA2,cD2,cD1) = pywt.wavedec(d.pupildata.values,'sym12','symmetric', 2)\n",
    "    except ValueError:\n",
    "        print('value error in wavedec')\n",
    "        return\n",
    "        \n",
    "    # normalize by 1=2j , j = 2 for 2-level DWT\n",
    "    cA2[:] = [x / math.sqrt(4.0) for x in cA2]\n",
    "    cD1[:] = [x / math.sqrt(2.0) for x in cD1]\n",
    "    cD2[:] = [x / math.sqrt(4.0) for x in cD2]\n",
    "    \n",
    "    # detect modulus maxima , see Listing 2\n",
    "    cD2m = modmax(cD2)\n",
    "    #print(len(cD2m))\n",
    "    \n",
    "    # threshold using universal threshold l_univ = s*sqrt(2logn)\n",
    "    # where s is the standard deviation of the noise\n",
    "    luniv = np.std(cD2m) * math.sqrt(2.0*np.log2(len(cD2m)))\n",
    "    cD2t = pywt.threshold(cD2m ,luniv,mode=\"hard\")\n",
    "        \n",
    "    # compute IPA\n",
    "    ctr = 0\n",
    "    for i in range(0, len(cD2t)):\n",
    "        if math.fabs(cD2t[i]) > 0: ctr += 1\n",
    "        #IPA = float(ctr)/tt\n",
    "        # maybe each pupil data has an IPA?\n",
    "    IPA = (float(ctr)/tt)\n",
    "    \n",
    "    return IPA, cD2m, cD2t, cD2, cD1, cA2, tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindAndPlotPupilSizeForEpoch(GazeLog, DwellTimes_ForBaseline, TimeEpochTrial, KeysSelected):\n",
    "    # function that uses the list of start and end trial times to find the pupil sizes for those trials and plots them\n",
    "    \n",
    "    # first create a list of times in gaze log\n",
    "    timeStrGazeLog = [item3[0] for item3 in GazeLog]\n",
    "    # convert the list of strings to datetime formats\n",
    "    timeGazeLog = timeConversion(timeStrGazeLog)\n",
    "    \n",
    "    # internal time, to depict seconds\n",
    "    timeInternalGazeLog = [float(item3[1]) for item3 in GazeLog]\n",
    "    \n",
    "    # extract pupil sizes in decimals from the strange 2 columns for every pupil\n",
    "    pupilLogL, pupilLogR = Convert2ColumnSizesTo1(GazeLog)\n",
    "    \n",
    "    ipaList = list()\n",
    "    timeOfGaze_TrialList = list()\n",
    "    \n",
    "    \n",
    "    # Keys Selected and the timing\n",
    "    timeStrKeysSelected = [item[0] for item in KeysSelected]\n",
    "    timeKeysSelected = timeConversion(timeStrKeysSelected)\n",
    "    \n",
    "    mistakesCorrectedPerTrial = list()\n",
    "    \n",
    "    blinkDurationList = list()\n",
    "    blinkDurationAverageList = list()\n",
    "    blinkTimeList = list()\n",
    "    blinkFrequencyList = list()\n",
    "    timeInS_List = list()\n",
    "    pupilMean_Absolute = list()\n",
    "    pupilMean_Relative = list()\n",
    "    interBlinkDurationList = list()\n",
    "    \n",
    "    # for every epoch, plot the pupil size\n",
    "    for trialNr in range(0, len(timeEpochTrial['Start'])):\n",
    "        if trialNr == 0:\n",
    "            continue\n",
    "        # find pupil sizes for the trial\n",
    "        pupilSizeL_Trial, pupilSizeR_Trial, timeGaze_Trial, timeInternal_Trial = PupilSizeFromTrialTimes(\n",
    "            [TimeEpochTrial['Start'][trialNr], TimeEpochTrial['End'][trialNr]], timeGazeLog, \n",
    "                                timeInternalGazeLog, pupilLogL, pupilLogR)\n",
    "        \n",
    "        pupilSize_Trial = dict()\n",
    "        pupilSize_Filter = dict()\n",
    "        pupilSize_woBlink = dict()\n",
    "        \n",
    "        # find difference in consecutive elements of internal time\n",
    "        timeInternalDifference = [t - s for s, t in zip(timeInternal_Trial, timeInternal_Trial[1:])]\n",
    "        # divide by 1000 to make it s\n",
    "        timeOfGaze_Trial = [sum(timeInternalDifference[:i])/1000000 for i in range(1,len(timeInternalDifference))]\n",
    "\n",
    "        # some trials were skipped, because the sentence was written before. If the time of trial is less than\n",
    "        # 10s, the trial is skipped\n",
    "        if timeOfGaze_Trial[-1] < 20:\n",
    "            print('trial number ', trialNr+1, 'with', timeOfGaze_Trial[-1], 's will be skipped')\n",
    "            continue\n",
    "        \n",
    "        pupilSize_Trial['Left'] = pupilSizeL_Trial\n",
    "        pupilSize_Trial['Right'] = pupilSizeR_Trial\n",
    "        \n",
    "        #if trialNr == 4:\n",
    "        #    for i in range(0, len(pupilSizeL_Trial)):\n",
    "        #        print(pupilSizeL_Trial[i], pupilSizeR_Trial[i])\n",
    "            \n",
    "        #print('Trial', len(pupilSizeL_Trial), len(pupilSizeR_Trial))\n",
    "        \n",
    "        # filter the blinks\n",
    "        pupilSizeL_woBlink, time_filter, missingPupilData, blinkDuration, blinkFrequency, blinkTimeList, timeInS_filter = filterBlinks(pupilSizeL_Trial, timeGaze_Trial, timeOfGaze_Trial)\n",
    "        pupilSizeR_woBlink, time_filter, missingPupilData, blinkDuration, blinkFrequency, blinkTimeList, timeInS_filter = filterBlinks(pupilSizeR_Trial, timeGaze_Trial, timeOfGaze_Trial)\n",
    "        \n",
    "#         print(trialNr, blinkFrequency)\n",
    "        #print(trialNr, blinkDuration)\n",
    "\n",
    "        # time of trial\n",
    "        timeInS_List.append(timeInS_filter)\n",
    "        #print(trialNr, timeInS_filter)\n",
    "        \n",
    "        #print(index_blinkEndL)\n",
    "        #print(index_blinkEndR)\n",
    "        pupilSize_woBlink['Left'] = pupilSizeL_woBlink\n",
    "        pupilSize_woBlink['Right'] = pupilSizeR_woBlink\n",
    "        \n",
    "        #print('After blink', len(pupilSizeL_woBlink), len(pupilSizeR_woBlink))\n",
    "        # Hampel filter to remove the outliers\n",
    "        winSize = 25\n",
    "        pupilSizeL_filter = hampel(pupilSizeL_woBlink, winSize, 3)\n",
    "        pupilSizeR_filter = hampel(pupilSizeR_woBlink, winSize, 3)\n",
    "\n",
    "        pupilSize_Filter['Left'] = pupilSizeL_filter.values.tolist()\n",
    "        pupilSize_Filter['Right'] = pupilSizeR_filter.values.tolist()\n",
    "        \n",
    "        pupilSizeL_filterList = [i[0] for i in pupilSizeL_filter.values]\n",
    "        pupilSizeR_filterList = [i[0] for i in pupilSizeR_filter.values]\n",
    "        \n",
    "        #print('filter', len(pupilSizeL_filterList), len(pupilSizeR_filterList))\n",
    "        RLCorrelation = np.corrcoef(pupilSizeL_filterList, pupilSizeR_filterList)\n",
    "        if RLCorrelation[0][1] < 0.8:\n",
    "            print('correlation between left and right:  ', RLCorrelation)\n",
    "        \n",
    "        # Relative Pupil Size Calculation \n",
    "        # First find baseline pupil size, which is the time when looking at NextPhrase key\n",
    "        Samples_ForBaseline = int((int(DwellTimes_ForBaseline[trialNr-1][:-2])*90)/1000) # Number of samples of looking at key depend on\n",
    "        \n",
    "        #print(DwellTimes_ForBaseline[trialNr-1])\n",
    "        \n",
    "        # dwell time\n",
    "        pupilL_baseline = np.mean(pupilSizeL_filterList[0:Samples_ForBaseline])\n",
    "        pupilR_baseline = np.mean(pupilSizeR_filterList[0:Samples_ForBaseline])\n",
    "        \n",
    "        pupilL_Relative = [pupil/pupilL_baseline for pupil in pupilSizeL_filterList]\n",
    "        pupilR_Relative = [pupil/pupilR_baseline for pupil in pupilSizeR_filterList]\n",
    "        \n",
    "        # average of whole trial\n",
    "        #pupilL_avgRelative.append(np.mean(pupilL_Relative))\n",
    "        #pupilR_avgRelative.append(np.mean(pupilR_Relative))\n",
    "        \n",
    "        # average of right and left\n",
    "        pupilAvg_Relative = [((pupilL_Relative[i] + pupilR_Relative[i])/2) for i in range(0, min(len(pupilL_Relative), len(pupilR_Relative)))]\n",
    "        \n",
    "        pupilAvg_Absolute = [((pupilSizeL_filterList[i] + pupilSizeR_filterList[i])/2) for i in range(0, min(len(pupilSizeL_filterList), len(pupilSizeR_filterList)))]\n",
    "        \n",
    "        pupilLog_filter_wTime_Tuple = list(zip(time_filter, pupilAvg_Absolute))\n",
    "        pupilAndTimeDf =  pd.DataFrame(pupilLog_filter_wTime_Tuple, columns=['timestamp','pupildata'])\n",
    "        \n",
    "        # compute IPA for the trial\n",
    "        ipaVal, coeff_modmax, coeff_hard, coeff_D2, coeff_D1, coeff_A, timePeriodTrial = ipaFunc(pupilAndTimeDf)\n",
    "        \n",
    "        #print(trialNr+1, ipaVal, timeOfGaze_Trial[-1])\n",
    "        \n",
    "        ipaList.append(ipaVal)\n",
    "        timeOfGaze_TrialList.append(timeOfGaze_Trial[-1])\n",
    "        \n",
    "        # find the inter blink duration\n",
    "        interBlinkDuration = list()\n",
    "        for i in range(1,len(blinkTimeList)):\n",
    "            interBlinkDuration.append((blinkTimeList[i]-blinkTimeList[i-1]).total_seconds())\n",
    "        if len(interBlinkDuration) > 1:\n",
    "            #print(np.median(interBlinkDuration))\n",
    "            interBlinkDurationList.append(np.median(interBlinkDuration))\n",
    "        else:\n",
    "            if interBlinkDuration:\n",
    "                #print(interBlinkDuration)\n",
    "                interBlinkDurationList.append(interBlinkDuration[0])\n",
    "            else:\n",
    "                interBlinkDurationList.append(0)\n",
    "        \n",
    "        blinkDurationList.append(blinkDuration)\n",
    "        blinkFrequencyList.append(blinkFrequency)\n",
    "        \n",
    "        \n",
    "        if len(blinkDuration)>0:\n",
    "            blinkDurationAverageList.append(np.mean(blinkDuration))\n",
    "        else:\n",
    "            blinkDurationAverageList.append(0)\n",
    "         \n",
    "        pupilMean_Absolute.append(np.mean(pupilAvg_Absolute))\n",
    "        pupilMean_Relative.append(np.mean(pupilAvg_Relative))\n",
    "        \n",
    "        \n",
    "        timeKeysSelectedStart, timeKeysSelectedStartInd = nearestTimePoint(timeKeysSelected, TimeEpochTrial['Start'][trialNr])\n",
    "        timeKeysSelectedEnd, timeKeysSelectedEndInd = nearestTimePoint(timeKeysSelected, TimeEpochTrial['End'][trialNr])\n",
    "        \n",
    "        mistakesCorrectedCount = 0\n",
    "        for i in range(timeKeysSelectedStartInd, timeKeysSelectedEndInd+1):\n",
    "            if KeysSelected[i][1] == 'BackOne' or KeysSelected[i][1] == 'BackMany':\n",
    "                mistakesCorrectedCount = mistakesCorrectedCount + 1\n",
    "                \n",
    "        mistakesCorrectedPerTrial.append(mistakesCorrectedCount/timeOfGaze_Trial[-1])\n",
    "        \n",
    "    return ipaList, pupilMean_Absolute, pupilMean_Relative, timeOfGaze_TrialList, blinkDurationList, blinkDurationAverageList, blinkFrequencyList, interBlinkDurationList, timeInS_List, mistakesCorrectedPerTrial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject bh\\Test_wChinRest\n",
      "trial number  11 with 4.596693 s will be skipped\n",
      "subject bh\\Test_woChinRest\n",
      "trial number  11 with 7.339166 s will be skipped\n",
      "subject ph\\Test_wChinRest\n",
      "trial number  11 with 18.00399 s will be skipped\n",
      "subject ph\\Test_woChinRest\n",
      "correlation between left and right:   [[1.         0.79152325]\n",
      " [0.79152325 1.        ]]\n",
      "subject pt\\Test_wChinRest\n",
      "subject pt\\Test_woChinRest\n",
      "trial number  11 with 17.47867 s will be skipped\n",
      "subject rh\\Test_wChinRest\\p1\n",
      "subject rh\\Test_wChinRest\\p2\n",
      "trial number  4 with 10.770031 s will be skipped\n",
      "trial number  10 with 14.989218 s will be skipped\n",
      "subject rh\\Test_woChinRest\n",
      "correlation between left and right:   [[1.         0.79354619]\n",
      " [0.79354619 1.        ]]\n",
      "trial number  11 with 10.476645 s will be skipped\n",
      "subject sa\\Test_wChinRest\n",
      "subject sa\\Test_woChinRest\\p1\n",
      "subject sa\\Test_woChinRest\\p2\n",
      "trial number  3 with 8.449478 s will be skipped\n",
      "trial number  5 with 8.926912 s will be skipped\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "blinkFrequency_Total = list()\n",
    "blinkDurationAverage_Total = list()\n",
    "\n",
    "timeTrial_Total = list()\n",
    "blinkDuration_Total = list()\n",
    "interBlinkInterval_Total = list()\n",
    "\n",
    "ipa_Total = list()\n",
    "pupilMeanAbsolute_Total = list()\n",
    "pupilMeanRelative_Total = list()\n",
    "\n",
    "scoreLIX_Total = list()\n",
    "scoreComplexity_Total = list()\n",
    "scoreDifficulty_Total = list()\n",
    "scoreSumOfScores_Total = list()\n",
    "scoreLen_Total = list()\n",
    "\n",
    "typingSpeed_Total = list()\n",
    "characters_Total = list()\n",
    "timeTypingTrial_Total = list()\n",
    "errorRate_Total = list()\n",
    "mistakeTrialList_Total = list()\n",
    "errorTrial_Total = list()\n",
    "\n",
    "mistakesCorrectedList_Total = list()\n",
    "\n",
    "subjName = r'C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data'\n",
    "j = 0\n",
    "flagFirstSubj = 0\n",
    "pupilData = dict()\n",
    "pupilData['RLCorrelation'] = []\n",
    "\n",
    "# extract self-reported scores list and LIX score of given sentence\n",
    "file_name = r'C:/DTU/Data/201812_ExptToCheckMovementEffect/Data/Scores.xlsx'\n",
    "\n",
    "\n",
    "#testNr = 'Test_wChinRest'\n",
    "for root, dirs, subfolder in os.walk(subjName):\n",
    "    scoreDifficult = list()\n",
    "    scoreMedium = list()\n",
    "    scoreEasy = list()\n",
    "    # Semantic modeling score from afinn\n",
    "    afinnDifficult = list()\n",
    "    afinnMedium = list()\n",
    "    afinnEasy = list()\n",
    "\n",
    "    if not dirs:\n",
    "        \n",
    "        if 'tb' in root or 'trial' in root:\n",
    "            continue\n",
    "            \n",
    "        userKeys = None\n",
    "        gazeLog = None\n",
    "        keysSelected = None\n",
    "        \n",
    "       \n",
    "        \n",
    "        for file in subfolder:\n",
    "            if fnmatch.fnmatch(file, 'ScratchPadLog*'):\n",
    "                try:\n",
    "                    fScratchPad = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerScratchPad = csv.reader(fScratchPad)\n",
    "                    scratchPad = list(readerScratchPad)\n",
    "                except:\n",
    "                    if fScratchPad is not None:\n",
    "                        fScratchPad.close()\n",
    "                    else:\n",
    "                        print('error in opening the scratchpad log file')\n",
    "                        \n",
    "            if fnmatch.fnmatch(file, 'phrase*'):\n",
    "                try:\n",
    "                    fPhraseLog = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerPhraseLog = csv.reader(fPhraseLog)\n",
    "                    phraseLog = list(readerPhraseLog)    \n",
    "                        \n",
    "                except:\n",
    "                    if fPhraseLog is not None:\n",
    "                        print('closing')\n",
    "                        fPhraseLog.close()\n",
    "                    else:\n",
    "                        print('error in opening the phrase log file')\n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'ReplacementPhraseLog.csv'):\n",
    "                \n",
    "                try:\n",
    "                    fPhraseLog = open(root + '\\\\' + file)\n",
    "                    readerPhraseLog = csv.reader(fPhraseLog)\n",
    "                    phraseLog = list(readerPhraseLog)\n",
    "                        \n",
    "                except:\n",
    "                    if fPhraseLog is not None:\n",
    "                        print('closing')\n",
    "                        fPhraseLog.close()\n",
    "                    else:\n",
    "                        print('error in opening the replacement phrase log file')\n",
    "                    \n",
    "                    \n",
    "            if fnmatch.fnmatch(file, 'user_looks*'):\n",
    "                try:\n",
    "                    \n",
    "                    fUserKey = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerUserKey = csv.reader(fUserKey)\n",
    "                    userKeys = list(readerUserKey)\n",
    "                    \n",
    "                    userKeys.remove(userKeys[0])\n",
    "                except:\n",
    "                    if fUserKey is not None:\n",
    "                        \n",
    "                        fUserKey.close()\n",
    "                    else:\n",
    "                        print('error in opening the user looks at log file')\n",
    "            \n",
    "            elif fnmatch.fnmatch(file, 'KeySelection*'):\n",
    "                try:\n",
    "                    \n",
    "                    fKeysSelected = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerKeysSelected = csv.reader(fKeysSelected)\n",
    "                    keysSelected = list(readerKeysSelected)\n",
    "                    \n",
    "                    keysSelected.remove(keysSelected[0])\n",
    "                except:\n",
    "                    if fKeysSelected is not None:\n",
    "                        \n",
    "                        fKeysSelected.close()\n",
    "                    else:\n",
    "                        print('error in opening the KeySelection log file')\n",
    "            \n",
    "            elif fnmatch.fnmatch(file, 'tobiiGazeLog*'):\n",
    "                try:\n",
    "                    fGazeLog = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerGazeLog = csv.reader(fGazeLog)\n",
    "                    gazeLog = list(readerGazeLog)\n",
    "                    \n",
    "                    gazeLog.remove(gazeLog[0]) # would not matter much even if the first row was not labels\n",
    "                    gazeLog.remove(gazeLog[-1])\n",
    "\n",
    "                except:\n",
    "                    if fGazeLog is not None:\n",
    "                        fGazeLog.close()\n",
    "                    else:\n",
    "                        print('error in opening the gaze log file')\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "                # if all these lists exist\n",
    "            if userKeys is None or keysSelected is None or gazeLog is None or scratchPad is None or phraseLog is None:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                a = re.compile('(?<=ExptToCheckMovementEffect\\\\\\\\Data\\\\\\\\)(.*)(?=\\\\\\\\2018-1)')\n",
    "                subjName = a.findall(root)[0]\n",
    "                print('subject', subjName)\n",
    "                \n",
    "                sheet_to_df_map = pd.read_excel(file_name, sheet_name=subjName[0:2])\n",
    "                \n",
    "                testNr_re = re.compile('(?<=\\\\\\Test)(.*)')\n",
    "                testNr = 'Test' + testNr_re.findall(subjName)[0]\n",
    "                if 'rh\\Test_wChinRest' in subjName or 'sa\\Test_woChinRest' in subjName:\n",
    "                    testNr = 'Test' + testNr_re.findall(subjName)[0][:-3]\n",
    "                #print(testNr)\n",
    "                columnName1 = testNr + '_SumOfScores'\n",
    "                columnName2 = testNr + '_LIX'\n",
    "                columnName3 = testNr + '_Complexity'\n",
    "                columnName4 = testNr + '_Difficulty'\n",
    "                columnName5 = testNr + '_AfinnScore'\n",
    "                \n",
    "                \n",
    "                # find _wChinRest of difficulty score\n",
    "                scoresSumOfScores = sheet_to_df_map[columnName1]\n",
    "                scoresSumOfScores = scoresSumOfScores[1:]\n",
    "\n",
    "                # find _wChinRest of SumOfScores score\n",
    "                scoresLIX = sheet_to_df_map[columnName2]\n",
    "                scoresLIX = scoresLIX[1:]\n",
    "                \n",
    "                # find _wChinRest of SumOfScores score\n",
    "                scoresComplexity = sheet_to_df_map[columnName3]\n",
    "                scoresComplexity = scoresComplexity[1:]\n",
    "                \n",
    "                # find _wChinRest of SumOfScores score\n",
    "                scoresDifficulty = sheet_to_df_map[columnName4]\n",
    "                scoresDifficulty = scoresDifficulty[1:]\n",
    "                \n",
    "                # find affin score\n",
    "                scoresAfinn = sheet_to_df_map[columnName5]\n",
    "                scoresAfinn = scoresAfinn[1:]\n",
    "                \n",
    "                if 'sa\\Test_woChinRest\\p1' in subjName or subjName == 'rh\\Test_wChinRest\\p1':\n",
    "                    scratchPad = scratchPad[:-1]\n",
    "                \n",
    "                # fix userKeys due to comma related file changes\n",
    "                scratchPad_new = FixScratchPad(scratchPad)\n",
    "            \n",
    "                #print(scratchPad_new)\n",
    "                # fix userKeys due to comma related file changes\n",
    "                phraseLog_new = FixScratchPad(phraseLog)\n",
    "                \n",
    "                phraseLog_reduced = stimPhrasesEdit(phraseLog_new, subjName)\n",
    "                \n",
    "                phraseUserEnd = scratchPadPhraseEdit(scratchPad_new, subjName)\n",
    "                \n",
    "                if 'rh\\Test_wChinRest\\p2' in subjName or 'sa\\Test_woChinRest\\p2' in subjName:\n",
    "                    \"Do not modify distance\"\n",
    "                else:\n",
    "                    dist = 0\n",
    "                    \n",
    "                scoreLen = list()\n",
    "                mistakeTrialList = list()\n",
    "                if len(phraseUserEnd)==len(phraseLog_reduced):\n",
    "                    for n in range(0,len(phraseLog_reduced)):\n",
    "                        scoreLen.append(len(phraseLog_reduced[n][1]))\n",
    "                        #print(phraseLog_reduced[n][1], phraseUserEnd[n][1])\n",
    "                        #print((levenshteinDist(phraseLog_reduced[n][1], phraseUserEnd[n][1]))/max(len(phraseLog_reduced[n][1]),len(phraseUserEnd[n][1])))\n",
    "                        mistakeTrialList.append((levenshteinDist(phraseLog_reduced[n][1], phraseUserEnd[n][1]))/max(len(phraseLog_reduced[n][1]),len(phraseUserEnd[n][1])))\n",
    "                        dist = dist + (levenshteinDist(phraseLog_reduced[n][1], phraseUserEnd[n][1]))/max(len(phraseLog_reduced[n][1]),len(phraseUserEnd[n][1]))\n",
    "                else:\n",
    "                    print('Unequal stimulation and user-generated phrases')\n",
    "    \n",
    "                if subjName == 'sa\\Test_woChinRest\\p2':\n",
    "                    userKeys = userKeys[:-1]\n",
    "                \n",
    "                stimPhraseList = [key[1] for key in phraseLog_new]\n",
    "                \n",
    "                # fix userKeys due to comma related file changes\n",
    "                userKeys_new = FixUserKeys(userKeys)\n",
    "                \n",
    "                # find dwell time of typing\n",
    "                userKeys_wDwellTime = ComputeDwellTime(userKeys_new)\n",
    "                \n",
    "                timeList = timeTypingStart(userKeys_new)\n",
    "                #print(timeList)\n",
    "                \n",
    "                if 'sa\\Test_wChinRest\\p1' in subjName:\n",
    "                    characters, timeTypingTrial, timeTypingTotal = phrasesTyped(scratchPad_new, timeList[2:], userKeys_wDwellTime, stimPhraseList, subjName) \n",
    "                elif 'sa\\Test_woChinRest\\p2' in subjName or 'rh\\Test_wChinRest\\p2' in subjName:\n",
    "                    characters, timeTypingTrial, timeTypingTotal = phrasesTyped(scratchPad_new, timeList, userKeys_wDwellTime, stimPhraseList, subjName) \n",
    "                else:\n",
    "                    characters, timeTypingTrial, timeTypingTotal = phrasesTyped(scratchPad_new, timeList[1:], userKeys_wDwellTime, stimPhraseList, subjName) \n",
    "            \n",
    "                \n",
    "                # find start time of typing\n",
    "                timeTyping = OptiKeyTypingTime(userKeys_new)\n",
    "                \n",
    "                # for some of the subjects, the data was not completely collected\n",
    "                if subjName == 'sa\\Test_woChinRest\\p1' or subjName == 'rh\\Test_wChinRest\\p1':\n",
    "                    del keysSelected[-1]\n",
    "                \n",
    "                # divide complete data into epochs of phrases\n",
    "                timeStartEndMixed = FindTrialEndTimes(keysSelected, timeTyping)\n",
    "                \n",
    "                # create trial time epoch using the list of start/end times of trial and userKeys, to make sure that \n",
    "                # Sleep is completely there in every trial, to allow for baseline\n",
    "                timeEpochTrial = CreateTimeEpochsOfTrials(timeStartEndMixed, userKeys_new)\n",
    "                #print(timeEpochTrial)\n",
    "                \n",
    "                dwellTimes_ForBaseline = DwellTimeForBaseline(userKeys_wDwellTime)\n",
    "                \n",
    "                \n",
    "                # find and plot pupil size for every trial\n",
    "                ipaList, pupilMeanAbsolute, pupilMeanRelative, timeOfTrialList, blinkDuration, blinkDurationAverage, blinkFrequency, interBlinkInterval, time_trialList, mistakesCorrectedList = FindAndPlotPupilSizeForEpoch(gazeLog, dwellTimes_ForBaseline, timeEpochTrial, keysSelected)\n",
    "                \n",
    "                if 'sa\\Test_woChinRest' in subjName or 'rh\\Test_wChinRest' in subjName:\n",
    "                    if 'p1' in root:\n",
    "                        ipaList1 = ipaList\n",
    "                        pupilMeanAbsolute1 = pupilMeanAbsolute\n",
    "                        pupilMeanRelative1 = pupilMeanRelative\n",
    "                        \n",
    "                        blinkDurationAverage1 = blinkDurationAverage\n",
    "                        blinkFrequency1 = blinkFrequency\n",
    "                        blinkDuration1 = blinkDuration\n",
    "                        interBlinkInterval1 = interBlinkInterval\n",
    "                        \n",
    "                        characters1 = characters\n",
    "                        timeTypingTotal1 = timeTypingTotal\n",
    "                        timeTypingTrial1 = timeTypingTrial\n",
    "                        \n",
    "                        dist1 = dist\n",
    "                        mistakeTrialList1 = mistakeTrialList\n",
    "                        \n",
    "                        mistakesCorrectedList1 = mistakesCorrectedList\n",
    "                        \n",
    "                        scoreLen1 = scoreLen\n",
    "                        continue\n",
    "                        \n",
    "                        #print('1', ipaList1)\n",
    "                    else:\n",
    "                        if 'sa\\Test_woChinRest' in subjName:\n",
    "                            ipaList2 = ipaList[1:]\n",
    "                            pupilMeanAbsolute2 = pupilMeanAbsolute[1:]\n",
    "                            pupilMeanRelative2 = pupilMeanRelative[1:]\n",
    "                            \n",
    "                            blinkDurationAverage2 = blinkDurationAverage[1:]\n",
    "                            blinkFrequency2 = blinkFrequency[1:]\n",
    "                            blinkDuration2 = blinkDuration[1:]\n",
    "                            interBlinkInterval2 = interBlinkInterval[1:]\n",
    "                            \n",
    "                            print(len(characters))\n",
    "                            characters2 = characters\n",
    "                            timeTypingTotal2 = timeTypingTotal\n",
    "                            timeTypingTrial2 = timeTypingTrial\n",
    "                            \n",
    "                            mistakeTrialList2 = mistakeTrialList\n",
    "                            dist2 = dist\n",
    "                            mistakesCorrectedList2 = mistakesCorrectedList\n",
    "                            scoreLen2 = scoreLen\n",
    "                            \n",
    "                        else:\n",
    "                            ipaList2 = ipaList\n",
    "                            pupilMeanAbsolute2 = pupilMeanAbsolute\n",
    "                            pupilMeanRelative2 = pupilMeanRelative\n",
    "                            \n",
    "                            blinkDurationAverage2 = blinkDurationAverage\n",
    "                            blinkFrequency2 = blinkFrequency\n",
    "                            blinkDuration2 = blinkDuration\n",
    "                            interBlinkInterval2 = interBlinkInterval\n",
    "                            \n",
    "                            characters2 = characters\n",
    "                            timeTypingTotal2 = timeTypingTotal\n",
    "                            timeTypingTrial2 = timeTypingTrial\n",
    "                            \n",
    "                            mistakeTrialList2 = mistakeTrialList\n",
    "                            dist2 = dist\n",
    "                            \n",
    "                            mistakesCorrectedList2 = mistakesCorrectedList\n",
    "                            scoreLen2 = scoreLen\n",
    "                            \n",
    "                            \n",
    "                    ipaList = ipaList1 + ipaList2\n",
    "                    pupilMeanAbsolute = pupilMeanAbsolute1 + pupilMeanAbsolute2\n",
    "                    pupilMeanRelative = pupilMeanRelative1 + pupilMeanRelative2\n",
    "                    \n",
    "                    blinkFrequency = blinkFrequency1 + blinkFrequency2\n",
    "                    blinkDurationAverage = blinkDurationAverage1 + blinkDurationAverage2\n",
    "                    blinkDuration = blinkDuration1 + blinkDuration2\n",
    "                    interBlinkInterval = interBlinkInterval1 + interBlinkInterval2\n",
    "                                        \n",
    "                    characters = characters1 + characters2\n",
    "                    timeTypingTotal = timeTypingTotal1 + timeTypingTotal2\n",
    "                    timeTypingTrial = timeTypingTrial1 + timeTypingTrial2\n",
    "                    \n",
    "                    mistakeTrialList = mistakeTrialList1 + mistakeTrialList2\n",
    "                    dist = dist1 + dist2\n",
    "                    \n",
    "                    scoreLen = scoreLen1 + scoreLen2\n",
    "                    mistakesCorrectedList = mistakesCorrectedList1 + mistakesCorrectedList2\n",
    "                    \n",
    "                #print(timeTypingTotal)\n",
    "                typingSpeed = sum(characters)/(5*timeTypingTotal)\n",
    "                #print(typingSpeed)\n",
    "                   \n",
    "                #if 'sa\\Test_woChinRest\\p2' in subjName or 'rh\\Test_wChinRest\\p2' in subjName:\n",
    "                #    errorRate = dist/8\n",
    "                #    #print('LESS TRIALS')\n",
    "                #else:\n",
    "                #    errorRate = dist/9\n",
    "                \n",
    "                errorRate = dist/9\n",
    "                \n",
    "                ipa_Total.append(ipaList)\n",
    "                pupilMeanAbsolute_Total.append(pupilMeanAbsolute)\n",
    "                pupilMeanRelative_Total.append(pupilMeanRelative)\n",
    "                \n",
    "                blinkFrequency_Total.append(blinkFrequency)\n",
    "                blinkDurationAverage_Total.append(blinkDurationAverage)\n",
    "                blinkDuration_Total.append(blinkDuration)\n",
    "                interBlinkInterval_Total.append(interBlinkInterval)\n",
    "                \n",
    "                    \n",
    "                scoreLIX_Total.append(scoresLIX)\n",
    "                scoreComplexity_Total.append(scoresComplexity)\n",
    "                scoreDifficulty_Total.append(scoresDifficulty)\n",
    "                scoreSumOfScores_Total.append(scoresSumOfScores)\n",
    "                \n",
    "                scoreLen_Total.append(scoreLen)\n",
    "                mistakesCorrectedList_Total.append(mistakesCorrectedList)\n",
    "                \n",
    "                #print(len(timeTypingTrial))\n",
    "                #print(len(characters))\n",
    "                characters_Total.append(characters)\n",
    "                #timeTyping_Total.append(timeTypingTotal)\n",
    "                timeTypingTrial_Total.append(timeTypingTrial)\n",
    "                typingSpeed_Total.append(typingSpeed)\n",
    "                \n",
    "                errorRate_individialList = list()\n",
    "                for i in range(0, len(mistakeTrialList)):\n",
    "                    errorRate_individialList.append(mistakeTrialList[i]/timeTypingTrial[i].total_seconds())\n",
    "                \n",
    "                #print(len(mistakeTrialList))\n",
    "                mistakeTrialList_Total.append(errorRate_individialList)\n",
    "                #print(errorRate)\n",
    "                errorRate_Total.append(errorRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# individual typing speeds\n",
    "\n",
    "typingSpeedTrial_Total = list()\n",
    "\n",
    "for subjInd in range(0, len(characters_Total)):\n",
    "    trialInd = -1\n",
    "    typingSpeedSubj = list()\n",
    "    for characterLen in characters_Total[subjInd]:\n",
    "        trialInd = trialInd + 1\n",
    "        typingSpeedSubj.append(characterLen/(timeTypingTrial_Total[subjInd][trialInd].total_seconds()/60))\n",
    "        \n",
    "    typingSpeedTrial_Total.append(typingSpeedSubj)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreComplexity_difficult = list()\n",
    "scoreDifficulty_difficult = list()\n",
    "\n",
    "            \n",
    "blinkFrequency_difficult = list()\n",
    "blinkDurationAverage_difficult = list()\n",
    "interBlinkInterval_difficult = list()\n",
    "\n",
    "ipa_difficult = list()\n",
    "pupilMeanAbsolute_difficult = list()\n",
    "pupilMeanRelative_difficult = list()\n",
    "\n",
    "typingSpeed_difficult = list()\n",
    "errorRate_difficult = list()\n",
    "mistakeCorrected_difficult = list()\n",
    "timeTyping_difficult = list()\n",
    "\n",
    "scoreComplexity_easy = list()\n",
    "scoreDifficulty_easy = list()\n",
    "\n",
    "            \n",
    "blinkFrequency_easy = list()\n",
    "blinkDurationAverage_easy = list()\n",
    "interBlinkInterval_easy = list()\n",
    "\n",
    "ipa_easy = list()\n",
    "pupilMeanAbsolute_easy = list()\n",
    "pupilMeanRelative_easy = list()\n",
    "\n",
    "typingSpeed_easy = list()\n",
    "errorRate_easy = list()\n",
    "mistakeCorrected_easy = list()\n",
    "timeTyping_easy = list()\n",
    "\n",
    "subjInd = -1\n",
    "for subjScores in scoreLIX_Total:\n",
    "    subjInd = subjInd + 1\n",
    "    \n",
    "    scoreComplexity_subj_diffiult = list()\n",
    "    scoreDifficulty_subj_difficult = list()\n",
    "    \n",
    "    blinkFrequency_subj_difficult = list()\n",
    "    blinkDurationAverage_subj_difficult = list()\n",
    "    interBlinkInterval_subj_difficult= list()\n",
    "    ipa_subj_difficult = list()\n",
    "    pupilMeanAbsolute_subj_difficult = list()\n",
    "    pupilMeanRelative_subj_difficult = list()\n",
    "    typingSpeed_subj_difficult = list()\n",
    "    errorRate_subj_difficult = list()\n",
    "    mistakeCorrecte_subj_difficult = list()\n",
    "    \n",
    "    timeTyping_subj_difficult = list()\n",
    "    \n",
    "    scoreComplexity_subj_easy = list()\n",
    "    scoreDifficulty_subj_easy = list()\n",
    "\n",
    "    blinkFrequency_subj_easy = list()\n",
    "    blinkDurationAverage_subj_easy = list()\n",
    "    interBlinkInterval_subj_easy = list()\n",
    "    ipa_subj_easy = list()\n",
    "    pupilMeanAbsolute_subj_easy = list()\n",
    "    pupilMeanRelative_subj_easy = list()\n",
    "    typingSpeed_subj_easy = list()\n",
    "    errorRate_subj_easy = list()\n",
    "    mistakeCorrecte_subj_easy = list()\n",
    "    \n",
    "    timeTyping_subj_easy = list()\n",
    "    \n",
    "    scoreInd = -1\n",
    "    blinkDurationList = list()\n",
    "    for score in subjScores:\n",
    "        scoreInd = scoreInd + 1\n",
    "        if score > 2:\n",
    "            \n",
    "            scoreComplexity_subj_diffiult.append(scoreComplexity_Total[subjInd][scoreInd+1])\n",
    "            scoreDifficulty_subj_difficult.append(scoreDifficulty_Total[subjInd][scoreInd+1])\n",
    "            \n",
    "            blinkFrequency_subj_difficult.append(blinkFrequency_Total[subjInd][scoreInd])\n",
    "            blinkDurationAverage_subj_difficult.append(blinkDurationAverage_Total[subjInd][scoreInd])\n",
    "            interBlinkInterval_subj_difficult.append(interBlinkInterval_Total[subjInd][scoreInd])\n",
    "            \n",
    "            ipa_subj_difficult.append(ipa_Total[subjInd][scoreInd])\n",
    "            pupilMeanAbsolute_subj_difficult.append(pupilMeanAbsolute_Total[subjInd][scoreInd])\n",
    "            pupilMeanRelative_subj_difficult.append(pupilMeanRelative_Total[subjInd][scoreInd])\n",
    "            \n",
    "            typingSpeed_subj_difficult.append(typingSpeedTrial_Total[subjInd][scoreInd])\n",
    "            errorRate_subj_difficult.append(mistakeTrialList_Total[subjInd][scoreInd])\n",
    "            mistakeCorrecte_subj_difficult.append(mistakesCorrectedList_Total[subjInd][scoreInd])\n",
    "            timeTyping_subj_difficult.append(timeTypingTrial_Total[subjInd][scoreInd].total_seconds())\n",
    "            \n",
    "        elif score < 2:\n",
    "            scoreComplexity_subj_easy.append(scoreComplexity_Total[subjInd][scoreInd+1])\n",
    "            scoreDifficulty_subj_easy.append(scoreDifficulty_Total[subjInd][scoreInd+1])\n",
    "            \n",
    "            blinkFrequency_subj_easy.append(blinkFrequency_Total[subjInd][scoreInd])\n",
    "            blinkDurationAverage_subj_easy.append(blinkDurationAverage_Total[subjInd][scoreInd])\n",
    "            interBlinkInterval_subj_easy.append(interBlinkInterval_Total[subjInd][scoreInd])\n",
    "            \n",
    "            ipa_subj_easy.append(ipa_Total[subjInd][scoreInd])\n",
    "            pupilMeanAbsolute_subj_easy.append(pupilMeanAbsolute_Total[subjInd][scoreInd])\n",
    "            pupilMeanRelative_subj_easy.append(pupilMeanRelative_Total[subjInd][scoreInd])\n",
    "            \n",
    "            typingSpeed_subj_easy.append(typingSpeedTrial_Total[subjInd][scoreInd])\n",
    "            errorRate_subj_easy.append(mistakeTrialList_Total[subjInd][scoreInd])\n",
    "            mistakeCorrecte_subj_easy.append(mistakesCorrectedList_Total[subjInd][scoreInd])\n",
    "            timeTyping_subj_easy.append(timeTypingTrial_Total[subjInd][scoreInd].total_seconds())\n",
    "            \n",
    "        if scoreInd == len(subjScores)-1:\n",
    "            scoreComplexity_difficult.append(np.mean(scoreComplexity_subj_diffiult))\n",
    "            scoreDifficulty_difficult.append(np.mean(scoreDifficulty_subj_difficult))\n",
    "            \n",
    "            blinkFrequency_difficult.append(np.mean(blinkFrequency_subj_difficult))\n",
    "            blinkDurationAverage_difficult.append(np.mean(blinkDurationAverage_subj_difficult))\n",
    "            interBlinkInterval_difficult.append(np.mean(interBlinkInterval_subj_difficult))\n",
    "            \n",
    "            ipa_difficult.append(np.mean(ipa_subj_difficult))\n",
    "            pupilMeanAbsolute_difficult.append(np.mean(pupilMeanAbsolute_subj_difficult))\n",
    "            pupilMeanRelative_difficult.append(np.mean(pupilMeanRelative_subj_difficult))\n",
    "            \n",
    "            typingSpeed_difficult.append(np.mean(typingSpeed_subj_difficult))\n",
    "            errorRate_difficult.append(np.mean(errorRate_subj_difficult))\n",
    "            mistakeCorrected_difficult.append(np.mean(mistakeCorrecte_subj_difficult))\n",
    "            \n",
    "            timeTyping_difficult.append(np.mean(timeTyping_subj_difficult))\n",
    "            \n",
    "            scoreComplexity_easy.append(np.mean(scoreComplexity_subj_easy))\n",
    "            scoreDifficulty_easy.append(np.mean(scoreDifficulty_subj_easy))\n",
    "            \n",
    "            blinkFrequency_easy.append(np.mean(blinkFrequency_subj_easy))\n",
    "            blinkDurationAverage_easy.append(np.mean(blinkDurationAverage_subj_easy))\n",
    "            interBlinkInterval_easy.append(np.mean(interBlinkInterval_subj_easy))\n",
    "            \n",
    "            ipa_easy.append(np.mean(ipa_subj_easy))\n",
    "            pupilMeanAbsolute_easy.append(np.mean(pupilMeanAbsolute_subj_easy))\n",
    "            pupilMeanRelative_easy.append(np.mean(pupilMeanRelative_subj_easy))\n",
    "            \n",
    "            typingSpeed_easy.append(np.mean(typingSpeed_subj_easy))\n",
    "            errorRate_easy.append(np.mean(errorRate_subj_easy))\n",
    "            mistakeCorrected_easy.append(np.mean(mistakeCorrecte_subj_easy))\n",
    "            \n",
    "            timeTyping_easy.append(np.mean(timeTyping_subj_easy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([pupilMeanRelative_easy + pupilMeanRelative_difficult][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyvttbl\n",
    "\n",
    "\n",
    "Sub = namedtuple('Sub', ['Sub_id', 'rt','condition'])               \n",
    "df = pt.DataFrame()\n",
    "for subid in xrange(0,N):\n",
    "    for i,condition in enumerate(P):\n",
    "        df.insert(Sub(subid+1,\n",
    "                     normal(mus[i], scale=112., size=1)[0],\n",
    "                           condition)._asdict())\n",
    "        \n",
    "# data set for anova\n",
    "subj_id = ['1w', '1', '2w', '2', '3w', '3', '4w', '4', '5w', '5','1w', '1', '2w', '2', '3w', '3', '4w', '4', '5w', '5',]\n",
    "level = ['easy', 'easy', 'easy', 'easy', 'easy', 'easy', 'easy', 'easy', 'easy', 'easy', 'difficult', 'difficult', 'difficult', 'difficult', 'difficult', 'difficult', 'difficult', 'difficult', 'difficult', 'difficult']\n",
    "chinRest = ['1', '0','1', '0','1', '0','1', '0','1', '0','1', '0','1', '0','1', '0','1', '0','1', '0']\n",
    "\n",
    "df_anova = pd.DataFrame({'subj_id' : subj_id,\n",
    " 'difficulty_level' : level,\n",
    " 'chinRest' : chinRest,\n",
    " 'scoreComplexity':[scoreComplexity_easy + scoreComplexity_difficult][0],\n",
    " 'scoreDifficulty' : [scoreDifficulty_easy + scoreDifficulty_difficult][0],\n",
    " 'blinkFrequency' : [blinkFrequency_easy + blinkFrequency_difficult][0],\n",
    " 'blinkDurationAverage' : [blinkDurationAverage_easy + blinkDurationAverage_difficult][0],\n",
    " 'interBlinkInterval' : [interBlinkInterval_easy + interBlinkInterval_difficult][0],\n",
    " 'ipa' : [ipa_easy + ipa_difficult][0],\n",
    " 'pupilMeanAbsolute' : [pupilMeanAbsolute_easy + pupilMeanAbsolute_difficult][0],\n",
    " 'pupilMeanRelative' : [pupilMeanRelative_easy + pupilMeanRelative_difficult][0],\n",
    " 'typingSpeed' : [typingSpeed_easy + typingSpeed_difficult][0],\n",
    " 'errorRate' : [errorRate_easy + errorRate_difficult][0]\n",
    "  }, columns=['difficulty_level', 'chinRest', 'scoreComplexity', 'scoreDifficulty', 'blinkFrequency', 'blinkDurationAverage', 'interBlinkInterval', 'ipa', 'pupilMeanAbsolute', 'pupilMeanRelative', 'typingSpeed', 'errorRate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeated measures anova\n",
    "\n",
    "a = statsmodels.stats.anova.AnovaRM(df_anova, 'pupilMeanRelative', 'subj_id', within = ['difficulty_level', 'chinRest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvttbl as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores\n",
      "Ttest_relResult(statistic=4.133991732024803, pvalue=0.0025443073595036274)\n",
      "2.1666666666666665 1.5723301886761005\n",
      "Ttest_relResult(statistic=5.676263889047659, pvalue=0.0003033015559492453)\n",
      "2.5166666666666666 1.330100246848585\n",
      "blinks\n",
      "Ttest_relResult(statistic=1.6833457357225243, pvalue=0.12659779923829523)\n",
      "0.024613109787373938 0.04386462495206224\n",
      "Ttest_relResult(statistic=1.0725247044177222, pvalue=0.3113994960516582)\n",
      "Ttest_relResult(statistic=-0.531013522013888, pvalue=0.6082623640154368)\n",
      "pupils\n",
      "Ttest_relResult(statistic=-2.066731172024787, pvalue=0.06872696101507828)\n",
      "-0.022785522886369463 0.03307472669129924\n",
      "Ttest_relResult(statistic=5.013808159181569, pvalue=0.000725181395188713)\n",
      "0.12252920253947633 0.0733150523410597\n",
      "5.098125379139588 0.8155680770055199 4.975596176600112 0.8405411768648375\n",
      "Ttest_relResult(statistic=1.4787256457462712, pvalue=0.17333801720571815)\n",
      "1.0365303089061573 0.04935563814803317 1.0240601899385804 0.06722672649138461\n",
      "0.012470118967577016 0.02529905193052298\n",
      "typing performance\n",
      "Ttest_relResult(statistic=-2.5462429656388377, pvalue=0.031387627632055715)\n",
      "34.01525952683424 5.233672452163237 37.41510158067514 7.404890419073995\n",
      "Ttest_relResult(statistic=8.05262874107371, pvalue=2.1004296081503506e-05)\n",
      "179.44566163333334 45.25849297270892 64.1495329 27.907499438806358\n",
      "error rate\n",
      "Ttest_relResult(statistic=4.677088477493725, pvalue=0.0011569504531691742)\n",
      "0.0011024528341068208 0.0008365883616903148 0.000706012042870732 0.0008025785109908317\n",
      "Ttest_relResult(statistic=0.19704930750621738, pvalue=0.8481670942467087)\n",
      "0.014678378481461852 0.012379564409586472 0.014089494214461465 0.015069491589962273\n"
     ]
    }
   ],
   "source": [
    "print('scores')\n",
    "print(stats.ttest_rel(scoreComplexity_difficult, scoreComplexity_easy))\n",
    "scoreComplexityDiff = [scoreComplexity_difficult[i] - scoreComplexity_easy[i] for i in range(0, len(scoreComplexity_easy))]\n",
    "print(np.mean(scoreComplexityDiff), np.std(scoreComplexityDiff))\n",
    "\n",
    "print(stats.ttest_rel(scoreDifficulty_difficult, scoreDifficulty_easy))\n",
    "scoreDifficultyDiff = [scoreDifficulty_difficult[i]-scoreDifficulty_easy[i] for i in range(0, len(scoreDifficulty_easy))]\n",
    "print(np.mean(scoreDifficultyDiff), np.std(scoreDifficultyDiff))\n",
    "\n",
    "print('blinks')\n",
    "print(stats.ttest_rel(blinkFrequency_difficult, blinkFrequency_easy))\n",
    "blinkFrequencyDiff = [blinkFrequency_difficult[i]-blinkFrequency_easy[i] for i in range(0, len(blinkFrequency_easy))]\n",
    "print(np.mean(blinkFrequencyDiff), np.std(blinkFrequencyDiff))\n",
    "print(stats.ttest_rel(blinkDurationAverage_difficult, blinkDurationAverage_easy))\n",
    "print(stats.ttest_rel(interBlinkInterval_difficult, interBlinkInterval_easy))\n",
    "\n",
    "print('pupils')\n",
    "print(stats.ttest_rel(ipa_difficult, ipa_easy))\n",
    "ipaDiff = [ipa_difficult[i]-ipa_easy[i] for i in range(0, len(ipa_easy))]\n",
    "print(np.mean(ipaDiff),np.std(ipaDiff))\n",
    "\n",
    "print(stats.ttest_rel(pupilMeanAbsolute_difficult, pupilMeanAbsolute_easy))\n",
    "pupilMeanAbsoluteDiff = [pupilMeanAbsolute_difficult[i]-pupilMeanAbsolute_easy[i] for i in range(0, len(pupilMeanAbsolute_easy))]\n",
    "print(np.mean(pupilMeanAbsoluteDiff), np.std(pupilMeanAbsoluteDiff))\n",
    "print(np.mean(pupilMeanAbsolute_difficult), np.std(pupilMeanAbsolute_difficult), np.mean(pupilMeanAbsolute_easy), np.std(pupilMeanAbsolute_easy))\n",
    "\n",
    "print(stats.ttest_rel(pupilMeanRelative_difficult, pupilMeanRelative_easy))\n",
    "pupilMeanRelativeDiff = [pupilMeanRelative_difficult[i]-pupilMeanRelative_easy[i] for i in range(0, len(pupilMeanRelative_easy))]\n",
    "print(np.mean(pupilMeanRelative_difficult), np.std(pupilMeanRelative_difficult), np.mean(pupilMeanRelative_easy), np.std(pupilMeanRelative_easy))\n",
    "print(np.mean(pupilMeanRelativeDiff), np.std(pupilMeanRelativeDiff))\n",
    "\n",
    "print(\"typing performance\")\n",
    "print(stats.ttest_rel(typingSpeed_difficult, typingSpeed_easy))\n",
    "print(np.mean(typingSpeed_difficult), np.std(typingSpeed_difficult), np.mean(typingSpeed_easy), np.std(typingSpeed_easy))\n",
    "print(stats.ttest_rel(timeTyping_difficult, timeTyping_easy))\n",
    "print(np.mean(timeTyping_difficult), np.std(timeTyping_difficult), np.mean(timeTyping_easy), np.std(timeTyping_easy))\n",
    "\n",
    "print('error rate')\n",
    "print(stats.ttest_rel(errorRate_difficult, errorRate_easy))\n",
    "print(np.mean(errorRate_difficult), np.std(errorRate_difficult), np.mean(errorRate_easy), np.std(errorRate_easy))\n",
    "\n",
    "print(stats.ttest_rel(mistakeCorrected_difficult, mistakeCorrected_easy))\n",
    "print(np.mean(mistakeCorrected_difficult), np.std(mistakeCorrected_difficult), np.mean(mistakeCorrected_easy), np.std(mistakeCorrected_easy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.timedelta(0, 126, 337536),\n",
       " datetime.timedelta(0, 82, 118996),\n",
       " datetime.timedelta(0, 59, 541539),\n",
       " datetime.timedelta(0, 39, 257028),\n",
       " datetime.timedelta(0, 39, 238031),\n",
       " datetime.timedelta(0, 38, 586491),\n",
       " datetime.timedelta(0, 59, 632563),\n",
       " datetime.timedelta(0, 49, 60137),\n",
       " datetime.timedelta(0, 48, 897773),\n",
       " datetime.timedelta(0, 98, 825235)]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeTyping_easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.285714285714285 3.6922422809485957\n"
     ]
    }
   ],
   "source": [
    "ages = [32, 26, 27, 23, 35, 28, 27]\n",
    "print(np.mean(ages), np.std(ages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreLIX = [3,3,3,3,3,3,3,3,3,3,1,1,1,1,1,1,1,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chinRest = [1,1,1,1,1,0,0,0,0,0,1,1,1,1,1,0,0,0,0,0]\n",
    "scoreLIX = [1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "scoreDifficulty_anova = scoreDifficulty_difficult + scoreDifficulty_easy\n",
    "scoreComplexity_anova = scoreComplexity_difficult + scoreComplexity_easy\n",
    "\n",
    "blinkFrequency_anova = blinkFrequency_difficult + blinkFrequency_easy\n",
    "interBlinkInterval_anova = interBlinkInterval_difficult + interBlinkInterval_easy\n",
    "\n",
    "pupilMeanAbsolute_anova = pupilMeanAbsolute_difficult + pupilMeanAbsolute_easy\n",
    "pupilMeanRelative_anova = pupilMeanRelative_difficult + pupilMeanRelative_easy\n",
    "\n",
    "ipa_anova = ipa_difficult + ipa_easy\n",
    "\n",
    "typingSpeed_anova = typingSpeed_difficult + typingSpeed_easy\n",
    "errorRate_anova = errorRate_difficult + errorRate_easy\n",
    "mistakeCorrected_anova = mistakeCorrected_difficult + mistakeCorrected_easy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7684602759890877, 7.561527021110162e-05)\n",
      "(0.7053975325688253, 0.0005123206342803252)\n",
      "(0.18581275451159754, 0.4328401146768457)\n",
      "(-0.129884154389972, 0.5852176546899217)\n",
      "(0.07377617041717159, 0.757234794595993)\n",
      "(0.10514296886684242, 0.6590948360223763)\n",
      "(-0.4144155765313178, 0.0692664734688405)\n",
      "(-0.25626808886626506, 0.2754432662421946)\n",
      "(0.23502967329195226, 0.3185364973327801)\n",
      "(0.021346572811319808, 0.9288216110380798)\n"
     ]
    }
   ],
   "source": [
    "scoreLIX = [3,3,3,3,3,3,3,3,3,3,1,1,1,1,1,1,1,1,1,1]\n",
    "\n",
    "print(stats.pearsonr(scoreDifficulty_anova, scoreLIX))\n",
    "print(stats.pearsonr(scoreComplexity_anova, scoreLIX))\n",
    "print(stats.pearsonr(blinkFrequency_anova, scoreLIX))\n",
    "print(stats.pearsonr(interBlinkInterval_anova, scoreLIX))\n",
    "print(stats.pearsonr(pupilMeanAbsolute_anova, scoreLIX))\n",
    "print(stats.pearsonr(pupilMeanRelative_anova, scoreLIX))\n",
    "print(stats.pearsonr(ipa_anova, scoreLIX))\n",
    "print(stats.pearsonr(typingSpeed_anova, scoreLIX))\n",
    "print(stats.pearsonr(errorRate_anova, scoreLIX))\n",
    "print(stats.pearsonr(mistakeCorrected_anova, scoreLIX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,11), pupilMeanRelative_anova[0:10], '*')\n",
    "plt.plot(np.arange(1,11), pupilMeanRelative_anova[10:21], 'o')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,11), typingSpeed_anova[0:10], '*')\n",
    "plt.plot(np.arange(1,11), typingSpeed_anova[10:21], 'o')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_svm = list()\n",
    "\n",
    "for i in range(0, 20):\n",
    "    inner_list = list()\n",
    "        \n",
    "    #inner_list.append(scoreDifficulty[i])\n",
    "    #inner_list.append(scoreComplexity[i])\n",
    "    inner_list.append(blinkFrequency_anova[i])\n",
    "    inner_list.append(interBlinkInterval_anova[i])\n",
    "    inner_list.append(pupilMeanAbsolute_anova[i])\n",
    "    inner_list.append(pupilMeanRelative_anova[i])\n",
    "    inner_list.append(ipa_anova[i])\n",
    "    inner_list.append(typingSpeed_anova[i])\n",
    "    inner_list.append(errorRate_anova[i])\n",
    "    #inner_list.append(mistakeCorrected_anova[i])\n",
    "    \n",
    "    list_svm.append(inner_list)\n",
    "    \n",
    "array_svm = np.array(list_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.43588989435406733\n"
     ]
    }
   ],
   "source": [
    "# k fold cross validation\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "\n",
    "fitScore = list()\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=None)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    #print('TEST:', test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "    \n",
    "    clf = svm.SVC(random_state=None, kernel='rbf')\n",
    "    clf.fit(X_train, y_train) \n",
    "    #print(clf.predict(X_test))\n",
    "    \n",
    "    fitScore.append(clf.score(X_test, y_test))\n",
    "    \n",
    "print(np.mean(fitScore), np.std(fitScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Df_anova = pd.DataFrame({'blinkFrequency': blinkFrequency_anova, 'interBlinkInterval' : interBlinkInterval_anova, 'pupilAbsolute' : pupilMeanAbsolute_anova, 'pupilRelative':pupilMeanRelative_anova, 'ipa':ipa_anova, 'typingSpeed' : typingSpeed_anova, 'errorRate': errorRate_anova, 'scoreDifficulty': scoreDifficulty, 'scoreComplexity': scoreComplexity })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2-way anova \n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_blinkFrequency = ols('blinkFrequency_anova ~ C(chinRest)*C(scoreLIX)', Df_anova).fit()\n",
    "table = sm.stats.anova_lm(model_blinkFrequency, typ=2)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_interBlinkInterval = ols('interBlinkInterval_anova ~ C(chinRest)*C(scoreLIX)', Df_anova).fit()\n",
    "table = sm.stats.anova_lm(model_interBlinkInterval, typ=2)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pupilAbsolute = ols('pupilMeanAbsolute_anova ~ C(chinRest)*C(scoreLIX)', Df_anova).fit()\n",
    "table = sm.stats.anova_lm(model_pupilAbsolute, typ=2)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pupilRelative = ols('pupilMeanRelative_anova ~ C(chinRest)*C(scoreLIX)', Df_anova).fit()\n",
    "table = sm.stats.anova_lm(model_pupilRelative, typ=2)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ipa = ols('ipa_anova ~ C(chinRest)*C(scoreLIX)', Df_anova).fit()\n",
    "table = sm.stats.anova_lm(model_ipa, typ=2)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Complexity= ols('scoreComplexity ~ C(chinRest)*C(scoreLIX)', Df_anova).fit()\n",
    "table = sm.stats.anova_lm(model_Complexity, typ=2)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Difficulty= ols('scoreDifficulty ~ C(chinRest)*C(scoreLIX)', Df_anova).fit()\n",
    "table = sm.stats.anova_lm(model_Difficulty, typ=2)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_TypingSpeed = ols('typingSpeed ~ C(chinRest)*C(scoreLIX)', Df_anova).fit()\n",
    "table = sm.stats.anova_lm(model_TypingSpeed, typ = 2)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_errorRate = ols('errorRate ~ C(chinRest)*C(scoreLIX)', Df_anova).fit()\n",
    "table = sm.stats.anova_lm(model_errorRate, typ = 2)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data for plotting\n",
    "blinkFrequency_plotMean = [[np.mean(blinkFrequency_easy), np.mean(blinkFrequency_wChinRest_easy), np.mean(blinkFrequency_woChinRest_easy)],\n",
    "                          [ np.mean(blinkFrequency_difficult), np.mean(blinkFrequency_wChinRest_difficult), np.mean(blinkFrequency_woChinRest_difficult)]]\n",
    "\n",
    "blinkFrequency_plotStd = [[np.std(blinkFrequency_easy), np.std(blinkFrequency_wChinRest_easy), np.std(blinkFrequency_woChinRest_easy)],\n",
    "                          [ np.std(blinkFrequency_difficult), np.std(blinkFrequency_wChinRest_difficult), np.std(blinkFrequency_woChinRest_difficult)]]\n",
    "\n",
    "# plots\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "X = np.arange(3)\n",
    "p1 = ax.bar(X + 0.00, blinkFrequency_plotMean[0], yerr = blinkFrequency_plotStd[0], color = 'orange', width = 0.20)\n",
    "p2 = ax.bar(X + 0.25, blinkFrequency_plotMean[1], yerr = blinkFrequency_plotStd[1], color = 'g', width = 0.20)\n",
    "\n",
    "ax.set_ylabel('Blink frequency [in Hz]')\n",
    "ax.set_xticks([0.125, 1.125, 2.125])\n",
    "#ax.set_xticklabels({'overall', 'with chin rest', 'without chin rest'})\n",
    "plt.xticks([0.125, 1.125, 2.125], ['overall', 'with chin rest', 'without chin rest'])\n",
    "\n",
    "blinkFrequency_stdmax = max(max(blinkFrequency_plotStd))\n",
    "blinkFrequency_meanmax = max(max(blinkFrequency_plotMean))\n",
    "ax.set_ylim([0, blinkFrequency_meanmax + blinkFrequency_stdmax+0.11])\n",
    "\n",
    "ax.legend((p1[0], p2[0]), ('easy', 'difficult') )\n",
    "\n",
    "ax.text((2.125), np.mean(blinkFrequency_woChinRest_easy) + np.std(blinkFrequency_woChinRest_easy)+0.04, \"*\", ha='center', va='bottom', color='k', fontsize = 20)\n",
    "plt.tight_layout()\n",
    "fig.savefig(r'C:\\DTU\\Results\\201812_PilotExptForMovement\\Paper\\CHI2019\\blinkFrequency.png', dpi = 300, bbox_to_anchor = (0.9, 0.1))\n",
    "\n",
    "#plt.savefig(r'C:\\DTU\\Results\\201812_PilotExptForMovement\\Paper\\CHI2019\\blinkFrequency.png', format='png', dpi=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ax.get_xticks()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data for plotting\n",
    "interBlinkInterval_plotMean = [[np.mean(interBlinkInterval_easy), np.mean(interBlinkInterval_wChinRest_easy), np.mean(interBlinkInterval_woChinRest_easy)],\n",
    "                          [ np.mean(interBlinkInterval_difficult), np.mean(interBlinkInterval_wChinRest_difficult), np.mean(interBlinkInterval_woChinRest_difficult)]]\n",
    "\n",
    "interBlinkInterval_plotStd = [[np.std(interBlinkInterval_easy), np.std(interBlinkInterval_wChinRest_easy), np.std(interBlinkInterval_woChinRest_easy)],\n",
    "                          [ np.std(interBlinkInterval_difficult), np.std(interBlinkInterval_wChinRest_difficult), np.std(interBlinkInterval_woChinRest_difficult)]]\n",
    "\n",
    "# plots\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "X = np.arange(3)\n",
    "ax.bar(X + 0.00, interBlinkInterval_plotMean[0], yerr = interBlinkInterval_plotStd[0], color = 'orange', width = 0.20)\n",
    "ax.bar(X + 0.25, interBlinkInterval_plotMean[1], yerr = interBlinkInterval_plotStd[1], color = 'g', width = 0.20)\n",
    "\n",
    "ax.set_ylabel('Inter-blink interval [in s]')\n",
    "#ax.set_xticks([0.125, 1.125, 2.125], ['overall', 'with chin rest', 'without chin rest'])\n",
    "plt.xticks([0.125, 1.125, 2.125], ['overall', 'with chin rest', 'without chin rest'])\n",
    "\n",
    "interBlinkInterval_max = max(max(interBlinkInterval_plotStd))\n",
    "ax.set_ylim([-1, interBlinkInterval_max+15])\n",
    "\n",
    "#ax.set_.text((2.125), np.mean(interBlinkInterval_woChinRest_easy) + np.std(interBlinkInterval_woChinRest_easy)+0.03, \"*\", ha='center', va='bottom', color='k', fontsize = 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data for plotting\n",
    "pupilMeanAbsolute_plotMean = [[np.mean(pupilMeanAbsolute_easy), np.mean(pupilMeanAbsolute_wChinRest_easy), np.mean(pupilMeanAbsolute_woChinRest_easy)],\n",
    "                          [ np.mean(pupilMeanAbsolute_difficult), np.mean(pupilMeanAbsolute_wChinRest_difficult), np.mean(pupilMeanAbsolute_woChinRest_difficult)]]\n",
    "\n",
    "pupilMeanAbsolute_plotStd = [[np.std(pupilMeanAbsolute_easy), np.std(pupilMeanAbsolute_wChinRest_easy), np.std(pupilMeanAbsolute_woChinRest_easy)],\n",
    "                          [ np.std(pupilMeanAbsolute_difficult), np.std(pupilMeanAbsolute_wChinRest_difficult), np.std(pupilMeanAbsolute_woChinRest_difficult)]]\n",
    "\n",
    "# plots\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "X = np.arange(3)\n",
    "p1 = ax.bar(X + 0.00, pupilMeanAbsolute_plotMean[0], yerr = pupilMeanAbsolute_plotStd[0], color = 'orange', width = 0.20)\n",
    "p2 = ax.bar(X + 0.25, pupilMeanAbsolute_plotMean[1], yerr = pupilMeanAbsolute_plotStd[1], color = 'g', width = 0.20)\n",
    "\n",
    "\n",
    "ax.set_ylabel('Absolute pupil size [in mm]')\n",
    "ax.set_xticks([0.125, 1.125, 2.125])\n",
    "#ax.set_xticklabels({'overall', 'with chin rest', 'without chin rest'})\n",
    "plt.xticks([0.125, 1.125, 2.125], ['overall', 'with chin rest', 'without chin rest'])\n",
    "\n",
    "pupilMeanAbsolute_stdmax = max(max(pupilMeanAbsolute_plotStd))\n",
    "pupilMeanAbsolute_meanmax = max(max(pupilMeanAbsolute_plotMean))\n",
    "ax.set_ylim([0, pupilMeanAbsolute_meanmax+pupilMeanAbsolute_stdmax+3])\n",
    "\n",
    "ax.legend((p1[0], p2[0]), ('easy', 'difficult') )\n",
    "\n",
    "ax.text((0.125), np.mean(pupilMeanAbsolute_easy) + np.std(pupilMeanAbsolute_easy)+0.5, \"***\", ha='center', va='bottom', color='k', fontsize = 20)\n",
    "ax.text((2.125), np.mean(pupilMeanAbsolute_woChinRest_easy) + np.std(pupilMeanAbsolute_woChinRest_easy)+0.5, \"**\", ha='center', va='bottom', color='k', fontsize = 20)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(r'C:\\DTU\\Results\\201812_PilotExptForMovement\\Paper\\CHI2019\\pupilSize.png', dpi = 300, bbox_to_anchor = (0.95, 0.1))\n",
    "#plt.savefig(r'C:\\DTU\\Results\\201812_PilotExptForMovement\\Paper\\CHI2019\\pupilSize', format='eps', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data for plotting\n",
    "ipa_plotMean = [[np.mean(ipa_easy), np.mean(ipa_wChinRest_easy), np.mean(ipa_woChinRest_easy)],\n",
    "                          [ np.mean(ipa_difficult), np.mean(ipa_wChinRest_difficult), np.mean(ipa_woChinRest_difficult)]]\n",
    "\n",
    "ipa_plotStd = [[np.std(ipa_wChinRest_easy), np.std(ipa_wChinRest_easy), np.std(ipa_woChinRest_easy)],\n",
    "                          [ np.std(ipa_difficult), np.std(ipa_wChinRest_difficult), np.std(ipa_woChinRest_difficult)]]\n",
    "\n",
    "# plots\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "X = np.arange(3)\n",
    "p1 = ax.bar(X + 0.00, ipa_plotMean[0], yerr = ipa_plotStd[0], color = 'orange', width = 0.20)\n",
    "p2 = ax.bar(X + 0.25, ipa_plotMean[1], yerr = ipa_plotStd[1], color = 'g', width = 0.20)\n",
    "\n",
    "ax.set_ylabel('IPA values [in Hz]')\n",
    "ax.set_xticks([0.125, 1.125, 2.125])\n",
    "#ax.set_xticklabels({'overall', 'with chin rest', 'without chin rest'})\n",
    "plt.xticks([0.125, 1.125, 2.125], ['overall', 'with chin rest', 'without chin rest'])\n",
    "\n",
    "ipa_stdmax = max(max(ipa_plotStd))\n",
    "ipa_meanmax = max(max(ipa_plotMean))\n",
    "ax.set_ylim([0, ipa_meanmax+ipa_stdmax+0.025])\n",
    "\n",
    "ax.legend((p1[0], p2[0]), ('easy', 'difficult') )\n",
    "plt.tight_layout()\n",
    "ax.text((2.125), np.mean(ipa_woChinRest_easy) + np.std(ipa_woChinRest_easy)+0.01, \"*\", ha='center', va='bottom', color='k', fontsize = 20)\n",
    "plt.savefig(r'C:\\DTU\\Results\\201812_PilotExptForMovement\\Paper\\CHI2019\\ipa.png', format='png', dpi=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data for plotting\n",
    "scoreComplexity_plotMean = [[np.mean(scoreComplexity_easy), np.mean(scoreComplexity_wChinRest_easy), np.mean(scoreComplexity_woChinRest_easy)],\n",
    "                          [ np.mean(scoreComplexity_difficult), np.mean(scoreComplexity_wChinRest_difficult), np.mean(scoreComplexity_woChinRest_difficult)]]\n",
    "\n",
    "scoreComplexity_plotStd = [[np.std(scoreComplexity_easy), np.std(scoreComplexity_wChinRest_easy), np.std(scoreComplexity_woChinRest_easy)],\n",
    "                          [ np.std(scoreComplexity_difficult), np.std(scoreComplexity_wChinRest_difficult), np.std(scoreComplexity_woChinRest_difficult)]]\n",
    "\n",
    "# plots\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "X = np.arange(3)\n",
    "p1 = ax.bar(X + 0.00, scoreComplexity_plotMean[0], yerr = scoreComplexity_plotStd[0], color = 'orange', width = 0.20)\n",
    "p2 = ax.bar(X + 0.25, scoreComplexity_plotMean[1], yerr = scoreComplexity_plotStd[1], color = 'g', width = 0.20)\n",
    "\n",
    "ax.set_ylabel('Expected task complexity score [A.U.]')\n",
    "ax.set_xticks([0.125, 1.125, 2.125])\n",
    "#ax.set_xticklabels({'overall', 'with chin rest', 'without chin rest'})\n",
    "plt.xticks([0.125, 1.125, 2.125], ['overall', 'with chin rest', 'without chin rest'])\n",
    "\n",
    "scoreComplexity_stdmax = max(max(scoreComplexity_plotStd))\n",
    "scoreComplexity_meanmax = max(max(scoreComplexity_plotMean))\n",
    "ax.set_ylim([0, scoreComplexity_meanmax+scoreComplexity_stdmax+4])\n",
    "\n",
    "ax.legend((p1[0], p2[0]), ('easy', 'difficult') )\n",
    "plt.tight_layout()\n",
    "ax.text((0.125), np.mean(scoreComplexity_easy) + np.std(scoreComplexity_easy)+3, \"**\", ha='center', va='bottom', color='k', fontsize = 20)\n",
    "ax.text((2.125), np.mean(scoreComplexity_easy) + np.std(scoreComplexity_easy)+3, \"***\", ha='center', va='bottom', color='k', fontsize = 20)\n",
    "\n",
    "fig.savefig(r'C:\\DTU\\Results\\201812_PilotExptForMovement\\Paper\\CHI2019\\Complexity.png', dpi = 300, bbox_to_anchor = (0.95, 0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data for plotting\n",
    "scoreDifficulty_plotMean = [[np.mean(scoreDifficulty_easy), np.mean(scoreDifficulty_wChinRest_easy), np.mean(scoreDifficulty_woChinRest_easy)],\n",
    "                          [ np.mean(scoreDifficulty_difficult), np.mean(scoreDifficulty_wChinRest_difficult), np.mean(scoreDifficulty_woChinRest_difficult)]]\n",
    "\n",
    "scoreDifficulty_plotStd = [[np.std(scoreDifficulty_easy), np.std(scoreDifficulty_wChinRest_easy), np.std(scoreDifficulty_woChinRest_easy)],\n",
    "                          [ np.std(scoreDifficulty_difficult), np.std(scoreDifficulty_wChinRest_difficult), np.std(scoreDifficulty_woChinRest_difficult)]]\n",
    "\n",
    "# plots\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "X = np.arange(3)\n",
    "p1 = ax.bar(X + 0.00, scoreDifficulty_plotMean[0], yerr = scoreDifficulty_plotStd[0], color = 'orange', width = 0.20)\n",
    "p2 = ax.bar(X + 0.25, scoreDifficulty_plotMean[1], yerr = scoreDifficulty_plotStd[1], color = 'g', width = 0.20)\n",
    "\n",
    "ax.set_ylabel('Subjective task difficulty score [A.U.]')\n",
    "ax.set_xticks([0.125, 1.125, 2.125])\n",
    "#ax.set_xticklabels({'overall', 'with chin rest', 'without chin rest'})\n",
    "plt.xticks([0.125, 1.125, 2.125], ['overall', 'with chin rest', 'without chin rest'])\n",
    "\n",
    "scoreDifficulty_stdmax = max(max(scoreDifficulty_plotStd))\n",
    "scoreDifficulty_meanmax = max(max(scoreDifficulty_plotMean))\n",
    "ax.set_ylim([0, scoreDifficulty_meanmax+scoreDifficulty_stdmax+4])\n",
    "\n",
    "ax.legend((p1[0], p2[0]), ('easy', 'difficult') )\n",
    "plt.tight_layout()\n",
    "ax.text((0.125), np.mean(scoreDifficulty_woChinRest_easy) + np.std(scoreDifficulty_woChinRest_easy)+3.7, \"***\", ha='center', va='bottom', color='k', fontsize = 20)\n",
    "ax.text((2.125), np.mean(scoreDifficulty_woChinRest_easy) + np.std(scoreDifficulty_woChinRest_easy)+3.7, \"***\", ha='center', va='bottom', color='k', fontsize = 20)\n",
    "\n",
    "fig.savefig(r'C:\\DTU\\Results\\201812_PilotExptForMovement\\Paper\\CHI2019\\Difficulty.png', dpi = 300, bbox_to_anchor = (0.95, 0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove medium trials from all measures\n",
    "\n",
    "ipa_ed = list()\n",
    "pupilMeanAbsolute_ed = list()\n",
    "pupilMeanRelative_ed = list()\n",
    "                \n",
    "blinkFrequency_ed = list()\n",
    "blinkDurationAverage_ed = list()\n",
    "interBlinkInterval_ed = list()\n",
    "                \n",
    "                    \n",
    "scoreLIX_ed = list()\n",
    "scoreComplexity_ed = list()\n",
    "scoreDifficulty_ed = list()\n",
    "scoreSumOfScores_ed = list()\n",
    "                \n",
    "timeTyping_ed = list()\n",
    "typingSpeed_ed = list()\n",
    "\n",
    "errorRate_ed = list()\n",
    "mistakeCorrected_ed = list()\n",
    "\n",
    "subjInd = -1\n",
    "for subjScores in scoreLIX_Total:\n",
    "    subjInd = subjInd + 1\n",
    "    \n",
    "    scoreLIX_subj = list()\n",
    "    scoreComplexity_subj = list()\n",
    "    scoreDifficulty_subj = list()\n",
    "    \n",
    "    blinkFrequency_subj = list()\n",
    "    blinkDurationAverage_subj = list()\n",
    "    interBlinkInterval_subj= list()\n",
    "    ipa_subj = list()\n",
    "    pupilMeanAbsolute_subj = list()\n",
    "    pupilMeanRelative_subj = list()\n",
    "    \n",
    "    time_subj = list()\n",
    "    typingSpeed_subj = list()\n",
    "    errorRate_subj = list()\n",
    "    mistakeCorrected_subj = list()\n",
    "    \n",
    "    \n",
    "    scoreInd = -1\n",
    "    \n",
    "    for score in subjScores:\n",
    "        scoreInd = scoreInd + 1\n",
    "        if score != 2:\n",
    "            \n",
    "            scoreLIX_subj.append(score)\n",
    "            scoreComplexity_subj.append(scoreComplexity_Total[subjInd][scoreInd+1])\n",
    "            scoreDifficulty_subj.append(scoreDifficulty_Total[subjInd][scoreInd+1])\n",
    "            \n",
    "            blinkFrequency_subj.append(blinkFrequency_Total[subjInd][scoreInd])\n",
    "            blinkDurationAverage_subj.append(blinkDurationAverage_Total[subjInd][scoreInd])\n",
    "            interBlinkInterval_subj.append(interBlinkInterval_Total[subjInd][scoreInd])\n",
    "            \n",
    "            ipa_subj.append(ipa_Total[subjInd][scoreInd])\n",
    "            pupilMeanAbsolute_subj.append(pupilMeanAbsolute_Total[subjInd][scoreInd])\n",
    "            pupilMeanRelative_subj.append(pupilMeanRelative_Total[subjInd][scoreInd])\n",
    "            \n",
    "            time_subj.append(timeTypingTrial_Total[subjInd][scoreInd])\n",
    "            typingSpeed_subj.append(typingSpeedTrial_Total[subjInd][scoreInd])\n",
    "            errorRate_subj.append(mistakeTrialList_Total[subjInd][scoreInd])\n",
    "            mistakeCorrected_subj.append(mistakesCorrectedList_Total[subjInd][scoreInd])\n",
    "        \n",
    "        if scoreInd == len(subjScores)-1:\n",
    "            scoreLIX_ed.append(scoreLIX_subj)\n",
    "            scoreComplexity_ed.append(scoreComplexity_subj)\n",
    "            scoreDifficulty_ed.append(scoreDifficulty_subj)\n",
    "            \n",
    "            blinkFrequency_ed.append(blinkFrequency_subj)\n",
    "            blinkDurationAverage_ed.append(blinkDurationAverage_subj)\n",
    "            interBlinkInterval_ed.append(interBlinkInterval_subj)\n",
    "            \n",
    "            ipa_ed.append(ipa_subj)\n",
    "            pupilMeanAbsolute_ed.append(pupilMeanAbsolute_subj)\n",
    "            pupilMeanRelative_ed.append(pupilMeanRelative_subj)\n",
    "            \n",
    "            timeTyping_ed.append(time_subj)\n",
    "            typingSpeed_ed.append(typingSpeed_subj)\n",
    "            errorRate_ed.append(errorRate_subj)\n",
    "            mistakeCorrected_ed.append(mistakeCorrected_subj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3780019608128874, 0.46000255503603166)\n",
      "(-0.3077696546022618, 0.5529218213750383)\n",
      "(0.9216903909460309, 0.008958479582853828)\n",
      "(-0.8369369479658, 0.03771645109166783)\n",
      "(-0.7578401801194873, 0.08086177473568981)\n",
      "(-0.7222026333231997, 0.10503806275150236)\n",
      "(-0.8164179502360746, 0.0917789207073314)\n",
      "(-0.682737362532259, 0.135016244126431)\n",
      "(-0.8233713432225207, 0.044041321224523776)\n",
      "(-0.34150695031318, 0.5076540395842171)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(stats.pearsonr(typingSpeed_ed[i], scoreLIX_ed[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.16443022090271112, 0.7555775430499931)\n",
      "(-0.0971126728583242, 0.8547889192687627)\n",
      "(-0.5363432162059614, 0.27262850538501543)\n",
      "(-0.37689802190747895, 0.4614225484527185)\n",
      "(0.5865234751514857, 0.2210996951232336)\n",
      "(0.25265183885263176, 0.6290859980311694)\n",
      "(0.6656866405209972, 0.22003264502842262)\n",
      "(0.6978050413864243, 0.12318419678738314)\n",
      "(0.5107439288834035, 0.3005002741087015)\n",
      "(-0.12608830959108736, 0.8118698280922478)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(stats.pearsonr(mistakeCorrected_ed[i], scoreLIX_ed[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0598092280595558, 0.878520263063244)\n",
      "(-0.05284583746144505, 0.8925935715835231)\n",
      "(0.5967411104821853, 0.08981491855613068)\n",
      "(-0.04085805472504482, 0.9168803603313256)\n",
      "(-0.26773075314788586, 0.4861209820496401)\n",
      "(0.23186932632222532, 0.5482940465869607)\n",
      "(0.5292079488538581, 0.14289487490123817)\n",
      "(0.021165658592797124, 0.9568977681109674)\n",
      "(-0.2622851816008829, 0.4953681994574484)\n",
      "(0.3456776252115975, 0.3621982942979109)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(stats.pearsonr(pupilMeanRelative_ed[i], scoreLIX_ed[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2889124696173692, 0.4508499707363738)\n",
      "(0.3789201634703881, 0.3145677770358573)\n",
      "(0.15282333204299772, 0.6946665966715058)\n",
      "(0.7924390763367668, 0.010876656428894352)\n",
      "(-0.021273639735898825, 0.9566780382744755)\n",
      "(-0.16787018595499945, 0.6659471644019934)\n",
      "(0.7264321451212303, 0.02665260090116814)\n",
      "(0.6458043161139179, 0.060264969633746994)\n",
      "(0.5530203627092198, 0.12249160552727775)\n",
      "(-0.05296705631807268, 0.8923483509860024)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(stats.pearsonr(pupilMeanAbsolute_ed[i], scoreLIX_ed[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.5233253273535193, 0.14822224178789073)\n",
      "(0.8545919183601838, 0.003338483402519436)\n",
      "(0.6434320078928056, 0.06152709640866575)\n",
      "(0.9342618180520093, 0.00022480732425499296)\n",
      "(-0.025344616834816223, 0.9483960005351307)\n",
      "(0.17339039090861622, 0.6555023064369098)\n",
      "(0.4451162454353458, 0.2299058127368574)\n",
      "(0.14653495235781816, 0.7067715790163469)\n",
      "(0.7506350102813695, 0.019778793324919035)\n",
      "(-0.2755695597060854, 0.47293705833085375)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(stats.pearsonr(blinkFrequency_ed[i], scoreLIX_ed[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.19353321366159207, 0.617836845102572)\n",
      "(0.026757001320487275, 0.9455235948326015)\n",
      "(-0.3886246869146906, 0.30129340453815645)\n",
      "(-0.2509465304125931, 0.5148496481955978)\n",
      "(0.5874737267922298, 0.09623129876456175)\n",
      "(0.3606041587291134, 0.3404032545274837)\n",
      "(-0.4845497820691076, 0.18619807193979757)\n",
      "(0.5648741829312377, 0.11302487536793902)\n",
      "(-0.529594037006703, 0.14254921618258296)\n",
      "(0.13480266746253333, 0.7295069015599771)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(stats.pearsonr(interBlinkInterval_ed[i], scoreLIX_ed[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.009223467009465958, 0.9812114393348916)\n",
      "(0.07378439856399002, 0.8503679221941699)\n",
      "(-0.3314544486220745, 0.3835695377509414)\n",
      "(0.4308170270224978, 0.24701041880290353)\n",
      "(-0.04565412105546281, 0.9071555800769652)\n",
      "(-0.2440194742058002, 0.5268986888760231)\n",
      "(0.3242464073477928, 0.39462003225376735)\n",
      "(-0.19137415656807774, 0.621839205935599)\n",
      "(0.36941618089973843, 0.3278470622753636)\n",
      "(0.4663629266501162, 0.2057213583365604)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(stats.pearsonr(blinkDurationAverage_ed[i], scoreLIX_ed[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.048221610672843314, 0.9019539015260606)\n",
      "(0.26794965334050463, 0.4857507685645235)\n",
      "(0.19359682343049447, 0.6177190594156509)\n",
      "(0.5751760832992027, 0.10516658720455986)\n",
      "(0.5523357637319026, 0.12305229241697362)\n",
      "(0.23734484816558407, 0.5386115745014725)\n",
      "(0.8802768300760926, 0.001735786710315682)\n",
      "(0.802961060805717, 0.00916653400110203)\n",
      "(0.16035745989180752, 0.680242004985877)\n",
      "(-0.11275302812239978, 0.7727210283926155)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(stats.pearsonr(errorRate_ed[i], scoreLIX_ed[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_svm = list()\n",
    "scoreLIX_svm = list()\n",
    "for i in range(0, 10):\n",
    "    inner_list = list()\n",
    "        \n",
    "    scoreLIX_svm.append(scoreLIX_ed[i])    \n",
    "    #inner_list.append(scoreDifficulty[i])\n",
    "    #inner_list.append(scoreComplexity[i])\n",
    "    inner_list.append(blinkFrequency_ed[i])\n",
    "    inner_list.append(interBlinkInterval_ed[i])\n",
    "    inner_list.append(pupilMeanAbsolute_ed[i])\n",
    "    inner_list.append(pupilMeanRelative_ed[i])\n",
    "    inner_list.append(ipa_ed[i])\n",
    "    inner_list.append(typingSpeed_ed[i])\n",
    "    inner_list.append(errorRate_ed[i])\n",
    "    inner_list.append(mistakeCorrected_ed[i])\n",
    "    \n",
    "    list_svm.append(inner_list)\n",
    "    \n",
    "array_svm = np.array(list_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 8)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_svm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0.0006591165944361684, 0.0011565544663365468, 0.0020955069987170683, 0.004353354370030242, 0.0026181155982945245, 0.0011066172221829054]\n",
      "1\n",
      "[0.0028083588224684535, 0.002433619192963668, 0.0012495849206909508, 0.0037859949231738937, 0.0020516709291985274, 0.0022432391465627296]\n",
      "2\n",
      "[0.0, 0.0007000747362738336, 0.0, 0.0, 0.0, 0.0]\n",
      "3\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0007540703018234249, 0.0004223602358951047]\n",
      "4\n",
      "[0.0002678129992165701, 0.003692735423452837, 0.0006841819904494736, 0.0019119365468028395, 0.0, 0.00034799363614850546]\n",
      "5\n",
      "[0.00015132961617796695, 0.0005917717219278881, 0.004004437261786715, 0.0005926580346829929, 0.0011613796335217226, 0.0032571680627844417]\n",
      "6\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0001588071815239873]\n",
      "7\n",
      "[0.0014798808796397842, 0.0, 0.0, 0.0, 0.0, 0.000485902866662257]\n",
      "8\n",
      "[0.0008193567891506299, 0.0, 0.000687975498001533, 0.0, 0.000825098822030908, 0.001883923651217131]\n",
      "9\n",
      "[0.0, 0.001659471001612876, 0.0004335371018407179, 0.0001928344708400939, 0.00011965930484620454, 0.0004058553559604664]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(i)\n",
    "    print(errorRate_ed[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136.93230732222224 81.0721257029385\n"
     ]
    }
   ],
   "source": [
    "# average time of typing\n",
    "timesTyping = [item.total_seconds() for sublist in timeTypingTrial_Total for item in sublist]\n",
    "\n",
    "print(np.mean(timesTyping), np.std(timesTyping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(0, 136, 932307)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeTypingAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesTyping = lambda l: [item for sublist in timeTypingTrial_Total for item in sublist]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
