{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import fnmatch\n",
    "from pathlib import Path\n",
    "from itertools import groupby\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "\n",
    "\n",
    "import distance\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import snowball\n",
    "\n",
    "# import other jupyter notebooks\n",
    "import import_ipynb\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all things that should be present when computing effective time\n",
    "list_keysToBeCounted = ['Comma', 'BackOne', 'BackMany', 'SpaceBar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FixScratchPad(ScratchPad_Old):\n",
    "    # Fix the situation where comma has divided decimals into separate columns\n",
    "    \n",
    "    ScratchPad_Times = [item[0] for item in ScratchPad_Old]\n",
    "    \n",
    "    ScratchPad_Phrases = list()\n",
    "    \n",
    "    # loop to combine phrases divided by commas\n",
    "    ScratchPadInd = -1 \n",
    "    while ScratchPadInd < len(ScratchPad_Old)-1:\n",
    "        ScratchPadInd = ScratchPadInd + 1\n",
    "        commasInPhrase = len(ScratchPad_Old[ScratchPadInd])-2\n",
    "        if commasInPhrase < 1:\n",
    "            #print(ScratchPad_Old[ScratchPadInd][1])\n",
    "            ScratchPad_Phrases.append(ScratchPad_Old[ScratchPadInd][1])\n",
    "            continue\n",
    "        scratchPadPhrase = ScratchPad_Old[ScratchPadInd][1]\n",
    "        for phraseJoinNr in range(1, commasInPhrase+1):\n",
    "            scratchPadPhrase = scratchPadPhrase + ', ' + ScratchPad_Old[ScratchPadInd][1+phraseJoinNr]\n",
    "        \n",
    "        ScratchPad_Phrases.append(scratchPadPhrase)\n",
    "            \n",
    "        \n",
    "    ScratchPad_New = [[ScratchPad_Times[ind], ScratchPad_Phrases[ind]] for ind in \n",
    "                    range(0, len(ScratchPad_Times))]\n",
    "    \n",
    "    #UserKeys_New = np.concatenate((UserKeys_Times, UserKeys_Keys, UserKeys_ProgressPercent), axis = 0)\n",
    "    \n",
    "    #print(ScratchPad_New)\n",
    "    return ScratchPad_New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FixUserKeys(UserKeys_Old):\n",
    "    # Fix the situation where comma has divided decimals into separate columns\n",
    "    \n",
    "    \n",
    "    Column_beforeDecimal = [item[2] for item in UserKeys_Old]\n",
    "    Column_afterDecimal = [item[3] if len(item)>3 else '00' for item in UserKeys_Old]\n",
    "    \n",
    "    UserKeys_ProgressPercent = [float(Column_beforeDecimal[i]+'.'+ Column_afterDecimal[i]) for i in \n",
    "                                range(0, len(Column_beforeDecimal))]\n",
    "    UserKeys_Times = [item[0] for item in UserKeys_Old]\n",
    "    UserKeys_Keys = [item[1] for item in UserKeys_Old]\n",
    "    \n",
    "    UserKeys_New = [[UserKeys_Times[ind], UserKeys_Keys[ind], UserKeys_ProgressPercent[ind]] for ind in \n",
    "                    range(0, len(UserKeys_ProgressPercent))]\n",
    "    \n",
    "    #UserKeys_New = np.concatenate((UserKeys_Times, UserKeys_Keys, UserKeys_ProgressPercent), axis = 0)\n",
    "    \n",
    "    \n",
    "    return UserKeys_New\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeDwellTime(userKeys):\n",
    "    # modify userKeys to include a column of time instead of progress pct, which is dependent on the then dwell time\n",
    "    \n",
    "    TimeDwellOrig = 800\n",
    "    \n",
    "    timeDwell = TimeDwellOrig\n",
    "    nKey = -1\n",
    "    for key in userKeys:\n",
    "        nKey = nKey + 1\n",
    "        #print(key[1])\n",
    "        if key[1] == 'IncreaseDwellTime':\n",
    "            if float(key[2]) == 1:\n",
    "                timeDwell = timeDwell + 100\n",
    "        elif key[1] == 'DecreaseDwellTime':\n",
    "            #print(key[2])\n",
    "            if float(key[2]) == 1:\n",
    "                timeDwell = timeDwell - 100\n",
    "        else:\n",
    "            userKeys[nKey].append(str(float(key[2])*timeDwell))\n",
    "    \n",
    "    return userKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will return the datetime in items which is the closest to the date pivot\n",
    "def nearestTimePoint(dates, date):\n",
    "    \n",
    "    for d in dates:\n",
    "        if d < date:\n",
    "            nearestTP = d\n",
    "        else:\n",
    "            continue\n",
    "    try: \n",
    "        nearestTP\n",
    "        nearestTPind = dates.index(nearestTP)\n",
    "    except:\n",
    "        nearestTP = 0\n",
    "        nearestTPind = -1\n",
    "        \n",
    "    return nearestTP, nearestTPind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stimPhrasesEdit_expt2019Dec(PhraseLog, subjName):\n",
    "    \n",
    "    # Now extract phrases from the phrase file\n",
    "    phraseStim_Phrases = [item[1] for item in PhraseLog]\n",
    "    phraseStim_PhrasesReduced = sorted(set(phraseStim_Phrases), key=phraseStim_Phrases.index)\n",
    "    \n",
    "    PhraseLogReduced= list()\n",
    "    ind = -1\n",
    "    \n",
    "    #print(phraseStim_PhrasesReduced)\n",
    "    \n",
    "    for i in phraseStim_PhrasesReduced:\n",
    "        ind = ind + 1\n",
    "\n",
    "        if ind == len(phraseStim_PhrasesReduced)-1:\n",
    "            if subjName == 'sa\\\\Test_woChinRest\\\\p1':\n",
    "                PhraseLogReduced.append([phraseLog[phraseStim_Phrases.index(i)][0], i[0:31]])\n",
    "                \n",
    "            elif subjName == 'rh\\\\Test_wChinRest\\\\p1':\n",
    "                PhraseLogReduced.append([phraseLog[phraseStim_Phrases.index(i)][0], i[0:-9]])\n",
    "            else:\n",
    "                PhraseLogReduced.append([phraseLog[phraseStim_Phrases.index(i)][0], i])\n",
    "        else:\n",
    "            PhraseLogReduced.append([phraseLog[phraseStim_Phrases.index(i)][0], i])\n",
    "            \n",
    "    del PhraseLogReduced[0]\n",
    "    del PhraseLogReduced[0]\n",
    "    \n",
    "\n",
    "    \n",
    "    if PhraseLogReduced[-1][1] == 'THE EXPERIMENT IS NOW DONE':\n",
    "        del PhraseLogReduced[-1]\n",
    "        \n",
    "    if 'rh\\\\Test_wChinRest\\\\p2' in subjName:\n",
    "        #print(PhraseLogReduced[2])\n",
    "        del PhraseLogReduced[2]\n",
    "        #print(PhraseLogReduced[-1])\n",
    "        del PhraseLogReduced[-1]\n",
    "        \n",
    "    #if subjName == 'sa\\\\Test_woChinRest\\\\p1' or subjName == 'rh\\\\Test_wChinRest\\\\p1':\n",
    "    #    del PhraseLogReduced[-1]\n",
    "        \n",
    "    if 'sa\\\\Test_woChinRest\\\\p2' in subjName:\n",
    "        del PhraseLogReduced[3]\n",
    "        del PhraseLogReduced[1]\n",
    "        del PhraseLogReduced[0]\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    return PhraseLogReduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scratchPadPhraseEdit_expt2019Dec(phraseUser, subjName):\n",
    "    phraseUserEnd = list()\n",
    "    \n",
    "    print(subjName)\n",
    "    \n",
    "    #print(phraseUser)\n",
    "    for row_ind in range(0, len(phraseUser)):\n",
    "        if row_ind!= 0 and phraseUser[row_ind][1] == '':\n",
    "            if len(phraseUser[row_ind-1][1])>10:\n",
    "                phraseUserEnd.append(phraseUser[row_ind-1])\n",
    "                #print(phraseUser[row_ind-1])\n",
    "    \n",
    "    if 'sa\\\\Test_woChinRest\\\\p1' in subjName:\n",
    "        phraseUserEnd.append([phraseUser[-1][0], phraseUser[-1][1][0:35]])\n",
    "    \n",
    "    if 'rh\\\\Test_wChinRest\\\\p1' in subjName:\n",
    "        phraseUserEnd.append(phraseUser[-1])\n",
    "        \n",
    "    # remove first trial of text composition\n",
    "    del phraseUserEnd[0]\n",
    "        \n",
    "    if 'rh\\\\Test_wChinRest\\\\p2' in subjName:\n",
    "        print('deleting: ', phraseUserEnd[-2])\n",
    "        del phraseUserEnd[-2]\n",
    "        \n",
    "    return phraseUserEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeCorrectLetters(PhraseStim, PhraseUserEnd):\n",
    "    \n",
    "    if len(PhraseUserEnd)==len(PhraseStim):\n",
    "        list_nCorrectLetters = list()\n",
    "        \n",
    "        for element in range(0,len(PhraseStim)):\n",
    "            sentence_phraseStim = PhraseStim[element][1]\n",
    "            sentence_phraseUser = PhraseUserEnd[element][1]\n",
    "            \n",
    "            #print(sentence_phraseStim)\n",
    "            #print(sentence_phraseUser)\n",
    "            \n",
    "            # edit sentence if it has a period at the end:\n",
    "            #if sentence_phraseStim[-1] == '.':\n",
    "            #    sentence_phraseStim = sentence_phraseStim[:-1]\n",
    "            #if sentence_phraseUser[-1] != '.':\n",
    "            #    sentence_phraseUser = sentence_phraseUser[:-1]\n",
    "                \n",
    "            # if pound sign in the sentence:\n",
    "            # check first if it is in the phraseStim.\n",
    "            if '£50' in sentence_phraseStim:\n",
    "                # now if some form of currency (pound/kr/kr.) is typed, that will also be added to the phraseStim\n",
    "                if 'pounds' in sentence_phraseUser:\n",
    "                    sentence_phraseStim = sentence_phraseStim.replace('£50', '50 pounds')\n",
    "                    #print('new', sentence_phraseStim)\n",
    "                elif 'pound' in sentence_phraseUser:\n",
    "                    sentence_phraseStim = sentence_phraseStim.replace('£50', '50 pound')\n",
    "                    #print('new', sentence_phraseStim)\n",
    "                \n",
    "                elif '50kr.' in sentence_phraseUser:\n",
    "                    sentence_phraseStim = sentence_phraseStim.replace('£50', '50kr.')\n",
    "                    #print('new', sentence_phraseStim)\n",
    "                elif '50kr' in sentence_phraseUser:\n",
    "                    sentence_phraseStim = sentence_phraseStim.replace('£50', '50kr')\n",
    "                    #print('new', sentence_phraseStim)\n",
    "                \n",
    "                elif '50 kr.' in sentence_phraseUser:\n",
    "                    sentence_phraseStim = sentence_phraseStim.replace('£50', '50 kr.')\n",
    "                    #print('new', sentence_phraseStim)\n",
    "                elif '50 kr' in sentence_phraseUser:\n",
    "                    sentence_phraseStim = sentence_phraseStim.replace('£50', '50 kr')\n",
    "                    #print('new', sentence_phraseStim)\n",
    "                \n",
    "                elif 'L50' in sentence_phraseUser:\n",
    "                    sentence_phraseStim = sentence_phraseStim.replace('£50', 'L50')\n",
    "                    #print('new', sentence_phraseStim)\n",
    "                \n",
    "                else:\n",
    "                    sentence_phraseStim = sentence_phraseStim.replace('£', '')\n",
    "                    #print('new', sentence_phraseStim)\n",
    "                    \n",
    "            \"\"\"\n",
    "            # if people write [?] instead of the complete sentence\n",
    "            if '[?]' in sentence_phraseUser:\n",
    "                sentence_phraseUser = sentence_phraseUser.replace('[?]', '')\n",
    "            \n",
    "            # if people write .../..../..... instead of the complete sentence\n",
    "            \n",
    "            if '.....' in sentence_phraseUser:\n",
    "                sentence_phraseUser = sentence_phraseUser.replace('.....', '')\n",
    "            elif '....' in sentence_phraseUser:\n",
    "                sentence_phraseUser = sentence_phraseUser.replace('....', '')\n",
    "            elif '...' in sentence_phraseUser:\n",
    "                sentence_phraseUser = sentence_phraseUser.replace('...', '')\n",
    "            elif '..' in sentence_phraseUser:\n",
    "                sentence_phraseUser = sentence_phraseUser.replace('..', '')\n",
    "            \"\"\"   \n",
    "            \n",
    "            #print(sentence_phraseStim)\n",
    "            #print(sentence_phraseUser)\n",
    "            #print('\\n')\n",
    "            \n",
    "            nCorrectLetters = max(len(sentence_phraseStim), len(sentence_phraseUser)) - distance.levenshtein(sentence_phraseStim.lower(), sentence_phraseUser.lower())\n",
    "            #nCorrectLetters = len(sentence_phraseUser) - distance.levenshtein(sentence_phraseStim.lower(), sentence_phraseUser.lower())\n",
    "            \n",
    "            list_nCorrectLetters.append(nCorrectLetters)\n",
    "            #print('Number of correct letters typed: ', nCorrectLetters, '   and number of letters to be typed: ', len(sentence_phraseStim))\n",
    "            #print('\\n')\n",
    "            \n",
    "    \n",
    "    else:\n",
    "        print('stimulation phrases and user phrases do not match')\n",
    "        print('stimulation phrases:    ', PhraseStim)\n",
    "        print('user phrases:    ', PhraseUserEnd)\n",
    "        \n",
    "    return list_nCorrectLetters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EffectiveTimeFromUserKeys(UserKeys, PhrasesStim, PhraseUser, ValidityGazeLog, pathOfSession):\n",
    "    \n",
    "    UserKeysTime = [val[0] for val in UserKeys]\n",
    "    ValidityGazeLog_time = [val[0] for val in ValidityGazeLog]\n",
    "    \n",
    "    # session name\n",
    "    session_folder_name = pathOfSession.split('\\\\')[-1]\n",
    "    \n",
    "    timeTypingList = list()\n",
    "    \n",
    "    # time between and within fixations on a single letter\n",
    "    ind_timePrevious = -1\n",
    "    for time1 in UserKeysTime[1:]:\n",
    "        ind_timePrevious = ind_timePrevious + 1\n",
    "        time0 = UserKeysTime[ind_timePrevious]\n",
    "        \n",
    "        time, t1, t2 = time0.partition('+')\n",
    "        timeStart = datetime.datetime.strptime(re.sub('[:.T]','-',time[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "        \n",
    "        time, t1, t2 = time1.partition('+')\n",
    "        timeEnd = datetime.datetime.strptime(re.sub('[:.T]','-',time[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "    \n",
    "        timeBnPoints = timeEnd - timeStart\n",
    "        \n",
    "    \n",
    "    # find starting point of every phrase \n",
    "    #print(len(PhrasesStim), len(PhraseUser))\n",
    "    for ind_phrase in range(0,len(PhrasesStim)):\n",
    "        #print(ind, PhrasesStim[ind][1], PhraseUser[ind][1])\n",
    "        timePhraseStarts = PhrasesStim[ind_phrase][0]\n",
    "        # Find the time when the phrase starts\n",
    "        timePhraseStartsWUserKeys, ind_start = nearestTimePoint(UserKeysTime, timePhraseStarts)\n",
    "        \n",
    "        \n",
    "        # find when the phrase ends:\n",
    "        if ind_phrase == len(PhrasesStim)-1: # if it is the last sentence, reverse index searching starts from the last index\n",
    "            ind_end = len(UserKeys) - 1\n",
    "            if 'sa\\\\Test_woChinRest\\\\p1' in root:\n",
    "                ind_end_time, ind_end = nearestTimePoint(UserKeysTime, '2018-12-04T13:47:56.5055472+01:00')\n",
    "        else: # if it's not the last sentence, reverse index searching starts from the next phrase\n",
    "            ind_end_time, ind_end = nearestTimePoint(UserKeysTime, PhrasesStim[ind_phrase+1][0])\n",
    "        \n",
    "        \n",
    "        flag_start = 0\n",
    "        typing_list = list()\n",
    "        letter_time_list = list()\n",
    "        letter_list = list()\n",
    "        keys_all_list = list()\n",
    "        keys_ind_list = list()\n",
    "        \n",
    "        \n",
    "        \n",
    "        n_key = 0\n",
    "        \n",
    "        # collect the typing letters in a list of lists\n",
    "        # leftshift do not count, because when comparing stim phrase and user phrase, the sentence is converted to lowercase\n",
    "        for ind_typing in range(ind_start, ind_end):\n",
    "            \n",
    "            # create a list of indexes of added keys, to see later if the time between them should be counted or not\n",
    "            \n",
    "            if ind_typing > ind_start:\n",
    "                if UserKeys[ind_typing-1][1] != UserKeys[ind_typing][1]:\n",
    "                    n_key = n_key + 1\n",
    "                    keys_all_list.append(UserKeys[ind_typing][1])\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            \n",
    "            if len(UserKeys[ind_typing][1]) == 1 or UserKeys[ind_typing][1] in list_keysToBeCounted or 'Suggestion' in UserKeys[ind_typing][1]:\n",
    "                \n",
    "                #if not UserKeys[ind_typing][1].isdigit(): # time for writing digits need to be counted, since they will \n",
    "                # be counted in counting the correct letters\n",
    "                 \n",
    "                letter_time_list.append(UserKeys[ind_typing][0]) \n",
    "                #print(UserKeys[ind_typing][1])\n",
    "                if UserKeys[ind_typing][1] != UserKeys[ind_typing+1][1]:\n",
    "                        \n",
    "                    # make a huge list of all things continuous to be added\n",
    "                    #if len(UserKeys[ind_typing+1][1]) != 1 and UserKeys[ind_typing+1][1] not in list_keysToBeCounted and 'Suggestion' not in UserKeys[ind_typing+1][1]:\n",
    "                        \n",
    "                    #print(UserKeys[ind_typing][1], ',', UserKeys[ind_typing+1][1])\n",
    "                    #print('letter time list', letter_time_list)\n",
    "                    #print(UserKeys[ind_typing][1])\n",
    "                    #print('')\n",
    "                    typing_list.append(letter_time_list)\n",
    "                    keys_ind_list.append(n_key)\n",
    "                    letter_list.append(UserKeys[ind_typing][1])\n",
    "                    letter_time_list = list()\n",
    "                   \n",
    "        \n",
    "        # print('start and end:', typing_list[0][0], typing_list[-1][-1])\n",
    "        time1, t1, t2 = typing_list[0][0].partition('+')\n",
    "        timeStart = datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "            \n",
    "        time2, t1, t2 = typing_list[-1][-1].partition('+')\n",
    "        timeEnd = datetime.datetime.strptime(re.sub('[:.T]','-',time2[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "            \n",
    "        timeDiff = timeEnd - timeStart\n",
    "        #print(timeDiff.total_seconds())\n",
    "        \n",
    "        # add the time for typing every letter in a phrase\n",
    "        time_typing_letter = 0\n",
    "        ind_typing_letter = -1\n",
    "        \n",
    "        for letter_typed_list in typing_list:\n",
    "            ind_typing_letter = ind_typing_letter + 1\n",
    "            \n",
    "            #if letter_list[ind_typing_letter] == '.' and ind_typing_letter < len(typing_list)-1: \n",
    "            #    if letter_list[ind_typing_letter+1] == '.':\n",
    "            #        print('next one', letter_list[ind_typing_letter], letter_list[ind_typing_letter+1])\n",
    "            #    if letter_list[ind_typing_letter-1] == '.':\n",
    "            #        print('previous one', letter_list[ind_typing_letter-1], letter_list[ind_typing_letter])\n",
    "            \n",
    "            #print(letter_list[ind_typing_letter])\n",
    "            \n",
    "            time1, t1, t2 = letter_typed_list[0].partition('+')\n",
    "            timeStart = datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "            \n",
    "            time2, t1, t2 = letter_typed_list[-1].partition('+')\n",
    "            timeEnd = datetime.datetime.strptime(re.sub('[:.T]','-',time2[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "            \n",
    "            timeDiff = timeEnd - timeStart\n",
    "            \n",
    "            time_typing_letter = time_typing_letter + timeDiff.total_seconds()\n",
    "        \n",
    "            \n",
    "            # activation time is 250ms - add that for every key looked at, which will not be counted afterwards\n",
    "            #time_typing_letter = time_typing_letter + 0.25\n",
    "            \n",
    "            \n",
    "            \n",
    "            #print(timeStart, timeEnd, timeDiff.total_seconds())\n",
    "        \n",
    "        timeTypingList.append(time_typing_letter)\n",
    "        #print(time_typing_letter)\n",
    "\n",
    "        \n",
    "        #print(pathOfSession)\n",
    "        \n",
    "        \n",
    "        #print('time in between')\n",
    "        \n",
    "        # add time between each letter, if it is valid to add --\n",
    "        # for data more than 5s, not added at all\n",
    "        # for data less than 5s, validity checked using gaze origin validity obtain from the tobii tracker, \n",
    "        # and if it shows valid pupil data for at least 50% of the time in between\n",
    "        ind_letterTyped_previous = -1\n",
    "        time_bnLetterCurrent = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        for letter_being_typed in typing_list[1:]:\n",
    "            \n",
    "            ind_letterTyped_previous = ind_letterTyped_previous + 1\n",
    "            \n",
    "            time_previousEnd_Str = typing_list[ind_letterTyped_previous][-1]\n",
    "            time_currentStart_Str = letter_being_typed[0]\n",
    "            \n",
    "            time1, t1, t2 = time_previousEnd_Str.partition('+')\n",
    "            time_previousEnd = datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "            \n",
    "            time2, t1, t2 = time_currentStart_Str.partition('+')\n",
    "            time_currentStart = datetime.datetime.strptime(re.sub('[:.T]','-',time2[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "            \n",
    "            time_bnLetters_notS = time_currentStart - time_previousEnd\n",
    "            time_bnLetters = time_bnLetters_notS.total_seconds()\n",
    "            \n",
    "            \n",
    "            if keys_ind_list[ind_letterTyped_previous+1] != keys_ind_list[ind_letterTyped_previous] + 1:\n",
    "                timeTypingList[-1] = timeTypingList[-1] + 0.25 \n",
    "                \n",
    "                #print('activation time at', time_currentStart)\n",
    "                continue\n",
    "            \n",
    "            #print(time_previousEnd, time_currentStart, time_bnLetters, 'between', letter_list[ind_letterTyped_previous], 'and', letter_list[ind_letterTyped_previous+1])\n",
    "            \n",
    "            if time_bnLetters < 5:\n",
    "                \n",
    "                if time_bnLetters < 2:\n",
    "                    time_bnLetterCurrent = time_bnLetterCurrent + time_bnLetters\n",
    "                    \n",
    "                else:\n",
    "                    \"\"\"\n",
    "                    #if '2019-01-16-17-00-12' in pathOfSession or '2019-01-17-15-31-12_2' in pathOfSession:\n",
    "                    if session_folder_name in dic_noGazeData:\n",
    "                        if ind == len(PhrasesStim)-1:\n",
    "                            return timeTypingList\n",
    "                        else:\n",
    "                            continue\n",
    "                    \"\"\"\n",
    "                    # find the number of valid points in gaze\n",
    "                    timeStart_gazeLog_Str, timeStart_gazeLog_ind = nearestTimePoint(ValidityGazeLog_time, time_previousEnd_Str)\n",
    "                    timeEnd_gazeLog_Str, timeEnd_gazeLog_ind = nearestTimePoint(ValidityGazeLog_time, time_currentStart_Str)\n",
    "                    validitySubset = [ValidityGazeLog[ind][1] for ind in range(timeStart_gazeLog_ind, timeEnd_gazeLog_ind)]\n",
    "                    validity_pct = validitySubset.count(True)/len(validitySubset)\n",
    "                    \n",
    "                    if validity_pct > 0.8:\n",
    "                        time_bnLetterCurrent = time_bnLetterCurrent + time_bnLetters\n",
    "                    \n",
    "        #print(timeTypingList[-1], time_bnLetterCurrent)    \n",
    "        timeTypingList[-1] = timeTypingList[-1] + time_bnLetterCurrent\n",
    "        #print(timeTypingList[-1])\n",
    "        \n",
    "    return timeTypingList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddToFile(typing_speed, subjectID, resultPathName):\n",
    "   \n",
    "    \n",
    "    \n",
    "    wb = load_workbook(resultPathName)\n",
    "    ws = wb.worksheets[0]\n",
    "    \n",
    "    typing_speed.insert(0, subjectID)\n",
    "    ws.append(typing_speed)\n",
    "    \n",
    "    \n",
    "    \n",
    "    wb.save(resultPathName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typing_speed\n",
      "subject path C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\bh\\Test_wChinRest\\2018-12-6-14-7-18\n",
      "subjand session name bh\\Test_wChinRest\n",
      "subject id:  bh\n",
      "C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\bh\\Test_wChinRest\\2018-12-6-14-7-18\n",
      "CORRECT LETTERS [71, 113, 38, 54, 52, 66, 48, 58, 36]\n",
      "effective time [147.019993, 197.15950700000008, 57.04250099999999, 106.64713799999998, 78.46974999999998, 173.95906399999996, 103.183287, 117.808735, 102.09836800000001]\n",
      "\n",
      "\n",
      "subject path C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\bh\\Test_woChinRest\\2018-12-4-11-28-41\n",
      "subjand session name bh\\Test_woChinRest\n",
      "subject id:  bh\n",
      "C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\bh\\Test_woChinRest\\2018-12-4-11-28-41\n",
      "CORRECT LETTERS [89, 101, 96, 96, 48, 43, 54, 100, 74]\n",
      "effective time [169.25365300000004, 196.62408199999993, 168.31506399999998, 182.1330380000001, 58.912909, 77.74975700000002, 62.482373, 201.79516899999993, 105.34690300000003]\n",
      "\n",
      "\n",
      "subject path C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\ph\\Test_wChinRest\\2018-12-5-13-46-55\n",
      "subjand session name ph\\Test_wChinRest\n",
      "subject id:  ph\n",
      "C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\ph\\Test_wChinRest\\2018-12-5-13-46-55\n",
      "CORRECT LETTERS [34, 51, 123, 38, 59, 55, 119, 17, 66]\n",
      "effective time [52.708459000000005, 76.168668, 242.879435, 74.01191199999997, 85.33223200000002, 76.96789899999999, 194.98163599999992, 24.379794, 108.96785899999995]\n",
      "\n",
      "\n",
      "subject path C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\ph\\Test_woChinRest\\2018-12-6-11-4-13\n",
      "subjand session name ph\\Test_woChinRest\n",
      "subject id:  ph\n",
      "C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\ph\\Test_woChinRest\\2018-12-6-11-4-13\n",
      "CORRECT LETTERS [100, 115, 110, 34, 31, 78, 21, 48, 135]\n",
      "effective time [167.272176, 164.40330399999993, 164.22120900000002, 45.079877, 42.34245200000001, 112.25255199999998, 27.041193, 76.10055000000001, 192.13594399999994]\n",
      "\n",
      "\n",
      "subject path C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\pt\\Test_wChinRest\\2018-12-4-9-24-15\n",
      "subjand session name pt\\Test_wChinRest\n",
      "subject id:  pt\n",
      "C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\pt\\Test_wChinRest\\2018-12-4-9-24-15\n",
      "CORRECT LETTERS [46, 87, 138, 104, 18, 20, 93, 45, 142]\n",
      "effective time [73.309017, 168.413495, 234.9245349999999, 200.88596700000008, 28.687792, 28.253026000000002, 151.18450099999998, 63.64975300000001, 233.72918999999993]\n",
      "\n",
      "\n",
      "subject path C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\pt\\Test_woChinRest\\2018-12-5-14-50-53\n",
      "subjand session name pt\\Test_woChinRest\n",
      "subject id:  pt\n",
      "C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\pt\\Test_woChinRest\\2018-12-5-14-50-53\n",
      "CORRECT LETTERS [67, 33, 67, 54, 35, 137, 97, 48, 15]\n",
      "effective time [97.78169700000001, 45.557871, 170.759104, 81.31896699999999, 46.866823, 246.44955500000006, 140.973169, 91.565848, 21.286026999999997]\n",
      "\n",
      "\n",
      "subject path C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\rh\\Test_wChinRest\\p1\\2018-11-29-12-52-2\n",
      "subjand session name rh\\Test_wChinRest\\p1\n",
      "subject id:  rh\n",
      "C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\rh\\Test_wChinRest\\p1\\2018-11-29-12-52-2\n",
      "subject path C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\rh\\Test_wChinRest\\p2\\2018-11-30-11-23-37\n",
      "subjand session name rh\\Test_wChinRest\\p2\n",
      "subject id:  rh\n",
      "C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\rh\\Test_wChinRest\\p2\\2018-11-30-11-23-37\n",
      "deleting:  ['2018-11-30T11:38:35.8784680+01:00', 'Efterårssemet']\n",
      "CORRECT LETTERS [73, 92, 83, 36, 52, 20, 89, 69, 58]\n",
      "effective time [134.93503, 247.43271100000013, 140.040391, 66.73810100000001, 85.02688500000001, 31.028521, 181.645669, 114.62791300000004, 96.33991699999999]\n",
      "\n",
      "\n",
      "subject path C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\rh\\Test_woChinRest\\2018-11-30-11-43-39\n",
      "subjand session name rh\\Test_woChinRest\n",
      "subject id:  rh\n",
      "C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\rh\\Test_woChinRest\\2018-11-30-11-43-39\n",
      "CORRECT LETTERS [114, 150, 38, 74, 34, 37, 29, 117, 170]\n",
      "effective time [170.00234799999996, 296.3252559999999, 49.214684000000005, 104.41378100000001, 45.473612999999986, 49.47685699999999, 38.10782599999999, 167.51523400000002, 250.38678700000014]\n",
      "\n",
      "\n",
      "subject path C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\sa\\Test_wChinRest\\2018-12-5-11-44-0\n",
      "subjand session name sa\\Test_wChinRest\n",
      "subject id:  sa\n",
      "C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\sa\\Test_wChinRest\\2018-12-5-11-44-0\n",
      "CORRECT LETTERS [53, 20, 74, 27, 67, 93, 64, 32, 57]\n",
      "effective time [115.631598, 34.781974000000005, 151.19963999999996, 49.132465999999994, 132.55012000000002, 207.36324400000007, 167.83777799999993, 61.26817599999999, 99.763841]\n",
      "\n",
      "\n",
      "subject path C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\sa\\Test_woChinRest\\p1\\2018-12-4-13-30-1\n",
      "subjand session name sa\\Test_woChinRest\\p1\n",
      "subject id:  sa\n",
      "C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\sa\\Test_woChinRest\\p1\\2018-12-4-13-30-1\n",
      "subject path C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\sa\\Test_woChinRest\\p2\\2018-12-5-11-8-24\n",
      "subjand session name sa\\Test_woChinRest\\p2\n",
      "subject id:  sa\n",
      "C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data\\sa\\Test_woChinRest\\p2\\2018-12-5-11-8-24\n",
      "CORRECT LETTERS [31, 87, 33, 50, 34, 46, 55, 117, 133]\n",
      "effective time [54.11857099999999, 239.83404799999983, 229.69312000000008, 150.67433800000003, 116.26510499999995, 98.28589100000002, 124.791325, 249.07095500000003, 396.41032499999983]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metricComputed = 'typing_speed'\n",
    "print(metricComputed)\n",
    "dataFolderName = r'C:\\DTU\\Data\\201812_ExptToCheckMovementEffect\\Data' # accessing external hard disk with the data\n",
    "a = re.compile('(?<=ExptToCheckMovementEffect\\\\\\\\Data\\\\\\\\)(.*)(?=\\\\\\\\2018-1)')\n",
    "\n",
    "\n",
    "TypingSpeed = list()\n",
    "\n",
    "list_typingSpeed_trial = list()\n",
    "list_typingSpeed_subject = list()\n",
    "\n",
    "typing_speed_wChinRest = list()\n",
    "typing_speed_woChinRest = list()\n",
    "\n",
    "for root, dirs, subfolder in os.walk(dataFolderName):\n",
    "    \n",
    "    \n",
    "    \n",
    "    if not dirs:\n",
    "        \n",
    "        if 'tb' in root or 'trial' in root or 'he\\\\' in root:\n",
    "            continue\n",
    "            \n",
    "        #if 'rh' not in root:\n",
    "        #    continue\n",
    "        \n",
    "        scratchPad = None\n",
    "        userKeys = None\n",
    "        phraseLog = None\n",
    "        \n",
    "        for file in subfolder:\n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'ScratchPadLog*'):\n",
    "                try:\n",
    "                    fScratchPad = open(root + '\\\\' + file, encoding='utf-8', newline='')\n",
    "                    readerScratchPad = csv.reader(fScratchPad, quotechar=None)\n",
    "                    scratchPad = list(readerScratchPad)\n",
    "                except:\n",
    "                    if fScratchPad is not None:\n",
    "                        fScratchPad.close()\n",
    "                    else:\n",
    "                        print('error in opening the scratchpad log file')\n",
    "            \n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'user*'):\n",
    "                try:\n",
    "                    fUserKey = open(root + '\\\\' + file, encoding='utf-8',  newline='')\n",
    "                    readerUserKey = csv.reader(fUserKey, quotechar=None)\n",
    "                    userKeys = list(readerUserKey)\n",
    "                    userKeys.remove(userKeys[0])\n",
    "                except:\n",
    "                    if fUserKey is not None:\n",
    "                        fUserKey.close()\n",
    "                    else:\n",
    "                        print('error in opening the user key log file')\n",
    "                        \n",
    "            if fnmatch.fnmatch(file, 'phrase*'):\n",
    "                try:\n",
    "                    fPhraseLog = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerPhraseLog = csv.reader(fPhraseLog, quotechar=None)\n",
    "                    phraseLog = list(readerPhraseLog)\n",
    "                    \n",
    "                except:\n",
    "                    if fPhraseLog is not None:\n",
    "                        fPhraseLog.close()\n",
    "                    else:\n",
    "                        print('error in opening the phrase log file')\n",
    "                        \n",
    "            if fnmatch.fnmatch(file, 'ReplacementPhraseLog.csv'):\n",
    "                \n",
    "                try:\n",
    "                    fPhraseLog = open(root + '\\\\' + file)\n",
    "                    readerPhraseLog = csv.reader(fPhraseLog)\n",
    "                    phraseLog = list(readerPhraseLog)\n",
    "                        \n",
    "                except:\n",
    "                    if fPhraseLog is not None:\n",
    "                        print('closing')\n",
    "                        fPhraseLog.close()\n",
    "                    else:\n",
    "                        print('error in opening the replacement phrase log file')\n",
    "                        \n",
    "            if fnmatch.fnmatch(file, 'multiKey*'):\n",
    "                technique = 'multiKey_selection'\n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'tobiiGazeLog*'):\n",
    "                try:\n",
    "                    fGazeLog = open(root + '\\\\' + file, encoding='utf-8', newline='')\n",
    "                    readerGazeLog = csv.reader(fGazeLog, quotechar=None)\n",
    "                    gazeLog = list(readerGazeLog)\n",
    "                    \n",
    "                except:\n",
    "                    if fGazeLog is not None:\n",
    "                        fGazeLog.close()\n",
    "                    else:\n",
    "                        print('error in opening the scratchpad log file')\n",
    "            \n",
    "                    \n",
    "                     \n",
    "        if scratchPad is None or userKeys is None or phraseLog is None or gazeLog is None:\n",
    "            continue\n",
    "        else:\n",
    "            print('subject path', root)\n",
    "            subjAndSessionName = a.findall(root)[0]\n",
    "            print('subjand session name', subjAndSessionName)\n",
    "            subjName = subjAndSessionName.split('\\\\')[0]\n",
    "            #print('subject id: ', subjName)\n",
    "            \n",
    "            # a participant had problem with the computer, so the last phrase is not documented completely\n",
    "            if 'sa\\\\Test_woChinRest\\\\p1' in root:\n",
    "                scratchPad = scratchPad[0:-1]\n",
    "            \n",
    "            # fix scratchpad due to comma related file changes\n",
    "            scratchPad_new = FixScratchPad(scratchPad)\n",
    "            \n",
    "            # fix phraselog due to comma related file changes\n",
    "            phraseLog_new = FixScratchPad(phraseLog)\n",
    "            \n",
    "            \n",
    "            # fix userKeys due to comma related file changes\n",
    "            userKeys_new = FixUserKeys(userKeys)\n",
    "                \n",
    "            # find dwell time of typing\n",
    "            userKeys_wDwellTime = ComputeDwellTime(userKeys_new)\n",
    "                \n",
    "            phraseStim_reduced = stimPhrasesEdit_expt2019Dec(phraseLog_new, root)\n",
    "            \n",
    "            phraseUserEnd_reduced = scratchPadPhraseEdit_expt2019Dec(scratchPad_new, root)\n",
    "            \n",
    "            \n",
    "            # find validity of gaze log -- combine a validity measure with an or of right and left gaze\n",
    "            time_gazeLog = [item[0] for item in gazeLog]\n",
    "            validity_leftGaze = [True if item[2]=='Valid' else False for item in gazeLog ]\n",
    "            validity_rightGaze = [True if item[9] == 'Valid' else False for item in gazeLog ]\n",
    "            \n",
    "            validity_gazeLog = [[time_gazeLog[i], validity_leftGaze[i] or validity_rightGaze[i]] for i in range(0, len(time_gazeLog)) ]\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            print('STIM PHRASES')\n",
    "            for i in phraseStim_reduced:\n",
    "                print(i)\n",
    "            print('USER PHRASES')\n",
    "            for i in phraseUserEnd_reduced:\n",
    "                print(i)\n",
    "            \"\"\"\n",
    "            \n",
    "            if 'p1' in root:\n",
    "                if 'sa\\\\Test_woChinRest' in root:\n",
    "                    phraseStim_reduced[-1][1] = phraseStim_reduced[-1][1][0:36]\n",
    "                else:\n",
    "                    phraseStim_reduced[1][1] = phraseStim_reduced[1][1][0:117]\n",
    "                #print('DONE:::::::', phraseStim_reduced)\n",
    "                    \n",
    "                phraseUserEnd_reduced1 = phraseUserEnd_reduced\n",
    "                phraseStim_reduced1 = phraseStim_reduced\n",
    "                userKeys_wDwellTime1 = userKeys_wDwellTime\n",
    "                validity_gazeLog1 = gazeLog\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            \n",
    "            if 'p2' in root:\n",
    "                phraseUserEnd_reduced2 = phraseUserEnd_reduced\n",
    "                phraseStim_reduced2 = phraseStim_reduced\n",
    "                userKeys_wDwellTime2 = userKeys_wDwellTime\n",
    "                validity_gazeLog2 = validity_gazeLog\n",
    "                \n",
    "                \n",
    "                \n",
    "                phraseUserEnd_reduced = phraseUserEnd_reduced1 + phraseUserEnd_reduced2\n",
    "                phraseStim_reduced = phraseStim_reduced1 + phraseStim_reduced2\n",
    "                userKeys_wDwellTime = userKeys_wDwellTime1 + userKeys_wDwellTime2\n",
    "                validity_gazeLog = validity_gazeLog1 + validity_gazeLog2\n",
    "                \n",
    "                phraseUserEnd_reduced1 = list()\n",
    "                phraseStim_reduced1 = list()\n",
    "                userKeys_wDwellTime1 = list()\n",
    "                validity_gazeLog1 = list()\n",
    "                \n",
    "            \n",
    "                \n",
    "            # check if the number of sentences match in the input and the output\n",
    "            if len(phraseUserEnd_reduced)!=len(phraseStim_reduced):\n",
    "                print('needs fixing of number of phrases')\n",
    "                #print('before', phraseStim_reduced)\n",
    "                #phraseStim_toMatch, phraseUserEnd_toMatch = MatchPhraseNumbers(phraseStim_reduced, phraseUserEnd_reduced)\n",
    "                #print('after', phraseStim_toMatch)\n",
    "            else:\n",
    "                phraseStim_toMatch = phraseStim_reduced\n",
    "                phraseUserEnd_toMatch = phraseUserEnd_reduced\n",
    "                \n",
    "            \n",
    "            #for sentence in phraseUserEnd_toMatch:\n",
    "            #    print(sentence[1])\n",
    "            \n",
    "            # Find the number of correct letters typed\n",
    "            # ComputeCorrectLetters(phraseStim_reduced, phraseUserEnd_reduced)\n",
    "            nCorrectLetters = ComputeCorrectLetters(phraseStim_toMatch, phraseUserEnd_toMatch)\n",
    "            print('CORRECT LETTERS', nCorrectLetters)\n",
    "            \n",
    "            # Effective time of typing:\n",
    "            # Find time of typing only every letter, numbers, space and changing of keyboards\n",
    "            \n",
    "            effective_time = EffectiveTimeFromUserKeys(userKeys_wDwellTime, phraseStim_toMatch, phraseUserEnd_toMatch, validity_gazeLog, root)\n",
    "            \n",
    "            \n",
    "            if len(nCorrectLetters) == len(effective_time):\n",
    "                for i in range(0, len(nCorrectLetters)):\n",
    "                    list_typingSpeed_trial.append((nCorrectLetters[i]*60)/(effective_time[i]*5))\n",
    "            else:\n",
    "                print('nCorrectLetters and effective_time have unequal lengths')\n",
    "            \n",
    "            \n",
    "            \n",
    "            print('effective time', effective_time)\n",
    "            print('\\n')\n",
    "            \n",
    "            if 'wChinRest' in root:\n",
    "                typing_speed_wChinRest.append(list_typingSpeed_trial)\n",
    "            else:\n",
    "                typing_speed_woChinRest.append(list_typingSpeed_trial)\n",
    "                \n",
    "            list_typingSpeed_trial = list()\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "new metric added\n"
     ]
    }
   ],
   "source": [
    "# save data to file\n",
    "\n",
    "participant_id = [1, 2, 3, 4, 5]\n",
    "n_trials = 9\n",
    "\n",
    "participant_id_list = [[1]*n_trials, [2]*n_trials, [3]*n_trials, [4]*n_trials, [5]*n_trials]\n",
    "\n",
    "# flatten lists\n",
    "typingSpeed_wChinRest = [item for sublist in typing_speed_wChinRest for item in sublist]\n",
    "typingSpeed_woChinRest = [item for sublist in typing_speed_woChinRest for item in sublist]\n",
    "\n",
    "# join lists of with and without chin rest\n",
    "typingSpeed_total = typingSpeed_wChinRest + typingSpeed_woChinRest\n",
    "\n",
    "# first find the number of columns in the existing file\n",
    "filePath_PythonData = \"C:\\\\DTU\\\\Data\\\\201812_ExptToCheckMovementEffect\\\\Data\\\\python_data2.xlsx\"\n",
    "loc = (filePath_PythonData) \n",
    "  \n",
    "sheet = xlrd.open_workbook(loc).sheet_by_index(0)\n",
    "\n",
    "# Extracting number of rows \n",
    "print(sheet.ncols) \n",
    "\n",
    "sheet_columns = [sheet.row(0)[i].value for i in range(0, sheet.ncols)]\n",
    "\n",
    "df_existing = pd.read_excel(filePath_PythonData)\n",
    "    \n",
    "if metricComputed not in sheet_columns:\n",
    "    filePath_PythonData_new = filePath_PythonData\n",
    "    print('new metric added')\n",
    "\n",
    "else:\n",
    "    filePath_PythonData_new = filePath_PythonData[0:-5] + '_new' + filePath_PythonData[-5:]\n",
    "    print('This metric is already calculated and saved: ', metricComputed)\n",
    "    \n",
    "df_existing[metricComputed] = typingSpeed_total\n",
    "df_existing.to_excel(filePath_PythonData_new ,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
