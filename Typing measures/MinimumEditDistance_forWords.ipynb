{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\taba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import csv\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import operator\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import snowball\n",
    "import distance\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phrasesEdit(phraseUser, phraseStim):\n",
    "    phraseUserEnd = list()\n",
    "    \n",
    "    #print(phraseUser)\n",
    "    for row_ind in range(0, len(phraseUser)):\n",
    "        if row_ind!= 0 and phraseUser[row_ind][1] == '':\n",
    "            phraseUserEnd.append(phraseUser[row_ind-1])\n",
    "    \n",
    "    # Attempt to remove all elements that are not end phrases - stimulated or user-generated\n",
    "    \n",
    "    for row_ind2 in range(0, len(phraseStim)):\n",
    "        if phraseStim[row_ind2][1] == 'THE EXPERIMENT IS NOW DONE':\n",
    "            phraseUserEnd.remove(phraseUserEnd[row_ind2])\n",
    "            phraseStim.remove(phraseStim[row_ind2])\n",
    "    \n",
    "    row_ind3 = len(phraseUserEnd)\n",
    "    while row_ind3 > -1:\n",
    "        row_ind3 = row_ind3 - 1\n",
    "#    for row_ind3 in range(0, len(phraseUserEnd)):\n",
    "        #print(phraseUserEnd[row_ind3][1])\n",
    "        if phraseUserEnd[row_ind3][1] == '':\n",
    "            \n",
    "            if row_ind3 < len(phraseStim):\n",
    "                #print(row_ind3)\n",
    "                #print(phraseStim[row_ind3])\n",
    "                #print(phraseUserEnd[row_ind3])\n",
    "                #print(phraseStim)\n",
    "                #print(phraseUserEnd)\n",
    "                phraseStim.remove(phraseStim[row_ind3])\n",
    "                phraseUserEnd.remove(phraseUserEnd[row_ind3])\n",
    "    \n",
    "    # if phrases documented have a comma, the said phrase is split and saved into different columns. They need to be joined\n",
    "    for row_ind4 in range(0, len(phraseStim)):\n",
    "        if len(phraseStim[row_ind4])>2:\n",
    "            phraseStim[row_ind4][1] = ''.join(phraseStim[row_ind4][1:])\n",
    "        \n",
    "    for row_ind5 in range(0, len(phraseUserEnd)):\n",
    "        if len(phraseUserEnd[row_ind5])>2:\n",
    "            phraseUserEnd[row_ind5][1] = ''.join(phraseUserEnd[row_ind5][1:])\n",
    "    \n",
    "    #print(phraseUserEnd)\n",
    "    #print('bvjdbvfjbvdjfvndfjvbdfjkvdfkn')\n",
    "    #print(phraseStim)\n",
    "    \n",
    "    return phraseUserEnd, phraseStim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find minimum cost and the operations that give rise to it\n",
    "def minValnInd(costOptions, flagSame):\n",
    "    operator = list()\n",
    "    unique_entries = set(costOptions)\n",
    "    valInd = { value : [ i for i, v in enumerate(costOptions) if v == value ] for value in unique_entries }\n",
    "    keyVal = list(valInd.keys())\n",
    "    min_value = min(keyVal)\n",
    "    \n",
    "    if 0 in valInd[min_value]:\n",
    "        operator.append('D')\n",
    "    if 1 in valInd[min_value]:\n",
    "        operator.append('I')\n",
    "    if 2 in valInd[min_value]:\n",
    "        if flagSame == 0:\n",
    "            operator.append('S')\n",
    "        else:\n",
    "            operator.append('N')   \n",
    "    flagSame = None    \n",
    "    return min_value, ''.join(operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the MSD, with cost of 2 for substitution and 1 for insertion and deletion\n",
    "costSub = 2\n",
    "costIns = 1\n",
    "costDel = 1\n",
    "\n",
    "def levenshteinDist(phraseIn, phraseOut):\n",
    "    \n",
    "    lenStim = len(phraseIn)\n",
    "    lenUser = len(phraseOut)\n",
    "    costMatrix = np.zeros((lenStim+1, lenUser+1), dtype=int)\n",
    "    MSDoperation = np.empty([lenStim+1, lenUser+1], dtype=\"U4\")\n",
    "    costMatrix[0,0:] = range(0, lenUser+1)\n",
    "    costMatrix[0:,0] = range(0, lenStim+1)\n",
    "    MSDoperation[0,0:] = 'I'\n",
    "    MSDoperation[0:,0] = 'D'\n",
    "    \n",
    "    for i in range(1, len(phraseIn)+1):\n",
    "        iP = i - 1\n",
    "        for j in range(1, len(phraseOut)+1):\n",
    "            jP = j - 1\n",
    "            if phraseIn[iP].lower() == phraseOut[jP].lower():\n",
    "                # Define the possible cost array\n",
    "                costOptionArray = [costMatrix[i,j-1]+costDel, costMatrix[i-1,j]+costIns, costMatrix[i-1,j-1]] \n",
    "                flagSame = 1\n",
    "            else:\n",
    "                costOptionArray = [costMatrix[i,j-1]+costDel, costMatrix[i-1,j]+costIns, costMatrix[i-1,j-1]+costSub]\n",
    "                flagSame = 0\n",
    "            costMatrix[i,j], MSDoperation[i][j] = minValnInd(costOptionArray, flagSame)\n",
    "    #print(costMatrix)\n",
    "    return costMatrix[-1,-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddDataToFile(metricComputed, Names, DataEvaluated):\n",
    "\n",
    "    # Save the data\n",
    "    fileIn = r'C:\\DTU\\Data\\201805_HealthnRehab\\data_summary.csv'\n",
    "\n",
    "    if Path(fileIn).is_file():\n",
    "        print(fileIn)\n",
    "        fSize = os.path.getsize(fileIn) # or pd.read_excel(filename) for xls file\n",
    "\n",
    "        # file exists\n",
    "        # check if the given column exists\n",
    "        with open(fileIn, 'r', newline='') as csvfileRead:\n",
    "            if fSize > 0:\n",
    "                fileOut = fileIn[:-4] + '1.csv'\n",
    "                with open(fileOut, 'w', newline='') as csvfileWrite:\n",
    "                    for row in csv.reader(csvfileRead):\n",
    "                        if metricComputed in row:\n",
    "                            # file exists and the metric is present in the file\n",
    "                            print('This metric is already calculated and saved: ', metricComputed)\n",
    "                            break\n",
    "                        else:\n",
    "                            # file exists but the metric is not present\n",
    "                            print('adding the metric')\n",
    "                            filewriter = csv.writer(csvfileWrite, delimiter = ',')\n",
    "                            if len(row) > 1:\n",
    "                                rowJoined = list()\n",
    "                                for rowElement in row:\n",
    "                                    rowJoined.append(rowElement)\n",
    "                                \n",
    "                                \n",
    "                                print(rowJoined[1])\n",
    "                                \n",
    "                                if rowJoined[1] == 'subject_name':\n",
    "                                    # write the titles of the metrics\n",
    "                                    rowJoined.append(metricComputed)\n",
    "                                    filewriter.writerow(rowJoined)\n",
    "                                else:\n",
    "                                    #filewriter.writerow([row, str(DataEvaluated[Names.index(row[0])])])\n",
    "                                    rowJoined.append(str(DataEvaluated[Names.index(row[1])]))\n",
    "                                    filewriter.writerow(rowJoined)\n",
    "                                \n",
    "                            else:\n",
    "                                if row[1] == 'subject_name':\n",
    "                                    # write the titles of the metrics\n",
    "                                    filewriter.writerow([row, metricComputed])\n",
    "                                else:\n",
    "                                    filewriter.writerow([row, str(DataEvaluated[Names.index(row[1])])])\n",
    "            \n",
    "            \n",
    "            else:\n",
    "                fileOut = fileIn\n",
    "                print('recreating a file')\n",
    "\n",
    "                with open(fileSave, 'w', newline='') as csvfileWrite:\n",
    "                    filewriter = csv.writer(csvfileWrite, delimiter=',')\n",
    "                    filewriter.writerow(['subject_name', metricComputed])\n",
    "                    for ind in enumerate(Names):\n",
    "                        filewriter.writerow([Names[ind], DataEvaluated[ind[0]]])\n",
    "                \n",
    "    else:\n",
    "        print('creating a file')\n",
    "        a = re.compile('(?<=TypingData)(.*)(?=OptiKey)')\n",
    "        with open(fileSave, 'w', newline='') as csvfileWrite:\n",
    "            filewriter = csv.writer(csvfileWrite, delimiter=',')\n",
    "            filewriter.writerow(['subject_name', metricComputed])\n",
    "            for ind in enumerate(Names):\n",
    "                subjName = a.findall(Names[ind[0]])\n",
    "                filewriter.writerow([subjName[0], DataEvaluated[ind[0]]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May15\\akt_MS\\OptiKeyLogs\\2018-5-15-14-3-18\n",
      "Minimum edit distance by the user is  0.3996635389286224\n",
      "['akt_MS']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May15\\be_DT\\OptiKeyLogs\\2018-5-15-14-51-13-notInclude\n",
      "Minimum edit distance by the user is  0.6813782991202346\n",
      "['be_DT']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May15\\jl_DT\\OptiKeyLogs\\2018-5-15-10-21-20-notEnough\n",
      "Minimum edit distance by the user is  0.8379629629629629\n",
      "['jl_DT']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May15\\KEA_MS\\OptiKeyLogs\\2018-5-15-12-31-49\n",
      "Minimum edit distance by the user is  0.17823862191711162\n",
      "['KEA_MS']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May15\\lone_DT\\OptiKeyLogs\\2018-5-15-11-4-33-notEnough\n",
      "Minimum edit distance by the user is  0.6614682539682539\n",
      "['lone_DT']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May15\\mcc_MS\\OptiKeyLogs\\2018-5-15-12-7-17\n",
      "Minimum edit distance by the user is  0.45185185185185184\n",
      "['mcc_MS']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May15\\MK_DT\\OptiKeyLogs\\2018-5-15-14-32-48\n",
      "Minimum edit distance by the user is  0.24222670250896056\n",
      "['MK_DT']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May15\\MT_MS\\OptiKeyLogs\\2018-5-15-10-52-23-notInclude\n",
      "Minimum edit distance by the user is  0.13634672619047616\n",
      "['MT_MS']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May15\\ok_MS\\OptiKeyLogs\\2018-5-15-12-23-16\n",
      "Minimum edit distance by the user is  0.11105163287725955\n",
      "['ok_MS']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May15\\pt_DT\\OptiKeyLogs\\2018-5-15-12-43-13\n",
      "Minimum edit distance by the user is  0.22266896392703422\n",
      "['pt_DT']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May15\\sc_MS\\OptiKeyLogs\\2018-5-15-14-25-39-notEnough\n",
      "Minimum edit distance by the user is  0.9136904761904762\n",
      "['sc_MS']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May15\\sh_MS\\OptiKeyLogs\\2018-5-15-15-36-9\n",
      "Minimum edit distance by the user is  0.30456709956709954\n",
      "['sh_MS']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May15\\slh_DT\\OptiKeyLogs\\2018-5-15-11-48-25-notInclude\n",
      "Minimum edit distance by the user is  0.22098366674605063\n",
      "['slh_DT']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May16\\ae_DT\\OptiKeyLogs\\2018-5-16-15-5-59-notEnough\n",
      "Minimum edit distance by the user is  0.9516129032258065\n",
      "['ae_DT']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May16\\ep_DT\\OptiKeyLogs\\2018-5-16-13-5-32-notInclude\n",
      "Minimum edit distance by the user is  0.025359740670461733\n",
      "['ep_DT']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May16\\hc_MS\\OptiKeyLogs\\2018-5-16-13-42-4\n",
      "Minimum edit distance by the user is  0.4234104437229437\n",
      "['hc_MS']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May16\\ib_MS\\OptiKeyLogs\\2018-5-16-10-36-58\n",
      "Minimum edit distance by the user is  0.5655322128851541\n",
      "['ib_MS']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May16\\js_MS\\OptiKeyLogs\\2018-5-16-10-18-59-notInclude\n",
      "Minimum edit distance by the user is  0.2673255228017133\n",
      "['js_MS']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May16\\km_DT\\OptiKeyLogs\\2018-5-16-14-1-18\n",
      "Minimum edit distance by the user is  0.22286023711810307\n",
      "['km_DT']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May16\\ma_DT\\OptiKeyLogs\\2018-5-16-10-7-33\n",
      "Minimum edit distance by the user is  0.3083707154359328\n",
      "['ma_DT']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May16\\mw_MS\\OptiKeyLogs-notInclude\\2018-5-16-16-13-42\n",
      "Minimum edit distance by the user is  0.591522075493867\n",
      "['mw_MS']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May16\\pgba_DT\\OptiKeyLogs\\2018-5-16-14-50-56\n",
      "Minimum edit distance by the user is  0.10452964909486649\n",
      "['pgba_DT']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May16\\pt_MS\\OptiKeyLogs\\2018-5-16-16-1-48-notInclude\n",
      "Minimum edit distance by the user is  0.62143261257072\n",
      "['pt_MS']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May16\\smn_DT\\OptiKeyLogs\\2018-5-16-11-59-49\n",
      "Minimum edit distance by the user is  0.06111982191250484\n",
      "['smn_DT']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May17\\eo_DT\\OptiKeyLogs\\2018-5-17-11-53-9-notEnough\n",
      "Minimum edit distance by the user is  0.959553775743707\n",
      "['eo_DT']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May17\\jek_MS\\OptiKeyLogs\\2018-5-17-13-38-4\n",
      "Minimum edit distance by the user is  0.5206039509926672\n",
      "['jek_MS']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May17\\jg_DT\\OptiKeyLogs\\2018-5-17-12-34-27-notEnough\n",
      "Minimum edit distance by the user is  1.0858974358974358\n",
      "['jg_DT']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May17\\lg_MS\\OptiKeyLogs\\2018-5-17-10-44-20-notEnough\n",
      "Minimum edit distance by the user is  0.7337144971217552\n",
      "['lg_MS']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May17\\lr_MS\\OptiKeyLogs\\2018-5-17-10-17-20\n",
      "Minimum edit distance by the user is  0.23224600220567965\n",
      "['lr_MS']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May17\\mm_MS\\OptiKeyLogs\\2018-5-17-13-22-11\n",
      "Minimum edit distance by the user is  0.11094202898550724\n",
      "['mm_MS']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May17\\mr_DT\\OptiKeyLogs-notInclude\\2018-5-17-15-27-31\n",
      "Minimum edit distance by the user is  0.19441187888198758\n",
      "['mr_DT']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May17\\snk_DT\\OptiKeyLogs\\2018-5-17-10-28-57\n",
      "Minimum edit distance by the user is  0.36296491228070177\n",
      "['snk_DT']\n",
      "C:\\DTU\\Data\\201805_HealthnRehab\\data_summary.csv\n",
      "adding the metric\n",
      "subject_name\n",
      "adding the metric\n",
      "akt_MS\n",
      "adding the metric\n",
      "be_DT\n",
      "adding the metric\n",
      "jl_DT\n",
      "adding the metric\n",
      "KEA_MS\n",
      "adding the metric\n",
      "lone_DT\n",
      "adding the metric\n",
      "mcc_MS\n",
      "adding the metric\n",
      "MK_DT\n",
      "adding the metric\n",
      "MT_MS\n",
      "adding the metric\n",
      "ok_MS\n",
      "adding the metric\n",
      "pt_DT\n",
      "adding the metric\n",
      "sc_MS\n",
      "adding the metric\n",
      "sh_MS\n",
      "adding the metric\n",
      "slh_DT\n",
      "adding the metric\n",
      "ae_DT\n",
      "adding the metric\n",
      "ep_DT\n",
      "adding the metric\n",
      "hc_MS\n",
      "adding the metric\n",
      "ib_MS\n",
      "adding the metric\n",
      "js_MS\n",
      "adding the metric\n",
      "km_DT\n",
      "adding the metric\n",
      "ma_DT\n",
      "adding the metric\n",
      "mw_MS\n",
      "adding the metric\n",
      "pgba_DT\n",
      "adding the metric\n",
      "pt_MS\n",
      "adding the metric\n",
      "smn_DT\n",
      "adding the metric\n",
      "eo_DT\n",
      "adding the metric\n",
      "jek_MS\n",
      "adding the metric\n",
      "jg_DT\n",
      "adding the metric\n",
      "lg_MS\n",
      "adding the metric\n",
      "lr_MS\n",
      "adding the metric\n",
      "mm_MS\n",
      "adding the metric\n",
      "mr_DT\n",
      "adding the metric\n",
      "snk_DT\n"
     ]
    }
   ],
   "source": [
    "metricComputed = 'error_rate_total'\n",
    "dataFolderName = r'C:\\DTU\\Data\\201805_HealthnRehab\\TypingData'\n",
    "\n",
    "errorRateList = list()\n",
    "TypingSpeed = list()\n",
    "Names = list()\n",
    "\n",
    "for root, dirs, subfolder in os.walk(dataFolderName):\n",
    "    \n",
    "    if not dirs:\n",
    "        \n",
    "        #if 'notCompleted' in root or 'notInclude' in root: # Some subjects do not have gaze log and have been marked as \n",
    "        \n",
    "        if 'notCompleted' in root: # Some subjects do not have gaze log and have been marked as \n",
    "            #notInclude\n",
    "            continue\n",
    "        if 'tb' in root or 'joha' in root:\n",
    "            continue\n",
    "            \n",
    "        scratchPad = None\n",
    "        phraseLog = None\n",
    "        \n",
    "        for file in subfolder:\n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'ScratchPadLog*'):\n",
    "                try:\n",
    "                    fScratchPad = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerScratchPad = csv.reader(fScratchPad)\n",
    "                    scratchPad = list(readerScratchPad)\n",
    "                    scratchPad.remove(scratchPad[0])\n",
    "                    #print(scratchPad)\n",
    "                except:\n",
    "                    if fScratchPad is not None:\n",
    "                        fScratchPad.close()\n",
    "                    else:\n",
    "                        print('error in opening the scratchpad log file')\n",
    "            if 'js' in root:\n",
    "                if fnmatch.fnmatch(file, 'ScratchPadLog*'):\n",
    "                    try:\n",
    "                        fScratchPad = open(root + '\\\\' + file)\n",
    "                        readerScratchPad = csv.reader(fScratchPad)\n",
    "                        scratchPad = list(readerScratchPad)\n",
    "                        scratchPad.remove(scratchPad[0])\n",
    "                        #print(scratchPad)\n",
    "                    except:\n",
    "                        if fScratchPad is not None:\n",
    "                            fScratchPad.close()\n",
    "                        else:\n",
    "                            print('error in opening the scratchpad log file')\n",
    "                \n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'phrase*'):\n",
    "                try:\n",
    "                    fPhraseLog = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerPhraseLog = csv.reader(fPhraseLog)\n",
    "                    phraseLog = list(readerPhraseLog)\n",
    "                    phraseLog.remove(phraseLog[0])\n",
    "                    #print(phraseLog)\n",
    "                except:\n",
    "                    if fPhraseLog is not None:\n",
    "                        fPhraseLog.close()\n",
    "                    else:\n",
    "                        print('error in opening the phrase log file')\n",
    "                     \n",
    "        if scratchPad is None or phraseLog is None:\n",
    "            #print(root)\n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            print(root)\n",
    "            \n",
    "            if 'mm' in root:\n",
    "                language = 'English'\n",
    "            else:\n",
    "                language = 'Danish'\n",
    "                \n",
    "            \n",
    "            stimPhraseList = [phraseKey[1] for phraseKey in phraseLog]\n",
    "            \n",
    "            # Customization of phrases \n",
    "            if 'jg' in root:\n",
    "                scratchPad.remove(scratchPad[4])\n",
    "            if 'snk' in root:\n",
    "                phraseLog.remove(phraseLog[0])\n",
    "            # for KEA, 10 was asked not to type\n",
    "            if 'butikken lukker kl. 10' in stimPhraseList:\n",
    "                index = stimPhraseList.index('butikken lukker kl. 10')\n",
    "                phraseLog[index][1] = 'butikken lukker kl.'\n",
    "            \n",
    "            #print(phraseLog)\n",
    "            phraseUserEnd, phraseStim = phrasesEdit(scratchPad, phraseLog)\n",
    "            \n",
    "            dist = 0\n",
    "            dist_word = 0\n",
    "            lenSum = 0\n",
    "            if len(phraseUserEnd)==len(phraseStim):\n",
    "                for element in range(0,len(phraseStim)):\n",
    "                    sentence_phraseStim = phraseStim[element][1]\n",
    "                    sentence_phraseUser = phraseUserEnd[element][1]\n",
    "                    \n",
    "                    # initialize the stemmer\n",
    "                    words_stemmer = snowball.DanishStemmer()\n",
    "                    \n",
    "                    roots_phraseStim = list()\n",
    "                    roots_phraseUser = list()\n",
    "                    \n",
    "                    for word in sentence_phraseStim.split():\n",
    "                        # find roots of words in stimulation phrase - \n",
    "                        roots_phraseStim.append(words_stemmer.stem(word))\n",
    "\n",
    "                    for word in sentence_phraseUser.split():\n",
    "                        roots_phraseUser.append(words_stemmer.stem(word))\n",
    "                        \n",
    "                    #print(roots_phraseStim)\n",
    "                    #print('and')\n",
    "                    #print(roots_phraseUser)\n",
    "                    \n",
    "                    #print(distance.levenshtein(roots_phraseStim, roots_phraseUser))\n",
    "                    dist_word = dist_word + distance.levenshtein(roots_phraseStim, roots_phraseUser)/max(len(roots_phraseStim), len(roots_phraseUser))\n",
    "                    \n",
    "                for n in range(0,len(phraseStim)):     \n",
    "                    dist = dist + (levenshteinDist(phraseStim[n][1], phraseUserEnd[n][1]))/max(len(phraseStim[n][1]),len(phraseUserEnd[n][1]))\n",
    "                    #print(dist)\n",
    "                \n",
    "                errorRate_char = dist/(n+1)  \n",
    "                errorRate_word = dist_word/(n+1)\n",
    "            else:\n",
    "                print('Unequal stimulation and user-generated phrases')\n",
    "            \n",
    "            errorRate_total = 0.5*errorRate_char + 0.5*errorRate_word\n",
    "            \n",
    "            #errorRate = dist/(lenSum*(n+1))\n",
    "            errorRateList.append(errorRate_total*100) # save error rate in percentage\n",
    "            print('Minimum edit distance by the user is ', errorRate_total)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # save only the name of the subject and the date part of the file\n",
    "            a = re.compile('(?<=TypingData\\\\\\May[0-9]{2}\\\\\\)(.*)(?=\\\\\\OptiKey)')\n",
    "            print(a.findall(root))\n",
    "            Names.append(a.findall(root)[0])\n",
    "            \n",
    "if errorRateList:\n",
    "    #print(Names)\n",
    "    AddDataToFile(metricComputed, Names, errorRateList)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjName = r'C:\\DTU\\Data\\201805_HealthnRehab\\TypingData\\May16\\pt_MS'\n",
    "\n",
    "\n",
    "for root, dirs, subfolder in os.walk(subjName):\n",
    "    if not dirs:\n",
    "        if 'notCompleted' in root:\n",
    "            continue\n",
    "        for file in subfolder:\n",
    "            if fnmatch.fnmatch(file, 'PhraseLog*'):\n",
    "                with open(root + '\\\\' + file, encoding='utf-8') as fp:\n",
    "                    reader = csv.reader(fp)\n",
    "                    phraseStim = list(reader)\n",
    "                    phraseStim.remove(phraseStim[0])\n",
    "            elif fnmatch.fnmatch(file, 'ScratchPadLog*'):\n",
    "                with open(root + '\\\\' + file, encoding='utf-8') as fs:\n",
    "                    reader = csv.reader(fs)\n",
    "                    phraseUser = list(reader)\n",
    "                    phraseUser.remove(phraseUser[0])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phraseUserEnd = list()\n",
    "\n",
    "for row_ind in range(0, len(phraseUser)):\n",
    "    if row_ind!= 0 and phraseUser[row_ind][1] == '':\n",
    "        phraseUserEnd.append(phraseUser[row_ind-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to remove all elements that are not end phrases - stimulated or user-generated\n",
    "\n",
    "for row_ind2 in range(0, len(phraseStim)):\n",
    "    if phraseStim[row_ind2][1] == 'THE EXPERIMENT IS NOW DONE':\n",
    "        phraseUserEnd.remove(phraseUserEnd[row_ind2])\n",
    "        phraseStim.remove(phraseStim[row_ind2])\n",
    "        \n",
    "for row_ind3 in range(0, len(phraseUserEnd)):\n",
    "    if phraseUserEnd[row_ind3][1] == '':\n",
    "        if row_ind3 < len(phraseStim):\n",
    "            phraseStim.remove(phraseStim[row_ind3])\n",
    "            phraseUserEnd.remove(phraseUserEnd[row_ind3])\n",
    "    \n",
    "# if phrases documented have a comma, the said phrase is split and saved into different columns. They need to be joined\n",
    "for row_ind4 in range(0, len(phraseStim)):\n",
    "    if len(phraseStim[row_ind4])>2:\n",
    "        phraseStim[row_ind4][1] = ''.join(phraseStim[row_ind4][1:])\n",
    "        \n",
    "for row_ind5 in range(0, len(phraseUserEnd)):\n",
    "    if len(phraseUserEnd[row_ind5])>2:\n",
    "        phraseUserEnd[row_ind5][1] = ''.join(phraseUserEnd[row_ind5][1:])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = 0\n",
    "if len(phraseUserEnd)==len(phraseStim):\n",
    "    for n in range(0,len(phraseStim)):\n",
    "        dist = dist + (levenshteinDist(phraseStim[n][1], phraseUserEnd[n][1]))/max(len(phraseStim[n][1]),len(phraseUserEnd[n][1]))\n",
    "        print(levenshteinDist(phraseStim[n][1], phraseUserEnd[n][1]), max(len(phraseStim[n][1]),len(phraseUserEnd[n][1])), n)\n",
    "    dist = float(dist/(n+1))\n",
    "    print(\"Minimum edit distance by the user is \", dist)\n",
    "else:\n",
    "    print('Unequal stimulation and user-generated phrases')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phraseStim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phraseUserEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
