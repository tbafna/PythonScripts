{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import csv\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import xlsxwriter\n",
    "import scipy.stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels\n",
    "from statsmodels.graphics.regressionplots import abline_plot\n",
    "from statsmodels.stats.api import anova_lm\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.mode.use_inf_as_na = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain data in form of pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# csv file with the saved data\n",
    "fileName = r\"C:\\DTU\\Data\\201805_HealthnRehab\\data_summary.csv\"\n",
    "\n",
    "df = pd.read_csv(fileName, delimiter=',')\n",
    "\n",
    "typingMechanismDictKeys = set(df['typing_mechanism'])\n",
    "\n",
    "# create reference data frame for age bins and gender (0:Less than 30/Male, 1:Greater than 30/Female)\n",
    "labels = ['age_bins', 'gender', 'typing_mechanism']\n",
    "dataReference = [['Less than 30', 'Male', 'Dwell-Time'], ['Greater than 30', 'Female', 'Multi-Key Selection']]\n",
    "df_refAgeGender = pd.DataFrame.from_records(dataReference, columns=labels)\n",
    "\n",
    "# replace data in df in string or category\n",
    "df = df.replace({'Less than 30': 0, 'Greater than 30': 1, 'Male': 0, 'Female': 1, 'DT' : 0, 'MS' : 1})\n",
    "\n",
    "# Create dataframe without Nan values\n",
    "df_woNaGenderAgeExperience = df.dropna(subset=['gender','age_bins', 'gaze_interaction_experience'], how='any') \n",
    "\n",
    "# Create a copy of the dataframe to avoid loc errors.\n",
    "df_ToAnalyze = df_woNaGenderAgeExperience.copy()\n",
    "\n",
    "# Convert columns of age_bins, typing_mechanism, gender into categorical columns\n",
    "df_ToAnalyze['gender'] = pd.Categorical(df_woNaGenderAgeExperience.gender).codes\n",
    "df_ToAnalyze['typing_mechanism'] = pd.Categorical(df_woNaGenderAgeExperience.typing_mechanism).codes\n",
    "df_ToAnalyze['age_bins'] = pd.Categorical(df_woNaGenderAgeExperience.age_bins).codes\n",
    "df_ToAnalyze['gaze_interaction_experience'] = pd.Categorical(df_woNaGenderAgeExperience.gaze_interaction_experience).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_ToAnalyze.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_Males = df_ToAnalyze.gender[df_ToAnalyze['gender'] == 0].count()\n",
    "n_Females = df_ToAnalyze.gender[df_ToAnalyze['gender'] == 1].count()\n",
    "\n",
    "n_Below30 = df_ToAnalyze.age_bins[df_ToAnalyze['age_bins'] == 0].count()\n",
    "n_Above30 = df_ToAnalyze.age_bins[df_ToAnalyze['age_bins'] == 1].count()\n",
    "\n",
    "n_DT = df_ToAnalyze.typing_mechanism[df_ToAnalyze['typing_mechanism'] == 0].count()\n",
    "n_MS = df_ToAnalyze.typing_mechanism[df_ToAnalyze['typing_mechanism'] == 1].count()\n",
    "\n",
    "n_ExperienceNever = df_ToAnalyze.gaze_interaction_experience[df_ToAnalyze['gaze_interaction_experience'] == 1].count()\n",
    "n_ExperienceMultiple = df_ToAnalyze.gaze_interaction_experience[df_ToAnalyze['gaze_interaction_experience'] == 0].count()\n",
    "n_ExperienceOnce = df_ToAnalyze.gaze_interaction_experience[df_ToAnalyze['gaze_interaction_experience'] == 2].count()\n",
    "\n",
    "\n",
    "print('Males:', n_Males, 'Females:', n_Females)\n",
    "print('Below 30:', n_Below30, 'Above 30', n_Above30)\n",
    "print('Dwell time', n_DT, 'Multi-key selection:', n_MS)\n",
    "print('No previous experience with gaze:', n_ExperienceNever, 'Tried once before:', n_ExperienceOnce, 'Multiple times', n_ExperienceMultiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_DT_Below30 = df_ToAnalyze.typing_mechanism[(df_ToAnalyze['typing_mechanism'] == 0) & (df_ToAnalyze['age_bins'] == 0)].count()\n",
    "n_DT_Above30 = df_ToAnalyze.typing_mechanism[(df_ToAnalyze['typing_mechanism'] == 0) & (df_ToAnalyze['age_bins'] == 1)].count()\n",
    "\n",
    "n_MS_Below30 = df_ToAnalyze.typing_mechanism[(df_ToAnalyze['typing_mechanism'] == 1) & (df_ToAnalyze['age_bins'] == 0)].count()\n",
    "n_MS_Above30 = df_ToAnalyze.typing_mechanism[(df_ToAnalyze['typing_mechanism'] == 1) & (df_ToAnalyze['age_bins'] == 1)].count()\n",
    "\n",
    "\n",
    "n_DT_Males = df_ToAnalyze.typing_mechanism[(df_ToAnalyze['typing_mechanism'] == 0) & (df_ToAnalyze['gender'] == 0)].count()\n",
    "n_DT_Females = df_ToAnalyze.typing_mechanism[(df_ToAnalyze['typing_mechanism'] == 0) & (df_ToAnalyze['gender'] == 1)].count()\n",
    "\n",
    "n_MS_Males = df_ToAnalyze.typing_mechanism[(df_ToAnalyze['typing_mechanism'] == 1) & (df_ToAnalyze['gender'] == 0)].count()\n",
    "n_MS_Females = df_ToAnalyze.typing_mechanism[(df_ToAnalyze['typing_mechanism'] == 1) & (df_ToAnalyze['gender'] == 1)].count()\n",
    "\n",
    "\n",
    "print(n_DT_Below30, n_DT_Above30, n_MS_Below30, n_MS_Above30)\n",
    "print(n_DT_Males, n_DT_Females, n_MS_Males, n_MS_Females)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experience (comfort, challenge level, fun) - \n",
    "df_ToAnalyze.how_challenging_was_the_task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of typing speed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS regression to check residuals of data for anova testing \n",
    "X = df_ToAnalyze[['age_bins', 'typing_mechanism', 'gender']] # independent variable\n",
    "y_typingSpeed = df_ToAnalyze.typing_speed # dependent variable\n",
    "\n",
    "model_typingSpeed = sm.OLS(y_typingSpeed, X)\n",
    "model_fit_typingSpeed = model_typingSpeed.fit()\n",
    "\n",
    "p_typingSpeed = model_fit_typingSpeed.params\n",
    "\n",
    "# Plot the residuals of each\n",
    "residuals_typingSpeed = model_fit_typingSpeed.resid # residuals\n",
    "fig = sm.qqplot(residuals_typingSpeed)\n",
    "plt.show()\n",
    "\n",
    "model_fit_typingSpeed.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments:\n",
    "Only 73.5% of variance is explained -- is high correlation value\n",
    "Prob(F-statistic) --> Null hypothesis is rejected, that the variability is random and alternate hypothesis that the variability\n",
    "can be explained is accepted\n",
    "\n",
    "From the graph, we see that the residuals are normally distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_typingSpeed = 'df_ToAnalyze.typing_speed ~ df_ToAnalyze.age_bins + df_ToAnalyze.gender + df_ToAnalyze.typing_mechanism + df_ToAnalyze.age_bins:df_ToAnalyze.gender + df_ToAnalyze.age_bins:df_ToAnalyze.typing_mechanism + df_ToAnalyze.gender:df_ToAnalyze.typing_mechanism'\n",
    "model_typingSpeed = ols(formula_typingSpeed, df_ToAnalyze).fit()\n",
    "aov_table_typingSpeed = statsmodels.stats.anova.anova_lm(model_typingSpeed, typ=2)\n",
    "print(aov_table_typingSpeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots of typing speed wrt independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plots\n",
    "\n",
    "figBoxPlot = plt.figure()\n",
    "\n",
    "# Age\n",
    "ax = figBoxPlot.add_subplot(131)\n",
    "df_ToAnalyze.boxplot( column = 'typing_speed', by='age_bins', ax = ax, grid = False)\n",
    "plt.xticks([1, 2], ['Less than 30', 'Greater than 30'])\n",
    "plt.yticks(np.arange(0, float(df.typing_speed.max())+2, step = 2))\n",
    "plt.ylabel('Typing speed [in wpm]')\n",
    "\n",
    "# Gender\n",
    "ax = figBoxPlot.add_subplot(132)\n",
    "df_ToAnalyze.boxplot(column = 'typing_speed', by='gender', ax = ax, grid = False)\n",
    "plt.xticks([1, 2], ['Male', 'Female'])\n",
    "plt.yticks(np.arange(0, float(df.typing_speed.max())+2, step = 2))\n",
    "plt.ylabel('Typing speed [in wpm]')\n",
    "\n",
    "# Typing mechanism\n",
    "ax = figBoxPlot.add_subplot(133)\n",
    "df_ToAnalyze.boxplot(column = 'typing_speed', by='typing_mechanism', ax = ax, grid = False)\n",
    "plt.xticks([1, 2], ['Dwell time', 'MultiKey selection'])\n",
    "plt.yticks(np.arange(0, float(df.typing_speed.max())+2, step = 2))\n",
    "plt.ylabel('Typing speed [in wpm]')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average speed and standard deviation for dwell time selection are: 4.6125712236 2.123543537879204\n",
      "Average speed and standard deviation for multi-key selection are: 7.495420426000001 1.9917046006795018\n"
     ]
    }
   ],
   "source": [
    "print('Average speed and standard deviation for dwell time selection are:', df_ToAnalyze.typing_speed[df_ToAnalyze['typing_mechanism']==0].mean(), df_ToAnalyze.typing_speed[df_ToAnalyze['typing_mechanism']==0].std())\n",
    "print('Average speed and standard deviation for multi-key selection are:', df_ToAnalyze.typing_speed[df_ToAnalyze['typing_mechanism']==1].mean(), df_ToAnalyze.typing_speed[df_ToAnalyze['typing_mechanism']==1].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms\n",
    "figHist = plt.figure()\n",
    "bins = np.arange(0, float(df_ToAnalyze.typing_speed.max()+2), step = 2)\n",
    "\n",
    "# Age\n",
    "ax = figHist.add_subplot(141)\n",
    "df_ToAnalyze.hist( column = 'typing_speed', ax = ax, grid = False)\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('Typing speed [in wpm]')\n",
    "plt.yticks(np.arange(0, 11, step = 2))\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "ax = figHist.add_subplot(142)\n",
    "df_ToAnalyze.typing_speed[df_ToAnalyze['age_bins'] == 0].hist(ax = ax, alpha=0.5, grid = False, label = 'Below 30 years')\n",
    "#df_ToAnalyze.hist(df_ToAnalyze.typing_speed[df_ToAnalyze['age_bins'] == 0], bins, ax = ax, grid = False)\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('Typing speed [in wpm]')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "ax = figHist.add_subplot(142)\n",
    "df_ToAnalyze.typing_speed[df_ToAnalyze['age_bins'] == 1].hist(ax = ax, alpha=0.5, grid = False, label = 'Above 30 years')\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('Typing speed [in wpm]')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Typing speed and Age')\n",
    "plt.legend()\n",
    "\n",
    "# Gender\n",
    "\n",
    "ax = figHist.add_subplot(143)\n",
    "df_ToAnalyze.typing_speed[df_ToAnalyze['gender'] == 0].hist(ax = ax, alpha=0.5, grid = False, label = 'Male')\n",
    "#df_ToAnalyze.hist(df_ToAnalyze.typing_speed[df_ToAnalyze['age_bins'] == 0], bins, ax = ax, grid = False)\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('Typing speed [in wpm]')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "ax = figHist.add_subplot(143)\n",
    "df_ToAnalyze.typing_speed[df_ToAnalyze['gender'] == 1].hist(ax = ax, alpha=0.5, grid = False, label = 'Female')\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('Typing speed [in wpm]')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Typing speed and Gender')\n",
    "plt.legend()\n",
    "\n",
    "# Typing Mechanism\n",
    "\n",
    "ax = figHist.add_subplot(144)\n",
    "df_ToAnalyze.typing_speed[df_ToAnalyze['typing_mechanism'] == 0].hist(ax = ax, alpha=0.5, grid = False, label = 'Dwell time')\n",
    "#df_ToAnalyze.hist(df_ToAnalyze.typing_speed[df_ToAnalyze['age_bins'] == 0], bins, ax = ax, grid = False)\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('Typing speed [in wpm]')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "ax = figHist.add_subplot(144)\n",
    "df_ToAnalyze.typing_speed[df_ToAnalyze['typing_mechanism'] == 1].hist(ax = ax, alpha=0.5, grid = False, label = 'Multi-key selection')\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('Typing speed [in wpm]')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Typing speed and Typing Mechanism')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the new calculations of typing speed, the histograms for typing speed are normal when distributed as per age and gender, \n",
    "but not using typing mechanism. Therefore, mann whitney test will be performed for typing mechanism (their variances are still\n",
    "more or less equal) and t-test for the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Typing speed statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age\n",
    "\n",
    "\n",
    "# Gender\n",
    "\n",
    "\n",
    "# Typing mechanism\n",
    "# the mann whitney test in scipy.stats clearly says that it is reliable only for sample size of 20 in each. Since we do not have\n",
    "# that, this test will be performed manually, based on - http://psych.unl.edu/psycrs/handcomp/hcmann.PDF\n",
    "n_DT = df_ToAnalyze.typing_mechanism[df_ToAnalyze['typing_mechanism'] == 0].count()\n",
    "n_MS = df_ToAnalyze.typing_mechanism[df_ToAnalyze['typing_mechanism'] == 1].count()\n",
    "\n",
    "# Rank the data and add up\n",
    "RankedSumDT = sum(df_ToAnalyze.typing_speed[df_ToAnalyze['typing_mechanism'] == 0].rank(axis=0, method='average'))\n",
    "\n",
    "U_DT = n_DT*n_MS + n_DT*(n_DT + 1)/2 - RankedSumDT\n",
    "U_MS = n_DT*n_MS - U_DT\n",
    "U_select = min(U_MS, U_DT)\n",
    "U_critical = 59\n",
    "if U_select < U_critical:\n",
    "    print('reject Ho')\n",
    "\n",
    "# using the function\n",
    "U_stat, p_val = scipy.stats.mannwhitneyu(df_ToAnalyze.typing_speed[df_ToAnalyze['typing_mechanism'] == 0], df_ToAnalyze.typing_speed[df_ToAnalyze['typing_mechanism'] == 1])\n",
    "print(U_stat, p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_DT, n_MS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age\n",
    "a = df_ToAnalyze.typing_speed[df_ToAnalyze['age_bins']==0]\n",
    "b = df_ToAnalyze.typing_speed[df_ToAnalyze['age_bins']==1]\n",
    "(h, p) = scipy.stats.kruskal(a.values, b.values)\n",
    "print('Kruskal result for age: H-statistic=', h, ', pvalue=', p)\n",
    "\n",
    "# Gender\n",
    "a = df_ToAnalyze.typing_speed[df_ToAnalyze['gender']==0]\n",
    "b = df_ToAnalyze.typing_speed[df_ToAnalyze['gender']==1]\n",
    "(h, p) = scipy.stats.kruskal(a.values, b.values)\n",
    "print('Kruskal result for gender: H-statistic=', h, ', pvalue=', p)\n",
    "\n",
    "# Typing mechanism\n",
    "a = df_ToAnalyze.typing_speed[df_ToAnalyze['typing_mechanism']==0]\n",
    "b = df_ToAnalyze.typing_speed[df_ToAnalyze['typing_mechanism']==1]\n",
    "(h, p) = scipy.stats.kruskal(a.values, b.values)\n",
    "print('Kruskal result for typing mechanism: H-statistic=', h, ', pvalue=', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of error rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS regression to check residuals of data for anova testing \n",
    "X = df_ToAnalyze[['age_bins', 'typing_mechanism', 'gender']] # independent variable\n",
    "y_errorRate = df_ToAnalyze.error_rate # dependent variable\n",
    "\n",
    "model_errorRate = sm.OLS(y_errorRate,X)\n",
    "model_fit_errorRate = model_errorRate.fit()\n",
    "\n",
    "p_errorRate = model_fit_errorRate.params\n",
    "\n",
    "# Plot the residuals of each\n",
    "residuals_errorRate = model_fit_errorRate.resid # residuals\n",
    "fig = sm.qqplot(residuals_errorRate)\n",
    "plt.show()\n",
    "\n",
    "model_fit_errorRate.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments: The residual plot is slightly skewed --> anova cannot be performed \n",
    "But Prob(F-statistic) is low enough to reject null hypothesis\n",
    "Still, anova is not performed due to the skewed residual plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Perform Shierer Ray Hare test \n",
    "\n",
    "# For now, it is performed in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equivalence testing of error rate for typing mechansims\n",
    "Here, the null hypothesis is that error rates for both is not equivalent\n",
    "For a practical equivalence value of 'del', Ho: |mu1 - mu2| > del and Ha: |mu1 - mu2| < del\n",
    "So, to reject the null hypothesis, both should be rejected:\n",
    "mu1 - mu2 > del and mu1 - mu2 < -del\n",
    "or in terms of two-one sided test :\n",
    "    ((y1m - y2m) + del)/sigma(1/n1 + 1/n2) > z(1-alpha) and ((y1m - y2m) - del)/sigma(1/n1 + 1/n2) < -z(1-alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_errorRate_DT = df_ToAnalyze.error_rate[df_ToAnalyze['typing_mechanism']==0].std()\n",
    "sd_errorRate_MS = df_ToAnalyze.error_rate[df_ToAnalyze['typing_mechanism']==1].std()\n",
    "\n",
    "n_DT = df_ToAnalyze.typing_mechanism[df_ToAnalyze['typing_mechanism'] == 0].count()\n",
    "n_MS = df_ToAnalyze.typing_mechanism[df_ToAnalyze['typing_mechanism'] == 1].count()\n",
    "\n",
    "mean_errorRate_DT = df_ToAnalyze.error_rate[df_ToAnalyze['typing_mechanism']==0].mean()\n",
    "mean_errorRate_MS = df_ToAnalyze.error_rate[df_ToAnalyze['typing_mechanism']==1].mean()\n",
    "\n",
    "sd = math.sqrt(((n_DT - 1)*(sd_errorRate_DT)**2 + (n_MS - 1)*(sd_errorRate_MS)**2)/(n_DT + n_MS - 2))\n",
    "\n",
    "print(sd*0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delError = 10 # As per Lakens 2017 Equivalence testing, del = d*sd, where d is Cohen's d = 0.3. For the given data, sd = ~36\n",
    "\n",
    "tL = (mean_errorRate_DT - mean_errorRate_MS - (-delError))/(math.sqrt(((sd_errorRate_DT**2)/n_DT) + (sd_errorRate_MS**2)/n_MS))\n",
    "tU = (mean_errorRate_DT - mean_errorRate_MS - (delError))/(math.sqrt(((sd_errorRate_DT**2)/n_DT) + (sd_errorRate_MS**2)/n_MS))\n",
    "\n",
    "#df = ((((sd_errorRate_DT**2)/(n_DT)) + ((sd_errorRate_MS**2)/(n_MS)))**2)/(((sd_errorRate_DT/n_DT)**2)/(n_DT-1) + ((sd_errorRate_MS/n_MS)**2)/(n_MS-1))\n",
    "\n",
    "df = (n_DT + n_MS - 1)\n",
    "\n",
    "print('tLower:', tL, ',tUpper:', tU,'with', df, ' degrees of freedom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#For t(28, 0.05) = 1.701\n",
    "To reject null hypothesis, both of the following should be followed - \n",
    "tU < -t(28, 0.05) AND tL > t(28, 0.05)\n",
    "As both are not, null hypothesis cannot be rejected \n",
    "Therefore, both cannot be equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error rate and standard deviation for dwell time selection are: 34.56389169613333 39.505970315291336\n",
      "Average error rate and standard deviation for multi-key selection are: 32.96715175792857 19.432188494849644\n"
     ]
    }
   ],
   "source": [
    "print('Average error rate and standard deviation for dwell time selection are:', df_ToAnalyze.error_rate[df_ToAnalyze['typing_mechanism']==0].mean(), df_ToAnalyze.error_rate[df_ToAnalyze['typing_mechanism']==0].std())\n",
    "print('Average error rate and standard deviation for multi-key selection are:', df_ToAnalyze.error_rate[df_ToAnalyze['typing_mechanism']==1].mean(), df_ToAnalyze.error_rate[df_ToAnalyze['typing_mechanism']==1].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots of error rate wrt independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "# Age\n",
    "ax = fig.add_subplot(131)\n",
    "df_ToAnalyze.boxplot(column = 'error_rate', by='age_bins', ax = ax, grid = False)\n",
    "plt.xticks([1, 2], ['Less than 30', 'Greater than 30'])\n",
    "#plt.yticks(np.arange(0, float(df.typing_speed.max())+2, step = 2))\n",
    "plt.ylabel('Typing speed [in wpm]')\n",
    "\n",
    "# Gender\n",
    "ax = fig.add_subplot(132)\n",
    "df_ToAnalyze.boxplot(column = 'error_rate', by='gender', ax = ax, grid = False)\n",
    "plt.xticks([1, 2], ['Male', 'Female'])\n",
    "#plt.yticks(np.arange(0, float(df.typing_speed.max())+2, step = 2))\n",
    "plt.ylabel('Typing speed [in wpm]')\n",
    "\n",
    "# Typing mechanism\n",
    "ax = fig.add_subplot(133)\n",
    "df_ToAnalyze.boxplot(column = 'error_rate', by='typing_mechanism', ax = ax, grid = False)\n",
    "plt.xticks([1, 2], ['Dwell time', 'MultiKey selection'])\n",
    "#plt.yticks(np.arange(0, float(df.typing_speed.max())+2, step = 2))\n",
    "plt.ylabel('Typing speed [in wpm]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error rate statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age\n",
    "a = df_ToAnalyze.error_rate[df_ToAnalyze['age_bins']==0]\n",
    "b = df_ToAnalyze.error_rate[df_ToAnalyze['age_bins']==1]\n",
    "(h, p) = scipy.stats.kruskal(a.values, b.values)\n",
    "print('Kruskal result for age: H-statistic=', h, ', pvalue=', p)\n",
    "\n",
    "# Typing mechanism\n",
    "a = df_ToAnalyze.error_rate[df_ToAnalyze['gender']==0]\n",
    "b = df_ToAnalyze.error_rate[df_ToAnalyze['gender']==1]\n",
    "(h, p) = scipy.stats.kruskal(a.values, b.values)\n",
    "print('Kruskal result for gender: H-statistic=', h, ', pvalue=', p)\n",
    "\n",
    "# Typing mechanism\n",
    "a = df_ToAnalyze.error_rate[df_ToAnalyze['typing_mechanism']==0]\n",
    "b = df_ToAnalyze.error_rate[df_ToAnalyze['typing_mechanism']==1]\n",
    "(h, p) = scipy.stats.kruskal(a.values, b.values)\n",
    "print('Kruskal result for typing mechanism: H-statistic=', h, ', pvalue=', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.hstack(df_ToAnalyze.typing_speed)\n",
    "plt.hist(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of error rate and typing speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22d36c7e390>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==0], df_ToAnalyze.error_rate[df_ToAnalyze.typing_mechanism==0], 'bo', label = 'dwell time')\n",
    "plt.plot(df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==1], df_ToAnalyze.error_rate[df_ToAnalyze.typing_mechanism==1], 'ro', label = 'multi-key selection')\n",
    "\n",
    "plt.xlabel('Typing speed [in wpm]')\n",
    "plt.ylabel('Error rate [in %]')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between typing speed and error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Error rate [in %]')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = str(df_ToAnalyze['typing_speed'].corr(df_ToAnalyze['error_rate']))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "a = df_ToAnalyze.typing_speed.sort_values()\n",
    "\n",
    "i = 0\n",
    "for ind in a.keys():\n",
    "    i = i + 1\n",
    "    ax1.plot(i, df_ToAnalyze['typing_speed'].loc[ind], 'bo')\n",
    "    ax2.plot(i, df_ToAnalyze['error_rate'].loc[ind], 'ro')\n",
    "    \n",
    "ax1.set_title('Correlation between typing speed and error rate is: %s' %c)\n",
    "ax1.set_ylabel('Typing speed [in wpm]', color = 'b')\n",
    "ax1.set_yticks(np.arange(0, 15, 2))\n",
    "ax2.set_ylabel('Error rate [in %]', color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 100)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# box chart of typing speed and error rate\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "#onlyPosErr_t\n",
    "\n",
    "ax1.bar(1, df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==0].mean(), yerr = [[0], [df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==0].std()]], label = 'Dwell time')\n",
    "ax1.bar(2, df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==1].mean(), yerr = [[0], [df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==1].std()]], label = 'Multi-key selection')\n",
    "ax1.set_ylabel('Typing speed [in wpm]')\n",
    "ax1.set_yticks(np.arange(0, 11, 2))\n",
    "ax1.legend(bbox_to_anchor=(0.6, 0))\n",
    "#ax1.xaxis.set_ticks_position('none')\n",
    "plt.xticks([], [])\n",
    "\n",
    "ax2.bar(5, df_ToAnalyze.error_rate[df_ToAnalyze.typing_mechanism==0].mean(), yerr = [[0], [df_ToAnalyze.error_rate[df_ToAnalyze.typing_mechanism==0].std()]])\n",
    "ax2.bar(6, df_ToAnalyze.error_rate[df_ToAnalyze.typing_mechanism==1].mean(), yerr = [[0], [df_ToAnalyze.error_rate[df_ToAnalyze.typing_mechanism==1].std()]])\n",
    "ax2.set_ylabel('Error rate [in %]')\n",
    "plt.xticks([], [])\n",
    "#ax1.grid(color='b', alpha = 0.1, linestyle='-', linewidth=2)\n",
    "#ax2.grid(color='b', alpha = 0.1, linestyle='-', linewidth=1.7)\n",
    "ax2.set_ylim([0, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Typing Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typing Mechanism and other Independent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pie charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "nSubj = len(df_ToAnalyze)\n",
    "\n",
    "# Overall\n",
    "# Gender\n",
    "ax = fig.add_subplot(131)\n",
    "df_ToAnalyze.gender.value_counts(sort = False).plot.pie(ax = ax, labels = ['Male', 'Female'], autopct='%1.1f%%')\n",
    "ax.set_title('Gender distribution \\n Total count = ' + str(nSubj))\n",
    "\n",
    "# Age\n",
    "ax = fig.add_subplot(132)\n",
    "df_ToAnalyze.age_bins.value_counts(sort = False).plot.pie(ax = ax, labels = ['Less than 30', 'Greater than 30'], autopct='%1.1f%%')\n",
    "ax.set_title('Age distribution \\n Total count = ' + str(nSubj))\n",
    "\n",
    "# Typing mechanism\n",
    "ax = fig.add_subplot(133)\n",
    "df_ToAnalyze.typing_mechanism.value_counts(sort = False).plot.pie(ax = ax, labels = ['Dwell time', 'MultiKey selection'], autopct='%1.1f%%')\n",
    "ax.set_title('Typing mechanism distribution \\n Total count = ' + str(nSubj))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "# DWELL TIME\n",
    "# Gender and Typing mechanism\n",
    "ax = fig.add_subplot(221)\n",
    "df_ToAnalyze.gender[df['typing_mechanism']==0].value_counts(sort = False).plot.pie(ax = ax, labels = ['Male', 'Female'], autopct='%1.1f%%')\n",
    "ax.set_title('Dwell time')\n",
    "\n",
    "# Age and Typing mechanism\n",
    "ax = fig.add_subplot(223)\n",
    "df_ToAnalyze.age_bins[df['typing_mechanism']==0].value_counts(sort = False).plot.pie(ax = ax, labels = ['Less than 30', 'Greater than 30'], autopct='%1.1f%%')\n",
    "\n",
    "# MULTIKEY SELECTION\n",
    "# Gender and Typing mechanism\n",
    "ax = fig.add_subplot(222)\n",
    "df_ToAnalyze.gender[df['typing_mechanism']==1].value_counts(sort = False).plot.pie(ax = ax, labels = ['Male', 'Female'], autopct='%1.1f%%')\n",
    "ax.set_title('MultiKey Selection')\n",
    "\n",
    "# Age and Typing mechanism\n",
    "ax = fig.add_subplot(224)\n",
    "df_ToAnalyze.age_bins[df['typing_mechanism']==1].value_counts(sort = False).plot.pie(ax = ax, labels = ['Less than 30', 'Greater than 30'], autopct='%1.1f%%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum number in the pie charts is 5 (Female, MultiKey Selection). This is the number of subjects that will be choosen \n",
    "randomly from every category and the statistical tests will be performed again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attended But Not Selected Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plots\n",
    "\n",
    "figBoxPlot = plt.figure()\n",
    "\n",
    "# Typing mechanism\n",
    "ax = figBoxPlot.add_subplot(111)\n",
    "df_ToAnalyze.boxplot( column = 'attended_but_not_selected_rate_time', by='typing_mechanism', ax = ax, grid = False)\n",
    "plt.xticks([1, 2], ['Dwell Time', 'Multi-key Selection'])\n",
    "plt.ylabel('Attended but not selected ratio of time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalence testing on ansr\n",
    "\n",
    "sd_ansr_DT = df_ToAnalyze.attended_but_not_selected_rate_time[df_ToAnalyze['typing_mechanism']==0].std()\n",
    "sd_ansr_MS = df_ToAnalyze.attended_but_not_selected_rate_time[df_ToAnalyze['typing_mechanism']==1].std()\n",
    "\n",
    "mean_ansr_DT = df_ToAnalyze.attended_but_not_selected_rate_time[df_ToAnalyze['typing_mechanism']==0].mean()\n",
    "mean_ansr_MS = df_ToAnalyze.attended_but_not_selected_rate_time[df_ToAnalyze['typing_mechanism']==1].mean()\n",
    "\n",
    "n_DT = df_ToAnalyze.typing_mechanism[df_ToAnalyze['typing_mechanism'] == 0].count()\n",
    "n_MS = df_ToAnalyze.typing_mechanism[df_ToAnalyze['typing_mechanism'] == 1].count()\n",
    "\n",
    "sd = math.sqrt(((n_DT - 1)*(sd_ansr_DT)**2 + (n_MS - 1)*(sd_ansr_MS)**2)/(n_DT + n_MS - 2))\n",
    "\n",
    "print(sd*0.3)\n",
    "\n",
    "print(mean_ansr_DT, sd_ansr_DT)\n",
    "print(mean_ansr_MS, sd_ansr_MS)\n",
    "\n",
    "delError = 0.005 # As per Lakens 2017 Equivalence testing, del = d*sd, where d is Cohen's d = 0.3. For the given data, sd = ~0.006\n",
    "\n",
    "tL = (mean_ansr_DT - mean_ansr_MS - (-delError))/(math.sqrt(((sd_ansr_DT**2)/n_DT) + (sd_ansr_MS**2)/n_MS))\n",
    "tU = (mean_ansr_DT - mean_ansr_MS - (delError))/(math.sqrt(((sd_ansr_DT**2)/n_DT) + (sd_ansr_MS**2)/n_MS))\n",
    "\n",
    "#df = ((((sd_errorRate_DT**2)/(n_DT)) + ((sd_errorRate_MS**2)/(n_MS)))**2)/(((sd_errorRate_DT/n_DT)**2)/(n_DT-1) + ((sd_errorRate_MS/n_MS)**2)/(n_MS-1))\n",
    "\n",
    "df = (n_DT + n_MS - 1)\n",
    "\n",
    "print('tLower:', tL, ',tUpper:', tU,'with', df, ' degrees of freedom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For t(28, 0.05) = 1.701 To reject null hypothesis, both of the following should be followed : tU < -t(28, 0.05) AND \n",
    "tL > t(28, 0.05) , but here, the former is true but the latter isnot. So, the null hypothesis cannot be rejected, and both\n",
    "cannot be said to be equivalent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of the two typing mechanisms\n",
    "\n",
    "# Histograms\n",
    "figHist = plt.figure()\n",
    "bins = np.arange(0, float(df_ToAnalyze.attended_but_not_selected_rate_time.max())+0.01, step = 0.01)\n",
    "\n",
    "# Typing Mechanism\n",
    "\n",
    "ax = figHist.add_subplot(111)\n",
    "df_ToAnalyze.attended_but_not_selected_rate_time[df_ToAnalyze['typing_mechanism'] == 0].hist(ax = ax, alpha=0.5, grid = False, label = 'Dwell time')\n",
    "#df_ToAnalyze.hist(df_ToAnalyze.typing_speed[df_ToAnalyze['age_bins'] == 0], bins, ax = ax, grid = False)\n",
    "#plt.xticks(bins)\n",
    "#plt.xlabel('Attended but Not Selected Ratio of Time')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "ax = figHist.add_subplot(111)\n",
    "df_ToAnalyze.attended_but_not_selected_rate_time[df_ToAnalyze['typing_mechanism'] == 1].hist(ax = ax, alpha=0.5, grid = False, label = 'Multi-key selection')\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('Attended but Not Selected Ratio of Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Typing speed and Attended but Not Selected Ratio')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Since the histograms are more or less normal and the means are also more or less the same, t-test can be performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.ttest_ind(df_ToAnalyze.attended_but_not_selected_rate_time[df.typing_mechanism == 0], df_ToAnalyze.attended_but_not_selected_rate_time[df.typing_mechanism == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between ansr and error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c = str(df_ToAnalyze['attended_but_not_selected_rate_time'].corr(df_ToAnalyze['error_rate']))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "a = df_ToAnalyze.attended_but_not_selected_rate_time.sort_values()\n",
    "\n",
    "i = 0\n",
    "for ind in a.keys():\n",
    "    i = i + 1\n",
    "    ax1.plot(i, df_ToAnalyze['attended_but_not_selected_rate_time'].loc[ind], 'bo')\n",
    "    ax2.plot(i, df_ToAnalyze['error_rate'].loc[ind], 'ro')\n",
    "    \n",
    "ax1.set_title('Correlation between ansr and error rate is: %s' %c)\n",
    "ax1.set_ylabel('Attended but not selected time ratio', color = 'b')\n",
    "ax1.set_yticks(np.arange(0,0.13,0.02))\n",
    "ax2.set_ylabel('Error rate [in %]', color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
