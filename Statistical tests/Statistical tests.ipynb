{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import csv\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import datetime\n",
    "import re \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import xlsxwriter\n",
    "import scipy.stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels\n",
    "from statsmodels.graphics.regressionplots import abline_plot\n",
    "from statsmodels.stats.api import anova_lm\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.mode.use_inf_as_na = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain data in form of pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# csv file with the saved data\n",
    "fileName = r\"C:\\DTU\\Data\\201805_HealthnRehab\\data_summary.csv\"\n",
    "\n",
    "df = pd.read_csv(fileName, delimiter=',')\n",
    "\n",
    "typingMechanismDictKeys = set(df['typing_mechanism'])\n",
    "\n",
    "# create reference data frame for age bins and gender (0:Less than 30/Male, 1:Greater than 30/Female)\n",
    "labels = ['age_bins', 'gender', 'typing_mechanism']\n",
    "dataReference = [['Less than 30', 'Male', 'Dwell-Time'], ['Greater than 30', 'Female', 'Multi-Key Selection']]\n",
    "df_refAgeGender = pd.DataFrame.from_records(dataReference, columns=labels)\n",
    "\n",
    "# replace data in df in string or category\n",
    "df = df.replace({'Less than 30': 0, 'Greater than 30': 1, 'Male': 0, 'Female': 1, 'DT' : 0, 'MS' : 1})\n",
    "\n",
    "# Create dataframe without Nan values\n",
    "df_woNaGenderAgeExperience = df.dropna(subset=['gender','age_bins', 'gaze_interaction_experience'], how='any') \n",
    "\n",
    "# Create a copy of the dataframe to avoid loc errors.\n",
    "df_ToAnalyze = df_woNaGenderAgeExperience.copy()\n",
    "\n",
    "# Convert columns of age_bins, typing_mechanism, gender into categorical columns\n",
    "df_ToAnalyze['gender'] = pd.Categorical(df_woNaGenderAgeExperience.gender).codes\n",
    "df_ToAnalyze['typing_mechanism'] = pd.Categorical(df_woNaGenderAgeExperience.typing_mechanism).codes\n",
    "df_ToAnalyze['age_bins'] = pd.Categorical(df_woNaGenderAgeExperience.age_bins).codes\n",
    "df_ToAnalyze['gaze_interaction_experience'] = pd.Categorical(df_woNaGenderAgeExperience.gaze_interaction_experience).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>subject_name</th>\n",
       "      <th>typing_mechanism</th>\n",
       "      <th>age</th>\n",
       "      <th>age_bins</th>\n",
       "      <th>gender</th>\n",
       "      <th>profession</th>\n",
       "      <th>vision</th>\n",
       "      <th>gaze_interaction_experience</th>\n",
       "      <th>application_of_gaze_interaction_used_before</th>\n",
       "      <th>...</th>\n",
       "      <th>any_suggestions/comments?</th>\n",
       "      <th>dataLog_saved?</th>\n",
       "      <th>comments</th>\n",
       "      <th>typing_speed</th>\n",
       "      <th>ms_per_char</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>read_text_events_frequency_ratio</th>\n",
       "      <th>read_text_events_time_ratio</th>\n",
       "      <th>attended_but_not_selected_rate_time</th>\n",
       "      <th>error_rate_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/15/2018 14:56</td>\n",
       "      <td>be_DT</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>Lenses</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>English speaker</td>\n",
       "      <td>1.878433</td>\n",
       "      <td>6.388303</td>\n",
       "      <td>66.275660</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.042949</td>\n",
       "      <td>68.137830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/15/2018 12:35</td>\n",
       "      <td>KEA_MS</td>\n",
       "      <td>1</td>\n",
       "      <td>20-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Student</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.785736</td>\n",
       "      <td>1.112581</td>\n",
       "      <td>13.147724</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.029752</td>\n",
       "      <td>17.823862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/15/2018 11:11</td>\n",
       "      <td>lone_DT</td>\n",
       "      <td>0</td>\n",
       "      <td>50-55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>nurse</td>\n",
       "      <td>Glasses</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>kom hurtigst mulig igang\\n</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.103884</td>\n",
       "      <td>2.924059</td>\n",
       "      <td>53.722222</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.024690</td>\n",
       "      <td>0.082312</td>\n",
       "      <td>66.146825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5/15/2018 12:12</td>\n",
       "      <td>mcc_MS</td>\n",
       "      <td>1</td>\n",
       "      <td>20-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>student</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.778835</td>\n",
       "      <td>1.366924</td>\n",
       "      <td>40.370370</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>0.034549</td>\n",
       "      <td>45.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5/15/2018 14:44</td>\n",
       "      <td>MK_DT</td>\n",
       "      <td>0</td>\n",
       "      <td>45-50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Product Developer</td>\n",
       "      <td>Not wearing glasses during exp</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>A brilliant tool for thouse that need it.</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.625490</td>\n",
       "      <td>2.594320</td>\n",
       "      <td>18.445341</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.005869</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>24.222670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5/15/2018 10:58</td>\n",
       "      <td>MT_MS</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Programmer</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>Virtual reality with eye tracking, Eye tracking</td>\n",
       "      <td>...</td>\n",
       "      <td>Backspace</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.144239</td>\n",
       "      <td>1.679675</td>\n",
       "      <td>8.816964</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.013547</td>\n",
       "      <td>0.015569</td>\n",
       "      <td>13.634673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5/15/2018 12:28</td>\n",
       "      <td>ok_MS</td>\n",
       "      <td>1</td>\n",
       "      <td>20-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>student</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.135985</td>\n",
       "      <td>1.077588</td>\n",
       "      <td>8.210327</td>\n",
       "      <td>0.045161</td>\n",
       "      <td>0.003269</td>\n",
       "      <td>0.033078</td>\n",
       "      <td>11.105163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5/15/2018 12:51</td>\n",
       "      <td>pt_DT</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Student - Health informatic KU</td>\n",
       "      <td>Lenses</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.230274</td>\n",
       "      <td>1.926079</td>\n",
       "      <td>9.676650</td>\n",
       "      <td>0.058442</td>\n",
       "      <td>0.004910</td>\n",
       "      <td>0.013036</td>\n",
       "      <td>22.266896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5/15/2018 15:42</td>\n",
       "      <td>sh_MS</td>\n",
       "      <td>1</td>\n",
       "      <td>20-25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>student</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>Gaming, hmd typing</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.309663</td>\n",
       "      <td>2.260031</td>\n",
       "      <td>25.246753</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.027771</td>\n",
       "      <td>30.456710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5/15/2018 11:48</td>\n",
       "      <td>slh_DT</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.241627</td>\n",
       "      <td>2.289366</td>\n",
       "      <td>7.530067</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.009696</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>22.098367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5/16/2018 15:13</td>\n",
       "      <td>ae_DT</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>electronics</td>\n",
       "      <td>Glasses</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>The feedback about the keyboard was not filled...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Not enough valid date</td>\n",
       "      <td>0.522646</td>\n",
       "      <td>22.960094</td>\n",
       "      <td>90.322581</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.030164</td>\n",
       "      <td>95.161290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5/16/2018 13:12</td>\n",
       "      <td>ep_DT</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Eye-tracking</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>Everything</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.320822</td>\n",
       "      <td>1.442165</td>\n",
       "      <td>2.988615</td>\n",
       "      <td>0.055215</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>0.005931</td>\n",
       "      <td>2.535974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5/16/2018 13:55</td>\n",
       "      <td>hc_MS</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>occopational terapist</td>\n",
       "      <td>Glasses</td>\n",
       "      <td>0</td>\n",
       "      <td>typing</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.895676</td>\n",
       "      <td>2.451143</td>\n",
       "      <td>39.285263</td>\n",
       "      <td>0.074257</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.069406</td>\n",
       "      <td>42.341044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5/16/2018 10:51</td>\n",
       "      <td>ib_MS</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>IKT - Teknologikonsulent</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>gaze typing</td>\n",
       "      <td>...</td>\n",
       "      <td>prediction for multi-swipe function</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.768202</td>\n",
       "      <td>1.772997</td>\n",
       "      <td>49.392157</td>\n",
       "      <td>0.059211</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>0.054967</td>\n",
       "      <td>56.553221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5/16/2018 10:25</td>\n",
       "      <td>js_MS</td>\n",
       "      <td>1</td>\n",
       "      <td>20-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>medicine</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>English speaker</td>\n",
       "      <td>7.463367</td>\n",
       "      <td>1.607853</td>\n",
       "      <td>22.909549</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.004519</td>\n",
       "      <td>0.036798</td>\n",
       "      <td>26.732552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5/16/2018 14:13</td>\n",
       "      <td>km_DT</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>psychology</td>\n",
       "      <td>Lenses</td>\n",
       "      <td>0</td>\n",
       "      <td>control of fixation</td>\n",
       "      <td>...</td>\n",
       "      <td>autocomplete suggestions were difficult to see...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.059759</td>\n",
       "      <td>2.371654</td>\n",
       "      <td>12.072047</td>\n",
       "      <td>0.141243</td>\n",
       "      <td>0.008967</td>\n",
       "      <td>0.020826</td>\n",
       "      <td>22.286024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5/16/2018 10:14</td>\n",
       "      <td>ma_DT</td>\n",
       "      <td>0</td>\n",
       "      <td>25-30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>student</td>\n",
       "      <td>Glasses</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.304923</td>\n",
       "      <td>2.262050</td>\n",
       "      <td>13.340810</td>\n",
       "      <td>0.146552</td>\n",
       "      <td>0.008179</td>\n",
       "      <td>0.026139</td>\n",
       "      <td>30.837072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5/16/2018 16:28</td>\n",
       "      <td>mw_MS</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>rehabilitation device distributor</td>\n",
       "      <td>Glasses</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>English speaker</td>\n",
       "      <td>5.280016</td>\n",
       "      <td>2.272721</td>\n",
       "      <td>47.447272</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.004081</td>\n",
       "      <td>0.062806</td>\n",
       "      <td>59.152208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5/16/2018 14:57</td>\n",
       "      <td>pgba_DT</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Student</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.411380</td>\n",
       "      <td>1.871672</td>\n",
       "      <td>4.517041</td>\n",
       "      <td>0.052980</td>\n",
       "      <td>0.006890</td>\n",
       "      <td>0.031186</td>\n",
       "      <td>10.452965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5/16/2018 16:01</td>\n",
       "      <td>pt_MS</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Student - Health informatic KU</td>\n",
       "      <td>Lenses</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.334700</td>\n",
       "      <td>1.439764</td>\n",
       "      <td>62.953189</td>\n",
       "      <td>0.101266</td>\n",
       "      <td>0.005530</td>\n",
       "      <td>0.073314</td>\n",
       "      <td>62.143261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5/16/2018 12:06</td>\n",
       "      <td>smn_DT</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>work with kids</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.522410</td>\n",
       "      <td>2.172964</td>\n",
       "      <td>1.668409</td>\n",
       "      <td>0.150327</td>\n",
       "      <td>0.008241</td>\n",
       "      <td>0.014623</td>\n",
       "      <td>6.111982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5/17/2018 11:57</td>\n",
       "      <td>eo_DT</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>consultant</td>\n",
       "      <td>Glasses</td>\n",
       "      <td>0</td>\n",
       "      <td>eye typing</td>\n",
       "      <td>...</td>\n",
       "      <td>The user got stressed while typing and stopped...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.095240</td>\n",
       "      <td>5.727267</td>\n",
       "      <td>96.910755</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>0.018605</td>\n",
       "      <td>95.955378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5/17/2018 13:54</td>\n",
       "      <td>jek_MS</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>Lenses</td>\n",
       "      <td>2</td>\n",
       "      <td>gesture control</td>\n",
       "      <td>...</td>\n",
       "      <td>no feedback for when a word is started, or wha...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.077941</td>\n",
       "      <td>1.974353</td>\n",
       "      <td>46.204124</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.007967</td>\n",
       "      <td>0.109562</td>\n",
       "      <td>52.060395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5/17/2018 12:40</td>\n",
       "      <td>jg_DT</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>Glasses</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>MSD goes higher than 100%</td>\n",
       "      <td>2.130563</td>\n",
       "      <td>5.632315</td>\n",
       "      <td>117.179487</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.006836</td>\n",
       "      <td>0.021263</td>\n",
       "      <td>108.589744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5/17/2018 10:48</td>\n",
       "      <td>lg_MS</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>occupational therapist</td>\n",
       "      <td>Lenses</td>\n",
       "      <td>0</td>\n",
       "      <td>communication (aac)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.673385</td>\n",
       "      <td>2.115139</td>\n",
       "      <td>63.779936</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.003936</td>\n",
       "      <td>0.093907</td>\n",
       "      <td>73.371450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5/17/2018 10:22</td>\n",
       "      <td>lr_MS</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>software testing</td>\n",
       "      <td>Glasses</td>\n",
       "      <td>0</td>\n",
       "      <td>learning and games</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.453259</td>\n",
       "      <td>1.419571</td>\n",
       "      <td>21.588089</td>\n",
       "      <td>0.161074</td>\n",
       "      <td>0.011078</td>\n",
       "      <td>0.054378</td>\n",
       "      <td>23.224600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5/17/2018 16:11</td>\n",
       "      <td>mm_MS</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>eye tracking sales</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>everything</td>\n",
       "      <td>...</td>\n",
       "      <td>divide into training and testing clearly, take...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>English speaker</td>\n",
       "      <td>8.834883</td>\n",
       "      <td>1.358252</td>\n",
       "      <td>12.188406</td>\n",
       "      <td>0.091346</td>\n",
       "      <td>0.008003</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>11.094203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5/17/2018 16:08</td>\n",
       "      <td>mr_DT</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ergoterapeut</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.736920</td>\n",
       "      <td>1.781229</td>\n",
       "      <td>5.549042</td>\n",
       "      <td>0.082278</td>\n",
       "      <td>0.008291</td>\n",
       "      <td>0.042316</td>\n",
       "      <td>19.441188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5/17/2018 10:36</td>\n",
       "      <td>snk_DT</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>administrativ sagsbehandler</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.004198</td>\n",
       "      <td>2.397987</td>\n",
       "      <td>18.259649</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.006794</td>\n",
       "      <td>0.046196</td>\n",
       "      <td>36.296491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          timestamp subject_name  typing_mechanism    age  age_bins  gender  \\\n",
       "1   5/15/2018 14:56        be_DT                 0     40         1       1   \n",
       "3   5/15/2018 12:35       KEA_MS                 1  20-25         0       0   \n",
       "4   5/15/2018 11:11      lone_DT                 0  50-55         1       1   \n",
       "5   5/15/2018 12:12       mcc_MS                 1  20-25         0       0   \n",
       "6   5/15/2018 14:44        MK_DT                 0  45-50         1       1   \n",
       "7   5/15/2018 10:58        MT_MS                 1     25         0       0   \n",
       "8   5/15/2018 12:28        ok_MS                 1  20-25         0       0   \n",
       "9   5/15/2018 12:51        pt_DT                 0     27         0       0   \n",
       "11  5/15/2018 15:42        sh_MS                 1  20-25         0       1   \n",
       "12  5/15/2018 11:48       slh_DT                 0     10         0       1   \n",
       "13  5/16/2018 15:13        ae_DT                 0     68         1       0   \n",
       "14  5/16/2018 13:12        ep_DT                 0     23         0       0   \n",
       "15  5/16/2018 13:55        hc_MS                 1     43         1       1   \n",
       "16  5/16/2018 10:51        ib_MS                 1     59         1       0   \n",
       "17  5/16/2018 10:25        js_MS                 1  20-25         0       0   \n",
       "18  5/16/2018 14:13        km_DT                 0     33         1       0   \n",
       "19  5/16/2018 10:14        ma_DT                 0  25-30         0       1   \n",
       "20  5/16/2018 16:28        mw_MS                 1     41         1       0   \n",
       "21  5/16/2018 14:57      pgba_DT                 0     27         0       0   \n",
       "22  5/16/2018 16:01        pt_MS                 1     27         0       0   \n",
       "23  5/16/2018 12:06       smn_DT                 0     29         0       1   \n",
       "24  5/17/2018 11:57        eo_DT                 0     25         0       0   \n",
       "25  5/17/2018 13:54       jek_MS                 1     42         1       0   \n",
       "26  5/17/2018 12:40        jg_DT                 0     46         1       0   \n",
       "27  5/17/2018 10:48        lg_MS                 1     34         1       1   \n",
       "28  5/17/2018 10:22        lr_MS                 1     40         1       1   \n",
       "29  5/17/2018 16:11        mm_MS                 1     27         0       1   \n",
       "30  5/17/2018 16:08        mr_DT                 0     39         1       1   \n",
       "31  5/17/2018 10:36       snk_DT                 0     55         1       1   \n",
       "\n",
       "                           profession                          vision  \\\n",
       "1                            business                          Lenses   \n",
       "3                             Student                          Normal   \n",
       "4                               nurse                         Glasses   \n",
       "5                             student                          Normal   \n",
       "6                   Product Developer  Not wearing glasses during exp   \n",
       "7                          Programmer                          Normal   \n",
       "8                             student                          Normal   \n",
       "9      Student - Health informatic KU                          Lenses   \n",
       "11                            student                          Normal   \n",
       "12                                NaN                          Normal   \n",
       "13                        electronics                         Glasses   \n",
       "14                       Eye-tracking                          Normal   \n",
       "15              occopational terapist                         Glasses   \n",
       "16           IKT - Teknologikonsulent                          Normal   \n",
       "17                           medicine                          Normal   \n",
       "18                         psychology                          Lenses   \n",
       "19                            student                         Glasses   \n",
       "20  rehabilitation device distributor                         Glasses   \n",
       "21                            Student                          Normal   \n",
       "22     Student - Health informatic KU                          Lenses   \n",
       "23                     work with kids                          Normal   \n",
       "24                         consultant                         Glasses   \n",
       "25                           Engineer                          Lenses   \n",
       "26                            Mobile                          Glasses   \n",
       "27             occupational therapist                          Lenses   \n",
       "28                   software testing                         Glasses   \n",
       "29                 eye tracking sales                          Normal   \n",
       "30                       Ergoterapeut                          Normal   \n",
       "31        administrativ sagsbehandler                          Normal   \n",
       "\n",
       "    gaze_interaction_experience  \\\n",
       "1                             1   \n",
       "3                             1   \n",
       "4                             1   \n",
       "5                             1   \n",
       "6                             1   \n",
       "7                             0   \n",
       "8                             1   \n",
       "9                             1   \n",
       "11                            0   \n",
       "12                            1   \n",
       "13                            1   \n",
       "14                            0   \n",
       "15                            0   \n",
       "16                            0   \n",
       "17                            1   \n",
       "18                            0   \n",
       "19                            1   \n",
       "20                            1   \n",
       "21                            1   \n",
       "22                            1   \n",
       "23                            1   \n",
       "24                            0   \n",
       "25                            2   \n",
       "26                            1   \n",
       "27                            0   \n",
       "28                            0   \n",
       "29                            0   \n",
       "30                            1   \n",
       "31                            1   \n",
       "\n",
       "         application_of_gaze_interaction_used_before        ...         \\\n",
       "1                                                NaN        ...          \n",
       "3                                                NaN        ...          \n",
       "4                                                NaN        ...          \n",
       "5                                                NaN        ...          \n",
       "6                                                NaN        ...          \n",
       "7   Virtual reality with eye tracking, Eye tracking         ...          \n",
       "8                                                NaN        ...          \n",
       "9                                                NaN        ...          \n",
       "11                                Gaming, hmd typing        ...          \n",
       "12                                               NaN        ...          \n",
       "13                                               NaN        ...          \n",
       "14                                        Everything        ...          \n",
       "15                                            typing        ...          \n",
       "16                                       gaze typing        ...          \n",
       "17                                               NaN        ...          \n",
       "18                               control of fixation        ...          \n",
       "19                                               NaN        ...          \n",
       "20                                               NaN        ...          \n",
       "21                                               NaN        ...          \n",
       "22                                               NaN        ...          \n",
       "23                                               NaN        ...          \n",
       "24                                        eye typing        ...          \n",
       "25                                   gesture control        ...          \n",
       "26                                               NaN        ...          \n",
       "27                               communication (aac)        ...          \n",
       "28                                learning and games        ...          \n",
       "29                                        everything        ...          \n",
       "30                                               NaN        ...          \n",
       "31                                               NaN        ...          \n",
       "\n",
       "                            any_suggestions/comments?  dataLog_saved?  \\\n",
       "1                                                 NaN             Yes   \n",
       "3                                                 NaN             Yes   \n",
       "4                          kom hurtigst mulig igang\\n             Yes   \n",
       "5                                                 NaN             Yes   \n",
       "6          A brilliant tool for thouse that need it.              Yes   \n",
       "7                                           Backspace              No   \n",
       "8                                                 NaN             Yes   \n",
       "9                                                 NaN             Yes   \n",
       "11                                                NaN             Yes   \n",
       "12                                                NaN              No   \n",
       "13  The feedback about the keyboard was not filled...             Yes   \n",
       "14                                                NaN              No   \n",
       "15                                                NaN             Yes   \n",
       "16               prediction for multi-swipe function              Yes   \n",
       "17                                                NaN             Yes   \n",
       "18  autocomplete suggestions were difficult to see...             Yes   \n",
       "19                                                NaN             Yes   \n",
       "20                                                NaN             Yes   \n",
       "21                                                NaN             Yes   \n",
       "22                                                NaN              No   \n",
       "23                                                NaN             Yes   \n",
       "24  The user got stressed while typing and stopped...             Yes   \n",
       "25  no feedback for when a word is started, or wha...             Yes   \n",
       "26                                                NaN             Yes   \n",
       "27                                                NaN             Yes   \n",
       "28                                                NaN             Yes   \n",
       "29  divide into training and testing clearly, take...             Yes   \n",
       "30                                                NaN              No   \n",
       "31                                                NaN             Yes   \n",
       "\n",
       "                     comments typing_speed ms_per_char  error_rate  \\\n",
       "1             English speaker     1.878433    6.388303   66.275660   \n",
       "3                         NaN    10.785736    1.112581   13.147724   \n",
       "4                         NaN     4.103884    2.924059   53.722222   \n",
       "5                         NaN     8.778835    1.366924   40.370370   \n",
       "6                         NaN     4.625490    2.594320   18.445341   \n",
       "7                         NaN     7.144239    1.679675    8.816964   \n",
       "8                         NaN    11.135985    1.077588    8.210327   \n",
       "9                         NaN     6.230274    1.926079    9.676650   \n",
       "11                        NaN     5.309663    2.260031   25.246753   \n",
       "12                        NaN     5.241627    2.289366    7.530067   \n",
       "13      Not enough valid date     0.522646   22.960094   90.322581   \n",
       "14                        NaN     8.320822    1.442165    2.988615   \n",
       "15                        NaN     4.895676    2.451143   39.285263   \n",
       "16                        NaN     6.768202    1.772997   49.392157   \n",
       "17            English speaker     7.463367    1.607853   22.909549   \n",
       "18                        NaN     5.059759    2.371654   12.072047   \n",
       "19                        NaN     5.304923    2.262050   13.340810   \n",
       "20            English speaker     5.280016    2.272721   47.447272   \n",
       "21                        NaN     6.411380    1.871672    4.517041   \n",
       "22                        NaN     8.334700    1.439764   62.953189   \n",
       "23                        NaN     5.522410    2.172964    1.668409   \n",
       "24                        NaN     2.095240    5.727267   96.910755   \n",
       "25                        NaN     6.077941    1.974353   46.204124   \n",
       "26  MSD goes higher than 100%     2.130563    5.632315  117.179487   \n",
       "27                        NaN     5.673385    2.115139   63.779936   \n",
       "28                        NaN     8.453259    1.419571   21.588089   \n",
       "29            English speaker     8.834883    1.358252   12.188406   \n",
       "30                        NaN     6.736920    1.781229    5.549042   \n",
       "31                        NaN     5.004198    2.397987   18.259649   \n",
       "\n",
       "   read_text_events_frequency_ratio  read_text_events_time_ratio  \\\n",
       "1                          0.277778                     0.007300   \n",
       "3                          0.056000                     0.003742   \n",
       "4                          0.205128                     0.024690   \n",
       "5                          0.076087                     0.005991   \n",
       "6                          0.092593                     0.005869   \n",
       "7                          0.185185                     0.013547   \n",
       "8                          0.045161                     0.003269   \n",
       "9                          0.058442                     0.004910   \n",
       "11                         0.108696                     0.001796   \n",
       "12                         0.155556                     0.009696   \n",
       "13                         0.555556                     0.001660   \n",
       "14                         0.055215                     0.004696   \n",
       "15                         0.074257                     0.003238   \n",
       "16                         0.059211                     0.003422   \n",
       "17                         0.093750                     0.004519   \n",
       "18                         0.141243                     0.008967   \n",
       "19                         0.146552                     0.008179   \n",
       "20                         0.116667                     0.004081   \n",
       "21                         0.052980                     0.006890   \n",
       "22                         0.101266                     0.005530   \n",
       "23                         0.150327                     0.008241   \n",
       "24                         0.368421                     0.002043   \n",
       "25                         0.086207                     0.007967   \n",
       "26                         0.382353                     0.006836   \n",
       "27                         0.083333                     0.003936   \n",
       "28                         0.161074                     0.011078   \n",
       "29                         0.091346                     0.008003   \n",
       "30                         0.082278                     0.008291   \n",
       "31                         0.096552                     0.006794   \n",
       "\n",
       "    attended_but_not_selected_rate_time  error_rate_total  \n",
       "1                              0.042949         68.137830  \n",
       "3                              0.029752         17.823862  \n",
       "4                              0.082312         66.146825  \n",
       "5                              0.034549         45.185185  \n",
       "6                              0.027000         24.222670  \n",
       "7                              0.015569         13.634673  \n",
       "8                              0.033078         11.105163  \n",
       "9                              0.013036         22.266896  \n",
       "11                             0.027771         30.456710  \n",
       "12                             0.020300         22.098367  \n",
       "13                             0.030164         95.161290  \n",
       "14                             0.005931          2.535974  \n",
       "15                             0.069406         42.341044  \n",
       "16                             0.054967         56.553221  \n",
       "17                             0.036798         26.732552  \n",
       "18                             0.020826         22.286024  \n",
       "19                             0.026139         30.837072  \n",
       "20                             0.062806         59.152208  \n",
       "21                             0.031186         10.452965  \n",
       "22                             0.073314         62.143261  \n",
       "23                             0.014623          6.111982  \n",
       "24                             0.018605         95.955378  \n",
       "25                             0.109562         52.060395  \n",
       "26                             0.021263        108.589744  \n",
       "27                             0.093907         73.371450  \n",
       "28                             0.054378         23.224600  \n",
       "29                             0.015625         11.094203  \n",
       "30                             0.042316         19.441188  \n",
       "31                             0.046196         36.296491  \n",
       "\n",
       "[29 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ToAnalyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Males: 16 Females: 13\n",
      "Below 30: 15 Above 30 14\n",
      "Dwell time 15 Multi-key selection: 14\n",
      "No previous experience with gaze: 18 Tried once before: 1 Multiple times 10\n"
     ]
    }
   ],
   "source": [
    "n_Males = df_ToAnalyze.gender[df_ToAnalyze['gender'] == 0].count()\n",
    "n_Females = df_ToAnalyze.gender[df_ToAnalyze['gender'] == 1].count()\n",
    "\n",
    "n_Below30 = df_ToAnalyze.age_bins[df_ToAnalyze['age_bins'] == 0].count()\n",
    "n_Above30 = df_ToAnalyze.age_bins[df_ToAnalyze['age_bins'] == 1].count()\n",
    "\n",
    "n_DT = df_ToAnalyze.typing_mechanism[df_ToAnalyze['typing_mechanism'] == 0].count()\n",
    "n_MS = df_ToAnalyze.typing_mechanism[df_ToAnalyze['typing_mechanism'] == 1].count()\n",
    "\n",
    "n_ExperienceNever = df_ToAnalyze.gaze_interaction_experience[df_ToAnalyze['gaze_interaction_experience'] == 1].count()\n",
    "n_ExperienceMultiple = df_ToAnalyze.gaze_interaction_experience[df_ToAnalyze['gaze_interaction_experience'] == 0].count()\n",
    "n_ExperienceOnce = df_ToAnalyze.gaze_interaction_experience[df_ToAnalyze['gaze_interaction_experience'] == 2].count()\n",
    "\n",
    "\n",
    "print('Males:', n_Males, 'Females:', n_Females)\n",
    "print('Below 30:', n_Below30, 'Above 30', n_Above30)\n",
    "print('Dwell time', n_DT, 'Multi-key selection:', n_MS)\n",
    "print('No previous experience with gaze:', n_ExperienceNever, 'Tried once before:', n_ExperienceOnce, 'Multiple times', n_ExperienceMultiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_DT_Below30 = df_ToAnalyze.typing_mechanism[(df_ToAnalyze['typing_mechanism'] == 0) & (df_ToAnalyze['age_bins'] == 0)].count()\n",
    "n_DT_Above30 = df_ToAnalyze.typing_mechanism[(df_ToAnalyze['typing_mechanism'] == 0) & (df_ToAnalyze['age_bins'] == 1)].count()\n",
    "\n",
    "n_MS_Below30 = df_ToAnalyze.typing_mechanism[(df_ToAnalyze['typing_mechanism'] == 1) & (df_ToAnalyze['age_bins'] == 0)].count()\n",
    "n_MS_Above30 = df_ToAnalyze.typing_mechanism[(df_ToAnalyze['typing_mechanism'] == 1) & (df_ToAnalyze['age_bins'] == 1)].count()\n",
    "\n",
    "\n",
    "n_DT_Males = df_ToAnalyze.typing_mechanism[(df_ToAnalyze['typing_mechanism'] == 0) & (df_ToAnalyze['gender'] == 0)].count()\n",
    "n_DT_Females = df_ToAnalyze.typing_mechanism[(df_ToAnalyze['typing_mechanism'] == 0) & (df_ToAnalyze['gender'] == 1)].count()\n",
    "\n",
    "n_MS_Males = df_ToAnalyze.typing_mechanism[(df_ToAnalyze['typing_mechanism'] == 1) & (df_ToAnalyze['gender'] == 0)].count()\n",
    "n_MS_Females = df_ToAnalyze.typing_mechanism[(df_ToAnalyze['typing_mechanism'] == 1) & (df_ToAnalyze['gender'] == 1)].count()\n",
    "\n",
    "\n",
    "print(n_DT_Below30, n_DT_Above30, n_MS_Below30, n_MS_Above30)\n",
    "print(n_DT_Males, n_DT_Females, n_MS_Males, n_MS_Females)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experience (comfort, challenge level, fun) - \n",
    "df_ToAnalyze.how_challenging_was_the_task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of typing speed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLS regression to check residuals of data for anova testing \n",
    "X = df_ToAnalyze[['age_bins', 'typing_mechanism', 'gender']] # independent variable\n",
    "y_typingSpeed = df_ToAnalyze.typing_speed # dependent variable\n",
    "\n",
    "model_typingSpeed = sm.OLS(y_typingSpeed, X)\n",
    "model_fit_typingSpeed = model_typingSpeed.fit()\n",
    "\n",
    "p_typingSpeed = model_fit_typingSpeed.params\n",
    "\n",
    "# Plot the residuals of each\n",
    "residuals_typingSpeed = model_fit_typingSpeed.resid # residuals\n",
    "fig = sm.qqplot(residuals_typingSpeed)\n",
    "plt.show()\n",
    "\n",
    "model_fit_typingSpeed.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments:\n",
    "Only 73.5% of variance is explained -- is high correlation value\n",
    "Prob(F-statistic) --> Null hypothesis is rejected, that the variability is random and alternate hypothesis that the variability\n",
    "can be explained is accepted\n",
    "\n",
    "From the graph, we see that the residuals are normally distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula_typingSpeed = 'df_ToAnalyze.typing_speed ~ df_ToAnalyze.age_bins + df_ToAnalyze.gender + df_ToAnalyze.typing_mechanism + df_ToAnalyze.age_bins:df_ToAnalyze.gender + df_ToAnalyze.age_bins:df_ToAnalyze.typing_mechanism + df_ToAnalyze.gender:df_ToAnalyze.typing_mechanism'\n",
    "model_typingSpeed = ols(formula_typingSpeed, df_ToAnalyze).fit()\n",
    "aov_table_typingSpeed = statsmodels.stats.anova.anova_lm(model_typingSpeed, typ=2)\n",
    "print(aov_table_typingSpeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots of typing speed wrt independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plots\n",
    "\n",
    "figBoxPlot = plt.figure()\n",
    "\n",
    "# Age\n",
    "ax = figBoxPlot.add_subplot(131)\n",
    "df_ToAnalyze.boxplot( column = 'typing_speed', by='age_bins', ax = ax, grid = False)\n",
    "plt.xticks([1, 2], ['Less than 30', 'Greater than 30'])\n",
    "plt.yticks(np.arange(0, float(df.typing_speed.max())+2, step = 2))\n",
    "plt.ylabel('Typing speed [in wpm]')\n",
    "\n",
    "# Gender\n",
    "ax = figBoxPlot.add_subplot(132)\n",
    "df_ToAnalyze.boxplot(column = 'typing_speed', by='gender', ax = ax, grid = False)\n",
    "plt.xticks([1, 2], ['Male', 'Female'])\n",
    "plt.yticks(np.arange(0, float(df.typing_speed.max())+2, step = 2))\n",
    "plt.ylabel('Typing speed [in wpm]')\n",
    "\n",
    "# Typing mechanism\n",
    "ax = figBoxPlot.add_subplot(133)\n",
    "df_ToAnalyze.boxplot(column = 'typing_speed', by='typing_mechanism', ax = ax, grid = False)\n",
    "plt.xticks([1, 2], ['Dwell time', 'MultiKey selection'])\n",
    "plt.yticks(np.arange(0, float(df.typing_speed.max())+2, step = 2))\n",
    "plt.ylabel('Typing speed [in wpm]')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average speed and standard deviation for dwell time selection are:', df_ToAnalyze.typing_speed[df_ToAnalyze['typing_mechanism']==0].mean(), df_ToAnalyze.typing_speed[df_ToAnalyze['typing_mechanism']==0].std())\n",
    "print('Average speed and standard deviation for multi-key selection are:', df_ToAnalyze.typing_speed[df_ToAnalyze['typing_mechanism']==1].mean(), df_ToAnalyze.typing_speed[df_ToAnalyze['typing_mechanism']==1].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms\n",
    "figHist = plt.figure()\n",
    "bins = np.arange(0, float(df_ToAnalyze.typing_speed.max()+2), step = 2)\n",
    "\n",
    "# Age\n",
    "ax = figHist.add_subplot(141)\n",
    "df_ToAnalyze.hist( column = 'typing_speed', ax = ax, grid = False)\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('Typing speed [in wpm]')\n",
    "plt.yticks(np.arange(0, 11, step = 2))\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "ax = figHist.add_subplot(142)\n",
    "df_ToAnalyze.typing_speed[df_ToAnalyze['age_bins'] == 0].hist(ax = ax, alpha=0.5, grid = False, label = 'Below 30 years')\n",
    "#df_ToAnalyze.hist(df_ToAnalyze.typing_speed[df_ToAnalyze['age_bins'] == 0], bins, ax = ax, grid = False)\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('Typing speed [in wpm]')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "ax = figHist.add_subplot(142)\n",
    "df_ToAnalyze.typing_speed[df_ToAnalyze['age_bins'] == 1].hist(ax = ax, alpha=0.5, grid = False, label = 'Above 30 years')\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('Typing speed [in wpm]')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Typing speed and Age')\n",
    "plt.legend()\n",
    "\n",
    "# Gender\n",
    "\n",
    "ax = figHist.add_subplot(143)\n",
    "df_ToAnalyze.typing_speed[df_ToAnalyze['gender'] == 0].hist(ax = ax, alpha=0.5, grid = False, label = 'Male')\n",
    "#df_ToAnalyze.hist(df_ToAnalyze.typing_speed[df_ToAnalyze['age_bins'] == 0], bins, ax = ax, grid = False)\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('Typing speed [in wpm]')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "ax = figHist.add_subplot(143)\n",
    "df_ToAnalyze.typing_speed[df_ToAnalyze['gender'] == 1].hist(ax = ax, alpha=0.5, grid = False, label = 'Female')\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('Typing speed [in wpm]')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Typing speed and Gender')\n",
    "plt.legend()\n",
    "\n",
    "# Typing Mechanism\n",
    "\n",
    "ax = figHist.add_subplot(144)\n",
    "df_ToAnalyze.typing_speed[df_ToAnalyze['typing_mechanism'] == 0].hist(ax = ax, alpha=0.5, grid = False, label = 'Dwell time')\n",
    "#df_ToAnalyze.hist(df_ToAnalyze.typing_speed[df_ToAnalyze['age_bins'] == 0], bins, ax = ax, grid = False)\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('Typing speed [in wpm]')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "ax = figHist.add_subplot(144)\n",
    "df_ToAnalyze.typing_speed[df_ToAnalyze['typing_mechanism'] == 1].hist(ax = ax, alpha=0.5, grid = False, label = 'Multi-key selection')\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('Typing speed [in wpm]')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Typing speed and Typing Mechanism')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the new calculations of typing speed, the histograms for typing speed are normal when distributed as per age and gender, \n",
    "but not using typing mechanism. Therefore, mann whitney test will be performed for typing mechanism (their variances are still\n",
    "more or less equal) and t-test for the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Typing speed statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age\n",
    "\n",
    "\n",
    "# Gender\n",
    "\n",
    "\n",
    "# Typing mechanism\n",
    "# the mann whitney test in scipy.stats clearly says that it is reliable only for sample size of 20 in each. Since we do not have\n",
    "# that, this test will be performed manually, based on - http://psych.unl.edu/psycrs/handcomp/hcmann.PDF\n",
    "n_DT = df_ToAnalyze.typing_mechanism[df_ToAnalyze['typing_mechanism'] == 0].count()\n",
    "n_MS = df_ToAnalyze.typing_mechanism[df_ToAnalyze['typing_mechanism'] == 1].count()\n",
    "\n",
    "# Rank the data and add up\n",
    "RankedSumDT = sum(df_ToAnalyze.typing_speed[df_ToAnalyze['typing_mechanism'] == 0].rank(axis=0, method='average'))\n",
    "\n",
    "U_DT = n_DT*n_MS + n_DT*(n_DT + 1)/2 - RankedSumDT\n",
    "U_MS = n_DT*n_MS - U_DT\n",
    "U_select = min(U_MS, U_DT)\n",
    "U_critical = 59\n",
    "if U_select < U_critical:\n",
    "    print('reject Ho')\n",
    "\n",
    "# using the function\n",
    "U_stat, p_val = scipy.stats.mannwhitneyu(df_ToAnalyze.typing_speed[df_ToAnalyze['typing_mechanism'] == 0], df_ToAnalyze.typing_speed[df_ToAnalyze['typing_mechanism'] == 1])\n",
    "print(U_stat, p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_DT, n_MS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age\n",
    "a = df_ToAnalyze.typing_speed[df_ToAnalyze['age_bins']==0]\n",
    "b = df_ToAnalyze.typing_speed[df_ToAnalyze['age_bins']==1]\n",
    "(h, p) = scipy.stats.kruskal(a.values, b.values)\n",
    "print('Kruskal result for age: H-statistic=', h, ', pvalue=', p)\n",
    "\n",
    "# Gender\n",
    "a = df_ToAnalyze.typing_speed[df_ToAnalyze['gender']==0]\n",
    "b = df_ToAnalyze.typing_speed[df_ToAnalyze['gender']==1]\n",
    "(h, p) = scipy.stats.kruskal(a.values, b.values)\n",
    "print('Kruskal result for gender: H-statistic=', h, ', pvalue=', p)\n",
    "\n",
    "# Typing mechanism\n",
    "a = df_ToAnalyze.typing_speed[df_ToAnalyze['typing_mechanism']==0]\n",
    "b = df_ToAnalyze.typing_speed[df_ToAnalyze['typing_mechanism']==1]\n",
    "(h, p) = scipy.stats.kruskal(a.values, b.values)\n",
    "print('Kruskal result for typing mechanism: H-statistic=', h, ', pvalue=', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ToAnalyze.error_rate[df_ToAnalyze.typing_mechanism==1].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of error rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>error_rate</td>    <th>  R-squared:         </th> <td>   0.557</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.506</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   10.90</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 13 Apr 2019</td> <th>  Prob (F-statistic):</th> <td>8.10e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:56:34</td>     <th>  Log-Likelihood:    </th> <td> -140.02</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    29</td>      <th>  AIC:               </th> <td>   286.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    26</td>      <th>  BIC:               </th> <td>   290.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_bins</th>         <td>   42.6122</td> <td>   11.041</td> <td>    3.859</td> <td> 0.001</td> <td>   19.917</td> <td>   65.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>typing_mechanism</th> <td>   16.8558</td> <td>    9.572</td> <td>    1.761</td> <td> 0.090</td> <td>   -2.820</td> <td>   36.531</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>           <td>   -6.0228</td> <td>   11.146</td> <td>   -0.540</td> <td> 0.594</td> <td>  -28.934</td> <td>   16.888</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>11.372</td> <th>  Durbin-Watson:     </th> <td>   1.955</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.003</td> <th>  Jarque-Bera (JB):  </th> <td>  10.231</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.225</td> <th>  Prob(JB):          </th> <td> 0.00600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.569</td> <th>  Cond. No.          </th> <td>    2.20</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             error_rate   R-squared:                       0.557\n",
       "Model:                            OLS   Adj. R-squared:                  0.506\n",
       "Method:                 Least Squares   F-statistic:                     10.90\n",
       "Date:                Sat, 13 Apr 2019   Prob (F-statistic):           8.10e-05\n",
       "Time:                        17:56:34   Log-Likelihood:                -140.02\n",
       "No. Observations:                  29   AIC:                             286.0\n",
       "Df Residuals:                      26   BIC:                             290.1\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "age_bins            42.6122     11.041      3.859      0.001      19.917      65.307\n",
       "typing_mechanism    16.8558      9.572      1.761      0.090      -2.820      36.531\n",
       "gender              -6.0228     11.146     -0.540      0.594     -28.934      16.888\n",
       "==============================================================================\n",
       "Omnibus:                       11.372   Durbin-Watson:                   1.955\n",
       "Prob(Omnibus):                  0.003   Jarque-Bera (JB):               10.231\n",
       "Skew:                           1.225   Prob(JB):                      0.00600\n",
       "Kurtosis:                       4.569   Cond. No.                         2.20\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OLS regression to check residuals of data for anova testing \n",
    "X = df_ToAnalyze[['age_bins', 'typing_mechanism', 'gender']] # independent variable\n",
    "y_errorRate = df_ToAnalyze.error_rate # dependent variable\n",
    "\n",
    "model_errorRate = sm.OLS(y_errorRate,X)\n",
    "model_fit_errorRate = model_errorRate.fit()\n",
    "\n",
    "p_errorRate = model_fit_errorRate.params\n",
    "\n",
    "# Plot the residuals of each\n",
    "residuals_errorRate = model_fit_errorRate.resid # residuals\n",
    "fig = sm.qqplot(residuals_errorRate)\n",
    "plt.show()\n",
    "\n",
    "model_fit_errorRate.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments: The residual plot is slightly skewed --> anova cannot be performed \n",
    "But Prob(F-statistic) is low enough to reject null hypothesis\n",
    "Still, anova is not performed due to the skewed residual plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Perform Shierer Ray Hare test \n",
    "\n",
    "# For now, it is performed in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equivalence testing of error rate for typing mechansims\n",
    "Here, the null hypothesis is that error rates for both is not equivalent\n",
    "For a practical equivalence value of 'del', Ho: |mu1 - mu2| > del and Ha: |mu1 - mu2| < del\n",
    "So, to reject the null hypothesis, both should be rejected:\n",
    "mu1 - mu2 > del and mu1 - mu2 < -del\n",
    "or in terms of two-one sided test :\n",
    "    ((y1m - y2m) + del)/sigma(1/n1 + 1/n2) > z(1-alpha) and ((y1m - y2m) - del)/sigma(1/n1 + 1/n2) < -z(1-alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.44440451869594\n"
     ]
    }
   ],
   "source": [
    "sd_errorRate_DT = df_ToAnalyze.error_rate[df_ToAnalyze['typing_mechanism']==0].std()\n",
    "sd_errorRate_MS = df_ToAnalyze.error_rate[df_ToAnalyze['typing_mechanism']==1].std()\n",
    "\n",
    "n_DT = df_ToAnalyze.typing_mechanism[df_ToAnalyze['typing_mechanism'] == 0].count()\n",
    "n_MS = df_ToAnalyze.typing_mechanism[df_ToAnalyze['typing_mechanism'] == 1].count()\n",
    "\n",
    "mean_errorRate_DT = df_ToAnalyze.error_rate[df_ToAnalyze['typing_mechanism']==0].mean()\n",
    "mean_errorRate_MS = df_ToAnalyze.error_rate[df_ToAnalyze['typing_mechanism']==1].mean()\n",
    "\n",
    "sd = math.sqrt(((n_DT - 1)*(sd_errorRate_DT)**2 + (n_MS - 1)*(sd_errorRate_MS)**2)/(n_DT + n_MS - 2))\n",
    "\n",
    "print(sd*0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tLower: 1.013133563052146 ,tUpper: -0.7341394954984529 with 28  degrees of freedom\n"
     ]
    }
   ],
   "source": [
    "delError = 10 # As per Lakens 2017 Equivalence testing, del = d*sd, where d is Cohen's d = !!0.3!! - 0.3 is not correct: needs to be the effect size. For the given data, sd = ~36\n",
    "\n",
    "tL = (mean_errorRate_DT - mean_errorRate_MS - (-delError))/(math.sqrt(((sd_errorRate_DT**2)/n_DT) + (sd_errorRate_MS**2)/n_MS))\n",
    "tU = (mean_errorRate_DT - mean_errorRate_MS - (delError))/(math.sqrt(((sd_errorRate_DT**2)/n_DT) + (sd_errorRate_MS**2)/n_MS))\n",
    "\n",
    "#df = ((((sd_errorRate_DT**2)/(n_DT)) + ((sd_errorRate_MS**2)/(n_MS)))**2)/(((sd_errorRate_DT/n_DT)**2)/(n_DT-1) + ((sd_errorRate_MS/n_MS)**2)/(n_MS-1))\n",
    "\n",
    "df = (n_DT + n_MS - 1)\n",
    "\n",
    "print('tLower:', tL, ',tUpper:', tU,'with', df, ' degrees of freedom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#For t(28, 0.05) = 1.701\n",
    "To reject null hypothesis, both of the following should be followed - \n",
    "tU < -t(28, 0.05) AND tL > t(28, 0.05)\n",
    "As both are not, null hypothesis cannot be rejected \n",
    "Therefore, both cannot be equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error rate and standard deviation for dwell time selection are: 34.56389169613333 39.505970315291336\n",
      "Average error rate and standard deviation for multi-key selection are: 32.96715175792857 19.432188494849644\n"
     ]
    }
   ],
   "source": [
    "print('Average error rate and standard deviation for dwell time selection are:', df_ToAnalyze.error_rate[df_ToAnalyze['typing_mechanism']==0].mean(), df_ToAnalyze.error_rate[df_ToAnalyze['typing_mechanism']==0].std())\n",
    "print('Average error rate and standard deviation for multi-key selection are:', df_ToAnalyze.error_rate[df_ToAnalyze['typing_mechanism']==1].mean(), df_ToAnalyze.error_rate[df_ToAnalyze['typing_mechanism']==1].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots of error rate wrt independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "# Age\n",
    "ax = fig.add_subplot(131)\n",
    "df_ToAnalyze.boxplot(column = 'error_rate', by='age_bins', ax = ax, grid = False)\n",
    "plt.xticks([1, 2], ['Less than 30', 'Greater than 30'])\n",
    "#plt.yticks(np.arange(0, float(df.typing_speed.max())+2, step = 2))\n",
    "plt.ylabel('Typing speed [in wpm]')\n",
    "\n",
    "# Gender\n",
    "ax = fig.add_subplot(132)\n",
    "df_ToAnalyze.boxplot(column = 'error_rate', by='gender', ax = ax, grid = False)\n",
    "plt.xticks([1, 2], ['Male', 'Female'])\n",
    "#plt.yticks(np.arange(0, float(df.typing_speed.max())+2, step = 2))\n",
    "plt.ylabel('Typing speed [in wpm]')\n",
    "\n",
    "# Typing mechanism\n",
    "ax = fig.add_subplot(133)\n",
    "df_ToAnalyze.boxplot(column = 'error_rate', by='typing_mechanism', ax = ax, grid = False)\n",
    "plt.xticks([1, 2], ['Dwell time', 'MultiKey selection'])\n",
    "#plt.yticks(np.arange(0, float(df.typing_speed.max())+2, step = 2))\n",
    "plt.ylabel('Typing speed [in wpm]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error rate statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal result for age: H-statistic= 5.973333333333329 , pvalue= 0.014523801235818043\n",
      "Kruskal result for gender: H-statistic= 0.27692307692306883 , pvalue= 0.5987250696528521\n",
      "Kruskal result for typing mechanism: H-statistic= 0.8399999999999892 , pvalue= 0.35939677082052246\n"
     ]
    }
   ],
   "source": [
    "# Age\n",
    "a = df_ToAnalyze.error_rate[df_ToAnalyze['age_bins']==0]\n",
    "b = df_ToAnalyze.error_rate[df_ToAnalyze['age_bins']==1]\n",
    "(h, p) = scipy.stats.kruskal(a.values, b.values)\n",
    "print('Kruskal result for age: H-statistic=', h, ', pvalue=', p)\n",
    "\n",
    "# Typing mechanism\n",
    "a = df_ToAnalyze.error_rate[df_ToAnalyze['gender']==0]\n",
    "b = df_ToAnalyze.error_rate[df_ToAnalyze['gender']==1]\n",
    "(h, p) = scipy.stats.kruskal(a.values, b.values)\n",
    "print('Kruskal result for gender: H-statistic=', h, ', pvalue=', p)\n",
    "\n",
    "# Typing mechanism\n",
    "a = df_ToAnalyze.error_rate[df_ToAnalyze['typing_mechanism']==0]\n",
    "b = df_ToAnalyze.error_rate[df_ToAnalyze['typing_mechanism']==1]\n",
    "(h, p) = scipy.stats.kruskal(a.values, b.values)\n",
    "print('Kruskal result for typing mechanism: H-statistic=', h, ', pvalue=', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.hstack(df_ToAnalyze.typing_speed)\n",
    "plt.hist(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of error rate and typing speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plt.plot(df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==0], df_ToAnalyze.error_rate[df_ToAnalyze.typing_mechanism==0], 'bo', label = 'dwell time')\n",
    "#plt.plot(df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==1], df_ToAnalyze.error_rate[df_ToAnalyze.typing_mechanism==1], 'ro', label = 'multi-key selection')\n",
    "n = df_ToAnalyze.subject_name.values \n",
    "plt.plot(df_ToAnalyze.typing_speed, df_ToAnalyze.error_rate, 'o')\n",
    "\n",
    "\n",
    "plt.xlabel('Typing speed [in wpm]')\n",
    "plt.ylabel('Error rate [in %]')\n",
    "plt.legend()\n",
    "for i, txt in enumerate(n):\n",
    "    plt.annotate(txt, (df_ToAnalyze.typing_speed.values[i], df_ToAnalyze.error_rate.values[i]))\n",
    "plt.grid('on')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total error rate = character error rate + word error rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>error_rate_total_normalLevenshtein</td> <th>  R-squared:         </th> <td>   0.627</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                            <td>OLS</td>                <th>  Adj. R-squared:    </th> <td>   0.584</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                      <td>Least Squares</td>           <th>  F-statistic:       </th> <td>   14.57</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>                      <td>Sat, 13 Apr 2019</td>          <th>  Prob (F-statistic):</th> <td>9.16e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                          <td>17:58:00</td>              <th>  Log-Likelihood:    </th> <td> -137.76</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>               <td>    29</td>               <th>  AIC:               </th> <td>   281.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>                   <td>    26</td>               <th>  BIC:               </th> <td>   285.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>                       <td>     3</td>               <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>               <td>nonrobust</td>             <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age_bins</th>         <td>   42.4376</td> <td>   10.214</td> <td>    4.155</td> <td> 0.000</td> <td>   21.442</td> <td>   63.433</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>typing_mechanism</th> <td>   15.9217</td> <td>    8.855</td> <td>    1.798</td> <td> 0.084</td> <td>   -2.280</td> <td>   34.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>           <td>    1.4998</td> <td>   10.311</td> <td>    0.145</td> <td> 0.885</td> <td>  -19.695</td> <td>   22.695</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 8.240</td> <th>  Durbin-Watson:     </th> <td>   1.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.016</td> <th>  Jarque-Bera (JB):  </th> <td>   6.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.952</td> <th>  Prob(JB):          </th> <td>  0.0384</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.332</td> <th>  Cond. No.          </th> <td>    2.20</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                    OLS Regression Results                                    \n",
       "==============================================================================================\n",
       "Dep. Variable:     error_rate_total_normalLevenshtein   R-squared:                       0.627\n",
       "Model:                                            OLS   Adj. R-squared:                  0.584\n",
       "Method:                                 Least Squares   F-statistic:                     14.57\n",
       "Date:                                Sat, 13 Apr 2019   Prob (F-statistic):           9.16e-06\n",
       "Time:                                        17:58:00   Log-Likelihood:                -137.76\n",
       "No. Observations:                                  29   AIC:                             281.5\n",
       "Df Residuals:                                      26   BIC:                             285.6\n",
       "Df Model:                                           3                                         \n",
       "Covariance Type:                            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "age_bins            42.4376     10.214      4.155      0.000      21.442      63.433\n",
       "typing_mechanism    15.9217      8.855      1.798      0.084      -2.280      34.124\n",
       "gender               1.4998     10.311      0.145      0.885     -19.695      22.695\n",
       "==============================================================================\n",
       "Omnibus:                        8.240   Durbin-Watson:                   1.881\n",
       "Prob(Omnibus):                  0.016   Jarque-Bera (JB):                6.522\n",
       "Skew:                           0.952   Prob(JB):                       0.0384\n",
       "Kurtosis:                       4.332   Cond. No.                         2.20\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OLS regression to check residuals of data for anova testing \n",
    "X = df_ToAnalyze[['age_bins', 'typing_mechanism', 'gender']] # independent variable\n",
    "y_errorRate_total = df_ToAnalyze.error_rate_total_normalLevenshtein # dependent variable\n",
    "\n",
    "model_errorRate_total = sm.OLS(y_errorRate_total,X)\n",
    "model_fit_errorRate_total = model_errorRate_total.fit()\n",
    "\n",
    "p_errorRate_total = model_fit_errorRate_total.params\n",
    "\n",
    "# Plot the residuals of each\n",
    "residuals_errorRate_total = model_fit_errorRate_total.resid # residuals\n",
    "fig = sm.qqplot(residuals_errorRate_total)\n",
    "plt.show()\n",
    "\n",
    "model_fit_errorRate_total.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments: The residual plot is slightly skewed, as skewness value is not close to 0, and value of kurtosis is high --> anova cannot be performed But Prob(F-statistic) is low enough to reject null hypothesis Still, anova is not performed due to the skewed residual plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equivalence testing of error rate for typing mechansims\n",
    "Here, the null hypothesis is that error rates for both is not equivalent For a practical equivalence value of 'del', Ho: |mu1 - mu2| > del and Ha: |mu1 - mu2| < del So, to reject the null hypothesis, both should be rejected: mu1 - mu2 > del and mu1 - mu2 < -del or in terms of two-one sided test : ((y1m - y2m) + del)/sigma(1/n1 + 1/n2) > z(1-alpha) and ((y1m - y2m) - del)/sigma(1/n1 + 1/n2) < -z(1-alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.7891756726892\n"
     ]
    }
   ],
   "source": [
    "sd_errorRate_total_DT = df_ToAnalyze.error_rate_total[df_ToAnalyze['typing_mechanism']==0].std()\n",
    "sd_errorRate_total_MS = df_ToAnalyze.error_rate_total[df_ToAnalyze['typing_mechanism']==1].std()\n",
    "\n",
    "n_DT = df_ToAnalyze.typing_mechanism[df_ToAnalyze['typing_mechanism'] == 0].count()\n",
    "n_MS = df_ToAnalyze.typing_mechanism[df_ToAnalyze['typing_mechanism'] == 1].count()\n",
    "\n",
    "mean_errorRate_total_DT = df_ToAnalyze.error_rate_total[df_ToAnalyze['typing_mechanism']==0].mean()\n",
    "mean_errorRate_total_MS = df_ToAnalyze.error_rate_total[df_ToAnalyze['typing_mechanism']==1].mean()\n",
    "\n",
    "sd = math.sqrt(((n_DT - 1)*(sd_errorRate_total_DT)**2 + (n_MS - 1)*(sd_errorRate_total_MS)**2)/(n_DT + n_MS - 2))\n",
    "\n",
    "print(sd*0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tLower: 1.3588927052975692 ,tUpper: -0.5096787478436346 with 28  degrees of freedom\n"
     ]
    }
   ],
   "source": [
    "delError = 10 # As per Lakens 2017 Equivalence testing, del = d*sd, where d is Cohen's d = !!0.3!! - 0.3 is not correct: needs to be the effect size. For the given data, sd = ~36\n",
    "\n",
    "tL = (mean_errorRate_total_DT - mean_errorRate_total_MS - (-delError))/(math.sqrt(((sd_errorRate_total_DT**2)/n_DT) + (sd_errorRate_total_MS**2)/n_MS))\n",
    "tU = (mean_errorRate_total_DT - mean_errorRate_total_MS - (delError))/(math.sqrt(((sd_errorRate_total_DT**2)/n_DT) + (sd_errorRate_total_MS**2)/n_MS))\n",
    "\n",
    "#df = ((((sd_errorRate_total_DT**2)/(n_DT)) + ((sd_errorRate_total_MS**2)/(n_MS)))**2)/(((sd_errorRate_total_DT/n_DT)**2)/(n_DT-1) + ((sd_errorRate_total_MS/n_MS)**2)/(n_MS-1))\n",
    "\n",
    "df = (n_DT + n_MS - 1)\n",
    "\n",
    "print('tLower:', tL, ',tUpper:', tU,'with', df, ' degrees of freedom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#For t(28, 0.05) = 1.701 To reject null hypothesis, both of the following should be followed - tU < -t(28, 0.05) AND tL > t(28, 0.05) As both are not, null hypothesis cannot be rejected Therefore, both cannot be equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error rate and standard deviation for dwell time selection are: 42.036046376880286 35.28910761283365\n",
      "Average error rate and standard deviation for multi-key selection are: 37.49132342274147 21.013525087932788\n",
      "Average error rate and standard deviation are: 39.84204219212362 28.862017687188693\n",
      "Range of error rate and standard deviation is:  2.535974067046173 to 108.58974358974358\n",
      "Average error rate and standard deviation (only normal levenshtein distance) are: 37.52299452119481 26.745019745527298\n",
      "Range of error rate and standard deviation (only normal levenshtein distance) is:  2.0457779886148013 to 95.70512820512822\n"
     ]
    }
   ],
   "source": [
    "print('Average error rate and standard deviation for dwell time selection are:', df_ToAnalyze.error_rate_total[df_ToAnalyze['typing_mechanism']==0].mean(), df_ToAnalyze.error_rate_total[df_ToAnalyze['typing_mechanism']==0].std())\n",
    "print('Average error rate and standard deviation for multi-key selection are:', df_ToAnalyze.error_rate_total[df_ToAnalyze['typing_mechanism']==1].mean(), df_ToAnalyze.error_rate_total[df_ToAnalyze['typing_mechanism']==1].std())\n",
    "print('Average error rate and standard deviation are:', df_ToAnalyze.error_rate_total.mean(), df_ToAnalyze.error_rate_total.std())\n",
    "\n",
    "print('Range of error rate and standard deviation is: ', df_ToAnalyze.error_rate_total.min(), 'to',  df_ToAnalyze.error_rate_total.max())\n",
    "\n",
    "print('Average error rate and standard deviation (only normal levenshtein distance) are:', df_ToAnalyze.error_rate_total_normalLevenshtein.mean(), df_ToAnalyze.error_rate_total_normalLevenshtein.std())\n",
    "\n",
    "print('Range of error rate and standard deviation (only normal levenshtein distance) is: ', df_ToAnalyze.error_rate_total_normalLevenshtein.min(), 'to',  df_ToAnalyze.error_rate_total_normalLevenshtein.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots of error rate wrt independent variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Error rate [in %]')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "# Age\n",
    "ax = fig.add_subplot(131)\n",
    "df_ToAnalyze.boxplot(column = 'error_rate_total', by='age_bins', ax = ax, grid = False)\n",
    "plt.xticks([1, 2], ['Less than 30', 'Greater than 30'])\n",
    "#plt.yticks(np.arange(0, float(df.typing_speed.max())+2, step = 2))\n",
    "plt.ylabel('Error rate [in %]')\n",
    "\n",
    "# Gender\n",
    "ax = fig.add_subplot(132)\n",
    "df_ToAnalyze.boxplot(column = 'error_rate_total', by='gender', ax = ax, grid = False)\n",
    "plt.xticks([1, 2], ['Male', 'Female'])\n",
    "#plt.yticks(np.arange(0, float(df.typing_speed.max())+2, step = 2))\n",
    "plt.ylabel('Error rate [in %]')\n",
    "\n",
    "# Typing mechanism\n",
    "ax = fig.add_subplot(133)\n",
    "df_ToAnalyze.boxplot(column = 'error_rate_total', by='typing_mechanism', ax = ax, grid = False)\n",
    "plt.xticks([1, 2], ['Dwell time', 'MultiKey selection'])\n",
    "#plt.yticks(np.arange(0, float(df.typing_speed.max())+2, step = 2))\n",
    "plt.ylabel('Error rate [in %]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error rate statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kruskal result for age: H-statistic= 7.560000000000002 , pvalue= 0.005967799197956402\n",
      "Kruskal result for gender: H-statistic= 0.06923076923077076 , pvalue= 0.7924600886080329\n",
      "Kruskal result for typing mechanism: H-statistic= 0.00761904761904475 , pvalue= 0.9304432630047605\n"
     ]
    }
   ],
   "source": [
    "# Age\n",
    "a = df_ToAnalyze.error_rate_total[df_ToAnalyze['age_bins']==0]\n",
    "b = df_ToAnalyze.error_rate_total[df_ToAnalyze['age_bins']==1]\n",
    "(h, p) = scipy.stats.kruskal(a.values, b.values)\n",
    "print('Kruskal result for age: H-statistic=', h, ', pvalue=', p)\n",
    "\n",
    "# Typing mechanism\n",
    "a = df_ToAnalyze.error_rate_total[df_ToAnalyze['gender']==0]\n",
    "b = df_ToAnalyze.error_rate_total[df_ToAnalyze['gender']==1]\n",
    "(h, p) = scipy.stats.kruskal(a.values, b.values)\n",
    "print('Kruskal result for gender: H-statistic=', h, ', pvalue=', p)\n",
    "\n",
    "# Typing mechanism\n",
    "a = df_ToAnalyze.error_rate_total[df_ToAnalyze['typing_mechanism']==0]\n",
    "b = df_ToAnalyze.error_rate_total[df_ToAnalyze['typing_mechanism']==1]\n",
    "(h, p) = scipy.stats.kruskal(a.values, b.values)\n",
    "print('Kruskal result for typing mechanism: H-statistic=', h, ', pvalue=', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Plot for typing speed and error rate\n",
    "\n",
    "#plt.plot(df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==0], df_ToAnalyze.error_rate[df_ToAnalyze.typing_mechanism==0], 'bo', label = 'dwell time')\n",
    "#plt.plot(df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==1], df_ToAnalyze.error_rate[df_ToAnalyze.typing_mechanism==1], 'ro', label = 'multi-key selection')\n",
    "n = df_ToAnalyze.subject_name.values \n",
    "plt.plot(df_ToAnalyze.typing_speed, df_ToAnalyze.error_rate_total, 'o')\n",
    "\n",
    "\n",
    "plt.xlabel('Typing speed [in wpm]')\n",
    "plt.ylabel('Error rate [in %]')\n",
    "plt.legend()\n",
    "for i, txt in enumerate(n):\n",
    "    plt.annotate(txt, (df_ToAnalyze.typing_speed.values[i], df_ToAnalyze.error_rate_total.values[i]))\n",
    "plt.grid('on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box chart of typing speed and total error rate\n",
    "label_fontSize = 60\n",
    "others_fontSize = 54\n",
    "\n",
    "fig = plt.figure(figsize=(24,24))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "#onlyPosErr_t\n",
    "\n",
    "ax1.bar(1, df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==0].mean(), yerr = [[0], [df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==0].std()]], label = 'Dwell time')\n",
    "ax1.bar(2, df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==1].mean(), yerr = [[0], [df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==1].std()]], label = 'Multi-key selection')\n",
    "ax1.set_ylabel('Typing speed [in wpm]', fontsize = label_fontSize)\n",
    "ax1.set_yticks(np.arange(0, 11, 2))\n",
    "ax1.legend(bbox_to_anchor=(1, 0.848), loc = 'lower right', fontsize = label_fontSize)\n",
    "ax1.tick_params(axis='both', which='major', labelsize= others_fontSize)\n",
    "#ax1.set_xticks([1.5])\n",
    "#ax1.set_xticklabels(['Typing speed'])\n",
    "\n",
    "ax2.bar(5, df_ToAnalyze.error_rate_total_normalLevenshtein[df_ToAnalyze.typing_mechanism==0].mean(), yerr = [[0], [df_ToAnalyze.error_rate_total_normalLevenshtein[df_ToAnalyze.typing_mechanism==0].std()]])\n",
    "ax2.bar(6, df_ToAnalyze.error_rate_total_normalLevenshtein[df_ToAnalyze.typing_mechanism==1].mean(), yerr = [[0], [df_ToAnalyze.error_rate_total_normalLevenshtein[df_ToAnalyze.typing_mechanism==1].std()]])\n",
    "ax2.set_ylabel('Error rate [in %]', fontsize = label_fontSize)\n",
    "plt.xticks([], [])\n",
    "#ax1.grid(color='b', alpha = 0.1, linestyle='-', linewidth=2)\n",
    "#ax2.grid(color='b', alpha = 0.1, linestyle='-', linewidth=1.7)\n",
    "ax2.set_ylim([0, 100])\n",
    "ax2.tick_params(axis='both', which='major', labelsize=others_fontSize)\n",
    "plt.tight_layout()\n",
    "fig.savefig('typingSpeed_errorRateTotalNormalLevenshtein_DTandMS.png', dpi = 300, bbox_to_anchor = (0.95, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box chart of typing speed and error rate\n",
    "label_fontSize = 98\n",
    "others_fontSize = 90\n",
    "\n",
    "fig = plt.figure(figsize=(30,30))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "#onlyPosErr_t\n",
    "x1_TypingSpeed = 1\n",
    "x2_TypingSpeed = 2\n",
    "ax1.bar(x1_TypingSpeed, df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==0].mean(), yerr = [[0], [df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==0].std()]], label = 'Dwell time')\n",
    "ax1.errorbar(x1_TypingSpeed, df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==0].mean(), yerr = [[0], [df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==0].std()]], elinewidth=3, ecolor='k')\n",
    "ax1.bar(x2_TypingSpeed, df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==1].mean(), yerr = [[0], [df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==1].std()]], label = 'Multi-key selection')\n",
    "ax1.errorbar(x2_TypingSpeed, df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==1].mean(), yerr = [[0], [df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==1].std()]], elinewidth=3, ecolor='k')\n",
    "ax1.set_ylabel('Typing speed [in wpm]', fontsize = label_fontSize)\n",
    "ax1.set_yticks(np.arange(0, 11, 2))\n",
    "#ax1.legend(bbox_to_anchor=(1, 0.79), loc = 'lower right', fontsize = others_fontSize, frameon=False)\n",
    "ax1.legend(bbox_to_anchor=(0.27, 0.802), loc = 'lower left', fontsize = others_fontSize, frameon=False)\n",
    "ax1.tick_params(axis='both', which='major', labelsize= others_fontSize)\n",
    "ax1.set_xticks([1.5])\n",
    "ax1.set_xticklabels(['Typing speed'])\n",
    "ax1.set_ylim([0, 10.4])\n",
    "\n",
    "# annotate with significance level\n",
    "maxTypingSpeed = 9.65\n",
    "y_TypingSpeed, h, col = maxTypingSpeed, 0.2, 'k'\n",
    "ax1.plot([x1_TypingSpeed, x1_TypingSpeed, x2_TypingSpeed, x2_TypingSpeed], [y_TypingSpeed, y_TypingSpeed+h, y_TypingSpeed+h, y_TypingSpeed], lw=2, c=col)\n",
    "#plt.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c=col)\n",
    "ax1.text((x1_TypingSpeed+x2_TypingSpeed)*.5, y_TypingSpeed+h+0.02, \"p<0.001\", ha='center', va='bottom', color=col, fontsize = others_fontSize)\n",
    "\n",
    "\n",
    "x1_ErrorRate = 5\n",
    "x2_ErrorRate = 6\n",
    "ax2.bar(x1_ErrorRate, df_ToAnalyze.error_rate_total_normalLevenshtein[df_ToAnalyze.typing_mechanism==0].mean())\n",
    "ax2.errorbar(x1_ErrorRate, df_ToAnalyze.error_rate_total_normalLevenshtein[df_ToAnalyze.typing_mechanism==0].mean(), yerr = [[0], [df_ToAnalyze.error_rate_total_normalLevenshtein[df_ToAnalyze.typing_mechanism==0].std()]], elinewidth=3, ecolor='k')\n",
    "ax2.bar(x2_ErrorRate, df_ToAnalyze.error_rate_total_normalLevenshtein[df_ToAnalyze.typing_mechanism==1].mean())\n",
    "ax2.errorbar(x2_ErrorRate, df_ToAnalyze.error_rate_total_normalLevenshtein[df_ToAnalyze.typing_mechanism==1].mean(), yerr = [[0], [df_ToAnalyze.error_rate_total_normalLevenshtein[df_ToAnalyze.typing_mechanism==1].std()]], linewidth = 3, ecolor='k')\n",
    "ax2.set_ylabel('Error rate [in %]', fontsize = label_fontSize)\n",
    "#plt.xticks([], [])\n",
    "#ax1.grid(color='b', alpha = 0.1, linestyle='-', linewidth=2)\n",
    "#ax2.grid(color='b', alpha = 0.1, linestyle='-', linewidth=1.7)\n",
    "ax2.set_ylim([0, 104])\n",
    "ax2.tick_params(axis='both', which='major', labelsize=others_fontSize)\n",
    "ax2.set_xticks([1.5, 5.5])\n",
    "ax2.set_xticklabels(['Typing speed', 'Error rate'])\n",
    "ax2.spines['bottom'].set_linewidth(4)\n",
    "ax2.spines['left'].set_linewidth(4)\n",
    "ax2.spines['right'].set_linewidth(4)\n",
    "ax2.spines['top'].set_linewidth(4)\n",
    "\n",
    "# annotate with significance level\n",
    "maxErrorRate = 72\n",
    "y_ErrorRate, h, col = maxErrorRate, 2, 'k'\n",
    "ax2.plot([x1_ErrorRate, x1_ErrorRate, x2_ErrorRate, x2_ErrorRate], [y_ErrorRate+1.5*h, y_ErrorRate+2.5*h, y_ErrorRate+2.5*h, y_ErrorRate+1.5*h], lw=2, c=col)\n",
    "#plt.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c=col)\n",
    "ax2.text((x1_ErrorRate+x2_ErrorRate)*.5, y_ErrorRate+2.5*h, \"n.s.\", ha='center', va='bottom', color=col, fontsize = others_fontSize)\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig('typingSpeed_errorRateTotalNormalLevenshteinDTandMS.png', dpi = 300, bbox_to_anchor = (0.95, 0.1))\n",
    "\n",
    "\n",
    "#plt.show()\n",
    "#plt.ioff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between typing speed and error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Error rate [in %]')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = str(df_ToAnalyze['typing_speed'].corr(df_ToAnalyze['error_rate_total']))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "a = df_ToAnalyze.typing_speed.sort_values()\n",
    "\n",
    "i = 0\n",
    "for ind in a.keys():\n",
    "    i = i + 1\n",
    "    ax1.plot(i, df_ToAnalyze['typing_speed'].loc[ind], 'bo')\n",
    "    ax2.plot(i, df_ToAnalyze['error_rate_total'].loc[ind], 'ro')\n",
    "    \n",
    "ax1.set_title('Correlation between typing speed and error rate is: %s' %c)\n",
    "ax1.set_ylabel('Typing speed [in wpm]', color = 'b')\n",
    "ax1.set_yticks(np.arange(0, 15, 2))\n",
    "ax2.set_ylabel('Error rate [in %]', color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# box chart of typing speed and error rate\n",
    "label_fontSize = 60\n",
    "others_fontSize = 54\n",
    "\n",
    "fig = plt.figure(figsize=(24,24))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "#onlyPosErr_t\n",
    "\n",
    "ax1.bar(1, df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==0].mean(), yerr = [[0], [df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==0].std()]], label = 'Dwell time')\n",
    "ax1.bar(2, df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==1].mean(), yerr = [[0], [df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==1].std()]], label = 'Multi-key selection')\n",
    "ax1.set_ylabel('Typing speed [in wpm]', fontsize = label_fontSize)\n",
    "ax1.set_yticks(np.arange(0, 11, 2))\n",
    "ax1.legend(bbox_to_anchor=(1, 0.848), loc = 'lower right', fontsize = label_fontSize)\n",
    "ax1.tick_params(axis='both', which='major', labelsize= others_fontSize)\n",
    "#ax1.set_xticks([1.5])\n",
    "#ax1.set_xticklabels(['Typing speed'])\n",
    "\n",
    "ax2.bar(5, df_ToAnalyze.error_rate[df_ToAnalyze.typing_mechanism==0].mean(), yerr = [[0], [df_ToAnalyze.error_rate[df_ToAnalyze.typing_mechanism==0].std()]])\n",
    "ax2.bar(6, df_ToAnalyze.error_rate[df_ToAnalyze.typing_mechanism==1].mean(), yerr = [[0], [df_ToAnalyze.error_rate[df_ToAnalyze.typing_mechanism==1].std()]])\n",
    "ax2.set_ylabel('Error rate [in %]', fontsize = label_fontSize)\n",
    "plt.xticks([], [])\n",
    "#ax1.grid(color='b', alpha = 0.1, linestyle='-', linewidth=2)\n",
    "#ax2.grid(color='b', alpha = 0.1, linestyle='-', linewidth=1.7)\n",
    "ax2.set_ylim([0, 100])\n",
    "ax2.tick_params(axis='both', which='major', labelsize=others_fontSize)\n",
    "plt.tight_layout()\n",
    "fig.savefig('typingSpeed_errorRate_DTandMS.png', dpi = 300, bbox_to_anchor = (0.95, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box chart of typing speed and error rate\n",
    "label_fontSize = 98\n",
    "others_fontSize = 90\n",
    "\n",
    "fig = plt.figure(figsize=(30,30))\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "#onlyPosErr_t\n",
    "x1_TypingSpeed = 1\n",
    "x2_TypingSpeed = 2\n",
    "ax1.bar(x1_TypingSpeed, df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==0].mean(), yerr = [[0], [df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==0].std()]], label = 'Dwell time')\n",
    "ax1.errorbar(x1_TypingSpeed, df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==0].mean(), yerr = [[0], [df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==0].std()]], elinewidth=3, ecolor='k')\n",
    "ax1.bar(x2_TypingSpeed, df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==1].mean(), yerr = [[0], [df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==1].std()]], label = 'Multi-key selection')\n",
    "ax1.errorbar(x2_TypingSpeed, df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==1].mean(), yerr = [[0], [df_ToAnalyze.typing_speed[df_ToAnalyze.typing_mechanism==1].std()]], elinewidth=3, ecolor='k')\n",
    "ax1.set_ylabel('Typing speed [in wpm]', fontsize = label_fontSize)\n",
    "ax1.set_yticks(np.arange(0, 11, 2))\n",
    "#ax1.legend(bbox_to_anchor=(1, 0.79), loc = 'lower right', fontsize = others_fontSize, frameon=False)\n",
    "ax1.legend(bbox_to_anchor=(0.27, 0.802), loc = 'lower left', fontsize = others_fontSize, frameon=False)\n",
    "ax1.tick_params(axis='both', which='major', labelsize= others_fontSize)\n",
    "ax1.set_xticks([1.5])\n",
    "ax1.set_xticklabels(['Typing speed'])\n",
    "ax1.set_ylim([0, 10.4])\n",
    "\n",
    "# annotate with significance level\n",
    "maxTypingSpeed = 9.65\n",
    "y_TypingSpeed, h, col = maxTypingSpeed, 0.2, 'k'\n",
    "ax1.plot([x1_TypingSpeed, x1_TypingSpeed, x2_TypingSpeed, x2_TypingSpeed], [y_TypingSpeed, y_TypingSpeed+h, y_TypingSpeed+h, y_TypingSpeed], lw=2, c=col)\n",
    "#plt.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c=col)\n",
    "ax1.text((x1_TypingSpeed+x2_TypingSpeed)*.5, y_TypingSpeed+h+0.02, \"p<0.001\", ha='center', va='bottom', color=col, fontsize = others_fontSize)\n",
    "\n",
    "\n",
    "x1_ErrorRate = 5\n",
    "x2_ErrorRate = 6\n",
    "ax2.bar(x1_ErrorRate, df_ToAnalyze.error_rate[df_ToAnalyze.typing_mechanism==0].mean())\n",
    "ax2.errorbar(x1_ErrorRate, df_ToAnalyze.error_rate[df_ToAnalyze.typing_mechanism==0].mean(), yerr = [[0], [df_ToAnalyze.error_rate[df_ToAnalyze.typing_mechanism==0].std()]], elinewidth=3, ecolor='k')\n",
    "ax2.bar(x2_ErrorRate, df_ToAnalyze.error_rate[df_ToAnalyze.typing_mechanism==1].mean())\n",
    "ax2.errorbar(x2_ErrorRate, df_ToAnalyze.error_rate[df_ToAnalyze.typing_mechanism==1].mean(), yerr = [[0], [df_ToAnalyze.error_rate[df_ToAnalyze.typing_mechanism==1].std()]], linewidth = 3, ecolor='k')\n",
    "ax2.set_ylabel('Error rate [in %]', fontsize = label_fontSize)\n",
    "#plt.xticks([], [])\n",
    "#ax1.grid(color='b', alpha = 0.1, linestyle='-', linewidth=2)\n",
    "#ax2.grid(color='b', alpha = 0.1, linestyle='-', linewidth=1.7)\n",
    "ax2.set_ylim([0, 104])\n",
    "ax2.tick_params(axis='both', which='major', labelsize=others_fontSize)\n",
    "ax2.set_xticks([1.5, 5.5])\n",
    "ax2.set_xticklabels(['Typing speed', 'Error rate'])\n",
    "ax2.spines['bottom'].set_linewidth(4)\n",
    "ax2.spines['left'].set_linewidth(4)\n",
    "ax2.spines['right'].set_linewidth(4)\n",
    "ax2.spines['top'].set_linewidth(4)\n",
    "\n",
    "# annotate with significance level\n",
    "maxErrorRate = 76\n",
    "y_ErrorRate, h, col = maxErrorRate, 2, 'k'\n",
    "ax2.plot([x1_ErrorRate, x1_ErrorRate, x2_ErrorRate, x2_ErrorRate], [y_ErrorRate, y_ErrorRate+h, y_ErrorRate+h, y_ErrorRate], lw=2, c=col)\n",
    "#plt.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c=col)\n",
    "ax2.text((x1_ErrorRate+x2_ErrorRate)*.5, y_ErrorRate+h, \"n.s.\", ha='center', va='bottom', color=col, fontsize = others_fontSize)\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig('typingSpeed_errorRate_DTandMS.png', dpi = 300, bbox_to_anchor = (0.95, 0.1))\n",
    "\n",
    "\n",
    "#plt.show()\n",
    "#plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "fig = pylab.figure()\n",
    "#figlegend = pylab.figure(figsize=(3,2))\n",
    "ax = fig.add_subplot(111)\n",
    "lines = ax.plot(range(10), pylab.randn(10), range(10), pylab.randn(10))\n",
    "figlegend.legend(lines, ('Dwell time', 'Multi-key selection'), 'center', prop={'size': 6})\n",
    "#fig.show()\n",
    "figlegend.show()\n",
    "figlegend.savefig('legend.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Typing Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typing Mechanism and other Independent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pie charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "nSubj = len(df_ToAnalyze)\n",
    "\n",
    "# Overall\n",
    "# Gender\n",
    "ax = fig.add_subplot(131)\n",
    "df_ToAnalyze.gender.value_counts(sort = False).plot.pie(ax = ax, labels = ['Male', 'Female'], autopct='%1.1f%%')\n",
    "ax.set_title('Gender distribution \\n Total count = ' + str(nSubj))\n",
    "\n",
    "# Age\n",
    "ax = fig.add_subplot(132)\n",
    "df_ToAnalyze.age_bins.value_counts(sort = False).plot.pie(ax = ax, labels = ['Less than 30', 'Greater than 30'], autopct='%1.1f%%')\n",
    "ax.set_title('Age distribution \\n Total count = ' + str(nSubj))\n",
    "\n",
    "# Typing mechanism\n",
    "ax = fig.add_subplot(133)\n",
    "df_ToAnalyze.typing_mechanism.value_counts(sort = False).plot.pie(ax = ax, labels = ['Dwell time', 'MultiKey selection'], autopct='%1.1f%%')\n",
    "ax.set_title('Typing mechanism distribution \\n Total count = ' + str(nSubj))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "# DWELL TIME\n",
    "# Gender and Typing mechanism\n",
    "ax = fig.add_subplot(221)\n",
    "df_ToAnalyze.gender[df['typing_mechanism']==0].value_counts(sort = False).plot.pie(ax = ax, labels = ['Male', 'Female'], autopct='%1.1f%%')\n",
    "ax.set_title('Dwell time')\n",
    "\n",
    "# Age and Typing mechanism\n",
    "ax = fig.add_subplot(223)\n",
    "df_ToAnalyze.age_bins[df['typing_mechanism']==0].value_counts(sort = False).plot.pie(ax = ax, labels = ['Less than 30', 'Greater than 30'], autopct='%1.1f%%')\n",
    "\n",
    "# MULTIKEY SELECTION\n",
    "# Gender and Typing mechanism\n",
    "ax = fig.add_subplot(222)\n",
    "df_ToAnalyze.gender[df['typing_mechanism']==1].value_counts(sort = False).plot.pie(ax = ax, labels = ['Male', 'Female'], autopct='%1.1f%%')\n",
    "ax.set_title('MultiKey Selection')\n",
    "\n",
    "# Age and Typing mechanism\n",
    "ax = fig.add_subplot(224)\n",
    "df_ToAnalyze.age_bins[df['typing_mechanism']==1].value_counts(sort = False).plot.pie(ax = ax, labels = ['Less than 30', 'Greater than 30'], autopct='%1.1f%%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum number in the pie charts is 5 (Female, MultiKey Selection). This is the number of subjects that will be choosen \n",
    "randomly from every category and the statistical tests will be performed again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attended But Not Selected Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plots\n",
    "\n",
    "figBoxPlot = plt.figure()\n",
    "\n",
    "# Typing mechanism\n",
    "ax = figBoxPlot.add_subplot(111)\n",
    "df_ToAnalyze.boxplot( column = 'attended_but_not_selected_rate_time', by='typing_mechanism', ax = ax, grid = False)\n",
    "plt.xticks([1, 2], ['Dwell Time', 'Multi-key Selection'])\n",
    "plt.ylabel('Attended but not selected ratio of time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalence testing on ansr\n",
    "\n",
    "sd_ansr_DT = df_ToAnalyze.attended_but_not_selected_rate_time[df_ToAnalyze['typing_mechanism']==0].std()\n",
    "sd_ansr_MS = df_ToAnalyze.attended_but_not_selected_rate_time[df_ToAnalyze['typing_mechanism']==1].std()\n",
    "\n",
    "mean_ansr_DT = df_ToAnalyze.attended_but_not_selected_rate_time[df_ToAnalyze['typing_mechanism']==0].mean()\n",
    "mean_ansr_MS = df_ToAnalyze.attended_but_not_selected_rate_time[df_ToAnalyze['typing_mechanism']==1].mean()\n",
    "\n",
    "n_DT = df_ToAnalyze.typing_mechanism[df_ToAnalyze['typing_mechanism'] == 0].count()\n",
    "n_MS = df_ToAnalyze.typing_mechanism[df_ToAnalyze['typing_mechanism'] == 1].count()\n",
    "\n",
    "sd = math.sqrt(((n_DT - 1)*(sd_ansr_DT)**2 + (n_MS - 1)*(sd_ansr_MS)**2)/(n_DT + n_MS - 2))\n",
    "\n",
    "print(sd*0.3)\n",
    "\n",
    "print(mean_ansr_DT, sd_ansr_DT)\n",
    "print(mean_ansr_MS, sd_ansr_MS)\n",
    "\n",
    "delError = 0.005 # As per Lakens 2017 Equivalence testing, del = d*sd, where d is Cohen's d = 0.3. For the given data, sd = ~0.006\n",
    "\n",
    "tL = (mean_ansr_DT - mean_ansr_MS - (-delError))/(math.sqrt(((sd_ansr_DT**2)/n_DT) + (sd_ansr_MS**2)/n_MS))\n",
    "tU = (mean_ansr_DT - mean_ansr_MS - (delError))/(math.sqrt(((sd_ansr_DT**2)/n_DT) + (sd_ansr_MS**2)/n_MS))\n",
    "\n",
    "#df = ((((sd_errorRate_DT**2)/(n_DT)) + ((sd_errorRate_MS**2)/(n_MS)))**2)/(((sd_errorRate_DT/n_DT)**2)/(n_DT-1) + ((sd_errorRate_MS/n_MS)**2)/(n_MS-1))\n",
    "\n",
    "df = (n_DT + n_MS - 1)\n",
    "\n",
    "print('tLower:', tL, ',tUpper:', tU,'with', df, ' degrees of freedom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For t(28, 0.05) = 1.701 To reject null hypothesis, both of the following should be followed : tU < -t(28, 0.05) AND \n",
    "tL > t(28, 0.05) , but here, the former is true but the latter isnot. So, the null hypothesis cannot be rejected, and both\n",
    "cannot be said to be equivalent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of the two typing mechanisms\n",
    "\n",
    "# Histograms\n",
    "figHist = plt.figure()\n",
    "bins = np.arange(0, float(df_ToAnalyze.attended_but_not_selected_rate_time.max())+0.01, step = 0.01)\n",
    "\n",
    "# Typing Mechanism\n",
    "\n",
    "ax = figHist.add_subplot(111)\n",
    "df_ToAnalyze.attended_but_not_selected_rate_time[df_ToAnalyze['typing_mechanism'] == 0].hist(ax = ax, alpha=0.5, grid = False, label = 'Dwell time')\n",
    "#df_ToAnalyze.hist(df_ToAnalyze.typing_speed[df_ToAnalyze['age_bins'] == 0], bins, ax = ax, grid = False)\n",
    "#plt.xticks(bins)\n",
    "#plt.xlabel('Attended but Not Selected Ratio of Time')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "ax = figHist.add_subplot(111)\n",
    "df_ToAnalyze.attended_but_not_selected_rate_time[df_ToAnalyze['typing_mechanism'] == 1].hist(ax = ax, alpha=0.5, grid = False, label = 'Multi-key selection')\n",
    "plt.xticks(bins)\n",
    "plt.xlabel('Attended but Not Selected Ratio of Time')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Typing speed and Attended but Not Selected Ratio')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Since the histograms are more or less normal and the means are also more or less the same, t-test can be performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.ttest_ind(df_ToAnalyze.attended_but_not_selected_rate_time[df.typing_mechanism == 0], df_ToAnalyze.attended_but_not_selected_rate_time[df.typing_mechanism == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between ansr and error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c = str(df_ToAnalyze['attended_but_not_selected_rate_time'].corr(df_ToAnalyze['error_rate']))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1,1,1)\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "a = df_ToAnalyze.attended_but_not_selected_rate_time.sort_values()\n",
    "\n",
    "i = 0\n",
    "for ind in a.keys():\n",
    "    i = i + 1\n",
    "    ax1.plot(i, df_ToAnalyze['attended_but_not_selected_rate_time'].loc[ind], 'bo')\n",
    "    ax2.plot(i, df_ToAnalyze['error_rate'].loc[ind], 'ro')\n",
    "    \n",
    "ax1.set_title('Correlation between ansr and error rate is: %s' %c)\n",
    "ax1.set_ylabel('Attended but not selected time ratio', color = 'b')\n",
    "ax1.set_yticks(np.arange(0,0.13,0.02))\n",
    "ax2.set_ylabel('Error rate [in %]', color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
