{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this script has been taken from the checkFiltering and DivideTrialsIntoReadingAndWriting script, and so all the filtering is based on the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetBlinkPropertiesForEvents(EventTrial_index, PupilData_df, MissingData_startNlength):\n",
    "    \n",
    "    samplingFrequency = 90\n",
    "    \n",
    "    blinkFrequencyList = list()\n",
    "    blinkDurationAverageList = list()\n",
    "    blinkDurationTotalList = list()\n",
    "    blinkCountList = list()\n",
    "    interBlinkDurationList = list()\n",
    "    \n",
    "    # for every trial event, find the blinks during that event\n",
    "    for ind, eventStart in enumerate(EventTrial_index['start']):\n",
    "        #print('eventStart: ', eventStart, PupilData_df['timeStamp'][eventStart])\n",
    "        blinkInd_missingData = np.array([indBlink for indBlink in range(0, len(MissingData_startNlength)) if \\\n",
    "                MissingData_startNlength[indBlink][0] > eventStart and MissingData_startNlength[indBlink][0] < \\\n",
    "                                         EventTrial_index['end'][ind]])\n",
    "        blinkDurations_trial = np.array([MissingData_startNlength[indBlink][1] for indBlink in blinkInd_missingData])\n",
    "        interBlinkDuration_trial = [MissingData_startNlength[indBlink][0] - MissingData_startNlength[indBlink-1][0] - \\\n",
    "                                  MissingData_startNlength[indBlink-1][1] for indBlink in blinkInd_missingData[1:]]\n",
    "        \n",
    "        \n",
    "        \n",
    "        trialTime = ((PupilData_df['timeStamp'][EventTrial_index['end'][ind]] - PupilData_df['timeStamp'][\\\n",
    "                                EventTrial_index['start'][ind]]).total_seconds())/60\n",
    "        \n",
    "        blinkCountList.append(len(blinkInd_missingData))\n",
    "        blinkFrequencyList.append(len(blinkInd_missingData)/trialTime)\n",
    "        \n",
    "        blinkDurationTotalList.append(sum(blinkDurations_trial)/samplingFrequency)\n",
    "        \n",
    "        interBlinkDurationList.append(np.mean(interBlinkDuration_trial)/samplingFrequency)\n",
    "        \n",
    "        blinkDurationAverageList.append(np.mean(blinkDurations_trial)/samplingFrequency)\n",
    "        MissingData_startNlength_array = np.array(MissingData_startNlength)\n",
    "        #print(MissingData_startNlength_array[blinkInd_missingData])\n",
    "        #print(len(blinkInd_missingData)/trialTime)\n",
    "        #print(sum(blinkDurations_trial)/samplingFrequency)\n",
    "        #print(np.mean(blinkDurations_trial)/samplingFrequency)\n",
    "        \n",
    "    Blink_df = pd.DataFrame(list(zip(blinkCountList, blinkFrequencyList, blinkDurationAverageList, blinkDurationTotalList,\\\n",
    "                                     interBlinkDurationList)), columns=['blinkCount', 'blinkFrequency', \\\n",
    "                                    'blinkDurationAverage', 'blinkDurationTotal', 'interBlinkDuration'])\n",
    "    Blink_df = Blink_df.fillna(0)\n",
    "    \n",
    "    \n",
    "    return Blink_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataForEveryTrial:\n",
    "    subjectID = ''\n",
    "    blockNumber = ''\n",
    "    sessionNumber = ''\n",
    "    variable = ''\n",
    "    dataForTrial = ''\n",
    "    resultPathName = ''\n",
    "   \n",
    "    \n",
    "    def printInfo(self):\n",
    "        dataFrame = pd.DataFrame(list(zip([self.subjectID]*len(self.dataForTrial), [self.blockNumber]*len(self.dataForTrial), [self.sessionNumber]*len(self.dataForTrial), range(0,len(self.dataForTrial)+1), self.dataForTrial)), columns=['subjectID', 'block', 'session', 'trial', self.variable])\n",
    "        \n",
    "        return dataFrame\n",
    "    \n",
    "    def AddToFile(self):\n",
    "        \n",
    "        dataFrame = pd.DataFrame(list(zip([self.subjectID]*len(self.dataForTrial), [self.blockNumber]*len(self.dataForTrial), [self.sessionNumber]*len(self.dataForTrial), range(0,len(self.dataForTrial)+1), self.dataForTrial)), columns=['subjectID', 'block', 'session', 'trial', self.variable])\n",
    "        book = load_workbook(self.resultPathName)\n",
    "        writer = pd.ExcelWriter(self.resultPathName, engine='openpyxl')\n",
    "        writer.book = book\n",
    "        writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "        startrow = writer.sheets['Sheet1'].max_row\n",
    "        dataFrame.to_excel(writer, startrow = startrow, index = False, header = False)\n",
    "        \n",
    "        writer.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject path E:\\Data\\Data\\ac\\1\\2019-02-11-11-18-30_1\n",
      "ac__1__2019-02-11-11-18-30_1\n",
      "subject and session name:  ac__1__2019-02-11-11-18-30_1\n",
      "eventReadingIndex:  {'start': [12632, 24860, 34766, 40450, 53276], 'end': [14815, 27049, 35533, 42556, 54098]}\n",
      "\n",
      "eventTrialIndex:   {'start': [12632, 24860, 34766, 40450, 53276], 'end': [23258, 32821, 38761, 51123, 57472]}\n",
      "  subjectID block session  trial  BlinkFrequency_writing\n",
      "0        ac     1       1      0               14.713004\n",
      "1        ac     1       1      1               12.165570\n",
      "2        ac     1       1      2               11.710261\n",
      "3        ac     1       1      3               11.353953\n",
      "4        ac     1       1      4                9.609495\n",
      "  subjectID block session  trial  BlinkDurationAverage_writing\n",
      "0        ac     1       1      0                      0.136715\n",
      "1        ac     1       1      1                      0.127350\n",
      "2        ac     1       1      2                      0.128571\n",
      "3        ac     1       1      3                      0.129630\n",
      "4        ac     1       1      4                      0.124074\n",
      "  subjectID block session  trial  InterBlinkDuration_writing\n",
      "0        ac     1       1      0                    3.974747\n",
      "1        ac     1       1      1                    4.662963\n",
      "2        ac     1       1      2                    4.848148\n",
      "3        ac     1       1      3                    5.221569\n",
      "4        ac     1       1      4                    5.877778\n",
      "subject path E:\\Data\\Data\\ac\\1\\2019-02-11-11-33-32_2\n",
      "ac__1__2019-02-11-11-33-32_2\n",
      "subject and session name:  ac__1__2019-02-11-11-33-32_2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9e5a2bd91f94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    161\u001b[0m                 \u001b[0mpupilData_filtered\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolatedIndices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissingData_fromBlinks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissingData_overall\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m                 missingDataBlink_startNlength, missingDataAll_startNlength  = FilterPupilSize_wBlinkData(gazeLog, \\\n\u001b[1;32m--> 163\u001b[1;33m                                                                             timeTyping, subjAndSessionName)\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m                 \"\"\"\n",
      "\u001b[1;32mC:\\DTU\\PythonScripts\\Analysis_Expt_201901\\Functions.py\u001b[0m in \u001b[0;36mFilterPupilSize_wBlinkData\u001b[1;34m(GazeLog, TimeTyping, subjectAndSessionName)\u001b[0m\n\u001b[0;32m   1762\u001b[0m     \u001b[0mtimeStrGazeLog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem3\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mGazeLog\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1763\u001b[0m     \u001b[1;31m# convert the list of strings to datetime formats\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1764\u001b[1;33m     \u001b[0mtimeGazeLog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeConversion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeStrGazeLog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1766\u001b[0m     \u001b[1;31m# internal time, to depict seconds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\DTU\\PythonScripts\\Analysis_Expt_201901\\Functions.py\u001b[0m in \u001b[0;36mtimeConversion\u001b[1;34m(timeStrList)\u001b[0m\n\u001b[0;32m    554\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtimeStrList\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[0mtime1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'+'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m         \u001b[0mtimeList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[:.T]'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"%Y-%m-%d-%H-%M-%S-%f\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtimeList\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\_strptime.py\u001b[0m in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \"\"\"Return a class cls instance based on the input string and the\n\u001b[0;32m    576\u001b[0m     format string.\"\"\"\n\u001b[1;32m--> 577\u001b[1;33m     \u001b[0mtt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfraction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgmtoff_fraction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_strptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    578\u001b[0m     \u001b[0mtzname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgmtoff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfraction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\_strptime.py\u001b[0m in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mgroup_key\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'm'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m             \u001b[0mmonth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'm'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mgroup_key\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'B'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m             \u001b[0mmonth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlocale_time\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_month\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'B'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mgroup_key\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metricComputed_count = 'BlinkCount_writing'\n",
    "metricComputed_freq = 'BlinkFrequency_writing'\n",
    "metricComputed_durTotal = 'BlinkDurationTotal_writing'\n",
    "metricComputed_durAvg = 'BlinkDurationAverage_writing'\n",
    "metricComputed_interDur = 'InterBlinkDuration_writing'\n",
    "\n",
    "dataFolderName = r'E:\\Data\\Data' # accessing external hard disk with the data\n",
    "a = re.compile('(?<=Data\\\\\\\\Data\\\\\\\\)(.*)(?=\\\\\\\\[1-9])')\n",
    "subjectName_listElement = 3\n",
    "\n",
    "#dataFolderName = r'C:\\DTU\\Data\\201901_JanuaryExpt' # accessing data saved in the computer\n",
    "#a = re.compile('(?<=Data\\\\\\\\201901_JanuaryExpt\\\\\\\\)(.*)(?=\\\\\\\\[1-9])')\n",
    "#subjectName_listElement = 4\n",
    "\n",
    "resultFileName_count = r'C:\\DTU\\Data\\201901_JanuaryExpt\\DataExtracted\\IndividualTrials\\Blinks\\Subject_Block_Session_Trial_' + metricComputed_count +  '.xlsx'\n",
    "resultFileName_freq = r'C:\\DTU\\Data\\201901_JanuaryExpt\\DataExtracted\\IndividualTrials\\Blinks\\Subject_Block_Session_Trial_' + metricComputed_freq +  '.xlsx'\n",
    "resultFileName_durTotal = r'C:\\DTU\\Data\\201901_JanuaryExpt\\DataExtracted\\IndividualTrials\\Blinks\\Subject_Block_Session_Trial_' + metricComputed_durTotal +  '.xlsx'\n",
    "resultFileName_durAvg = r'C:\\DTU\\Data\\201901_JanuaryExpt\\DataExtracted\\IndividualTrials\\Blinks\\Subject_Block_Session_Trial_' + metricComputed_durAvg +  '.xlsx'\n",
    "resultFileName_interDur = r'C:\\DTU\\Data\\201901_JanuaryExpt\\DataExtracted\\IndividualTrials\\Blinks\\Subject_Block_Session_Trial_' + metricComputed_interDur +  '.xlsx'\n",
    "\n",
    "\n",
    "\n",
    "for root, dirs, subfolder in os.walk(dataFolderName):\n",
    "    \n",
    "    technique = 'dwell_time'\n",
    "    \n",
    "    if not dirs:\n",
    "        \n",
    "        #if 'notCompleted' in root or 'notInclude' in root: # Some subjects do not have gaze log and have been marked as \n",
    "        \n",
    "        if 'noData' in root or 'Trial' in root or 'trial' in root or 'Nothing' in root: # Some subjects do not have gaze log and have been marked as \n",
    "            #notInclude\n",
    "            continue\n",
    "        if 'Jonas' in root or 'Praktikant' in root or 'Villads' in root:\n",
    "            continue\n",
    "            \n",
    "        if 'Picture' in root:\n",
    "            continue\n",
    "        #if '_MS' not in root:\n",
    "        #    continue\n",
    "        \n",
    "        #if 'af\\\\1\\\\' not in root:\n",
    "        #    continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        #if '2019-1-16-16-36-17_1stPart_2' not in root:\n",
    "        #    continue\n",
    "            \n",
    "        keysSelected = None\n",
    "        userKeys = None\n",
    "        phraseLog = None\n",
    "        \n",
    "        for file in subfolder:\n",
    "            \n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'KeySelection*'):\n",
    "                try:\n",
    "                    \n",
    "                    fKeysSelected = open(root + '\\\\' + file, encoding='utf-8', newline='')\n",
    "                    readerKeysSelected = csv.reader(fKeysSelected)\n",
    "                    keysSelected = list(readerKeysSelected)\n",
    "                    \n",
    "                    keysSelected.remove(keysSelected[0])\n",
    "                except:\n",
    "                    if fKeysSelected is not None:\n",
    "                        fKeysSelected.close()\n",
    "                    else:\n",
    "                        print('error in opening the KeySelection log file')\n",
    "                        \n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'user*'):\n",
    "                try:\n",
    "                    fUserKey = open(root + '\\\\' + file, encoding='utf-8',  newline='')\n",
    "                    readerUserKey = csv.reader(fUserKey, quotechar=None)\n",
    "                    userKeys = list(readerUserKey)\n",
    "                    userKeys.remove(userKeys[0])\n",
    "                except:\n",
    "                    if fUserKey is not None:\n",
    "                        fUserKey.close()\n",
    "                    else:\n",
    "                        print('error in opening the user key log file')\n",
    "                        \n",
    "            if fnmatch.fnmatch(file, 'phrase*'):\n",
    "                try:\n",
    "                    fPhraseLog = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerPhraseLog = csv.reader(fPhraseLog, quotechar=None)\n",
    "                    phraseLog = list(readerPhraseLog)\n",
    "                    \n",
    "                except:\n",
    "                    if fPhraseLog is not None:\n",
    "                        fPhraseLog.close()\n",
    "                    else:\n",
    "                        print('error in opening the phrase log file')\n",
    "                        \n",
    "            if fnmatch.fnmatch(file, 'multiKey*'):\n",
    "                technique = 'multiKey_selection'\n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'tobiiGazeLog*'):\n",
    "                try:\n",
    "                    fGazeLog = open(root + '\\\\' + file, encoding='utf-8', newline='')\n",
    "                    readerGazeLog = csv.reader(fGazeLog, quotechar=None)\n",
    "                    gazeLog = list(readerGazeLog)\n",
    "                    gazeLog.remove(gazeLog[0])\n",
    "                    gazeLog.remove(gazeLog[-1])\n",
    "                except:\n",
    "                    if fGazeLog is not None:\n",
    "                        fGazeLog.close()\n",
    "                    else:\n",
    "                        print('error in opening the scratchpad log file')\n",
    "            \n",
    "                    \n",
    "                     \n",
    "        if keysSelected is None or userKeys is None or phraseLog is None or gazeLog is None:\n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            print('subject path', root)\n",
    "            subjAndSessionName = '__'.join(root.split('\\\\')[subjectName_listElement:])\n",
    "            print(subjAndSessionName)\n",
    "            subjName = subjAndSessionName.split('__')[0]\n",
    "            print('subject and session name: ', subjAndSessionName)\n",
    "            sessionFolderName = root.split('\\\\')[-1]\n",
    "            \n",
    "            a = re.compile('(?<=Data\\\\\\\\Data\\\\\\\\)(.*)(?=\\\\\\\\[1-9])')\n",
    "            \n",
    "    \n",
    "            # fix userKeys due to comma related file changes\n",
    "            userKeys_new = FixUserKeys(userKeys)\n",
    "            \n",
    "            # need to fix keys selected, where rows get combined because of an inverted comma\n",
    "            keysSelected_new = FixKeysSelected(keysSelected)\n",
    "            \n",
    "            # find start time of typing\n",
    "            timeTyping = OptiKeyTypingTime(userKeys_new)\n",
    "            \n",
    "            # divide complete data into epochs of phrases\n",
    "            timeStartEndKeys_reading, timeStartEndKeys_writing = FindExptStartEndTimes(keysSelected_new, timeTyping, root)\n",
    "            \n",
    "            userKeys_new_wDwellTime = ComputeDwellTime(userKeys_new, root)\n",
    "            \n",
    "            # use the times of trial start and end, to divide the time of trial into reading and writing\n",
    "            eventTrialsInKeysSelected_reading, eventTrialsInKeysSelected_readingIndex = \\\n",
    "            FindReadingPartsOfTrial_inKeysSelected(timeStartEndKeys_reading, keysSelected_new, root, \\\n",
    "                                                   userKeys_new_wDwellTime)\n",
    "            \n",
    "            eventTrialsInKeysSelected_writing, eventTrialsInKeysSelected_writingIndex = \\\n",
    "            FindWritingPartsOfTrial_inKeysSelected(timeStartEndKeys_writing, keysSelected_new, eventTrialsInKeysSelected_reading)\n",
    "            \n",
    "            \n",
    "            if sessionFolderName in dict_noGazeData:\n",
    "                print('no gaze data present')\n",
    "                blinkCount = [np.nan]*len(eventTrialsInKeysSelected_writing['start'])\n",
    "                blinkDurationTotal = [np.nan]*len(eventTrialsInKeysSelected_writing['start'])\n",
    "                blinkDurationAverage = [np.nan]*len(eventTrialsInKeysSelected_writing['start'])\n",
    "                blinkFrequency = [np.nan]*len(eventTrialsInKeysSelected_writing['start'])\n",
    "                interBlinkDuration = [np.nan]*len(eventTrialsInKeysSelected_writing['start'])\n",
    "            \n",
    "            else:\n",
    "                # filter the data\n",
    "                pupilData_filtered, interpolatedIndices, missingData_fromBlinks, missingData_overall, \\\n",
    "                missingDataBlink_startNlength, missingDataAll_startNlength  = FilterPupilSize_wBlinkData(gazeLog, \\\n",
    "                                                                            timeTyping, subjAndSessionName)\n",
    "                \n",
    "                \"\"\"\n",
    "                print('missing data ratio: ', sum(missingData_overall)/len(missingData_overall))\n",
    "                print('interpolated data ratio: ', sum(interpolatedIndices)/len(interpolatedIndices))\n",
    "                print('missing data from blinks ratio: ', sum(missingData_fromBlinks)/len(missingData_fromBlinks))\n",
    "                \n",
    "                blinkDurations = [item[1] for item in missingDataBlink_startNlength]\n",
    "                fig=plt.figure(), plt.hist(blinkDurations)\n",
    "                plt.title('blinkDurationHistograms')\n",
    "                pickle.dump(fig, open(r'C:\\DTU\\Results\\201901_Expt\\Blinks\\blinkDurationHistograms'+'\\\\'+subjName+'\\\\'+subjAndSessionName, 'wb'))\n",
    "                \n",
    "                missingDataAllDurations = [item[1] for item in missingDataAll_startNlength]\n",
    "                fig=plt.figure(), plt.hist(missingDataAllDurations)\n",
    "                plt.title('MissingDataLengthHistograms')\n",
    "                pickle.dump(fig, open(r'C:\\DTU\\Results\\201901_Expt\\Blinks\\MissingDataLengthHistograms'+'\\\\'+subjName+'\\\\'+subjAndSessionName, 'wb'))\n",
    "                \n",
    "                \n",
    "                \"\"\"\n",
    "                #print(missingDataBlink_startNlength)\n",
    "                \n",
    "                # divide trials into reading and writing\n",
    "                eventReading, eventReading_index = EventPartsFromPupilData(eventTrialsInKeysSelected_reading, pupilData_filtered, root)\n",
    "                eventWriting, eventWriting_index = EventPartsFromPupilData(eventTrialsInKeysSelected_writing, pupilData_filtered, root)\n",
    "                \n",
    "                eventTrial, eventTrial_index = CombineReadingWriting(eventReading, eventWriting, eventReading_index, eventWriting_index)\n",
    "                \n",
    "                print('eventReadingIndex: ', eventReading_index)\n",
    "                print('')\n",
    "                print('eventTrialIndex:  ', eventTrial_index)\n",
    "                \n",
    "                # compute blink durations for all trials\n",
    "                blink = GetBlinkPropertiesForEvents(eventWriting_index, pupilData_filtered, missingDataBlink_startNlength)\n",
    "                \n",
    "                blinkCount = blink['blinkCount'].tolist()\n",
    "                blinkFrequency = blink['blinkFrequency'].tolist()\n",
    "                blinkDurationAverage = blink['blinkDurationAverage'].tolist()\n",
    "                blinkDurationTotal = blink['blinkDurationTotal'].tolist()\n",
    "                interBlinkDuration = blink['interBlinkDuration'].tolist()\n",
    "                \n",
    "            if '1stPart' in root:\n",
    "                print('1stPart')\n",
    "                blinkCount1 = blinkCount\n",
    "                blinkFrequency1 = blinkFrequency\n",
    "                blinkDurationAverage1 = blinkDurationAverage\n",
    "                blinkDurationTotal1 = blinkDurationTotal\n",
    "                interBlinkDuration1 = interBlinkDuration\n",
    "                \n",
    "                continue\n",
    "            \n",
    "            if '2ndPart' in root:\n",
    "                print('2ndPart')\n",
    "                blinkCount2 = blinkCount\n",
    "                blinkFrequency2 = blinkFrequency\n",
    "                blinkDurationAverage2 = blinkDurationAverage\n",
    "                blinkDurationTotal2 = blinkDurationTotal\n",
    "                interBlinkDuration2 = interBlinkDuration\n",
    "                \n",
    "                blinkCount = blinkCount1 + blinkCount2\n",
    "                blinkFrequency = blinkFrequency1 + blinkFrequency2\n",
    "                blinkDurationAverage = blinkDurationAverage1 + blinkDurationAverage2\n",
    "                blinkDurationTotal = blinkDurationTotal1 + blinkDurationTotal2\n",
    "                interBlinkDuration = interBlinkDuration1 + interBlinkDuration2\n",
    "                \n",
    "                blinkCount1 = list()\n",
    "                blinkFrequency1 = list()\n",
    "                blinkDurationAverage1 = list()\n",
    "                blinkDurationTotal1 = list()\n",
    "                interBlinkDuration1 = list()\n",
    "                \n",
    "            \n",
    "            # save the blink count\n",
    "            dataToSave_count = DataForEveryTrial()\n",
    "            dataToSave_count.subjectID = subjAndSessionName.split('__')[0]\n",
    "            dataToSave_count.blockNumber = subjAndSessionName.split('__')[1]\n",
    "            dataToSave_count.sessionNumber = subjAndSessionName[-1]\n",
    "            dataToSave_count.variable = metricComputed_count\n",
    "            dataToSave_count.dataForTrial = blinkCount\n",
    "            dataToSave_count.resultPathName = resultFileName_count\n",
    "            \n",
    "            #print(dataToSave_count.printInfo())\n",
    "            \n",
    "            \n",
    "            # save the blink frequency\n",
    "            dataToSave_freq = DataForEveryTrial()\n",
    "            dataToSave_freq.subjectID = subjAndSessionName.split('__')[0]\n",
    "            dataToSave_freq.blockNumber = subjAndSessionName.split('__')[1]\n",
    "            dataToSave_freq.sessionNumber = subjAndSessionName[-1]\n",
    "            dataToSave_freq.variable = metricComputed_freq\n",
    "            dataToSave_freq.dataForTrial = blinkFrequency\n",
    "            dataToSave_freq.resultPathName = resultFileName_freq\n",
    "            \n",
    "            print(dataToSave_freq.printInfo())\n",
    "            \n",
    "            # save the blink duration total\n",
    "            dataToSave_durTotal = DataForEveryTrial()\n",
    "            dataToSave_durTotal.subjectID = subjAndSessionName.split('__')[0]\n",
    "            dataToSave_durTotal.blockNumber = subjAndSessionName.split('__')[1]\n",
    "            dataToSave_durTotal.sessionNumber = subjAndSessionName[-1]\n",
    "            dataToSave_durTotal.variable = metricComputed_durTotal\n",
    "            dataToSave_durTotal.dataForTrial = blinkDurationTotal\n",
    "            dataToSave_durTotal.resultPathName = resultFileName_durTotal\n",
    "            \n",
    "            #print(dataToSave_durTotal.printInfo())\n",
    "            \n",
    "            \n",
    "            # save the blink duration average\n",
    "            dataToSave_durAvg = DataForEveryTrial()\n",
    "            dataToSave_durAvg.subjectID = subjAndSessionName.split('__')[0]\n",
    "            dataToSave_durAvg.blockNumber = subjAndSessionName.split('__')[1]\n",
    "            dataToSave_durAvg.sessionNumber = subjAndSessionName[-1]\n",
    "            dataToSave_durAvg.variable = metricComputed_durAvg\n",
    "            dataToSave_durAvg.dataForTrial = blinkDurationAverage\n",
    "            dataToSave_durAvg.resultPathName = resultFileName_durAvg\n",
    "            \n",
    "            print(dataToSave_durAvg.printInfo())\n",
    "            \n",
    "            # save the inter blink duration \n",
    "            dataToSave_interDur = DataForEveryTrial()\n",
    "            dataToSave_interDur.subjectID = subjAndSessionName.split('__')[0]\n",
    "            dataToSave_interDur.blockNumber = subjAndSessionName.split('__')[1]\n",
    "            dataToSave_interDur.sessionNumber = subjAndSessionName[-1]\n",
    "            dataToSave_interDur.variable = metricComputed_interDur\n",
    "            dataToSave_interDur.dataForTrial = interBlinkDuration\n",
    "            dataToSave_interDur.resultPathName = resultFileName_interDur\n",
    "            \n",
    "            print(dataToSave_interDur.printInfo())\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            #dataToSave_count.AddToFile()\n",
    "            dataToSave_freq.AddToFile()\n",
    "            #dataToSave_durTotal.AddToFile()\n",
    "            dataToSave_durAvg.AddToFile()\n",
    "            dataToSave_interDur.AddToFile()\n",
    "                        \n",
    "            \"\"\"\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
