{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this script has been taken from the checkFiltering and DivideTrialsIntoReadingAndWriting script, and so all the filtering is based on the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import fnmatch\n",
    "from pathlib import Path\n",
    "from itertools import groupby\n",
    "import copy\n",
    "import itertools\n",
    "#import distance\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import snowball\n",
    "\n",
    "from itertools import *\n",
    "from operator import *\n",
    "\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exceptional removal of particular extra sentences not typed by the user \n",
    "dict_phraseStim = {\n",
    "    #'2019-02-05-14-10-39_2ndPart_2' : [1, 2, 3, 4, 5, 6, 9, 10],\n",
    "    #'2019-01-14-14-58-30' : [0], # ys, session_trial ()\n",
    "    '2019-01-16-16-36-17_1stPart_2' : [-1], # af_session1\n",
    "    '2019-01-16-17-00-12_2ndPart_2': [1], # af_session1\n",
    "    '2019-01-17-15-27-20_1stPart_2' : [4], # Af session2\n",
    "    '2019-01-17-16-03-27_2ndPart_2' : [0, 1, 2], # Af session2\n",
    "    '2019-02-06-11-25-41_1' : [7],               # aq_session1    \n",
    "    '2019-02-08-11-33-53_1stPart_1' : [1],  # aq session3_1_part1\n",
    "    '2019-02-08-12-11-34_2ndPart_1' : [0, 1, 2, 3],  # aq session3_1_part2\n",
    "    '2019-01-31-09-37-5_2ndPart_2' : range(1,5), # bh1, session 4 , all sentences except the first one deleted\n",
    "    '2019-01-31-09-22-49_1stPart_2' : [4],  # bh1_session4_2_part1\n",
    "    '2019-02-21-16-09-44_1stPart_1' : [1], # bh2_session1\n",
    "    '2019-02-21-16-22-22_2ndPart_1' : [2, 3, 4],# bh2_session1\n",
    "    '2019-02-28-17-03-53_1stPart_2' : [2],       # bh2_session3\n",
    "    '2019-02-28-17-24-2_2ndPart_2' : [0, 2],     # bh2_session3\n",
    "    '2019-02-14-13-28-20_1stPart_2' : [2], # cw_session3_2_part1\n",
    "    '2019-02-14-13-57-41_2ndPart_2' : [0, 2, 3], # cw_session3_2_part2\n",
    "    '2019-02-21-15-01-4_1stPart_1' : [0],        # le_session3\n",
    "    '2019-02-21-15-25-56_2ndPart_1' : [1],        # le_session3\n",
    "    '2019-02-18-10-28-35_2' : [0],               # ls2_session4 # picture not described\n",
    "    '2019-02-05-14-00-27_1stPart_2' : [3],        # mh_session1\n",
    "    '2019-02-05-14-10-39_2ndPart_2' : [0, 1, 3],   # mh_session1\n",
    "    '2019-02-08-10-51-3_1stPart_1' : [4],        # mn_session1\n",
    "    '2019-02-08-11-05-7_2ndPart_1' : [0, 2, 3, 4], # mn_session1\n",
    "    '2019-02-19-10-34-7_1stPart_1' : [3],          # mn_session3\n",
    "    '2019-02-19-10-56-43_2ndPart_1' : [1, 2, 3, 4], # mn_session3\n",
    "    '2019-01-16-15-18-0_1' : [4],            # no_session1\n",
    "    '2019-02-19-17-10-45_1' : [3],                  # ph_session5\n",
    "    '2019-01-29-13-25-4_1' : [3],        # ph_session2\n",
    "    '2019-03-07-16-44-5_2' : [1],                   # rh_session1\n",
    "    '2019-03-14-13-56-56_2' : [2],                  # rh_session3\n",
    "    '2019-01-14-15-07-21_1' : [4], # ys_session1\n",
    "    '2019-01-16-15-18-50_1stPart_1' : [3, 4], # ys_session2\n",
    "    '2019-01-16-15-42-51_2ndPart_1' : [2], # ys_session2\n",
    "    '2019-01-30-11-22-25_1' : [3, 5, 7],          # ys_session4\n",
    "    '2019-01-30-11-22-25_1' : [4, 6, 7] # ys, session 4\n",
    "}\n",
    "\n",
    "# exceptional removal of sentences/words typed by the user, but then deleted everything to have a blank scratchpad\n",
    "\n",
    "dict_phraseUser = {\n",
    "    \"2019-02-06-15-44-15_1\" : [2, 3, 6], \n",
    "    \"2019-02-06-16-19-9_2\" : [1, 3, 6, 7],\n",
    "    \"2019-02-12-11-21-21_2\" : [0],\n",
    "    \"2019-02-14-14-28-49_1\" : [0, 2, 3], # ac_session3_1\n",
    "    \"2019-02-14-14-45-49_2\" : [0, 5, 6], # ac_session3_2\n",
    "    '2019-01-29-14-19-26_1' : [0, 3, 4], # bh1_session2_1\n",
    "    '2019-01-29-14-40-36_2' : [0, 1, 2], # bh1_session2_2\n",
    "    '2019-01-30-14-29-29_2' : [4],       # bh1_session3_2\n",
    "    '2019-01-31-09-12-2_1' : [3],         # bh1_session4_1\n",
    "    '2019-01-31-09-22-49_1stPart_2' : [4], # bh1_session4_2_part1\n",
    "    '2019-03-05-09-15-11_1' : [1],         # bh2_session5_1\n",
    "    '2019-03-05-09-15-11_2' : [1],        # bh2_session5_2\n",
    "    '2019-02-21-15-55-56_2' : [2],       # ch_session5_2\n",
    "    '2019-01-30-15-19-36_2' : [1],       # jm_session2_1\n",
    "    '2019-01-30-15-04-30_1' : [0],         # jm_session2_2\n",
    "    '2019-01-16-15-18-50_1stPart_1' : [1],  # ys_session2\n",
    "    '2019-01-16-15-42-51_2ndPart_1' : [0], # ys_session2\n",
    "    '2019-01-30-11-22-25_1' : [2, 4],       # ys_session4\n",
    "    '2019-01-30-11-57-3_2' : [0] ,          # ys_session4\n",
    "    '2019-01-31-13-13-2_1' : [4],           # ys_session5\n",
    "    '2019-01-30-10-20-32_1' : [0, 1, 2, 3, 4, 5], # no_session4\n",
    "    '2019-01-30-10-46-38_2' : [0],          # \n",
    "    '2019-02-28-17-03-53_1stPart_2' : [2],   # bh2_session3\n",
    "    '2019-03-12-09-30-5_1' : [0],            # kj_session3\n",
    "    '2019-02-13-15-20-38_1' : [0, 1, 2, 3, 6], # ls1_session3\n",
    "    '2019-02-18-10-25-52_1' : [1],              # ls2_session4\n",
    "    '2019-02-18-10-46-26_2' : [0],            # ls2_session4\n",
    "    '2019-01-29-13-25-4_1' : [0, 1, 7],        # ph_session2\n",
    "    '2019-01-29-13-43-50_2' : [0],              # ph_session2\n",
    "    '2019-03-07-16-17-30_1' : [0],              # rh_session1\n",
    "    '2019-03-07-16-44-5_2' : [0, 1],         # rh_session1\n",
    "    '2019-03-14-13-56-56_2' : [0, 1, 3]         # rh_session3\n",
    "}\n",
    "\n",
    "# key selection can have extra selections of NextPhrase at the end\n",
    "dict_keySelectionOfNextPhrase = {\n",
    "    \"2019-02-11-11-18-30_1\" : [12, 13], # ac_session1\n",
    "    \"2019-01-16-17-00-12_2ndPart_2\" : [12], # af_session1\n",
    "    \"2019-01-17-15-27-20_1stPart_2\" : [12], # af_session2\n",
    "    \"2019-02-06-16-19-9_2\" : [12], # af_session3\n",
    "    \"2019-02-12-11-07-43_1\" : [12], # af_session4\n",
    "    \"2019-02-27-15-08-32_1\" : [12], # af_session5\n",
    "    \"2019-01-28-14-30-44_1\" : [12], # bh1_session1\n",
    "    \"2019-02-21-16-22-22_2ndPart_1\" : [12], # bh2_session1\n",
    "    \"2019-02-18-14-02-56_2\" : [12], # le_session1\n",
    "    \"2019-02-19-10-03-14_1\" : [12], # le_session2\n",
    "    \"2019-02-08-11-05-7_2ndPart_1\" : [12], # mn_session1\n",
    "    \"2019-02-08-11-12-51_2\" : [12, 13], # mn_session1\n",
    "    \"2019-02-15-11-38-22_1\" : [12, 13], # mn_session2\n",
    "    \"2019-02-15-11-54-25_2\" : [12], # mn_session2\n",
    "    \"2019-01-16-15-18-0_1\" : [12], # no_session1\n",
    "    \"2019-01-28-13-31-51_1\" : [12], # ph_session1\n",
    "    \"2019-01-28-13-49-14_2\" : [12], # ph_session1\n",
    "    \"2019-01-14-15-07-21_1\" : [12], # ys_session1\n",
    "    \"2019-01-17-15-05-1_1\" : [12], # ys_session3\n",
    "    \"2019-01-30-11-22-25_1\" : [12], # ys_session4\n",
    "    \"2019-01-31-13-32-2_2\" : [12], # ys_session5\n",
    "}\n",
    "\n",
    "\n",
    "# key selection when participants skips some sentences\n",
    "dict_keySelectionNotCompleted = {\n",
    "    \"2019-01-16-16-36-17_1stPart_2\" : [0, 1, 3, 5, 7], # af_session1 ---- last sentence is not finished\n",
    "    \"2019-01-16-17-00-12_2ndPart_2\" : [0, 1, 3, 4, 5, 7, 9, 11], # af_session1\n",
    "    \"2019-01-17-15-27-20_1stPart_2\" : [0, 1, 3, 5, 7, 9, 11], # af_session2 \n",
    "    \"2019-01-17-16-03-27_2ndPart_2\" : [0, 1, 2, 3, 4, 5, 6, 7, 9, 11], # af_session2\n",
    "    \"2019-02-08-11-33-53_1stPart_1\" : [0, 1, 3, 4, 5, 7, 9, 11], # aq_session3\n",
    "    \"2019-02-08-12-11-34_2ndPart_1\" : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11], # aq_session3\n",
    "    \"2019-01-28-14-30-44_1\" : [0, 1, 3, 5], # bh1_session1\n",
    "    \"2019-01-31-09-22-49_1stPart_2\": [0, 1, 3, 5, 7, 9, 10, 11], # bh1_session4\n",
    "    \"2019-01-31-09-37-5_2ndPart_2\" : [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11], # bh1_session4\n",
    "    \"2019-02-21-16-09-44_1stPart_1\" : [0, 1, 3, 4, 5, 7, 9, 11], # bh2_session1\n",
    "    \"2019-02-21-16-22-22_2ndPart_1\" : [0, 1, 3, 5, 6, 7, 8, 9, 10, 11], # bh2_session1\n",
    "    \"2019-02-28-17-03-53_1stPart_2\" : [0, 1, 3, 5, 6, 7, 9, 11], # bh2_session3\n",
    "    \"2019-02-28-17-24-2_2ndPart_2\" : [0, 1, 2, 3, 5], # bh2_session3     ----\n",
    "    \"2019-02-14-13-28-20_1stPart_2\" : [0, 1, 3, 5, 6, 7, 9, 11], # cw_session3\n",
    "    \"2019-02-14-13-57-41_2ndPart_2\" : [0, 1, 2, 3, 5, 6, 7, 8, 9, 11], # cw_session3\n",
    "    \"2019-02-21-15-01-4_1stPart_1\" : [0, 1, 2, 3, 5, 7, 9, 11], # le_session3\n",
    "    \"2019-02-21-15-25-56_2ndPart_1\" : [0, 1, 3], # le_session3       ----\n",
    "    \"2019-02-05-14-00-27_1stPart_2\" : [0, 1, 3, 5, 7, 8], # mh_session1\n",
    "    \"2019-02-05-14-10-39_2ndPart_2\" : [0, 1, 2, 3, 4, 5, 7, 8, 9, 11], # mh_session1\n",
    "    \"2019-02-08-10-51-3_1stPart_1\" : [0, 1, 3, 5, 7, 9, 10, 11], # mn_session1\n",
    "    \"2019-02-08-11-05-7_2ndPart_1\" : [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11], # mn_session1\n",
    "    \"2019-02-19-10-34-7_1stPart_1\" : [0, 1, 3, 5, 7, 8, 9, 11], # mn_session3\n",
    "    \"2019-02-19-10-56-43_2ndPart_1\" : [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11], # mn_session3\n",
    "    \"2019-01-29-13-25-4_1\" : [0, 1, 3, 5, 7], # ph_session2  -- sessions where there are less score questions \n",
    "    # and more sentences typed\n",
    "    \"2019-01-16-15-18-50_1stPart_1\" : [0, 1, 3, 5, 7, 8, 9, 10], # ys_session2\n",
    "    \"2019-01-17-15-05-1_1\" : [0, 1, 3, 5],  # ys_session3  -- sessions where there are less score questions \n",
    "    # and more sentences typed\n",
    "    \"2019-02-06-11-25-41_1\" : [0, 1, 3, 5, 11], # aq_session1 -- sessions where there are less score questions \n",
    "    # and more sentences typed\n",
    "    \"2019-01-16-15-42-51_2ndPart_1\" : [0, 1, 2, 5], # ys_session2 -- different for reading and writing, this one is for\n",
    "    # writing\n",
    "    '2019-01-30-11-22-25_1' : [0, 1, 3, 5, 7, 9, 11]   # ys_session4 -- sessions where there are less score questions \n",
    "    # and more sentences typed\n",
    "   \n",
    "}\n",
    "\n",
    "# dictionary for phrase removal just like in the dict_phraseStim, but since not all participants require that, some that \n",
    "# do, are added to this new dictionary here\n",
    "dict_keySelection_phraseStim = {\n",
    "    '2019-01-17-15-27-20_1stPart_2' : [4], # Af session2\n",
    "    '2019-01-16-15-18-0_1' : [4],        # no_session1\n",
    "    '2019-02-19-17-10-45_1' : [3],                  # ph_session5\n",
    "    '2019-03-07-16-44-5_2' : [1],        # rh_session1\n",
    "    '2019-03-14-13-56-56_2' : [2],              # rh_session3\n",
    "    '2019-01-14-15-07-21_1' : [4]         # ys_session1\n",
    "}\n",
    "\n",
    "\n",
    "# in the beginning experiments, not everyone started with 800 initial dwell time\n",
    "\n",
    "dict_dwellTimeOrig_not800 = {\n",
    "    \"2019-01-16-15-51-13_2\" : 600, # no_session1\n",
    "    \"2019-01-16-15-18-0_1\" : 600, # no_session1\n",
    "    \"2019-01-16-15-43-8_1\" : 100, # af_session1\n",
    "    \"2019-01-16-16-36-17_1stPart_2\" : 100, # af_session1\n",
    "    \"2019-01-16-17-00-12_2ndPart_2\" : 100, # af_session1\n",
    "    \"2019-01-17-15-03-40_1\" : 100, # af_session2\n",
    "    \"2019-01-17-15-27-20_1stPart_2\" : 0, # af_session2\n",
    "    \"2019-01-17-16-03-27_2ndPart_2\" : 100, # af_session2\n",
    "    \"2019-01-14-15-07-21_1\" : 500, # ys_session1\n",
    "    \"2019-01-14-15-25-55_2\" : 300, # ys_session1\n",
    "    \"2019-01-16-15-18-50_1stpart_1\" : 200, # ys_session2\n",
    "    \"2019-01-16-15-42-51_2ndPart_1\" : 100, # ys_session2\n",
    "    \"2019-01-16-15-59-55_2\" : 100, # ys_session2\n",
    "    \"2019-01-17-15-05-1_1\" : 100, # ys_session3\n",
    "    \"2019-01-17-15-31-12_2\" : 100 # ys_session3\n",
    "}\n",
    "\n",
    "\n",
    "# list of all things that should be present when computing effective time\n",
    "list_keysToBeCounted = ['Comma', 'BackOne', 'BackMany', 'SpaceBar']\n",
    "\n",
    "# some sessions do not have gaze data\n",
    "dict_noGazeData = {\n",
    "    '2019-01-16-17-00-12_2ndPart_2' : 'no gaze data', # af_session2\n",
    "    '2019-01-17-15-31-12_2' : 'no gaze data', #ys_session2\n",
    "    '2019-01-30-11-57-3_2' : 'no gaze data' # ys_session4\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_keySelection_ReadingTrials = {\n",
    "    \"2019-01-16-15-42-51_2ndPart_1\" : [0, 1, 3, 5], # ys_session2 \n",
    "}\n",
    "\n",
    "dict_keySelection_WritingTrials = {\n",
    "    \"2019-01-16-15-42-51_2ndPart_1\" : [0, 1, 2, 5], # ys_session2   \n",
    "}\n",
    "\n",
    "# normally, reading part of trial ends when people look at the keyboardwithphrases. For some trials, this is not done,\n",
    "# as the reading is done, and the trial is accidentally skipped, and written in the next trial. Here, the trial number \n",
    "# given will have the reading time ending as sleep, and not keyboard with phrases. \n",
    "dict_keyboardNotChange_ReadingTrials = {\n",
    "    \"2019-01-16-15-42-51_2ndPart_1\" : 0, # ys_session2 \n",
    "}\n",
    "\n",
    "dict_keySelection_firstSleepNotCounted = {\n",
    "    \"2019-01-28-14-50-41_2\" : (0, 2), # bh1_session1 -- 3rd sleep activation to be counted\n",
    "    \"2019-02-19-10-56-43_2ndPart_1\" : 2  # mn_session3 -- 3rd sleep activation is to be counted\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeDwellOrig = 800\n",
    "TimeFixation = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FixUserKeys(UserKeys_Old):\n",
    "    # Fix the situation where comma has divided decimals into separate columns\n",
    "    \n",
    "    Column_beforeDecimal = [item[2] for item in UserKeys_Old]\n",
    "    Column_afterDecimal = [item[3] if len(item)>3 else '00' for item in UserKeys_Old]\n",
    "    \n",
    "    UserKeys_ProgressPercent = [float(Column_beforeDecimal[i]+'.'+ Column_afterDecimal[i]) for i in \n",
    "                                range(0, len(Column_beforeDecimal))]\n",
    "    UserKeys_Times = [item[0] for item in UserKeys_Old]\n",
    "    UserKeys_Keys = [item[1] for item in UserKeys_Old]\n",
    "    \n",
    "    UserKeys_New = [[UserKeys_Times[ind], UserKeys_Keys[ind], UserKeys_ProgressPercent[ind]] for ind in \n",
    "                    range(0, len(UserKeys_ProgressPercent))]\n",
    "    \n",
    "    #UserKeys_New = np.concatenate((UserKeys_Times, UserKeys_Keys, UserKeys_ProgressPercent), axis = 0)\n",
    "    \n",
    "    \n",
    "    return UserKeys_New\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FixKeysSelected(KeysSelected_Old):\n",
    "    # Fix the situation where comma has divided decimals into separate columns\n",
    "    \n",
    "    KeysSelected_New = list()\n",
    "    \n",
    "    # loop to combine phrases divided by commas\n",
    "    KeysSelectedInd = -1 \n",
    "    while KeysSelectedInd < len(KeysSelected_Old)-1:\n",
    "        KeysSelectedInd = KeysSelectedInd + 1\n",
    "        \n",
    "        if KeysSelected_Old[KeysSelectedInd][1].count(',') > 0:\n",
    "            \n",
    "            keys_split = KeysSelected_Old[KeysSelectedInd][1].split(\"\\r\\n\")\n",
    "            del keys_split[0]\n",
    "            del keys_split[-1]\n",
    "            \n",
    "            keys_split = [key.split(',') for key in keys_split]\n",
    "            \n",
    "            KeysSelected_New.extend(keys_split)\n",
    "        else:\n",
    "            KeysSelected_New.append(KeysSelected_Old[KeysSelectedInd])\n",
    "        \n",
    "    \n",
    "    return KeysSelected_New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeDwellTime(userKeys, full_path):\n",
    "    # modify userKeys to include a column of time instead of progress pct, which is dependent on the then dwell time\n",
    "    \n",
    "    TimeDwellOrig = 800\n",
    "    \n",
    "    # session name\n",
    "    session_folder_name = full_path.split('\\\\')[-1]\n",
    "    \n",
    "    if session_folder_name in dict_dwellTimeOrig_not800:\n",
    "        TimeDwellOrig = dict_dwellTimeOrig_not800[session_folder_name]\n",
    "    \n",
    "    #print(TimeDwellOrig)\n",
    "    \n",
    "    timeDwell = TimeDwellOrig\n",
    "    nKey = -1\n",
    "    for key in userKeys:\n",
    "        nKey = nKey + 1\n",
    "        #print(key[1])\n",
    "        if key[1] == 'IncreaseDwellTime':\n",
    "            if float(key[2]) == 1:\n",
    "                timeDwell = timeDwell + 100\n",
    "        elif key[1] == 'DecreaseDwellTime':\n",
    "            #print(key[2])\n",
    "            if float(key[2]) == 1:\n",
    "                timeDwell = timeDwell - 100\n",
    "        else:\n",
    "            userKeys[nKey].append(str(float(key[2])*timeDwell))\n",
    "    \n",
    "    return userKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will return the datetime in items which is the closest to the date pivot\n",
    "def nearestTimePoint(dates, date):\n",
    "    \n",
    "    for d in dates:\n",
    "        if d < date:\n",
    "            nearestTP = d\n",
    "        else:\n",
    "            continue\n",
    "    try: \n",
    "        nearestTP\n",
    "        nearestTPind = dates.index(nearestTP)\n",
    "    except:\n",
    "        nearestTP = 0\n",
    "        nearestTPind = -1\n",
    "        \n",
    "    return nearestTP, nearestTPind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAndRemoveTrials(session_name, dictionary_saved, trials, replacingList):\n",
    "    # function to check the session_name in the dictionary_saved and remove those trials from the dictionary_trial\n",
    "    \n",
    "    if session_name in dictionary_saved:\n",
    "        index_list = dictionary_saved[session_name]\n",
    "    else:\n",
    "        index_list = replacingList\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    if index_list:\n",
    "        if type(trials) == list:\n",
    "            for index in sorted(index_list, reverse=True):\n",
    "                del trials[index]\n",
    "                \n",
    "        else:\n",
    "            for index in sorted(index_list, reverse=True):\n",
    "                del trials['start'][index]\n",
    "                del trials['end'][index]\n",
    "            \n",
    "    return trials    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert list of date and time into datetime format list\n",
    "def timeConversion(timeStrList):\n",
    "    timeList = list()\n",
    "    for time in timeStrList:\n",
    "        time1, t1, t2 = time.partition('+')\n",
    "        timeList.append(datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\"))\n",
    "    return timeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OptiKeyTypingTime(UserKeys):\n",
    "    \n",
    "    TimeTyping = dict()\n",
    "    \n",
    "    time1, t1, t2 = UserKeys[0][0].partition('+')\n",
    "    startTime = datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "    \n",
    "    time2, t1, t2 = UserKeys[-1][0].partition('+')\n",
    "    endTime = datetime.datetime.strptime(re.sub('[:.T]','-',time2[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "    \n",
    "    TimeTyping['startTime'] = startTime\n",
    "    TimeTyping['endTime'] = endTime\n",
    "    \n",
    "    return TimeTyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindExptStartEndTimes(KeysSelected, timeTyping, full_path):\n",
    "    # function to find start and end of tasks in experiments\n",
    "    \n",
    "    # session name\n",
    "    session_folder_name = full_path.split('\\\\')[-1]\n",
    "    \n",
    "    timeTrialDict = dict()\n",
    "    timeTrialDict = {'start': [],\n",
    "                    'end':[]}\n",
    "    \n",
    "    nTrial = -1\n",
    "    \n",
    "    \n",
    "    \n",
    "    for keys in KeysSelected:\n",
    "        \n",
    "            \n",
    "        \n",
    "        if keys[1] == 'NextPhrase':\n",
    "            nTrial = nTrial + 1\n",
    "            time1, t1, t2 = keys[0].partition('+')\n",
    "            endTimeTrial = datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "            \n",
    "            if nTrial != 0:\n",
    "                # print('end: ', endTimeTrial)\n",
    "                #print('')\n",
    "                timeTrialDict['end'].append(endTimeTrial)\n",
    "            \n",
    "            \n",
    "            startTimeTrial = endTimeTrial + datetime.timedelta(seconds=5)\n",
    "            \n",
    "            #print('start: ', startTimeTrial)\n",
    "            timeTrialDict['start'].append(startTimeTrial)\n",
    "        \n",
    "    del timeTrialDict['start'][-1]\n",
    "    \n",
    "    \n",
    "    # remove the extra selections of NewPhrase at the end of some sessions\n",
    "    replacingList = []\n",
    "    timeTrialDict = findAndRemoveTrials(session_folder_name, dict_keySelectionOfNextPhrase, timeTrialDict, replacingList)\n",
    "    \n",
    "    timeTrialDict_copy = copy.deepcopy(timeTrialDict)\n",
    "    \n",
    "    # separate the reading and writing trials for some participants who read in the actual trial, but write in the next\n",
    "    # trial\n",
    "    if session_folder_name in dict_keySelection_ReadingTrials:\n",
    "        # check the reading and writing separate dictionaries\n",
    "        print('reading and writing sessions are separate')\n",
    "        \n",
    "        #print(len(timeTrialDict['start']))\n",
    "        # writing trials - \n",
    "        timeTrialDict_writing = findAndRemoveTrials(session_folder_name, dict_keySelection_WritingTrials, timeTrialDict, replacingList)\n",
    "        #print(len(timeTrialDict_copy['start']))\n",
    "        \n",
    "        # reading trials\n",
    "        timeTrialDict_reading = findAndRemoveTrials(session_folder_name, dict_keySelection_ReadingTrials, timeTrialDict_copy, replacingList)\n",
    "    else:\n",
    "        # some participants skip some sentences, and then it affects the scoreQuestions too. Remove the skipped sentences or \n",
    "        # remove the score questions \n",
    "        # for these participants, reading and writing trials are the same\n",
    "        \n",
    "        #print('same reading and writing trials')\n",
    "        scoreQuestions = [0, 1, 3, 5, 7, 9, 11]\n",
    "        timeTrialDict = findAndRemoveTrials(session_folder_name, dict_keySelectionNotCompleted, timeTrialDict, scoreQuestions)\n",
    "        \n",
    "        # most of the skipped sentences are removed, but for those that are not removed\n",
    "        timeTrialDict_writing = findAndRemoveTrials(session_folder_name, dict_keySelection_phraseStim, timeTrialDict, replacingList)\n",
    "        \n",
    "        timeTrialDict_reading = timeTrialDict_writing \n",
    "        \n",
    "    \n",
    "          \n",
    "    return timeTrialDict_reading, timeTrialDict_writing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindReadingPartsOfTrial_inKeysSelected(EventTrials_reading, KeysSelected_new, full_path, userKeys):\n",
    "    # find the reading end in the pupil size data\n",
    "    \n",
    "    # session name\n",
    "    session_folder_name = full_path.split('\\\\')[-1]\n",
    "    \n",
    "    KeysSelected_timeStr = [key[0] for key in KeysSelected_new]\n",
    "    KeysSelected_time = timeConversion(KeysSelected_timeStr)\n",
    "    \n",
    "    KeysSelected_keys = [key[1] for key in KeysSelected_new]\n",
    "    \n",
    "    userKeysTimeStr = [key[0] for key in userKeys]\n",
    "    userKeysTime = timeConversion(userKeysTimeStr)\n",
    "    \n",
    "    EventReading = dict()    \n",
    "    EventReading['start'] = list()\n",
    "    EventReading['end'] = list()\n",
    "    \n",
    "    EventReading_index = dict()    \n",
    "    EventReading_index['start'] = list()\n",
    "    EventReading_index['end'] = list()\n",
    "    \n",
    "    for ind, startTrialTime_afterCoolDown in enumerate(EventTrials_reading['start']):\n",
    "        \n",
    "        startTrialTime, startTrialInd = nearestTimePoint(KeysSelected_time, startTrialTime_afterCoolDown)\n",
    "        \n",
    "        \n",
    "        EventReading['start'].append(KeysSelected_time[startTrialInd]+datetime.timedelta(seconds=5)) # start time needs \n",
    "        #to start 5s later, which is when the phrase is visible\n",
    "        EventReading_index['start'].append(startTrialInd) \n",
    "        \n",
    "        \n",
    "        #print(ind, EventReading['start'][-1], EventReading_index['start'][-1])\n",
    "        \n",
    "        endTrialTime = EventTrials_reading['end'][ind]\n",
    "        endTrialInd = KeysSelected_time.index(endTrialTime)\n",
    "        \n",
    "        keysSelected_trial = KeysSelected_keys[startTrialInd:endTrialInd]\n",
    "        \n",
    "        \n",
    "        for i, key in enumerate(keysSelected_trial):\n",
    "            if len(key) == 1:\n",
    "                endReading_keyInd = startTrialInd + keysSelected_trial.index(key) - 1\n",
    "                break\n",
    "                    \n",
    "        endReading_keyTime = KeysSelected_time[endReading_keyInd]\n",
    "        \n",
    "        \"\"\"\n",
    "        # compute the end of reading time -- which is taken when the keyboard with phrases key is pressed\n",
    "        if session_folder_name not in dict_keyboardNotChange_ReadingTrials:\n",
    "            \n",
    "            for i, key in enumerate(keysSelected_trial):\n",
    "                if len(key) == 1:\n",
    "                    endReading_keyInd = startTrialInd + keysSelected_trial.index(key) - 1\n",
    "                    break\n",
    "                    \n",
    "            #endReading_keyInd = startTrialInd + keysSelected_trial.index('KeyboardWithPhrases') - 1\n",
    "            endReading_keyTime = KeysSelected_time[endReading_keyInd]\n",
    "            \n",
    "        else:\n",
    "            if ind == dict_keyboardNotChange_ReadingTrials[session_folder_name]:\n",
    "                endReading_keyInd = startTrialInd + keysSelected_trial.index('Sleep') - 1\n",
    "                endReading_keyTime = KeysSelected_time[endReading_keyInd]\n",
    "                \n",
    "            else:\n",
    "                endReading_keyInd = startTrialInd + keysSelected_trial.index('KeyboardWithPhrases') - 1\n",
    "                endReading_keyTime = KeysSelected_time[endReading_keyInd]\n",
    "                \n",
    "        \"\"\"       \n",
    "        \n",
    "        \n",
    "        userKeyTime, userKeyInd = nearestTimePoint(userKeysTime, KeysSelected_time[endReading_keyInd+1])\n",
    "        \n",
    "        # remove the dwell time from end of selecting the first key (letter/number)\n",
    "        EventReading['end'].append(KeysSelected_time[endReading_keyInd+1]-datetime.timedelta(milliseconds=\\\n",
    "                                    float(userKeys[userKeyInd][-1])))\n",
    "        \n",
    "        EventReading_index['end'].append(KeysSelected_time[endReading_keyInd+1])\n",
    "        \n",
    "        #print(ind, EventReading['start'][ind], EventReading['end'][ind])\n",
    "        \n",
    "        #print(ind)\n",
    "        #print('reading: ', EventReading['start'][ind], EventReading['end'][ind])\n",
    "        \n",
    "    \n",
    "    \n",
    "    return EventReading, EventReading_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindWritingPartsOfTrial_inKeysSelected(EventTrials_writing, KeysSelected_new, EventReading):\n",
    "    \n",
    "    KeysSelected_timeStr = [key[0] for key in KeysSelected_new]\n",
    "    KeysSelected_time = timeConversion(KeysSelected_timeStr)\n",
    "    \n",
    "    KeysSelected_keys = [key[1] for key in KeysSelected_new]\n",
    "    \n",
    "    EventWriting = dict()    \n",
    "    EventWriting['start'] = list()\n",
    "    EventWriting['end'] = list()\n",
    "    \n",
    "    EventWriting_index = dict()    \n",
    "    EventWriting_index['start'] = list()\n",
    "    EventWriting_index['end'] = list()\n",
    "    \n",
    "    for ind, startTrialTime_afterCoolDown in enumerate(EventTrials_writing['start']):\n",
    "        \n",
    "        startTrialTime, startTrialInd = nearestTimePoint(KeysSelected_time, startTrialTime_afterCoolDown)\n",
    "        \n",
    "        endTrialTime = EventTrials_writing['end'][ind]\n",
    "        endTimeReading = EventReading['end'][ind]\n",
    "        \n",
    "        \n",
    "        # for some participants, reading and writing trials are different. So their writing times will not be the end of \n",
    "        # the reading time.\n",
    "        # Regardless, the writing time should start later than when the reading time ends.\n",
    "        # We choose the starting time for writing as the one that is later than the start time from writing trials\n",
    "        # and end time from reading trials\n",
    "        \n",
    "        if startTrialTime > endTimeReading:\n",
    "            EventWriting['start'].append(startTrialTime)\n",
    "            EventWriting_index['start'].append(startTrialInd)\n",
    "        else:\n",
    "            EventWriting['start'].append(endTimeReading)\n",
    "            endTimeReading_keys, endTimeReading_ind = nearestTimePoint(KeysSelected_time, endTimeReading)\n",
    "            EventWriting_index['start'].append(KeysSelected_time.index(endTimeReading_keys))\n",
    "        \n",
    "        EventWriting['end'].append(endTrialTime)\n",
    "        EventWriting_index['end'].append(KeysSelected_time.index(endTrialTime))\n",
    "        \n",
    "        #print(ind)\n",
    "        #print('writing: ', EventWriting['start'][ind], EventWriting['end'][ind])\n",
    "        \n",
    "    \n",
    "    \n",
    "    return EventWriting, EventWriting_index     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gazeConvert2ColumnsTo1(GazeLog, columnIndwValidity_list, indValidity):\n",
    "    # function to convert pupilsizes from 2 columns for every pupil due to comma use instead of decimal, \n",
    "    # to proper pupil sizes\n",
    "    \n",
    "    #columnInd_list = [joinColumn1_1, joinColumn1_2, joinColumn2_1, joinColumn2_2]\n",
    "    \n",
    "    # number of columns in the final dictionary\n",
    "    nColumns = int(len(columnIndwValidity_list)/2)\n",
    "    \n",
    "    # dictionary of columns that are to be joined later\n",
    "    columns_beforeDecimal = dict()\n",
    "    columns_afterDecimal = dict()\n",
    "    \n",
    "    # dictionary of joined columns\n",
    "    columnsFinal = dict()\n",
    "    \n",
    "    # dictionary to find and equalize missing values in every column\n",
    "    missingVal_column = dict()\n",
    "    missingVal = list()\n",
    "    \n",
    "    # find correct index of validity column to be used, to find the actual columns relative to that\n",
    "    columnsValidity_inUse = list()\n",
    "    \n",
    "    for ind, row in enumerate(GazeLog):\n",
    "        #print(ind)\n",
    "        #print(sorted(list(np.where(np.array(row) == 'Valid')[0])+list(np.where(np.array(row)=='Invalid')[0]))[indValidity])\n",
    "\n",
    "        columnsValidity = (sorted(list(np.where(np.array(row) == 'Valid')[0])+list(np.where(np.array(row)=='Invalid')[0]))[indValidity])\n",
    "        columnsValidity_inUse.append(int(columnsValidity))\n",
    "    \n",
    "    columnsValidity_inUse = np.array(columnsValidity_inUse)\n",
    "    \n",
    "    columnInd_list = [[columnsValidity_inUse+i] for i in columnIndwValidity_list]\n",
    "    \n",
    "    \n",
    "    for ind in range(0, nColumns):\n",
    "        \n",
    "        dict_name = 'column' + str(ind+1)\n",
    "        columnsFinal[dict_name] = list()\n",
    "        columns_afterDecimal[dict_name] = list()\n",
    "                \n",
    "        #for indItem, item4 in enumerate(GazeLog):\n",
    "        #    if 'Invalid' not in item4:\n",
    "        #        if columnInd_list[2*ind+1][0][indItem] < len(item4):\n",
    "        #            columns_afterDecimal[dict_name].append(item4[columnInd_list[2*ind+1][0][indItem]])\n",
    "        #        else:\n",
    "        #            columns_afterDecimal[dict_name].append('0')\n",
    "        #    else:\n",
    "        #        columns_afterDecimal[dict_name].append('nan')\n",
    "        \n",
    "                \n",
    "        columns_beforeDecimal[dict_name] = [item4[columnInd_list[2*ind][0][indItem]] if 'Invalid' not in item4 else 'nan' for indItem, item4 in enumerate(GazeLog)]\n",
    "        columns_afterDecimal[dict_name] = [item4[columnInd_list[2*ind+1][0][indItem]] if 'Invalid' not in item4 and columnInd_list[2*ind+1][0][indItem] < len(item4) else 'nan' for indItem, item4 in enumerate(GazeLog)]\n",
    "\n",
    "        \n",
    "        for i in range(0, len(columns_beforeDecimal[dict_name])):\n",
    "            if 'Valid' not in columns_beforeDecimal[dict_name][i] and 'Valid' not in columns_afterDecimal[dict_name][i]:\n",
    "                if 'nan' not in columns_beforeDecimal[dict_name][i] and 'nan' not in columns_afterDecimal[dict_name][i]:\n",
    "                    if float(columns_afterDecimal[dict_name][i]) > 0: \n",
    "                        columnsFinal[dict_name].append(float(columns_beforeDecimal[dict_name][i]+'.'+columns_afterDecimal[dict_name][i]))\n",
    "                    else:\n",
    "                        columnsFinal[dict_name].append(np.nan)\n",
    "                else:\n",
    "                    columnsFinal[dict_name].append(np.nan)\n",
    "            else:\n",
    "                # Rarely, the pupil size is a whole number\n",
    "                columnsFinal[dict_name].append(np.nan) # we will ignore the row, since there is no way of automatically knowing which - \n",
    "                # right or left eye has whole number pupil size\n",
    "    \n",
    "        missingVal_column[dict_name] = np.argwhere(np.isnan(columnsFinal[dict_name]))\n",
    "        missingVal_column[dict_name] = list(itertools.chain.from_iterable(missingVal_column[dict_name])) # flatten the list\n",
    "        \n",
    "        missingVal.extend(missingVal_column[dict_name])\n",
    "        \n",
    "        \n",
    "    \n",
    "    missingVal = sorted(set(missingVal))\n",
    "    \n",
    "    # if one of the columns are nan, the other one is converted too\n",
    "    for column in range(0, nColumns):\n",
    "        dict_name = 'column' + str(column+1)\n",
    "        for ind in missingVal:\n",
    "            if ind < len(columnsFinal[dict_name]):\n",
    "                columnsFinal[dict_name][ind] = np.nan\n",
    "                \n",
    "    \n",
    "    return columnsFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hampel(dvec, radius=5, nsigma=3, rem_nomed=False):\n",
    "\n",
    "    # replace outliers with median values (hampel filter)\n",
    "    \n",
    "    mvec = pd.Series(dvec).rolling(radius*2+1, center=True, min_periods=radius).median()\n",
    "    svec = 1.4862 * np.abs(dvec-mvec).rolling(radius*2+1, center=True, min_periods=radius).median()\n",
    "    plonk = np.abs(dvec-mvec) > nsigma*svec\n",
    "    dvec = np.array(dvec)\n",
    "    dvec[plonk.tolist()] = mvec[plonk.tolist()]\n",
    "\n",
    "    # remove \"bad data\" where we cannot calculate a median value due to already missing values\n",
    "    if (rem_nomed):\n",
    "        dvec[np.isnan(mvec)] = np.nan\n",
    "    return dvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterBlinks_wBlinkData(pupilDataL, pupilDataR, timeInDatetime):\n",
    "    # filter any blinks and nan values lasting around 250ms (on average)\n",
    "    # first the single nan occurances are replaced with mean of the values on either sides, \n",
    "    # as they are assumed to be from hardware problems\n",
    "    # for the rest of the blinks, 250ms before and after the nan values are interpolated with a linear function\n",
    "    # returns a dataframe with pupil size, and timestamp\n",
    "    # http://faculty.washington.edu/chudler/facts.html\n",
    "   \n",
    "    \n",
    "    # create a dataframe from the pupilsize and time\n",
    "    pupilData_df = pd.DataFrame(list(zip(timeInDatetime, pupilDataL, pupilDataR)), columns=['timeStamp', 'pupilLeft', 'pupilRight'])\n",
    "    \n",
    "    # blink is every nan value in the range of 100-400ms \n",
    "    # 250 ms (22 samples) before and after the blink will also be removed\n",
    "    extraBlinkSamples = 18\n",
    "    \n",
    "    \n",
    "    #pupilData_woSingleMissingData = pupilData.copy()\n",
    "    #timeList_woSingleMissingData = timeInDatetime.copy()\n",
    "    #timeInS_woSingleMissingData = timeInS_Trial[-1]\n",
    "    \n",
    "    # in case of single missing data, that are due to hardware error, replace with the mean of the pupil size before and\n",
    "    # after the nan value\n",
    "    # missing values will be the same for left and right pupil\n",
    "    missingVal_Single = np.argwhere(np.isnan(pupilDataL))\n",
    "    missingVal_Single = list(itertools.chain.from_iterable(missingVal_Single)) # flatten the list \n",
    "    \n",
    "    \n",
    "    \n",
    "    # if no blinks present, return the data\n",
    "    if len(missingVal_Single) == 0:\n",
    "        interpolatedNan_bool = np.array([False]*len(pupilData_df['pupilLeft']))\n",
    "        return pupilData_df, interpolatedNan_bool\n",
    "    \n",
    "    # find the index and values to replace for single nan values\n",
    "    pupilData_tuples_replaceSingleNan_left = [(val, np.mean([pupilDataL[val-1], pupilDataL[val+1]])) for i, val in enumerate(missingVal_Single) if (val != 0 and val != (len(pupilDataL)-1)) if not np.isnan(pupilDataL[val-1]) and not np.isnan(pupilDataL[val+1])]\n",
    "    pupilData_tuples_replaceSingleNan_right = [(val, np.mean([pupilDataR[val-1], pupilDataR[val+1]])) for i, val in enumerate(missingVal_Single) if (val != 0 and val != (len(pupilDataR)-1)) if not np.isnan(pupilDataR[val-1]) and not np.isnan(pupilDataR[val+1])]\n",
    "    \n",
    "    \n",
    "    interpolatedNan_bool = np.array([True if ind in dict(pupilData_tuples_replaceSingleNan_left) else False for ind, val in enumerate(pupilDataL)])\n",
    "    missingData_single = interpolatedNan_bool\n",
    "    \n",
    "    # replace the single nan values with the mean of the pupil size on either sides\n",
    "    indList = -1\n",
    "    for ind, val in pupilData_tuples_replaceSingleNan_left:\n",
    "        indList = indList + 1\n",
    "        pupilData_df.iloc[ind, pupilData_df.columns.get_loc('pupilLeft')] = val\n",
    "        pupilData_df.iloc[ind, pupilData_df.columns.get_loc('pupilRight')] = pupilData_tuples_replaceSingleNan_right[indList][1]\n",
    "        \n",
    "    \n",
    "    # again, find the nan values in the pupil size\n",
    "    # the list missingVal_SingleDifference contains the index of the first blink, followed by the difference in the index\n",
    "    # to the next nan value\n",
    "    \n",
    "    \n",
    "    \n",
    "    # find the nan values again from pupilData['pupilLeft']\n",
    "    missingVal_Rest_trueFalse = pupilData_df['pupilLeft'].isnull()\n",
    "    missingVal_Rest = [i for i, x in enumerate(missingVal_Rest_trueFalse) if x]\n",
    "    \n",
    "    # if no blinks left, return the current pupilData\n",
    "    if len(missingVal_Rest) == 0:\n",
    "        return pupilData_df, interpolatedNan_bool\n",
    "\n",
    "    \n",
    "    # in the blinks left, find when the blinks start by finding a difference in the consecutive values of the indices\n",
    "    missingVal_RestDifference = [t - s for s, t in zip(missingVal_Rest, missingVal_Rest[1:])]\n",
    "    missingVal_RestDifference.insert(0, missingVal_Rest[0])\n",
    "    \n",
    "    blinkStart_tupleList = [(ind, sum(missingVal_RestDifference[0:ind+1])) for ind, val in enumerate(missingVal_RestDifference) if val != 1]\n",
    "    \n",
    "    blinkStart_tupleList_wLength = list()\n",
    "    \n",
    "    # create a list of tuples of blink start index and the length of the blink\n",
    "    ind = -1\n",
    "    blinkLengthSum = 0\n",
    "    for blink_ind, blinkStartInd in blinkStart_tupleList:\n",
    "        ind = ind + 1\n",
    "        if ind != len(blinkStart_tupleList) - 1:\n",
    "            \n",
    "            blinkLength = blinkStart_tupleList[ind+1][0]-blink_ind\n",
    "            blinkLengthSum = blinkLengthSum + blinkLength\n",
    "            \n",
    "            blinkStart_tupleList_wLength.append(tuple((blinkStartInd, blinkLength)))\n",
    "        else:\n",
    "            # for the last blink -- all blink lengths summed and subtracted from the length of the list\n",
    "            # missingVal_RestDifference \n",
    "            blinkLength = len(missingVal_RestDifference)-blinkLengthSum\n",
    "            blinkStart_tupleList_wLength.append(tuple((blinkStartInd, blinkLength)))\n",
    "     \n",
    "    \n",
    "    \n",
    "    \n",
    "    # create a vector with True if a blink was at the position\n",
    "    samplingFrequency = 90\n",
    "    blinkLengthMax = np.ceil(0.5*samplingFrequency)\n",
    "    blinkLengthMin = np.ceil(0.075*samplingFrequency)\n",
    "    blinkStart_tupleList_wLength_allMissingData = [(blinkStart, blinkLength) for blinkStart, blinkLength in blinkStart_tupleList_wLength]    \n",
    "    blinkStart_tupleList_wLength_maxBlinkLength = [(blinkStart, blinkLength) for blinkStart, blinkLength in blinkStart_tupleList_wLength if blinkLength<blinkLengthMax and blinkLength>blinkLengthMin]\n",
    "    \n",
    "    missingData_blinks_bool = np.array([False]*len(pupilData_df['pupilLeft']))\n",
    "    for blinkStart, blinkLength in blinkStart_tupleList_wLength_maxBlinkLength:\n",
    "        blinkIndices = np.arange(blinkStart, blinkStart + blinkLength).astype(int)\n",
    "        if blinkIndices[-1] > len(pupilDataL):\n",
    "            blinkIndices = np.arange(blinkStart, len(pupilDataL)-1)\n",
    "        missingData_blinks_bool[blinkIndices] = True\n",
    "        \n",
    "    \n",
    "    \n",
    "    missingData_blinks_boolAll = np.array([False]*len(pupilData_df['pupilLeft']))\n",
    "    for blinkStart, blinkLength in blinkStart_tupleList_wLength:\n",
    "        blinkIndices = np.arange(blinkStart, blinkStart + blinkLength).astype(int)\n",
    "        if blinkIndices[-1] > len(pupilDataL):\n",
    "            blinkIndices = np.arange(blinkStart, len(pupilDataL)-1)\n",
    "        missingData_blinks_boolAll[blinkIndices] = True\n",
    "        \n",
    "    missingDataOverall_bool = missingData_single + missingData_blinks_boolAll\n",
    "    \n",
    "    # add to vector with start and end of tuple\n",
    "    #beforeAfterNan = [False]*len(pupilData_df['pupilLeft'])\n",
    "    #for blinkStart, blinkLength in blinkStart_tupleList_wLength:\n",
    "    #    beforeAfterNan[blinkStart] = True\n",
    "    #    beforeAfterNan[blinkStart+blinkLength] = True\n",
    "    #    #print('start and end points: ', pupilData_df['timeStamp'][blinkStart], pupilData_df['timeStamp'][blinkStart + blinkLength])\n",
    "    \n",
    "    \n",
    "    # create lists with start and end values for the blinks, based on blinkStart_tupleList_wLength, regardless of the blink length\n",
    "    blink_missingData_startList = [blinkStartInd - extraBlinkSamples if (blinkStartInd - extraBlinkSamples) > 0 else 0 for blinkStartInd, blinkLength in blinkStart_tupleList_wLength]\n",
    "    blink_missingData_endList = [blinkStartInd + blinkLength + extraBlinkSamples if (blinkStartInd + blinkLength + extraBlinkSamples) < (len(pupilData_df['pupilLeft'])-1) else (len(pupilData_df['pupilLeft'])-1) for blinkStartInd, blinkLength in blinkStart_tupleList_wLength]\n",
    "    # create a list of tuples from the start and end points of the blink\n",
    "    blink_missingData_startEndTuple = [(blinkStart, blink_missingData_endList[ind]) for ind, blinkStart in enumerate(blink_missingData_startList)] \n",
    "    \n",
    "    \n",
    "    # check if blinks need to be combined - blinksCombine is a list of list of 2 elements, the index of the blinks that should be combined\n",
    "    blinksCombine = [[ind, ind+1] for ind, blink in enumerate(blink_missingData_startEndTuple[0:-1]) if blink[1] > blink_missingData_startEndTuple[ind+1][0]]\n",
    "        \n",
    "    if blinksCombine:\n",
    "        # combine blinks that need to be combined - if multiple consecutive blinks need to be removed: eg - [1, 2], [2, 3] \n",
    "        # are included in the blinksCombine, the combined version should be [1, 3] \n",
    "        blinksCombineFinal = list()\n",
    "        ind = -1\n",
    "        while ind < len(blinksCombine)-2:\n",
    "            \n",
    "            ind = ind + 1\n",
    "            blinkCombining = blinksCombine[ind]\n",
    "            blinksCombineFinal.append(blinkCombining)\n",
    "            while ind < len(blinksCombine)-2 and blinkCombining[1] == blinksCombine[ind+1][0]:\n",
    "                # change the ending of the last added blink of blinksCombineFinal\n",
    "                blinksCombineFinal[-1][1] = blinksCombine[ind+1][1]\n",
    "                ind = ind + 1\n",
    "            \n",
    "            \n",
    "        if len(blinksCombine) == 1:\n",
    "            blinksCombineFinal = blinksCombine.copy()\n",
    "            \n",
    "        \n",
    "        if blinksCombine[-1][1] != blinksCombineFinal[-1][1]:\n",
    "            if blinksCombine[-1][0] == blinksCombineFinal[-1][1]:\n",
    "                blinksCombineFinal[-1][1] = blinksCombine[-1][1]\n",
    "            else:\n",
    "                blinksCombineFinal.append(blinksCombine[-1])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    #    for w, z in groupby(sorted(list(blinksCombine)), lambda x, y=itertools.count(): next(y)-x):\n",
    "    #        group = list(z)\n",
    "    #        blinksCombineFinal.append(tuple((group[0], group[-1])))\n",
    "        \n",
    "        for x in sorted(blinksCombineFinal, reverse=True):\n",
    "            new_start = blink_missingData_startEndTuple[x[0]][0] \n",
    "            new_end = blink_missingData_startEndTuple[x[1]][1] \n",
    "            \n",
    "            x_start = x[0]\n",
    "            x_end = x[1]\n",
    "            \n",
    "            # delete also the blinkStart_tupleList_wLength, since it is going to be used to compute other metrics\n",
    "            for blinkRemove in range(x[1], x[0]-1, -1):\n",
    "                del blink_missingData_startEndTuple[blinkRemove]\n",
    "            \n",
    "            blink_missingData_startEndTuple.insert(x[0], tuple((new_start, new_end)))\n",
    "    \n",
    "    \n",
    "    #blinkAndNonBlinkDurationList = [length/90 for start, length in blinkStart_tupleList_wLength]\n",
    "    #timeInS_Trial_filter = timeInS_Trial[-1] - sum(blinkAndNonBlinkDurationList) \n",
    "    \n",
    "    \n",
    "    # remove blinks from data\n",
    "    for blinkStart, blinkEnd in blink_missingData_startEndTuple:\n",
    "        pupilData_df.loc[blinkStart:blinkEnd,'pupilLeft'] = np.nan\n",
    "        pupilData_df.loc[blinkStart:blinkEnd,'pupilRight'] = np.nan\n",
    "        replaceTrueList = range(blinkStart, blinkEnd+1, 1)\n",
    "        interpolatedNan_bool[replaceTrueList] = True\n",
    "    \n",
    "    \n",
    "    \n",
    "    pupilData_df['pupilLeft'] = pupilData_df['pupilLeft'].astype(float).interpolate('linear', limit_direction = 'both')\n",
    "    pupilData_df['pupilRight'] = pupilData_df['pupilRight'].astype(float).interpolate('linear', limit_direction = 'both')\n",
    "    \n",
    "    if pupilData_df.isnull().any().any():\n",
    "        print('nan values in filtered data')\n",
    "        #for i,val in enumerate(pupilData_filter[0:5000]):\n",
    "        #    print(i, val, pupilData_woSingleMissingData[i])\n",
    "        \n",
    "    \n",
    "    return pupilData_df, interpolatedNan_bool, missingData_blinks_bool, missingDataOverall_bool, blinkStart_tupleList_wLength_maxBlinkLength, blinkStart_tupleList_wLength_allMissingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FilterPupilSize_wBlinkData(GazeLog, TimeTyping, subjectAndSessionName):\n",
    "    # function that uses the list of start and end trial times to find the pupil sizes for those trials and plots them\n",
    "    \n",
    "    # first create a list of times in gaze log\n",
    "    timeStrGazeLog = [item3[0] for item3 in GazeLog]\n",
    "    # convert the list of strings to datetime formats\n",
    "    timeGazeLog = timeConversion(timeStrGazeLog)\n",
    "    \n",
    "    # internal time, to depict seconds\n",
    "    timeInternalGazeLog = [float(item3[1]) for item3 in GazeLog]\n",
    "    \n",
    "    # extract pupil sizes in decimals from the strange 2 columns for every pupil\n",
    "    pupil_indWrtValidityL = [1, 2]\n",
    "    pupil_validityL = 4\n",
    "    pupilLogL_raw = gazeConvert2ColumnsTo1(GazeLog, pupil_indWrtValidityL, pupil_validityL)\n",
    "    \n",
    "    pupil_indWrtValidityR = [1, 2]\n",
    "    pupil_validityR = 5\n",
    "    pupilLogR_raw = gazeConvert2ColumnsTo1(GazeLog, pupil_indWrtValidityR, pupil_validityR)\n",
    "    \n",
    "    \n",
    "    # reduce the data to start and end of typing time\n",
    "    timeTyping_start, timeTyping_startInd = nearestTimePoint(timeGazeLog, TimeTyping['startTime'])\n",
    "    timeTyping_end, timeTyping_endInd = nearestTimePoint(timeGazeLog, TimeTyping['endTime'])\n",
    "    \n",
    "    \n",
    "    pupilLogL_wDefinedTime = pupilLogL_raw['column1'][timeTyping_startInd:timeTyping_endInd+1]\n",
    "    pupilLogR_wDefinedTime = pupilLogR_raw['column1'][timeTyping_startInd:timeTyping_endInd+1]\n",
    "    \n",
    "    timeGazeLog_wDefinedTime = timeGazeLog[timeTyping_startInd:timeTyping_endInd+1]\n",
    "    \n",
    "    timeInS_GazeLog_wDefinedTime = timeInternalGazeLog[timeTyping_startInd:timeTyping_endInd+1]\n",
    "    timeInS_Difference = [(t - s)/1000000 for s, t in zip(timeInS_GazeLog_wDefinedTime, timeInS_GazeLog_wDefinedTime[1:])]\n",
    "    timeInS_Difference.insert(0, 0)\n",
    "    \n",
    "    \n",
    "    #timeInS = [sum(timeInS_Difference[:i]) for i, v in enumerate(timeInS_Difference)]\n",
    "    \n",
    "    \n",
    "    #pupilData_df, interpolated_items, missingData_fromBlinks, missingData, missingDataBlink_startNlength, \\\n",
    "    #missingDataAll_startNlength = filterBlinks_wBlinkData(pupilLogL_wDefinedTime, pupilLogR_wDefinedTime, timeGazeLog_wDefinedTime)\n",
    "    \n",
    "    pupilData_df, interpolated_items, missingData_fromBlinks, missingData, missingDataBlink_startNlength, \\\n",
    "    missingDataAll_startNlength = filterBlinks_wBlinkData(pupilLogL_raw['column1'], pupilLogR_raw['column1'], timeGazeLog)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #timeGazeLog_plot = np.arange(0, timeInS[-1], 1/90)\n",
    "    \n",
    "    #plotPupilSize_checkFilter(pupilData_df, pupilLogL_wDefinedTime, blinkStartAndEnd, 'blink removal', subjectAndSessionName)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    pupilData_df_hampel = dict()\n",
    "    \n",
    "    pupilData_df_hampel = pupilData_df.copy()\n",
    "    pupilData_df_hampel['pupilLeft'] = hampel(pupilData_df['pupilLeft'], 25, 3, False)\n",
    "    pupilData_df_hampel['pupilRight'] = hampel(pupilData_df['pupilRight'], 25, 3, False)\n",
    "        \n",
    "    \n",
    "        \n",
    "    return pupilData_df_hampel, interpolated_items, missingData_fromBlinks, missingData, missingDataBlink_startNlength, missingDataAll_startNlength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EventPartsFromPupilData(EventTimeInKeys, PupilSize_df, full_path):\n",
    "    \n",
    "    # session name\n",
    "    session_folder_name = full_path.split('\\\\')[-1]\n",
    "    \n",
    "    EventTime = dict()    \n",
    "    EventTime['start'] = list()\n",
    "    EventTime['end'] = list()\n",
    "    \n",
    "    EventIndex = dict()    \n",
    "    EventIndex['start'] = list()\n",
    "    EventIndex['end'] = list()\n",
    "    \n",
    "    EventBaseline_startKeyTime = list()\n",
    "    \n",
    "    for ind, eventStartInKeys in enumerate(EventTimeInKeys['start']):\n",
    "        \n",
    "        eventStartTime, eventStartInd = nearestTimePoint(PupilSize_df['timeStamp'].tolist(), eventStartInKeys)\n",
    "        eventEndTime, eventEndInd = nearestTimePoint(PupilSize_df['timeStamp'].tolist(), EventTimeInKeys['end'][ind])\n",
    "        \n",
    "        # reading start is the same as trial start\n",
    "        EventTime['start'].append(eventStartTime)\n",
    "        EventIndex['start'].append(eventStartInd)\n",
    "        \n",
    "        EventTime['end'].append(eventEndTime)\n",
    "        EventIndex['end'].append(eventEndInd)\n",
    "        \n",
    "        \n",
    "    return EventTime, EventIndex    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CombineReadingWriting(EventReading, EventWriting, EventReading_index, EventWriting_index):\n",
    "    \n",
    "    EventTrial = copy.deepcopy(EventReading)\n",
    "    EventTrialEnd = [endTime for endTime in EventWriting['end']]\n",
    "    EventTrial['end'] = EventTrialEnd\n",
    "    \n",
    "    EventTrial_index = copy.deepcopy(EventReading_index)\n",
    "    EventTrialEnd_index = [endTime for endTime in EventWriting_index['end']]\n",
    "    EventTrial_index['end'] = EventTrialEnd_index\n",
    "    \n",
    "    \n",
    "    return EventTrial, EventTrial_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetBlinkPropertiesForEvents(EventTrial_index, PupilData_df, MissingData_startNlength):\n",
    "    \n",
    "    samplingFrequency = 90\n",
    "    \n",
    "    blinkFrequencyList = list()\n",
    "    blinkDurationAverageList = list()\n",
    "    blinkDurationTotalList = list()\n",
    "    blinkCountList = list()\n",
    "    interBlinkDurationList = list()\n",
    "    \n",
    "    # for every trial event, find the blinks during that event\n",
    "    for ind, eventStart in enumerate(EventTrial_index['start']):\n",
    "        #print('eventStart: ', eventStart, PupilData_df['timeStamp'][eventStart])\n",
    "        blinkInd_missingData = np.array([indBlink for indBlink in range(0, len(MissingData_startNlength)) if \\\n",
    "                MissingData_startNlength[indBlink][0] > eventStart and MissingData_startNlength[indBlink][0] < \\\n",
    "                                         EventTrial_index['end'][ind]])\n",
    "        blinkDurations_trial = np.array([MissingData_startNlength[indBlink][1] for indBlink in blinkInd_missingData])\n",
    "        interBlinkDuration_trial = [MissingData_startNlength[indBlink][0] - MissingData_startNlength[indBlink-1][0] - \\\n",
    "                                  MissingData_startNlength[indBlink-1][1] for indBlink in blinkInd_missingData[1:]]\n",
    "        \n",
    "        \n",
    "        \n",
    "        trialTime = ((PupilData_df['timeStamp'][EventTrial_index['end'][ind]] - PupilData_df['timeStamp'][\\\n",
    "                                EventTrial_index['start'][ind]]).total_seconds())/60\n",
    "        \n",
    "        blinkCountList.append(len(blinkInd_missingData))\n",
    "        blinkFrequencyList.append(len(blinkInd_missingData)/trialTime)\n",
    "        \n",
    "        blinkDurationTotalList.append(sum(blinkDurations_trial)/samplingFrequency)\n",
    "        \n",
    "        interBlinkDurationList.append(np.mean(interBlinkDuration_trial)/samplingFrequency)\n",
    "        \n",
    "        blinkDurationAverageList.append(np.mean(blinkDurations_trial)/samplingFrequency)\n",
    "        MissingData_startNlength_array = np.array(MissingData_startNlength)\n",
    "        #print(MissingData_startNlength_array[blinkInd_missingData])\n",
    "        #print(len(blinkInd_missingData)/trialTime)\n",
    "        #print(sum(blinkDurations_trial)/samplingFrequency)\n",
    "        #print(np.mean(blinkDurations_trial)/samplingFrequency)\n",
    "        \n",
    "    Blink_df = pd.DataFrame(list(zip(blinkCountList, blinkFrequencyList, blinkDurationAverageList, blinkDurationTotalList,\\\n",
    "                                     interBlinkDurationList)), columns=['blinkCount', 'blinkFrequency', \\\n",
    "                                    'blinkDurationAverage', 'blinkDurationTotal', 'interBlinkDuration'])\n",
    "    Blink_df = Blink_df.fillna(0)\n",
    "    \n",
    "    \n",
    "    return Blink_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataForEveryTrial:\n",
    "    subjectID = ''\n",
    "    blockNumber = ''\n",
    "    sessionNumber = ''\n",
    "    variable = ''\n",
    "    dataForTrial = ''\n",
    "    resultPathName = ''\n",
    "   \n",
    "    \n",
    "    def printInfo(self):\n",
    "        dataFrame = pd.DataFrame(list(zip([self.subjectID]*len(self.dataForTrial), [self.blockNumber]*len(self.dataForTrial), [self.sessionNumber]*len(self.dataForTrial), range(0,len(self.dataForTrial)+1), self.dataForTrial)), columns=['subjectID', 'block', 'session', 'trial', self.variable])\n",
    "        \n",
    "        return dataFrame\n",
    "    \n",
    "    def AddToFile(self):\n",
    "        \n",
    "        dataFrame = pd.DataFrame(list(zip([self.subjectID]*len(self.dataForTrial), [self.blockNumber]*len(self.dataForTrial), [self.sessionNumber]*len(self.dataForTrial), range(0,len(self.dataForTrial)+1), self.dataForTrial)), columns=['subjectID', 'block', 'session', 'trial', self.variable])\n",
    "        book = load_workbook(self.resultPathName)\n",
    "        writer = pd.ExcelWriter(self.resultPathName, engine='openpyxl')\n",
    "        writer.book = book\n",
    "        writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "        startrow = writer.sheets['Sheet1'].max_row\n",
    "        dataFrame.to_excel(writer, startrow = startrow, index = False, header = False)\n",
    "        \n",
    "        writer.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject path E:\\Data\\Data\\ac\\1\\2019-02-11-11-18-30_1\n",
      "ac__1__2019-02-11-11-18-30_1\n",
      "subject and session name:  ac__1__2019-02-11-11-18-30_1\n",
      "eventReadingIndex:  {'start': [13080, 25308, 35214, 40898, 53724], 'end': [15263, 27497, 35981, 43004, 54546]}\n",
      "\n",
      "eventTrialIndex:   {'start': [13080, 25308, 35214, 40898, 53724], 'end': [23706, 33269, 39209, 51571, 57920]}\n",
      "  subjectID block session  trial  BlinkFrequency_writing\n",
      "0        ac     1       1      0               14.713004\n",
      "1        ac     1       1      1               12.165570\n",
      "2        ac     1       1      2               11.710261\n",
      "3        ac     1       1      3               11.353953\n",
      "4        ac     1       1      4                9.609495\n",
      "  subjectID block session  trial  BlinkDurationAverage_writing\n",
      "0        ac     1       1      0                      0.136715\n",
      "1        ac     1       1      1                      0.127350\n",
      "2        ac     1       1      2                      0.128571\n",
      "3        ac     1       1      3                      0.129630\n",
      "4        ac     1       1      4                      0.124074\n",
      "  subjectID block session  trial  InterBlinkDuration_writing\n",
      "0        ac     1       1      0                    3.974747\n",
      "1        ac     1       1      1                    4.662963\n",
      "2        ac     1       1      2                    4.848148\n",
      "3        ac     1       1      3                    5.221569\n",
      "4        ac     1       1      4                    5.877778\n",
      "subject path E:\\Data\\Data\\ac\\1\\2019-02-11-11-33-32_2\n",
      "ac__1__2019-02-11-11-33-32_2\n",
      "subject and session name:  ac__1__2019-02-11-11-33-32_2\n",
      "eventReadingIndex:  {'start': [13820, 32206, 65856, 94734, 125179], 'end': [17671, 42306, 75256, 102538, 130550]}\n",
      "\n",
      "eventTrialIndex:   {'start': [13820, 32206, 65856, 94734, 125179], 'end': [30712, 64267, 93238, 123638, 150434]}\n",
      "  subjectID block session  trial  BlinkFrequency_writing\n",
      "0        ac     1       2      0                9.939817\n",
      "1        ac     1       2      1               10.085583\n",
      "2        ac     1       2      2               10.516620\n",
      "3        ac     1       2      3               10.745832\n",
      "4        ac     1       2      4               13.588330\n",
      "  subjectID block session  trial  BlinkDurationAverage_writing\n",
      "0        ac     1       2      0                      0.133796\n",
      "1        ac     1       2      1                      0.115176\n",
      "2        ac     1       2      2                      0.107619\n",
      "3        ac     1       2      3                      0.133862\n",
      "4        ac     1       2      4                      0.124444\n",
      "  subjectID block session  trial  InterBlinkDuration_writing\n",
      "0        ac     1       2      0                    5.798068\n",
      "1        ac     1       2      1                    5.644167\n",
      "2        ac     1       2      2                    5.313072\n",
      "3        ac     1       2      3                    5.377778\n",
      "4        ac     1       2      4                    4.259637\n",
      "subject path E:\\Data\\Data\\ac\\2\\2019-02-12-15-00-04_1\n",
      "ac__2__2019-02-12-15-00-04_1\n",
      "subject and session name:  ac__2__2019-02-12-15-00-04_1\n",
      "eventReadingIndex:  {'start': [12434, 57610, 67405, 91333, 112994], 'end': [29097, 59263, 75778, 96159, 117932]}\n",
      "\n",
      "eventTrialIndex:   {'start': [12434, 57610, 67405, 91333, 112994], 'end': [56164, 65901, 89917, 111033, 126480]}\n",
      "  subjectID block session  trial  BlinkFrequency_writing\n",
      "0        ac     2       1      0               17.557066\n",
      "1        ac     2       1      1               11.397216\n",
      "2        ac     2       1      2               12.209008\n",
      "3        ac     2       1      3               13.073084\n",
      "4        ac     2       1      4                8.848238\n",
      "  subjectID block session  trial  BlinkDurationAverage_writing\n",
      "0        ac     2       1      0                      0.118939\n",
      "1        ac     2       1      1                      0.112698\n",
      "2        ac     2       1      2                      0.107639\n",
      "3        ac     2       1      3                      0.108333\n",
      "4        ac     2       1      4                      0.106349\n",
      "  subjectID block session  trial  InterBlinkDuration_writing\n",
      "0        ac     2       1      0                    3.255300\n",
      "1        ac     2       1      1                    3.831624\n",
      "2        ac     2       1      2                    4.793190\n",
      "3        ac     2       1      3                    3.949206\n",
      "4        ac     2       1      4                    5.970940\n",
      "subject path E:\\Data\\Data\\ac\\2\\2019-02-12-15-27-37_2\n",
      "ac__2__2019-02-12-15-27-37_2\n",
      "subject and session name:  ac__2__2019-02-12-15-27-37_2\n",
      "eventReadingIndex:  {'start': [10316, 19844, 31768, 40777, 45152], 'end': [12348, 22617, 33483, 41292, 48626]}\n",
      "\n",
      "eventTrialIndex:   {'start': [10316, 19844, 31768, 40777, 45152], 'end': [18356, 30333, 39448, 43780, 58455]}\n",
      "  subjectID block session  trial  BlinkFrequency_writing\n",
      "0        ac     2       2      0               12.587676\n",
      "1        ac     2       2      1               13.287234\n",
      "2        ac     2       2      2               12.678266\n",
      "3        ac     2       2      3               13.031383\n",
      "4        ac     2       2      4               11.532335\n",
      "  subjectID block session  trial  BlinkDurationAverage_writing\n",
      "0        ac     2       2      0                      0.121429\n",
      "1        ac     2       2      1                      0.118713\n",
      "2        ac     2       2      2                      0.129365\n",
      "3        ac     2       2      3                      0.120370\n",
      "4        ac     2       2      4                      0.107937\n",
      "  subjectID block session  trial  InterBlinkDuration_writing\n",
      "0        ac     2       2      0                    4.753846\n",
      "1        ac     2       2      1                    4.016049\n",
      "2        ac     2       2      2                    4.324786\n",
      "3        ac     2       2      3                    4.275556\n",
      "4        ac     2       2      4                    5.029444\n",
      "subject path E:\\Data\\Data\\ac\\3_MS\\2019-02-14-14-28-49_1\n",
      "ac__3_MS__2019-02-14-14-28-49_1\n",
      "subject and session name:  ac__3_MS__2019-02-14-14-28-49_1\n",
      "eventReadingIndex:  {'start': [14499, 23897, 35910, 46668, 69822], 'end': [16066, 25864, 37596, 50093, 72195]}\n",
      "\n",
      "eventTrialIndex:   {'start': [14499, 23897, 35910, 46668, 69822], 'end': [22301, 34384, 45071, 68308, 78807]}\n",
      "  subjectID block session  trial  BlinkFrequency_writing\n",
      "0        ac  3_MS       1      0                5.198212\n",
      "1        ac  3_MS       1      1               13.946377\n",
      "2        ac  3_MS       1      2                6.504447\n",
      "3        ac  3_MS       1      3                8.895719\n",
      "4        ac  3_MS       1      4                6.535866\n",
      "  subjectID block session  trial  BlinkDurationAverage_writing\n",
      "0        ac  3_MS       1      0                      0.109259\n",
      "1        ac  3_MS       1      1                      0.117677\n",
      "2        ac  3_MS       1      2                      0.109877\n",
      "3        ac  3_MS       1      3                      0.151111\n",
      "4        ac  3_MS       1      4                      0.111111\n",
      "  subjectID block session  trial  InterBlinkDuration_writing\n",
      "0        ac  3_MS       1      0                    7.024444\n",
      "1        ac  3_MS       1      1                    4.182011\n",
      "2        ac  3_MS       1      2                    7.962500\n",
      "3        ac  3_MS       1      3                    6.400000\n",
      "4        ac  3_MS       1      4                    7.957143\n",
      "subject path E:\\Data\\Data\\ac\\3_MS\\2019-02-14-14-45-49_2\n",
      "ac__3_MS__2019-02-14-14-45-49_2\n",
      "subject and session name:  ac__3_MS__2019-02-14-14-45-49_2\n",
      "eventReadingIndex:  {'start': [15204, 54823, 95760, 103997, 159496], 'end': [23774, 64864, 97203, 111317, 161602]}\n",
      "\n",
      "eventTrialIndex:   {'start': [15204, 54823, 95760, 103997, 159496], 'end': [53308, 94260, 102545, 158108, 175432]}\n",
      "  subjectID block session  trial  BlinkFrequency_writing\n",
      "0        ac  3_MS       2      0               12.063443\n",
      "1        ac  3_MS       2      1               10.654635\n",
      "2        ac  3_MS       2      2                9.104042\n",
      "3        ac  3_MS       2      3               12.232823\n",
      "4        ac  3_MS       2      4                9.765065\n",
      "  subjectID block session  trial  BlinkDurationAverage_writing\n",
      "0        ac  3_MS       2      0                      0.112963\n",
      "1        ac  3_MS       2      1                      0.128927\n",
      "2        ac  3_MS       2      2                      0.107407\n",
      "3        ac  3_MS       2      3                      0.124948\n",
      "4        ac  3_MS       2      4                      0.112889\n",
      "  subjectID block session  trial  InterBlinkDuration_writing\n",
      "0        ac  3_MS       2      0                    4.875385\n",
      "1        ac  3_MS       2      1                    5.559844\n",
      "2        ac  3_MS       2      2                    5.498611\n",
      "3        ac  3_MS       2      3                    4.737037\n",
      "4        ac  3_MS       2      4                    6.069444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject path E:\\Data\\Data\\ac\\4\\2019-02-18-14-59-21_1\n",
      "ac__4__2019-02-18-14-59-21_1\n",
      "subject and session name:  ac__4__2019-02-18-14-59-21_1\n",
      "eventReadingIndex:  {'start': [14031, 32465, 56136, 71063, 98137], 'end': [21119, 40652, 59930, 81244, 105142]}\n",
      "\n",
      "eventTrialIndex:   {'start': [14031, 32465, 56136, 71063, 98137], 'end': [31017, 54752, 69682, 96916, 120644]}\n",
      "  subjectID block session  trial  BlinkFrequency_writing\n",
      "0        ac     4       1      0               10.368192\n",
      "1        ac     4       1      1               12.637073\n",
      "2        ac     4       1      2               10.518716\n",
      "3        ac     4       1      3               10.658327\n",
      "4        ac     4       1      4                9.751800\n",
      "  subjectID block session  trial  BlinkDurationAverage_writing\n",
      "0        ac     4       1      0                      0.112865\n",
      "1        ac     4       1      1                      0.146801\n",
      "2        ac     4       1      2                      0.133918\n",
      "3        ac     4       1      3                      0.116846\n",
      "4        ac     4       1      4                      0.111905\n",
      "  subjectID block session  trial  InterBlinkDuration_writing\n",
      "0        ac     4       1      0                    5.498765\n",
      "1        ac     4       1      1                    4.592014\n",
      "2        ac     4       1      2                    5.198148\n",
      "3        ac     4       1      3                    5.478148\n",
      "4        ac     4       1      4                    5.988889\n",
      "subject path E:\\Data\\Data\\ac\\4\\2019-2-18-15-23-54_2\n",
      "ac__4__2019-2-18-15-23-54_2\n",
      "subject and session name:  ac__4__2019-2-18-15-23-54_2\n",
      "eventReadingIndex:  {'start': [12587, 16317, 25390, 29479, 41843], 'end': [13081, 18224, 25985, 32629, 44409]}\n",
      "\n",
      "eventTrialIndex:   {'start': [12587, 16317, 25390, 29479, 41843], 'end': [15048, 24131, 28158, 40584, 48421]}\n",
      "  subjectID block session  trial  BlinkFrequency_writing\n",
      "0        ac     4       2      0                5.494402\n",
      "1        ac     4       2      1                6.403763\n",
      "2        ac     4       2      2                7.460127\n",
      "3        ac     4       2      3                8.149353\n",
      "4        ac     4       2      4                6.723404\n",
      "  subjectID block session  trial  BlinkDurationAverage_writing\n",
      "0        ac     4       2      0                      0.122222\n",
      "1        ac     4       2      1                      0.114286\n",
      "2        ac     4       2      2                      0.111111\n",
      "3        ac     4       2      3                      0.121296\n",
      "4        ac     4       2      4                      0.122222\n",
      "  subjectID block session  trial  InterBlinkDuration_writing\n",
      "0        ac     4       2      0                   10.355556\n",
      "1        ac     4       2      1                    9.190741\n",
      "2        ac     4       2      2                    5.816667\n",
      "3        ac     4       2      3                    7.384848\n",
      "4        ac     4       2      4                    5.850000\n",
      "subject path E:\\Data\\Data\\ac\\5\\2019-02-19-15-07-5_1\n",
      "ac__5__2019-02-19-15-07-5_1\n",
      "subject and session name:  ac__5__2019-02-19-15-07-5_1\n",
      "eventReadingIndex:  {'start': [13019, 19094, 26239, 33164, 42612], 'end': [14083, 20662, 27458, 36040, 43694]}\n",
      "\n",
      "eventTrialIndex:   {'start': [13019, 19094, 26239, 33164, 42612], 'end': [17729, 25049, 31930, 41328, 48031]}\n",
      "  subjectID block session  trial  BlinkFrequency_writing\n",
      "0        ac     5       1      0                4.437976\n",
      "1        ac     5       1      1                8.622375\n",
      "2        ac     5       1      2                7.246340\n",
      "3        ac     5       1      3                7.150444\n",
      "4        ac     5       1      4                7.475925\n",
      "  subjectID block session  trial  BlinkDurationAverage_writing\n",
      "0        ac     5       1      0                      0.122222\n",
      "1        ac     5       1      1                      0.117460\n",
      "2        ac     5       1      2                      0.116667\n",
      "3        ac     5       1      3                      0.133333\n",
      "4        ac     5       1      4                      0.137037\n",
      "  subjectID block session  trial  InterBlinkDuration_writing\n",
      "0        ac     5       1      0                   10.355556\n",
      "1        ac     5       1      1                    5.303704\n",
      "2        ac     5       1      2                    7.953333\n",
      "3        ac     5       1      3                    7.090741\n",
      "4        ac     5       1      4                    7.228889\n",
      "subject path E:\\Data\\Data\\ac\\5\\2019-02-19-15-18-20_2\n",
      "ac__5__2019-02-19-15-18-20_2\n",
      "subject and session name:  ac__5__2019-02-19-15-18-20_2\n",
      "eventReadingIndex:  {'start': [13398, 28527, 38797, 62001, 92722], 'end': [17391, 32198, 48246, 73665, 95018]}\n",
      "\n",
      "eventTrialIndex:   {'start': [13398, 28527, 38797, 62001, 92722], 'end': [27272, 37569, 60786, 91510, 98230]}\n",
      "  subjectID block session  trial  BlinkFrequency_writing\n",
      "0        ac     5       2      0                7.107908\n",
      "1        ac     5       2      1                7.036546\n",
      "2        ac     5       2      2                9.480289\n",
      "3        ac     5       2      3               11.809884\n",
      "4        ac     5       2      4               13.459321\n",
      "  subjectID block session  trial  BlinkDurationAverage_writing\n",
      "0        ac     5       2      0                      0.115385\n",
      "1        ac     5       2      1                      0.114286\n",
      "2        ac     5       2      2                      0.141919\n",
      "3        ac     5       2      3                      0.129345\n",
      "4        ac     5       2      4                      0.126389\n",
      "  subjectID block session  trial  InterBlinkDuration_writing\n",
      "0        ac     5       2      0                    8.352778\n",
      "1        ac     5       2      1                    6.562963\n",
      "2        ac     5       2      2                    6.340212\n",
      "3        ac     5       2      3                    4.844444\n",
      "4        ac     5       2      4                    4.241270\n",
      "subject path E:\\Data\\Data\\af\\1\\2019-01-16-15-43-8_1\n",
      "af__1__2019-01-16-15-43-8_1\n",
      "subject and session name:  af__1__2019-01-16-15-43-8_1\n",
      "eventReadingIndex:  {'start': [51164, 124346, 160243, 185442, 213467], 'end': [98667, 146282, 170072, 194946, 215019]}\n",
      "\n",
      "eventTrialIndex:   {'start': [51164, 124346, 160243, 185442, 213467], 'end': [121965, 158428, 183229, 211427, 220194]}\n",
      "  subjectID block session  trial  BlinkFrequency_writing\n",
      "0        af     1       1      0                2.782550\n",
      "1        af     1       1      1                1.334717\n",
      "2        af     1       1      2                6.976385\n",
      "3        af     1       1      3                5.899503\n",
      "4        af     1       1      4                4.176870\n",
      "  subjectID block session  trial  BlinkDurationAverage_writing\n",
      "0        af     1       1      0                      0.166667\n",
      "1        af     1       1      1                      0.122222\n",
      "2        af     1       1      2                      0.175817\n",
      "3        af     1       1      3                      0.138272\n",
      "4        af     1       1      4                      0.108333\n",
      "  subjectID block session  trial  InterBlinkDuration_writing\n",
      "0        af     1       1      0                   20.832323\n",
      "1        af     1       1      1                   54.688889\n",
      "2        af     1       1      2                    8.396528\n",
      "3        af     1       1      3                    9.789542\n",
      "4        af     1       1      4                   13.400000\n",
      "subject path E:\\Data\\Data\\af\\1\\2019-01-16-16-36-17_1stPart_2\n",
      "af__1__2019-01-16-16-36-17_1stPart_2\n",
      "subject and session name:  af__1__2019-01-16-16-36-17_1stPart_2\n",
      "eventReadingIndex:  {'start': [68602, 83196, 90575], 'end': [70102, 83952, 92177]}\n",
      "\n",
      "eventTrialIndex:   {'start': [68602, 83196, 90575], 'end': [81480, 89008, 98035]}\n",
      "1stPart\n",
      "subject path E:\\Data\\Data\\af\\1\\2019-01-16-17-00-12_2ndPart_2\n",
      "af__1__2019-01-16-17-00-12_2ndPart_2\n",
      "subject and session name:  af__1__2019-01-16-17-00-12_2ndPart_2\n",
      "no gaze data present\n",
      "2ndPart\n",
      "  subjectID block session  trial  BlinkFrequency_writing\n",
      "0        af     1       2      0                7.595889\n",
      "1        af     1       2      1                2.137621\n",
      "2        af     1       2      2                2.767409\n",
      "3        af     1       2      3                     NaN\n",
      "4        af     1       2      4                     NaN\n",
      "5        af     1       2      5                     NaN\n",
      "6        af     1       2      6                     NaN\n",
      "  subjectID block session  trial  BlinkDurationAverage_writing\n",
      "0        af     1       2      0                      0.136806\n",
      "1        af     1       2      1                      0.133333\n",
      "2        af     1       2      2                      0.140741\n",
      "3        af     1       2      3                           NaN\n",
      "4        af     1       2      4                           NaN\n",
      "5        af     1       2      5                           NaN\n",
      "6        af     1       2      6                           NaN\n",
      "  subjectID block session  trial  InterBlinkDuration_writing\n",
      "0        af     1       2      0                    6.371852\n",
      "1        af     1       2      1                   44.211111\n",
      "2        af     1       2      2                    9.561111\n",
      "3        af     1       2      3                         NaN\n",
      "4        af     1       2      4                         NaN\n",
      "5        af     1       2      5                         NaN\n",
      "6        af     1       2      6                         NaN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject path E:\\Data\\Data\\af\\2\\2019-01-17-15-03-40_1\n",
      "af__2__2019-01-17-15-03-40_1\n",
      "subject and session name:  af__2__2019-01-17-15-03-40_1\n",
      "eventReadingIndex:  {'start': [46389, 56704, 63328, 72142, 89471], 'end': [47153, 57222, 63870, 79781, 100845]}\n",
      "\n",
      "eventTrialIndex:   {'start': [46389, 56704, 63328, 72142, 89471], 'end': [54910, 61721, 70757, 87651, 110731]}\n",
      "  subjectID block session  trial  BlinkFrequency_writing\n",
      "0        af     2       1      0                7.662958\n",
      "1        af     2       1      1               14.413220\n",
      "2        af     2       1      2               12.453969\n",
      "3        af     2       1      3                7.548644\n",
      "4        af     2       1      4                8.692241\n",
      "  subjectID block session  trial  BlinkDurationAverage_writing\n",
      "0        af     2       1      0                      0.130303\n",
      "1        af     2       1      1                      0.147222\n",
      "2        af     2       1      2                      0.225694\n",
      "3        af     2       1      3                      0.141414\n",
      "4        af     2       1      4                      0.159722\n",
      "  subjectID block session  trial  InterBlinkDuration_writing\n",
      "0        af     2       1      0                    7.593333\n",
      "1        af     2       1      1                    3.569697\n",
      "2        af     2       1      2                    3.936296\n",
      "3        af     2       1      3                    6.621111\n",
      "4        af     2       1      4                    6.352593\n",
      "subject path E:\\Data\\Data\\af\\2\\2019-01-17-15-27-20_1stPart_2\n",
      "af__2__2019-01-17-15-27-20_1stPart_2\n",
      "subject and session name:  af__2__2019-01-17-15-27-20_1stPart_2\n",
      "eventReadingIndex:  {'start': [39778, 46351, 86056, 129035], 'end': [40780, 67072, 106362, 158658]}\n",
      "\n",
      "eventTrialIndex:   {'start': [39778, 46351, 86056, 129035], 'end': [45125, 84445, 127079, 177987]}\n",
      "1stPart\n",
      "subject path E:\\Data\\Data\\af\\2\\2019-01-17-16-03-27_2ndPart_2\n",
      "af__2__2019-01-17-16-03-27_2ndPart_2\n",
      "subject and session name:  af__2__2019-01-17-16-03-27_2ndPart_2\n",
      "eventReadingIndex:  {'start': [11059, 42248], 'end': [28282, 43241]}\n",
      "\n",
      "eventTrialIndex:   {'start': [11059, 42248], 'end': [41044, 49178]}\n",
      "2ndPart\n",
      "  subjectID block session  trial  BlinkFrequency_writing\n",
      "0        af     2       2      0                8.687892\n",
      "1        af     2       2      1                8.084036\n",
      "2        af     2       2      2                5.194935\n",
      "3        af     2       2      3               10.328285\n",
      "4        af     2       2      4                8.462668\n",
      "5        af     2       2      5                6.369037\n",
      "  subjectID block session  trial  BlinkDurationAverage_writing\n",
      "0        af     2       2      0                      0.133333\n",
      "1        af     2       2      1                      0.150855\n",
      "2        af     2       2      2                      0.133889\n",
      "3        af     2       2      3                      0.145345\n",
      "4        af     2       2      4                      0.117778\n",
      "5        af     2       2      5                      0.115873\n",
      "  subjectID block session  trial  InterBlinkDuration_writing\n",
      "0        af     2       2      0                    6.631481\n",
      "1        af     2       2      1                    7.086222\n",
      "2        af     2       2      2                   10.242105\n",
      "3        af     2       2      3                    5.540123\n",
      "4        af     2       2      4                    7.176608\n",
      "5        af     2       2      5                    8.288889\n",
      "subject path E:\\Data\\Data\\af\\3_MS\\2019-02-06-15-44-15_1\n",
      "af__3_MS__2019-02-06-15-44-15_1\n",
      "subject and session name:  af__3_MS__2019-02-06-15-44-15_1\n",
      "eventReadingIndex:  {'start': [25375, 67404, 90298, 117132, 142568], 'end': [35782, 72663, 97469, 120749, 148718]}\n",
      "\n",
      "eventTrialIndex:   {'start': [25375, 67404, 90298, 117132, 142568], 'end': [65501, 88420, 115663, 141020, 172407]}\n",
      "  subjectID block session  trial  BlinkFrequency_writing\n",
      "0        af  3_MS       1      0                3.442611\n",
      "1        af  3_MS       1      1                3.428999\n",
      "2        af  3_MS       1      2                8.598420\n",
      "3        af  3_MS       1      3                5.855826\n",
      "4        af  3_MS       1      4                6.372413\n",
      "  subjectID block session  trial  BlinkDurationAverage_writing\n",
      "0        af  3_MS       1      0                      0.155556\n",
      "1        af  3_MS       1      1                      0.152222\n",
      "2        af  3_MS       1      2                      0.137165\n",
      "3        af  3_MS       1      3                      0.126768\n",
      "4        af  3_MS       1      4                      0.188492\n",
      "  subjectID block session  trial  InterBlinkDuration_writing\n",
      "0        af  3_MS       1      0                   16.764198\n",
      "1        af  3_MS       1      1                   15.903704\n",
      "2        af  3_MS       1      2                    6.818254\n",
      "3        af  3_MS       1      3                   10.051323\n",
      "4        af  3_MS       1      4                    8.696296\n",
      "subject path E:\\Data\\Data\\af\\3_MS\\2019-02-06-16-19-9_2\n",
      "af__3_MS__2019-02-06-16-19-9_2\n",
      "subject and session name:  af__3_MS__2019-02-06-16-19-9_2\n",
      "eventReadingIndex:  {'start': [32575, 44488, 50862, 65168, 69647], 'end': [33501, 45304, 52786, 65786, 71363]}\n",
      "\n",
      "eventTrialIndex:   {'start': [32575, 44488, 50862, 65168, 69647], 'end': [43040, 49339, 63749, 68165, 82008]}\n",
      "  subjectID block session  trial  BlinkFrequency_writing\n",
      "0        af  3_MS       2      0                4.531944\n",
      "1        af  3_MS       2      1                6.696341\n",
      "2        af  3_MS       2      2                2.956883\n",
      "3        af  3_MS       2      3                6.814401\n",
      "4        af  3_MS       2      4                3.553517\n",
      "  subjectID block session  trial  BlinkDurationAverage_writing\n",
      "0        af  3_MS       2      0                      0.152778\n",
      "1        af  3_MS       2      1                      0.120000\n",
      "2        af  3_MS       2      2                      0.112963\n",
      "3        af  3_MS       2      3                      0.196296\n",
      "4        af  3_MS       2      4                      0.149206\n",
      "  subjectID block session  trial  InterBlinkDuration_writing\n",
      "0        af  3_MS       2      0                   10.363492\n",
      "1        af  3_MS       2      1                    6.905556\n",
      "2        af  3_MS       2      2                   19.495556\n",
      "3        af  3_MS       2      3                    6.183333\n",
      "4        af  3_MS       2      4                   16.894444\n",
      "subject path E:\\Data\\Data\\af\\4\\2019-02-12-11-07-43_1\n",
      "af__4__2019-02-12-11-07-43_1\n",
      "subject and session name:  af__4__2019-02-12-11-07-43_1\n",
      "eventReadingIndex:  {'start': [29353, 33600, 39794, 43982, 53800], 'end': [30069, 34616, 40420, 44803, 54280]}\n",
      "\n",
      "eventTrialIndex:   {'start': [29353, 33600, 39794, 43982, 53800], 'end': [32160, 38408, 42739, 52568, 58628]}\n",
      "  subjectID block session  trial  BlinkFrequency_writing\n",
      "0        af     4       1      0                0.000000\n",
      "1        af     4       1      1                1.425053\n",
      "2        af     4       1      2                2.330234\n",
      "3        af     4       1      3                0.694760\n",
      "4        af     4       1      4                0.000000\n",
      "  subjectID block session  trial  BlinkDurationAverage_writing\n",
      "0        af     4       1      0                      0.000000\n",
      "1        af     4       1      1                      0.111111\n",
      "2        af     4       1      2                      0.155556\n",
      "3        af     4       1      3                      0.100000\n",
      "4        af     4       1      4                      0.000000\n",
      "  subjectID block session  trial  InterBlinkDuration_writing\n",
      "0        af     4       1      0                         0.0\n",
      "1        af     4       1      1                         0.0\n",
      "2        af     4       1      2                         0.0\n",
      "3        af     4       1      3                         0.0\n",
      "4        af     4       1      4                         0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject path E:\\Data\\Data\\af\\4\\2019-02-12-11-21-21_2\n",
      "af__4__2019-02-12-11-21-21_2\n",
      "subject and session name:  af__4__2019-02-12-11-21-21_2\n",
      "eventReadingIndex:  {'start': [22840, 56952, 62655, 78322, 99409], 'end': [36352, 58167, 66413, 85182, 104300]}\n",
      "\n",
      "eventTrialIndex:   {'start': [22840, 56952, 62655, 78322, 99409], 'end': [55671, 61450, 77057, 97780, 122821]}\n",
      "  subjectID block session  trial  BlinkFrequency_writing\n",
      "0        af     4       2      0                2.795623\n",
      "1        af     4       2      1                1.645997\n",
      "2        af     4       2      2                3.046129\n",
      "3        af     4       2      3                4.268995\n",
      "4        af     4       2      4                5.540785\n",
      "  subjectID block session  trial  BlinkDurationAverage_writing\n",
      "0        af     4       2      0                      0.148889\n",
      "1        af     4       2      1                      0.144444\n",
      "2        af     4       2      2                      0.138889\n",
      "3        af     4       2      3                      0.136667\n",
      "4        af     4       2      4                      0.161988\n",
      "  subjectID block session  trial  InterBlinkDuration_writing\n",
      "0        af     4       2      0                   21.424691\n",
      "1        af     4       2      1                    0.000000\n",
      "2        af     4       2      2                   18.195556\n",
      "3        af     4       2      3                   14.446914\n",
      "4        af     4       2      4                   10.279630\n",
      "subject path E:\\Data\\Data\\af\\5\\2019-02-27-15-08-32_1\n",
      "af__5__2019-02-27-15-08-32_1\n",
      "subject and session name:  af__5__2019-02-27-15-08-32_1\n",
      "eventReadingIndex:  {'start': [12512, 30303, 59279, 80318, 102636], 'end': [17160, 37105, 67107, 85988, 107010]}\n",
      "\n",
      "eventTrialIndex:   {'start': [12512, 30303, 59279, 80318, 102636], 'end': [28898, 57877, 78952, 101436, 122475]}\n",
      "  subjectID block session  trial  BlinkFrequency_writing\n",
      "0        af     5       1      0                2.761689\n",
      "1        af     5       1      1                2.860542\n",
      "2        af     5       1      2                1.824159\n",
      "3        af     5       1      3                1.042581\n",
      "4        af     5       1      4                2.444272\n",
      "  subjectID block session  trial  BlinkDurationAverage_writing\n",
      "0        af     5       1      0                      0.146296\n",
      "1        af     5       1      1                      0.131313\n",
      "2        af     5       1      2                      0.191667\n",
      "3        af     5       1      3                      0.111111\n",
      "4        af     5       1      4                      0.169841\n",
      "  subjectID block session  trial  InterBlinkDuration_writing\n",
      "0        af     5       1      0                   14.111111\n",
      "1        af     5       1      1                   15.050000\n",
      "2        af     5       1      2                   23.362963\n",
      "3        af     5       1      3                   21.138889\n",
      "4        af     5       1      4                   19.570370\n",
      "subject path E:\\Data\\Data\\af\\5\\2019-02-27-15-40-6_2\n",
      "af__5__2019-02-27-15-40-6_2\n",
      "subject and session name:  af__5__2019-02-27-15-40-6_2\n",
      "eventReadingIndex:  {'start': [21044, 29127, 36542, 42485, 51692], 'end': [21717, 30005, 37186, 43562, 52449]}\n",
      "\n",
      "eventTrialIndex:   {'start': [21044, 29127, 36542, 42485, 51692], 'end': [27845, 35240, 41257, 50033, 62342]}\n",
      "  subjectID block session  trial  BlinkFrequency_writing\n",
      "0        af     5       2      0                0.000000\n",
      "1        af     5       2      1                4.128788\n",
      "2        af     5       2      2                3.982171\n",
      "3        af     5       2      3                3.336663\n",
      "4        af     5       2      4                9.270350\n",
      "  subjectID block session  trial  BlinkDurationAverage_writing\n",
      "0        af     5       2      0                      0.000000\n",
      "1        af     5       2      1                      0.122222\n",
      "2        af     5       2      2                      0.196296\n",
      "3        af     5       2      3                      0.188889\n",
      "4        af     5       2      4                      0.194771\n",
      "  subjectID block session  trial  InterBlinkDuration_writing\n",
      "0        af     5       2      0                    0.000000\n",
      "1        af     5       2      1                   10.929630\n",
      "2        af     5       2      2                    6.822222\n",
      "3        af     5       2      3                    5.522222\n",
      "4        af     5       2      4                    5.390278\n",
      "subject path E:\\Data\\Data\\aq\\1\\2019-02-06-11-25-41_1\n",
      "aq__1__2019-02-06-11-25-41_1\n",
      "subject and session name:  aq__1__2019-02-06-11-25-41_1\n",
      "eventReadingIndex:  {'start': [21099, 52104, 84037, 111559, 164249, 193319, 216649], 'end': [26475, 57426, 89608, 129111, 170899, 199664, 229879]}\n",
      "\n",
      "eventTrialIndex:   {'start': [21099, 52104, 84037, 111559, 164249, 193319, 216649], 'end': [48631, 82057, 111116, 163799, 192869, 216199, 258700]}\n",
      "  subjectID block session  trial  BlinkFrequency_writing\n",
      "0        aq     1       1      0                7.559447\n",
      "1        aq     1       1      1                7.239913\n",
      "2        aq     1       1      2                8.039966\n",
      "3        aq     1       1      3                5.763666\n",
      "4        aq     1       1      4                4.427373\n",
      "5        aq     1       1      5                3.921772\n",
      "6        aq     1       1      6                7.300211\n",
      "  subjectID block session  trial  BlinkDurationAverage_writing\n",
      "0        aq     1       1      0                      0.142294\n",
      "1        aq     1       1      1                      0.128620\n",
      "2        aq     1       1      2                      0.127083\n",
      "3        aq     1       1      3                      0.163363\n",
      "4        aq     1       1      4                      0.148148\n",
      "5        aq     1       1      5                      0.138889\n",
      "6        aq     1       1      6                      0.143875\n",
      "  subjectID block session  trial  InterBlinkDuration_writing\n",
      "0        aq     1       1      0                    7.631111\n",
      "1        aq     1       1      1                    7.777778\n",
      "2        aq     1       1      2                    7.299283\n",
      "3        aq     1       1      3                   10.256790\n",
      "4        aq     1       1      4                   13.541176\n",
      "5        aq     1       1      5                   14.756566\n",
      "6        aq     1       1      6                    7.681287\n",
      "subject path E:\\Data\\Data\\aq\\1\\2019-02-06-12-37-45_2\n",
      "aq__1__2019-02-06-12-37-45_2\n",
      "subject and session name:  aq__1__2019-02-06-12-37-45_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-ae57d51b2314>\", line 142, in <module>\n",
      "    userKeys_new_wDwellTime)\n",
      "  File \"<ipython-input-13-0513de755db2>\", line 13, in FindReadingPartsOfTrial_inKeysSelected\n",
      "    userKeysTime = timeConversion(userKeysTimeStr)\n",
      "  File \"<ipython-input-10-0eba601d9327>\", line 6, in timeConversion\n",
      "    timeList.append(datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\"))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\_strptime.py\", line 577, in _strptime_datetime\n",
      "    tt, fraction, gmtoff_fraction = _strptime(data_string, format)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\_strptime.py\", line 426, in _strptime\n",
      "    second = int(found_dict['S'])\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "metricComputed_count = 'BlinkCount_writing'\n",
    "metricComputed_freq = 'BlinkFrequency_writing'\n",
    "metricComputed_durTotal = 'BlinkDurationTotal_writing'\n",
    "metricComputed_durAvg = 'BlinkDurationAverage_writing'\n",
    "metricComputed_interDur = 'InterBlinkDuration_writing'\n",
    "\n",
    "dataFolderName = r'E:\\Data\\Data' # accessing external hard disk with the data\n",
    "a = re.compile('(?<=Data\\\\\\\\Data\\\\\\\\)(.*)(?=\\\\\\\\[1-9])')\n",
    "subjectName_listElement = 3\n",
    "\n",
    "#dataFolderName = r'C:\\DTU\\Data\\201901_JanuaryExpt' # accessing data saved in the computer\n",
    "#a = re.compile('(?<=Data\\\\\\\\201901_JanuaryExpt\\\\\\\\)(.*)(?=\\\\\\\\[1-9])')\n",
    "#subjectName_listElement = 4\n",
    "\n",
    "resultFileName_count = r'C:\\DTU\\Data\\201901_JanuaryExpt\\DataExtracted\\IndividualTrials\\Blinks\\Subject_Block_Session_Trial_' + metricComputed_count +  '.xlsx'\n",
    "resultFileName_freq = r'C:\\DTU\\Data\\201901_JanuaryExpt\\DataExtracted\\IndividualTrials\\Blinks\\Subject_Block_Session_Trial_' + metricComputed_freq +  '.xlsx'\n",
    "resultFileName_durTotal = r'C:\\DTU\\Data\\201901_JanuaryExpt\\DataExtracted\\IndividualTrials\\Blinks\\Subject_Block_Session_Trial_' + metricComputed_durTotal +  '.xlsx'\n",
    "resultFileName_durAvg = r'C:\\DTU\\Data\\201901_JanuaryExpt\\DataExtracted\\IndividualTrials\\Blinks\\Subject_Block_Session_Trial_' + metricComputed_durAvg +  '.xlsx'\n",
    "resultFileName_interDur = r'C:\\DTU\\Data\\201901_JanuaryExpt\\DataExtracted\\IndividualTrials\\Blinks\\Subject_Block_Session_Trial_' + metricComputed_interDur +  '.xlsx'\n",
    "\n",
    "\n",
    "\n",
    "for root, dirs, subfolder in os.walk(dataFolderName):\n",
    "    \n",
    "    technique = 'dwell_time'\n",
    "    \n",
    "    if not dirs:\n",
    "        \n",
    "        #if 'notCompleted' in root or 'notInclude' in root: # Some subjects do not have gaze log and have been marked as \n",
    "        \n",
    "        if 'noData' in root or 'Trial' in root or 'trial' in root or 'Nothing' in root: # Some subjects do not have gaze log and have been marked as \n",
    "            #notInclude\n",
    "            continue\n",
    "        if 'Jonas' in root or 'Praktikant' in root or 'Villads' in root:\n",
    "            continue\n",
    "            \n",
    "        if 'Picture' in root:\n",
    "            continue\n",
    "        #if '_MS' not in root:\n",
    "        #    continue\n",
    "        \n",
    "        #if 'af\\\\1\\\\' not in root:\n",
    "        #    continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        #if '2019-1-16-16-36-17_1stPart_2' not in root:\n",
    "        #    continue\n",
    "            \n",
    "        keysSelected = None\n",
    "        userKeys = None\n",
    "        phraseLog = None\n",
    "        \n",
    "        for file in subfolder:\n",
    "            \n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'KeySelection*'):\n",
    "                try:\n",
    "                    \n",
    "                    fKeysSelected = open(root + '\\\\' + file, encoding='utf-8', newline='')\n",
    "                    readerKeysSelected = csv.reader(fKeysSelected)\n",
    "                    keysSelected = list(readerKeysSelected)\n",
    "                    \n",
    "                    keysSelected.remove(keysSelected[0])\n",
    "                except:\n",
    "                    if fKeysSelected is not None:\n",
    "                        fKeysSelected.close()\n",
    "                    else:\n",
    "                        print('error in opening the KeySelection log file')\n",
    "                        \n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'user*'):\n",
    "                try:\n",
    "                    fUserKey = open(root + '\\\\' + file, encoding='utf-8',  newline='')\n",
    "                    readerUserKey = csv.reader(fUserKey, quotechar=None)\n",
    "                    userKeys = list(readerUserKey)\n",
    "                    userKeys.remove(userKeys[0])\n",
    "                except:\n",
    "                    if fUserKey is not None:\n",
    "                        fUserKey.close()\n",
    "                    else:\n",
    "                        print('error in opening the user key log file')\n",
    "                        \n",
    "            if fnmatch.fnmatch(file, 'phrase*'):\n",
    "                try:\n",
    "                    fPhraseLog = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerPhraseLog = csv.reader(fPhraseLog, quotechar=None)\n",
    "                    phraseLog = list(readerPhraseLog)\n",
    "                    \n",
    "                except:\n",
    "                    if fPhraseLog is not None:\n",
    "                        fPhraseLog.close()\n",
    "                    else:\n",
    "                        print('error in opening the phrase log file')\n",
    "                        \n",
    "            if fnmatch.fnmatch(file, 'multiKey*'):\n",
    "                technique = 'multiKey_selection'\n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'tobiiGazeLog*'):\n",
    "                try:\n",
    "                    fGazeLog = open(root + '\\\\' + file, encoding='utf-8', newline='')\n",
    "                    readerGazeLog = csv.reader(fGazeLog, quotechar=None)\n",
    "                    gazeLog = list(readerGazeLog)\n",
    "                    gazeLog.remove(gazeLog[0])\n",
    "                    gazeLog.remove(gazeLog[-1])\n",
    "                except:\n",
    "                    if fGazeLog is not None:\n",
    "                        fGazeLog.close()\n",
    "                    else:\n",
    "                        print('error in opening the scratchpad log file')\n",
    "            \n",
    "                    \n",
    "                     \n",
    "        if keysSelected is None or userKeys is None or phraseLog is None or gazeLog is None:\n",
    "            continue\n",
    "        else:\n",
    "            \n",
    "            print('subject path', root)\n",
    "            subjAndSessionName = '__'.join(root.split('\\\\')[subjectName_listElement:])\n",
    "            print(subjAndSessionName)\n",
    "            subjName = subjAndSessionName.split('__')[0]\n",
    "            print('subject and session name: ', subjAndSessionName)\n",
    "            sessionFolderName = root.split('\\\\')[-1]\n",
    "            \n",
    "            # fix userKeys due to comma related file changes\n",
    "            userKeys_new = FixUserKeys(userKeys)\n",
    "            \n",
    "            # need to fix keys selected, where rows get combined because of an inverted comma\n",
    "            keysSelected_new = FixKeysSelected(keysSelected)\n",
    "            \n",
    "            # find start time of typing\n",
    "            timeTyping = OptiKeyTypingTime(userKeys_new)\n",
    "            \n",
    "            # divide complete data into epochs of phrases\n",
    "            timeStartEndKeys_reading, timeStartEndKeys_writing = FindExptStartEndTimes(keysSelected_new, timeTyping, root)\n",
    "            \n",
    "            userKeys_new_wDwellTime = ComputeDwellTime(userKeys_new, root)\n",
    "            \n",
    "            # use the times of trial start and end, to divide the time of trial into reading and writing\n",
    "            eventTrialsInKeysSelected_reading, eventTrialsInKeysSelected_readingIndex = \\\n",
    "            FindReadingPartsOfTrial_inKeysSelected(timeStartEndKeys_reading, keysSelected_new, root, \\\n",
    "                                                   userKeys_new_wDwellTime)\n",
    "            \n",
    "            eventTrialsInKeysSelected_writing, eventTrialsInKeysSelected_writingIndex = \\\n",
    "            FindWritingPartsOfTrial_inKeysSelected(timeStartEndKeys_writing, keysSelected_new, eventTrialsInKeysSelected_reading)\n",
    "            \n",
    "            \n",
    "            if sessionFolderName in dict_noGazeData:\n",
    "                print('no gaze data present')\n",
    "                blinkCount = [np.nan]*len(eventTrialsInKeysSelected_writing['start'])\n",
    "                blinkDurationTotal = [np.nan]*len(eventTrialsInKeysSelected_writing['start'])\n",
    "                blinkDurationAverage = [np.nan]*len(eventTrialsInKeysSelected_writing['start'])\n",
    "                blinkFrequency = [np.nan]*len(eventTrialsInKeysSelected_writing['start'])\n",
    "                interBlinkDuration = [np.nan]*len(eventTrialsInKeysSelected_writing['start'])\n",
    "            \n",
    "            else:\n",
    "                # filter the data\n",
    "                pupilData_filtered, interpolatedIndices, missingData_fromBlinks, missingData_overall, \\\n",
    "                missingDataBlink_startNlength, missingDataAll_startNlength  = FilterPupilSize_wBlinkData(gazeLog, \\\n",
    "                                                                            timeTyping, subjAndSessionName)\n",
    "                \n",
    "                \"\"\"\n",
    "                print('missing data ratio: ', sum(missingData_overall)/len(missingData_overall))\n",
    "                print('interpolated data ratio: ', sum(interpolatedIndices)/len(interpolatedIndices))\n",
    "                print('missing data from blinks ratio: ', sum(missingData_fromBlinks)/len(missingData_fromBlinks))\n",
    "                \n",
    "                blinkDurations = [item[1] for item in missingDataBlink_startNlength]\n",
    "                fig=plt.figure(), plt.hist(blinkDurations)\n",
    "                plt.title('blinkDurationHistograms')\n",
    "                pickle.dump(fig, open(r'C:\\DTU\\Results\\201901_Expt\\Blinks\\blinkDurationHistograms'+'\\\\'+subjName+'\\\\'+subjAndSessionName, 'wb'))\n",
    "                \n",
    "                missingDataAllDurations = [item[1] for item in missingDataAll_startNlength]\n",
    "                fig=plt.figure(), plt.hist(missingDataAllDurations)\n",
    "                plt.title('MissingDataLengthHistograms')\n",
    "                pickle.dump(fig, open(r'C:\\DTU\\Results\\201901_Expt\\Blinks\\MissingDataLengthHistograms'+'\\\\'+subjName+'\\\\'+subjAndSessionName, 'wb'))\n",
    "                \n",
    "                \n",
    "                \"\"\"\n",
    "                #print(missingDataBlink_startNlength)\n",
    "                \n",
    "                # divide trials into reading and writing\n",
    "                eventReading, eventReading_index = EventPartsFromPupilData(eventTrialsInKeysSelected_reading, pupilData_filtered, root)\n",
    "                eventWriting, eventWriting_index = EventPartsFromPupilData(eventTrialsInKeysSelected_writing, pupilData_filtered, root)\n",
    "                \n",
    "                eventTrial, eventTrial_index = CombineReadingWriting(eventReading, eventWriting, eventReading_index, eventWriting_index)\n",
    "                \n",
    "                print('eventReadingIndex: ', eventReading_index)\n",
    "                print('')\n",
    "                print('eventTrialIndex:  ', eventTrial_index)\n",
    "                \n",
    "                # compute blink durations for all trials\n",
    "                blink = GetBlinkPropertiesForEvents(eventWriting_index, pupilData_filtered, missingDataBlink_startNlength)\n",
    "                \n",
    "                blinkCount = blink['blinkCount'].tolist()\n",
    "                blinkFrequency = blink['blinkFrequency'].tolist()\n",
    "                blinkDurationAverage = blink['blinkDurationAverage'].tolist()\n",
    "                blinkDurationTotal = blink['blinkDurationTotal'].tolist()\n",
    "                interBlinkDuration = blink['interBlinkDuration'].tolist()\n",
    "                \n",
    "            if '1stPart' in root:\n",
    "                print('1stPart')\n",
    "                blinkCount1 = blinkCount\n",
    "                blinkFrequency1 = blinkFrequency\n",
    "                blinkDurationAverage1 = blinkDurationAverage\n",
    "                blinkDurationTotal1 = blinkDurationTotal\n",
    "                interBlinkDuration1 = interBlinkDuration\n",
    "                \n",
    "                continue\n",
    "            \n",
    "            if '2ndPart' in root:\n",
    "                print('2ndPart')\n",
    "                blinkCount2 = blinkCount\n",
    "                blinkFrequency2 = blinkFrequency\n",
    "                blinkDurationAverage2 = blinkDurationAverage\n",
    "                blinkDurationTotal2 = blinkDurationTotal\n",
    "                interBlinkDuration2 = interBlinkDuration\n",
    "                \n",
    "                blinkCount = blinkCount1 + blinkCount2\n",
    "                blinkFrequency = blinkFrequency1 + blinkFrequency2\n",
    "                blinkDurationAverage = blinkDurationAverage1 + blinkDurationAverage2\n",
    "                blinkDurationTotal = blinkDurationTotal1 + blinkDurationTotal2\n",
    "                interBlinkDuration = interBlinkDuration1 + interBlinkDuration2\n",
    "                \n",
    "                blinkCount1 = list()\n",
    "                blinkFrequency1 = list()\n",
    "                blinkDurationAverage1 = list()\n",
    "                blinkDurationTotal1 = list()\n",
    "                interBlinkDuration1 = list()\n",
    "                \n",
    "            \n",
    "            # save the blink count\n",
    "            dataToSave_count = DataForEveryTrial()\n",
    "            dataToSave_count.subjectID = subjAndSessionName.split('__')[0]\n",
    "            dataToSave_count.blockNumber = subjAndSessionName.split('__')[1]\n",
    "            dataToSave_count.sessionNumber = subjAndSessionName[-1]\n",
    "            dataToSave_count.variable = metricComputed_count\n",
    "            dataToSave_count.dataForTrial = blinkCount\n",
    "            dataToSave_count.resultPathName = resultFileName_count\n",
    "            \n",
    "            #print(dataToSave_count.printInfo())\n",
    "            \n",
    "            \n",
    "            # save the blink frequency\n",
    "            dataToSave_freq = DataForEveryTrial()\n",
    "            dataToSave_freq.subjectID = subjAndSessionName.split('__')[0]\n",
    "            dataToSave_freq.blockNumber = subjAndSessionName.split('__')[1]\n",
    "            dataToSave_freq.sessionNumber = subjAndSessionName[-1]\n",
    "            dataToSave_freq.variable = metricComputed_freq\n",
    "            dataToSave_freq.dataForTrial = blinkFrequency\n",
    "            dataToSave_freq.resultPathName = resultFileName_freq\n",
    "            \n",
    "            print(dataToSave_freq.printInfo())\n",
    "            \n",
    "            # save the blink duration total\n",
    "            dataToSave_durTotal = DataForEveryTrial()\n",
    "            dataToSave_durTotal.subjectID = subjAndSessionName.split('__')[0]\n",
    "            dataToSave_durTotal.blockNumber = subjAndSessionName.split('__')[1]\n",
    "            dataToSave_durTotal.sessionNumber = subjAndSessionName[-1]\n",
    "            dataToSave_durTotal.variable = metricComputed_durTotal\n",
    "            dataToSave_durTotal.dataForTrial = blinkDurationTotal\n",
    "            dataToSave_durTotal.resultPathName = resultFileName_durTotal\n",
    "            \n",
    "            #print(dataToSave_durTotal.printInfo())\n",
    "            \n",
    "            \n",
    "            # save the blink duration average\n",
    "            dataToSave_durAvg = DataForEveryTrial()\n",
    "            dataToSave_durAvg.subjectID = subjAndSessionName.split('__')[0]\n",
    "            dataToSave_durAvg.blockNumber = subjAndSessionName.split('__')[1]\n",
    "            dataToSave_durAvg.sessionNumber = subjAndSessionName[-1]\n",
    "            dataToSave_durAvg.variable = metricComputed_durAvg\n",
    "            dataToSave_durAvg.dataForTrial = blinkDurationAverage\n",
    "            dataToSave_durAvg.resultPathName = resultFileName_durAvg\n",
    "            \n",
    "            print(dataToSave_durAvg.printInfo())\n",
    "            \n",
    "            # save the inter blink duration \n",
    "            dataToSave_interDur = DataForEveryTrial()\n",
    "            dataToSave_interDur.subjectID = subjAndSessionName.split('__')[0]\n",
    "            dataToSave_interDur.blockNumber = subjAndSessionName.split('__')[1]\n",
    "            dataToSave_interDur.sessionNumber = subjAndSessionName[-1]\n",
    "            dataToSave_interDur.variable = metricComputed_interDur\n",
    "            dataToSave_interDur.dataForTrial = interBlinkDuration\n",
    "            dataToSave_interDur.resultPathName = resultFileName_interDur\n",
    "            \n",
    "            print(dataToSave_interDur.printInfo())\n",
    "            \n",
    "            \n",
    "            \n",
    "            #dataToSave_count.AddToFile()\n",
    "            dataToSave_freq.AddToFile()\n",
    "            #dataToSave_durTotal.AddToFile()\n",
    "            dataToSave_durAvg.AddToFile()\n",
    "            dataToSave_interDur.AddToFile()\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
