{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import fnmatch\n",
    "from pathlib import Path\n",
    "from itertools import groupby\n",
    "import copy\n",
    "import itertools\n",
    "import distance\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import snowball\n",
    "\n",
    "from itertools import *\n",
    "from operator import *\n",
    "\n",
    "# import other jupyter notebooks\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exceptional removal of particular extra sentences not typed by the user \n",
    "dict_phraseStim = {\n",
    "    '2019-01-30-11-22-25_1' : [4, 6, 7], # ys, session 4\n",
    "    '2019-01-31-09-37-5_2ndPart_2' : range(1,5), # bh1, session 4 , all sentences except the first one deleted\n",
    "    #'2019-02-05-14-10-39_2ndPart_2' : [1, 2, 3, 4, 5, 6, 9, 10],\n",
    "    #'2019-01-14-14-58-30' : [0], # ys, session_trial ()\n",
    "    '2019-01-16-16-36-17_1stPart_2' : [-1], # af_session1\n",
    "    '2019-01-16-17-00-12_2ndPart_2': [1], # af_session1\n",
    "    '2019-01-17-15-27-20_1stPart_2' : [4], # Af session2\n",
    "    '2019-01-17-16-03-27_2ndPart_2' : [0, 1, 2], # Af session2\n",
    "    '2019-02-06-11-25-41_1' : [7],               # aq_session1    \n",
    "    '2019-02-08-11-33-53_1stPart_1' : [1],  # aq session3_1_part1\n",
    "    '2019-02-08-12-11-34_2ndPart_1' : [0, 1, 2, 3],  # aq session3_1_part2\n",
    "    '2019-01-31-09-22-49_1stPart_2' : [4],  # bh1_session4_2_part1\n",
    "    '2019-02-14-13-28-20_1stPart_2' : [2], # ch_session3_2_part1\n",
    "    '2019-02-14-13-57-41_2ndPart_2' : [0, 2, 3], # ch_session3_2_part2\n",
    "    '2019-01-14-15-07-21_1' : [4], # ys_session1\n",
    "    '2019-01-16-15-18-50_1stPart_1' : [3, 4], # ys_session2\n",
    "    '2019-01-16-15-42-51_2ndPart_1' : [2], # ys_session2\n",
    "    '2019-01-30-11-22-25_1' : [3, 5, 7],          # ys_session4\n",
    "    '2019-01-16-15-18-0_1' : [4],            # no_session1\n",
    "    '2019-02-21-16-09-44_1stPart_1' : [1], # bh2_session1\n",
    "    '2019-02-21-16-22-22_2ndPart_1' : [2, 3, 4],# bh2_session1\n",
    "    '2019-02-28-17-03-53_1stPart_2' : [2],       # bh2_session3\n",
    "    '2019-02-28-17-24-2_2ndPart_2' : [0, 2],     # bh2_session3\n",
    "    '2019-02-21-15-01-4_1stPart_1' : [0],        # le_session3\n",
    "    '2019-02-21-15-25-56_2ndPart_1' : [1],        # le_session3\n",
    "    '2019-02-18-10-28-35_2' : [0],               # ls2_session4\n",
    "    '2019-02-05-14-00-27_1stPart_2' : [3],        # mh_session1\n",
    "    '2019-02-05-14-10-39_2ndPart_2' : [0, 1, 3],   # mh_session1\n",
    "    '2019-02-08-10-51-3_1stPart_1' : [4],        # mn_session1\n",
    "    '2019-02-08-11-05-7_2ndPart_1' : [0, 2, 3, 4], # mn_session1\n",
    "    '2019-02-19-10-34-7_1stPart_1' : [3],          # mn_session3\n",
    "    '2019-02-19-10-56-43_2ndPart_1' : [1, 2, 3, 4], # mn_session3\n",
    "    '2019-01-29-13-25-4_1' : [3],        # ph_session2\n",
    "    '2019-03-07-16-44-5_2' : [1],                   # rh_session1\n",
    "    '2019-03-14-13-56-56_2' : [2],                  # rh_session3\n",
    "    '2019-02-19-17-10-45_1' : [3]                  # ph_session5\n",
    "}\n",
    "\n",
    "# exceptional removal of sentences/words typed by the user, but then deleted everything to have a blank scratchpad\n",
    "\n",
    "dict_phraseUser = {\n",
    "    \"2019-02-06-15-44-15_1\" : [2, 3, 6], \n",
    "    \"2019-02-06-16-19-9_2\" : [1, 3, 6, 7],\n",
    "    \"2019-02-12-11-21-21_2\" : [0],\n",
    "    \"2019-02-14-14-28-49_1\" : [0, 2, 3], # ac_session3_1\n",
    "    \"2019-02-14-14-45-49_2\" : [0, 5, 6], # ac_session3_2\n",
    "    '2019-01-29-14-19-26_1' : [0, 3, 4], # bh1_session2_1\n",
    "    '2019-01-29-14-40-36_2' : [0, 1, 2], # bh1_session2_2\n",
    "    '2019-01-30-14-29-29_2' : [4],       # bh1_session3_2\n",
    "    '2019-01-31-09-12-2_1' : [3],         # bh1_session4_1\n",
    "    '2019-01-31-09-22-49_1stPart_2' : [4], # bh1_session4_2_part1\n",
    "    '2019-03-05-09-15-11_1' : [1],         # bh2_session5_1\n",
    "    '2019-03-05-09-15-11_2' : [1],        # bh2_session5_2\n",
    "    '2019-02-21-15-55-56_2' : [2],       # ch_session5_2\n",
    "    '2019-01-30-15-19-36_2' : [1],       # jm_session2_1\n",
    "    '2019-01-30-15-04-30_1' : [0],         # jm_session2_2\n",
    "    '2019-01-16-15-18-50_1stPart_1' : [1],  # ys_session2\n",
    "    '2019-01-16-15-42-51_2ndPart_1' : [0], # ys_session2\n",
    "    '2019-01-30-11-22-25_1' : [2, 4],       # ys_session4\n",
    "    '2019-01-30-11-57-3_2' : [0] ,          # ys_session4\n",
    "    '2019-01-31-13-13-2_1' : [4],           # ys_session5\n",
    "    '2019-01-30-10-20-32_1' : [0, 1, 2, 3, 4, 5], # no_session4\n",
    "    '2019-01-30-10-46-38_2' : [0],          # \n",
    "    '2019-02-28-17-03-53_1stPart_2' : [2],   # bh2_session3\n",
    "    '2019-03-12-09-30-5_1' : [0],            # kj_session3\n",
    "    '2019-02-13-15-20-38_1' : [0, 1, 2, 3, 6], # ls1_session3\n",
    "    '2019-02-18-10-25-52_1' : [1],              # ls2_session4\n",
    "    '2019-02-18-10-46-26_2' : [0],            # ls2_session4\n",
    "    '2019-01-29-13-25-4_1' : [0, 1, 7],        # ph_session2\n",
    "    '2019-01-29-13-43-50_2' : [0],              # ph_session2\n",
    "    '2019-03-07-16-17-30_1' : [0],              # rh_session1\n",
    "    '2019-03-07-16-44-5_2' : [0, 1],         # rh_session1\n",
    "    '2019-03-14-13-56-56_2' : [0, 1, 3]         # rh_session3\n",
    "}\n",
    "\n",
    "# key selection can have extra selections of NextPhrase at the end\n",
    "dict_keySelectionOfNextPhrase = {\n",
    "    \"2019-02-11-11-18-30_1\" : [12, 13], # ac_session1\n",
    "    \"2019-01-16-17-00-12_2ndPart_2\" : [12], # af_session1\n",
    "    \"2019-01-17-15-27-20_1stPart_2\" : [12], # af_session2\n",
    "    \"2019-02-06-16-19-9_2\" : [12], # af_session3\n",
    "    \"2019-02-12-11-07-43_1\" : [12], # af_session4\n",
    "    \"2019-02-27-15-08-32_1\" : [12], # af_session5\n",
    "    \"2019-01-28-14-30-44_1\" : [12], # bh1_session1\n",
    "    \"2019-02-21-16-22-22_2ndPart_1\" : [12], # bh2_session1\n",
    "    \"2019-02-18-14-02-56_2\" : [12], # le_session1\n",
    "    \"2019-02-19-10-03-14_1\" : [12], # le_session2\n",
    "    \"2019-02-08-11-05-7_2ndPart_1\" : [12], # mn_session1\n",
    "    \"2019-02-08-11-12-51_2\" : [12, 13], # mn_session1\n",
    "    \"2019-02-15-11-38-22_1\" : [12, 13], # mn_session2\n",
    "    \"2019-02-15-11-54-25_2\" : [12], # mn_session2\n",
    "    \"2019-01-16-15-18-0_1\" : [12], # no_session1\n",
    "    \"2019-01-28-13-31-51_1\" : [12], # ph_session1\n",
    "    \"2019-01-28-13-49-14_2\" : [12], # ph_session1\n",
    "    \"2019-01-14-15-07-21_1\" : [12], # ys_session1\n",
    "    \"2019-01-17-15-05-1_1\" : [12], # ys_session3\n",
    "    \"2019-01-30-11-22-25_1\" : [12], # ys_session4\n",
    "    \"2019-01-31-13-32-2_2\" : [12], # ys_session5\n",
    "}\n",
    "\n",
    "\n",
    "# key selection when participants skips some sentences\n",
    "dict_keySelectionNotCompleted = {\n",
    "    \"2019-01-16-16-36-17_1stPart_2\" : [0, 1, 3, 5, 7], # af_session1 ---- last sentence is not finished\n",
    "    \"2019-01-16-17-00-12_2ndPart_2\" : [0, 1, 3, 4, 5, 7, 9, 11], # af_session1\n",
    "    \"2019-01-17-15-27-20_1stPart_2\" : [0, 1, 3, 5, 7, 9, 11], # af_session2 \n",
    "    \"2019-01-17-16-03-27_2ndPart_2\" : [0, 1, 2, 3, 4, 5, 6, 7, 9, 11], # af_session2\n",
    "    \"2019-02-08-11-33-53_1stPart_1\" : [0, 1, 3, 4, 5, 7, 9, 11], # aq_session3\n",
    "    \"2019-02-08-12-11-34_2ndPart_1\" : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11], # aq_session3\n",
    "    \"2019-01-31-09-22-49_1stPart_2\": [0, 1, 3, 5, 7, 9, 10, 11], # bh1_session4\n",
    "    \"2019-01-31-09-37-5_2ndPart_2\" : [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11], # bh1_session4\n",
    "    \"2019-02-21-16-09-44_1stPart_1\" : [0, 1, 3, 4, 5, 7, 9, 11], # bh2_session1\n",
    "    \"2019-02-21-16-22-22_2ndPart_1\" : [0, 1, 3, 5, 6, 7, 8, 9, 10, 11], # bh2_session1\n",
    "    \"2019-02-28-17-03-53_1stPart_2\" : [0, 1, 3, 5, 6, 7, 9, 11], # bh2_session3\n",
    "    \"2019-02-28-17-24-2_2ndPart_2\" : [0, 1, 2, 3, 5], # bh2_session3     ----\n",
    "    \"2019-02-14-13-28-20_1stPart_2\" : [0, 1, 3, 5, 6, 7, 9, 11], # cw_session3\n",
    "    \"2019-02-14-13-57-41_2ndPart_2\" : [0, 1, 2, 3, 5, 6, 7, 8, 9, 11], # cw_session3\n",
    "    \"2019-02-21-15-01-4_1stPart_1\" : [0, 1, 2, 3, 5, 7, 9, 11], # le_session3\n",
    "    \"2019-02-21-15-25-56_2ndPart_1\" : [0, 1, 3], # le_session3       ----\n",
    "    \"2019-02-05-14-00-27_1stPart_2\" : [0, 1, 3, 5, 7, 8], # mh_session1\n",
    "    \"2019-02-05-14-10-39_2ndPart_2\" : [0, 1, 2, 3, 4, 5, 7, 8, 9, 11], # mh_session1\n",
    "    \"2019-02-08-10-51-3_1stPart_1\" : [0, 1, 3, 5, 7, 9, 10, 11], # mn_session1\n",
    "    \"2019-02-19-10-34-7_1stPart_1\" : [0, 1, 3, 5, 7, 8, 9, 11], # mn_session3\n",
    "    \"2019-02-19-10-56-43_2ndPart_1\" : [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11], # mn_session3\n",
    "    \"2019-01-29-13-25-4_1\" : [0, 1, 3, 5, 7], # ph_session2  -- sessions where there are less score questions \n",
    "    # and more sentences typed\n",
    "    \"2019-01-16-15-18-50_1stPart_1\" : [0, 1, 3, 5, 7, 8, 9, 10], # ys_session2\n",
    "    \"2019-01-17-15-05-1_1\" : [0, 1, 3, 5],  # ys_session3  -- sessions where there are less score questions \n",
    "    # and more sentences typed\n",
    "    \"2019-02-06-11-25-41_1\" : [0, 1, 3, 5, 11], # aq_session1 -- sessions where there are less score questions \n",
    "    # and more sentences typed\n",
    "    \"2019-01-16-15-42-51_2ndPart_1\" : [0, 1, 2, 5], # ys_session2 -- different for reading and writing, this one is for\n",
    "    # writing\n",
    "    '2019-01-30-11-22-25_1' : [0, 1, 3, 5, 7, 9, 11],   # ys_session4 -- sessions where there are less score questions \n",
    "    # and more sentences typed\n",
    "    \"2019-02-08-11-05-7_2ndPart_1\" : [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11] # mn_session1 -- -- different for reading and \n",
    "    # writing, this one is for writing\n",
    "}\n",
    "\n",
    "# dictionary for phrase removal just like in the dict_phraseStim, but since not all participants require that, some that \n",
    "# do, are added to this new dictionary here\n",
    "dict_keySelection_phraseStim = {\n",
    "    '2019-01-17-15-27-20_1stPart_2' : [4], # Af session2\n",
    "    '2019-01-16-15-18-0_1' : [4],        # no_session1\n",
    "    '2019-02-19-17-10-45_1' : [3],                  # ph_session5\n",
    "    '2019-03-07-16-44-5_2' : [1],        # rh_session1\n",
    "    '2019-03-14-13-56-56_2' : [2],              # rh_session3\n",
    "    '2019-01-14-15-07-21_1' : [4]         # ys_session1\n",
    "}\n",
    "\n",
    "\n",
    "# in the beginning experiments, not everyone started with 800 initial dwell time\n",
    "\n",
    "dict_dwellTimeOrig_not800 = {\n",
    "    \"2019-01-16-15-51-13_2\" : 600, # no_session1\n",
    "    \"2019-01-16-15-18-0_1\" : 600, # no_session1\n",
    "    \"2019-01-16-15-43-8_1\" : 100, # af_session1\n",
    "    \"2019-01-16-16-36-17_1stPart_2\" : 100, # af_session1\n",
    "    \"2019-01-16-17-00-12_2ndPart_2\" : 100, # af_session1\n",
    "    \"2019-01-17-15-03-40_1\" : 100, # af_session2\n",
    "    \"2019-01-17-15-27-20_1stPart_2\" : 0, # af_session2\n",
    "    \"2019-01-17-16-03-27_2ndPart_2\" : 100, # af_session2\n",
    "    \"2019-01-14-15-07-21_1\" : 500, # ys_session1\n",
    "    \"2019-01-14-15-25-55_2\" : 300, # ys_session1\n",
    "    \"2019-01-16-15-18-50_1stpart_1\" : 200, # ys_session2\n",
    "    \"2019-01-16-15-42-51_2ndPart_1\" : 100, # ys_session2\n",
    "    \"2019-01-16-15-59-55_2\" : 100, # ys_session2\n",
    "    \"2019-01-17-15-05-1_1\" : 100, # ys_session3\n",
    "    \"2019-01-17-15-31-12_2\" : 100 # ys_session3\n",
    "}\n",
    "\n",
    "\n",
    "# list of all things that should be present when computing effective time\n",
    "list_keysToBeCounted = ['Comma', 'BackOne', 'BackMany', 'SpaceBar']\n",
    "\n",
    "# some sessions do not have gaze data\n",
    "dict_noGazeData = {\n",
    "    '2019-01-16-17-00-12_2ndPart_2' : 'no gaze data', # af_session2\n",
    "    '2019-01-17-15-31-12_2' : 'no gaze data', #ys_session2\n",
    "    '2019-01-30-11-57-3_2' : 'no gaze data' # ys_session4\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_keySelection_ReadingTrials = {\n",
    "    \"2019-01-16-15-42-51_2ndPart_1\" : [0, 1, 3, 5], # ys_session2 \n",
    "}\n",
    "\n",
    "dict_keySelection_WritingTrials = {\n",
    "    \"2019-01-16-15-42-51_2ndPart_1\" : [0, 1, 2, 5], # ys_session2   \n",
    "}\n",
    "\n",
    "# normally, reading part of trial ends when people look at the keyboardwithphrases. For some trials, this is not done,\n",
    "# as the reading is done, and the trial is accidentally skipped, and written in the next trial. Here, the trial number \n",
    "# given will have the reading time ending as sleep, and not keyboard with phrases. \n",
    "dict_keyboardNotChange_ReadingTrials = {\n",
    "    \"2019-01-16-15-42-51_2ndPart_1\" : 0, # ys_session2 \n",
    "}\n",
    "\n",
    "dict_keySelection_firstSleepNotCounted = {\n",
    "    \"2019-01-28-14-50-41_2\" : (0, 2), # bh1_session1 -- 3rd sleep activation to be counted\n",
    "    \"2019-02-19-10-56-43_2ndPart_1\" : 2  # mn_session3 -- 3rd sleep activation is to be counted\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_TrialQuestionClean = {'2019-01-17-15-27-20_1stPart_2' : [11, 12], # af_2\n",
    "                           '2019-01-17-16-03-27_2ndPart_2' : [1,2,3,4,5,6,7,8], # af_2\n",
    "                           '2019-02-06-11-25-41_1' : [12], # aq_1\n",
    "                           '2019-02-08-11-33-53_1stPart_1' : [5,6] , # aq_3\n",
    "                           '2019-02-08-12-11-34_2ndPart_1' : [1,2,3,4,5,6,7,8,9,10], # aq_3\n",
    "                           '2019-01-31-09-22-49_1stPart_2' : [11,12], # bh1_4\n",
    "                           '2019-01-31-09-37-5_2ndPart_2' : [1,2,5,6,7,8,9,10,11,12], # bh1_4\n",
    "                           '2019-02-21-16-09-44_1stPart_1': [5, 6, 8], # bh2_1\n",
    "                           '2019-02-21-16-22-22_2ndPart_1': [1,2,7,8,9,10,11,12], # bh2_1\n",
    "                           '2019-02-28-17-03-53_1stPart_2' : [7,8], # bh2_3\n",
    "                           '2019-02-28-17-24-2_2ndPart_2': [1,2,3,4], # bh2_3\n",
    "                           '2019-02-14-13-28-20_1stPart_2': [7,8], # cw_3\n",
    "                           '2019-02-14-13-57-41_2ndPart_2': [1,2,3,4,7,8,9,10], # cw_3\n",
    "                           '2019-02-21-15-01-4_1stPart_1': [3,4], # le_3\n",
    "                           '2019-02-21-15-25-56_2ndPart_1': [1,2], # le_3\n",
    "                           '2019-02-18-10-28-35_2': [1,2], # ls2_4\n",
    "                           '2019-02-05-14-00-27_1stPart_2': [9], # mh_1\n",
    "                           '2019-02-05-14-10-39_2ndPart_2': [1,2,3,4,5,6,9,10] , # mh_2\n",
    "                           '2019-02-08-10-51-3_1stPart_1': [11,12], # mn_1\n",
    "                           '2019-02-08-11-05-7_2ndPart_1': [1,2,3,4,7,8,9,10,11,12], # mn_1\n",
    "                           '2019-02-19-10-34-7_1stPart_1': [9,10], # mn_3\n",
    "                           '2019-02-19-10-56-43_2ndPart_1': [1,2,5,6,7,8,9,10,11,12], # mn_3\n",
    "                           '2019-02-19-17-10-45_1': [9, 10], # ph_5\n",
    "                           '2019-01-16-15-18-0_1': [11,12], # no_1\n",
    "                           '2019-03-07-16-44-5_2': [5,6], #rh_1\n",
    "                           '2019-03-14-13-56-56_2' : [7,8], #rh_3\n",
    "                           '2019-01-14-15-07-21_1' : [11, 12], # ys_1\n",
    "                           '2019-01-16-15-18-50_1stPart_1': [6, 9, 10, 11], # ys_2\n",
    "                           '2019-01-16-15-42-51_2ndPart_1': [1, 2, 3, 4] # ys_2\n",
    "                          }\n",
    "\n",
    "\n",
    "\n",
    "dict_ChangeInTrials = {\n",
    "    '2019-01-17-15-05-1_1': ['Baseline', 'PictureSentence', 'PictureDifficulty', 'TrialSentence', \\\n",
    "                            'TrialDifficulty', 'TrialSentence', 'TrialDifficulty', 'TrialSentence', \\\n",
    "                            'TrialSentence', 'TrialSentence', 'TrialSentence', 'TrialSentence',\\\n",
    "                            'TrialSentence'], # ys_3\n",
    "    '2019-02-06-11-25-41_1': ['Baseline', 'PictureSentence', 'PictureDifficulty', 'TrialSentence', 'TrialDifficulty', \\\n",
    "                             'TrialSentence', 'TrialDifficulty', 'TrialSentence', 'TrialSentence', 'TrialSentence', \\\n",
    "                              'TrialSentence', 'TrialSentence'], # aq_1\n",
    "    '2019-01-28-14-30-44_1' : ['Baseline', 'PictureSentence', 'PictureDifficulty', 'TrialSentence', \\\n",
    "                            'TrialDifficulty', 'TrialSentence', 'TrialDifficulty', 'TrialSentence', \\\n",
    "                            'TrialSentence', 'TrialSentence', 'TrialSentence', 'TrialSentence',\\\n",
    "                            'TrialSentence'], # bh1_1\n",
    "    '2019-01-29-13-25-4_1' : ['Baseline', 'PictureSentence', 'PictureDifficulty', 'TrialSentence', \\\n",
    "                            'TrialDifficulty', 'TrialSentence', 'TrialDifficulty', 'TrialSentence', \\\n",
    "                            'TrialDifficulty', 'TrialSentence', 'TrialSentence', 'TrialSentence',\\\n",
    "                            'TrialSentence']\n",
    "                      }\n",
    "\n",
    "dict_ChangeInTrials_boolAddNextTrialData = {\n",
    "    '2019-01-17-15-05-1_1': [False, True, False, True, False, True, False, 0, 0, 0, 0, 0, 0], # ys_3\n",
    "    '2019-02-06-11-25-41_1': [False, True, False, True, False, True, False, False, False, False, False, False], # aq_1\n",
    "    '2019-01-28-14-30-44_1' : [False, True, False, True, False, True, False, False, False, False, False, False, False], # bh1_1\n",
    "    '2019-01-29-13-25-4_1' : [False, True, False, True, False, True, False, True, False, False, False, False, False]\n",
    "                      }\n",
    "                       \n",
    "dict_TrialToNan = {#'2019-02-12-15-27-37_2' : [0], # ac_2_2 --> Cannot be sure\n",
    "                   '2019-02-14-14-28-49_1': [7,8], # ac_3_MS_1 --> [7,8]\n",
    "                   #'2019-01-16-15-43-8_1': [0], # af_1_1 --> cannot be sure\n",
    "                   #'2019-01-17-15-27-20_1stPart_2' : [0], # af_2\n",
    "                   #'2019-01-17-16-03-27_2ndPart_2' : [0], # af_2\n",
    "                    '2019-02-19-13-31-29_2' : [5,6], # jp_5_2 --> [5,6]\n",
    "                    #'2019-03-04-11-20-5_1' : [0], # le_5_MS_1 --> is looking to the picture\n",
    "                    #'2019-03-04-12-00-15_2': [0], # le_5_MS_2 --> looking at the picture\n",
    "                    '2019-03-07-16-17-30_1': [11, 12], # rh_1_1 --> [11, 12]\n",
    "                    '2019-03-13-13-40-7_2': [3,4], # rh_2_2 --> [3,4] \n",
    "                    '2019-01-16-15-18-50_1stPart_1': [0, 6, 9, 10, 11] # ys_2 --> [0, 6, 9, 10, 11]\n",
    "                    #'2019-01-31-13-13-2_1': [0] # ys_5_1 --> cannot be sure\n",
    "}\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeDwellOrig = 800\n",
    "TimeFixation = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FixUserKeys(UserKeys_Old):\n",
    "    # Fix the situation where comma has divided decimals into separate columns\n",
    "    \n",
    "    Column_beforeDecimal = [item[2] for item in UserKeys_Old]\n",
    "    Column_afterDecimal = [item[3] if len(item)>3 else '00' for item in UserKeys_Old]\n",
    "    \n",
    "    UserKeys_ProgressPercent = [float(Column_beforeDecimal[i]+'.'+ Column_afterDecimal[i]) for i in \n",
    "                                range(0, len(Column_beforeDecimal))]\n",
    "    UserKeys_Times = [item[0] for item in UserKeys_Old]\n",
    "    UserKeys_Keys = [item[1] for item in UserKeys_Old]\n",
    "    \n",
    "    UserKeys_New = [[UserKeys_Times[ind], UserKeys_Keys[ind], UserKeys_ProgressPercent[ind]] for ind in \n",
    "                    range(0, len(UserKeys_ProgressPercent))]\n",
    "    \n",
    "    #UserKeys_New = np.concatenate((UserKeys_Times, UserKeys_Keys, UserKeys_ProgressPercent), axis = 0)\n",
    "    \n",
    "    \n",
    "    return UserKeys_New\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FixScratchPad(ScratchPad_Old):\n",
    "    # Fix the situation where comma has divided decimals into separate columns\n",
    "    \n",
    "    ScratchPad_Times = [item[0] for item in ScratchPad_Old]\n",
    "    \n",
    "    ScratchPad_Phrases = list()\n",
    "    \n",
    "    # loop to combine phrases divided by commas\n",
    "    ScratchPadInd = -1 \n",
    "    while ScratchPadInd < len(ScratchPad_Old)-1:\n",
    "        ScratchPadInd = ScratchPadInd + 1\n",
    "        commasInPhrase = len(ScratchPad_Old[ScratchPadInd])-2\n",
    "        if commasInPhrase < 1:\n",
    "            #print(ScratchPad_Old[ScratchPadInd][1])\n",
    "            ScratchPad_Phrases.append(ScratchPad_Old[ScratchPadInd][1])\n",
    "            continue\n",
    "        scratchPadPhrase = ScratchPad_Old[ScratchPadInd][1]\n",
    "        for phraseJoinNr in range(1, commasInPhrase+1):\n",
    "            scratchPadPhrase = scratchPadPhrase + ', ' + ScratchPad_Old[ScratchPadInd][1+phraseJoinNr]\n",
    "        \n",
    "        ScratchPad_Phrases.append(scratchPadPhrase)\n",
    "            \n",
    "        \n",
    "    ScratchPad_New = [[ScratchPad_Times[ind], ScratchPad_Phrases[ind]] for ind in \n",
    "                    range(0, len(ScratchPad_Times))]\n",
    "    \n",
    "    #UserKeys_New = np.concatenate((UserKeys_Times, UserKeys_Keys, UserKeys_ProgressPercent), axis = 0)\n",
    "    \n",
    "    #print(ScratchPad_New)\n",
    "    return ScratchPad_New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FixKeysSelected(KeysSelected_Old):\n",
    "    # Fix the situation where comma has divided decimals into separate columns\n",
    "    \n",
    "    KeysSelected_New = list()\n",
    "    \n",
    "    # loop to combine phrases divided by commas\n",
    "    KeysSelectedInd = -1 \n",
    "    while KeysSelectedInd < len(KeysSelected_Old)-1:\n",
    "        KeysSelectedInd = KeysSelectedInd + 1\n",
    "        \n",
    "        if KeysSelected_Old[KeysSelectedInd][1].count(',') > 0:\n",
    "            \n",
    "            keys_split = KeysSelected_Old[KeysSelectedInd][1].split(\"\\r\\n\")\n",
    "            del keys_split[0]\n",
    "            del keys_split[-1]\n",
    "            \n",
    "            keys_split = [key.split(',') for key in keys_split]\n",
    "            \n",
    "            KeysSelected_New.extend(keys_split)\n",
    "        else:\n",
    "            KeysSelected_New.append(KeysSelected_Old[KeysSelectedInd])\n",
    "        \n",
    "    \n",
    "    return KeysSelected_New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeDwellTime(userKeys, full_path):\n",
    "    # modify userKeys to include a column of time instead of progress pct, which is dependent on the then dwell time\n",
    "    \n",
    "    TimeDwellOrig = 800\n",
    "    \n",
    "    # session name\n",
    "    session_folder_name = full_path.split('\\\\')[-1]\n",
    "    \n",
    "    if session_folder_name in dict_dwellTimeOrig_not800:\n",
    "        TimeDwellOrig = dict_dwellTimeOrig_not800[session_folder_name]\n",
    "    \n",
    "    #print(TimeDwellOrig)\n",
    "    \n",
    "    timeDwell = TimeDwellOrig\n",
    "    nKey = -1\n",
    "    for key in userKeys:\n",
    "        nKey = nKey + 1\n",
    "        #print(key[1])\n",
    "        if key[1] == 'IncreaseDwellTime':\n",
    "            if float(key[2]) == 1:\n",
    "                timeDwell = timeDwell + 100\n",
    "        elif key[1] == 'DecreaseDwellTime':\n",
    "            #print(key[2])\n",
    "            if float(key[2]) == 1:\n",
    "                timeDwell = timeDwell - 100\n",
    "        else:\n",
    "            userKeys[nKey].append(str(float(key[2])*timeDwell))\n",
    "    \n",
    "    return userKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will return the datetime in items which is the closest to the date pivot\n",
    "def nearestTimePoint(dates, date):\n",
    "    \n",
    "    for d in dates:\n",
    "        if d < date:\n",
    "            nearestTP = d\n",
    "        else:\n",
    "            continue\n",
    "    try: \n",
    "        nearestTP\n",
    "        nearestTPind = dates.index(nearestTP)\n",
    "    except:\n",
    "        nearestTP = 0\n",
    "        nearestTPind = -1\n",
    "        \n",
    "    return nearestTP, nearestTPind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAndRemoveTrials(session_name, dictionary_saved, trials, replacingList):\n",
    "    # function to check the session_name in the dictionary_saved and remove those trials from the dictionary_trial\n",
    "    \n",
    "    if session_name in dictionary_saved:\n",
    "        index_list = dictionary_saved[session_name]\n",
    "    else:\n",
    "        index_list = replacingList\n",
    "    \n",
    "    \n",
    "    \n",
    "    if index_list:\n",
    "        if type(trials) == list:\n",
    "            for index in sorted(index_list, reverse=True):\n",
    "                del trials[index]\n",
    "                \n",
    "        else:\n",
    "            for index in sorted(index_list, reverse=True):\n",
    "                del trials['start'][index]\n",
    "                del trials['end'][index]\n",
    "            \n",
    "    return trials    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert list of date and time into datetime format list\n",
    "def timeConversion(timeStrList):\n",
    "    timeList = list()\n",
    "    for time in timeStrList:\n",
    "        time1, t1, t2 = time.partition('+')\n",
    "        timeList.append(datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\"))\n",
    "    return timeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeTypingStart(userKeys):\n",
    "    # From the user keys, find when the user actually starts typing, after having looked at the phrase and all the other \n",
    "    # function keys\n",
    "    \n",
    "    timeTypingStartInd = 0\n",
    "    \n",
    "    timeTypingStartIndList = list()\n",
    "            \n",
    "    timeUserTimeInd = 0\n",
    "    \n",
    "    ind = 0\n",
    "    # Get start time of first trial\n",
    "    \n",
    "    while ind < len(userKeys):\n",
    "        #print(len(userKeys[ind][1]))\n",
    "        if len(userKeys[ind][1]) > 1:\n",
    "            ind = ind + 1\n",
    "        else:\n",
    "            timeTypingStartInd = ind\n",
    "            timeTypingStartIndList.append(ind)\n",
    "            break\n",
    "    \n",
    "    #print(timeTypingStartInd)\n",
    "    # Get every next phrase start timings\n",
    "    while ind < len(userKeys):\n",
    "        \n",
    "        if userKeys[ind][1] == 'NextPhrase' and float(userKeys[ind][2]) == 1:\n",
    "            \n",
    "            #timeTypingStartIndList.append(ind+1)\n",
    "            for ind2 in range(ind+1, len(userKeys)):\n",
    "                if len(userKeys[ind2][1]) > 1:\n",
    "                    ind = ind + 1\n",
    "                    continue\n",
    "                elif userKeys[ind2][1] == 'NextPhrase' and float(userKeys[ind][2]) == 1:\n",
    "                    ind = ind + 1\n",
    "                    continue\n",
    "                else:\n",
    "                    ind = ind2\n",
    "                    timeTypingStartIndList.append(ind)\n",
    "                    break\n",
    "                    \n",
    "        else:\n",
    "            ind = ind + 1\n",
    "            \n",
    "    #print(timeTypingStartIndList)\n",
    "    \n",
    "    return timeTypingStartIndList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gazeConvert2ColumnsTo1(GazeLog, columnIndwValidity_list, indValidity):\n",
    "    # function to convert pupilsizes from 2 columns for every pupil due to comma use instead of decimal, \n",
    "    # to proper pupil sizes\n",
    "    \n",
    "    #columnInd_list = [joinColumn1_1, joinColumn1_2, joinColumn2_1, joinColumn2_2]\n",
    "    \n",
    "    # number of columns in the final dictionary\n",
    "    nColumns = int(len(columnIndwValidity_list)/2)\n",
    "    \n",
    "    # dictionary of columns that are to be joined later\n",
    "    columns_beforeDecimal = dict()\n",
    "    columns_afterDecimal = dict()\n",
    "    \n",
    "    # dictionary of joined columns\n",
    "    columnsFinal = dict()\n",
    "    \n",
    "    # dictionary to find and equalize missing values in every column\n",
    "    missingVal_column = dict()\n",
    "    missingVal = list()\n",
    "    \n",
    "    # find correct index of validity column to be used, to find the actual columns relative to that\n",
    "    columnsValidity_inUse = list()\n",
    "    \n",
    "    for ind, row in enumerate(GazeLog):\n",
    "        #print(ind)\n",
    "        #print(sorted(list(np.where(np.array(row) == 'Valid')[0])+list(np.where(np.array(row)=='Invalid')[0]))[indValidity])\n",
    "\n",
    "        columnsValidity = (sorted(list(np.where(np.array(row) == 'Valid')[0])+list(np.where(np.array(row)=='Invalid')[0]))[indValidity])\n",
    "        columnsValidity_inUse.append(int(columnsValidity))\n",
    "    \n",
    "    columnsValidity_inUse = np.array(columnsValidity_inUse)\n",
    "    \n",
    "    columnInd_list = [[columnsValidity_inUse+i] for i in columnIndwValidity_list]\n",
    "    \n",
    "    \n",
    "    for ind in range(0, nColumns):\n",
    "        \n",
    "        dict_name = 'column' + str(ind+1)\n",
    "        columnsFinal[dict_name] = list()\n",
    "        columns_afterDecimal[dict_name] = list()\n",
    "                \n",
    "        #for indItem, item4 in enumerate(GazeLog):\n",
    "        #    if 'Invalid' not in item4:\n",
    "        #        if columnInd_list[2*ind+1][0][indItem] < len(item4):\n",
    "        #            columns_afterDecimal[dict_name].append(item4[columnInd_list[2*ind+1][0][indItem]])\n",
    "        #        else:\n",
    "        #            columns_afterDecimal[dict_name].append('0')\n",
    "        #    else:\n",
    "        #        columns_afterDecimal[dict_name].append('nan')\n",
    "        \n",
    "                \n",
    "        columns_beforeDecimal[dict_name] = [item4[columnInd_list[2*ind][0][indItem]] if 'Invalid' not in item4 else 'nan' for indItem, item4 in enumerate(GazeLog)]\n",
    "        columns_afterDecimal[dict_name] = [item4[columnInd_list[2*ind+1][0][indItem]] if 'Invalid' not in item4 and columnInd_list[2*ind+1][0][indItem] < len(item4) else 'nan' for indItem, item4 in enumerate(GazeLog)]\n",
    "\n",
    "        \n",
    "        for i in range(0, len(columns_beforeDecimal[dict_name])):\n",
    "            if 'Valid' not in columns_beforeDecimal[dict_name][i] and 'Valid' not in columns_afterDecimal[dict_name][i]:\n",
    "                if 'nan' not in columns_beforeDecimal[dict_name][i] and 'nan' not in columns_afterDecimal[dict_name][i]:\n",
    "                    if float(columns_afterDecimal[dict_name][i]) > 0: \n",
    "                        columnsFinal[dict_name].append(float(columns_beforeDecimal[dict_name][i]+'.'+columns_afterDecimal[dict_name][i]))\n",
    "                    else:\n",
    "                        columnsFinal[dict_name].append(np.nan)\n",
    "                else:\n",
    "                    columnsFinal[dict_name].append(np.nan)\n",
    "            else:\n",
    "                # Rarely, the pupil size is a whole number\n",
    "                columnsFinal[dict_name].append(np.nan) # we will ignore the row, since there is no way of automatically knowing which - \n",
    "                # right or left eye has whole number pupil size\n",
    "    \n",
    "        missingVal_column[dict_name] = np.argwhere(np.isnan(columnsFinal[dict_name]))\n",
    "        missingVal_column[dict_name] = list(itertools.chain.from_iterable(missingVal_column[dict_name])) # flatten the list\n",
    "        \n",
    "        missingVal.extend(missingVal_column[dict_name])\n",
    "        \n",
    "        \n",
    "    \n",
    "    missingVal = sorted(set(missingVal))\n",
    "    \n",
    "    # if one of the columns are nan, the other one is converted too\n",
    "    for column in range(0, nColumns):\n",
    "        dict_name = 'column' + str(column+1)\n",
    "        for ind in missingVal:\n",
    "            if ind < len(columnsFinal[dict_name]):\n",
    "                columnsFinal[dict_name][ind] = np.nan\n",
    "                \n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(len(columnsFinal['column1']), len(columnsFinal['column2']))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    return columnsFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EyeMovementPlot(timeBetweenTrials, GazeLog):\n",
    "    \n",
    "    # first create a list of times in gaze log\n",
    "    timeStrGazeLog = [item3[0] for item3 in GazeLog]\n",
    "    # convert the list of strings to datetime formats\n",
    "    timeGazeLog = timeConversion(timeStrGazeLog)\n",
    "    \n",
    "    # Obtain gaze location data\n",
    "    # Location of eye gaze on screen in the ADCS by Tobii (in arbitrary units)\n",
    "    #print('gaze point on screen')\n",
    "    gazePointADCS_indWrtValidityL = [-4, -3, -2, -1]\n",
    "    gazePointADCS_validityL = 3\n",
    "    gazePointADCS_Left_au = gazeConvert2ColumnsTo1(GazeLog, gazePointADCS_indWrtValidityL, gazePointADCS_validityL)\n",
    "    \n",
    "    \n",
    "    gazePointADCS_indWrtValidityR = [-4, -3, -2, -1]\n",
    "    gazePointADCS_validityR = 4\n",
    "    gazePointADCS_Right_au = gazeConvert2ColumnsTo1(GazeLog, gazePointADCS_indWrtValidityR, gazePointADCS_validityR)\n",
    "    \n",
    "    \n",
    "    # gazePointADCS is in arbitrary units and needs to be converted to cm  \n",
    "    screenLength = 59\n",
    "    screenWidth = 34.5\n",
    "    \n",
    "    gazePointADCS_Left_au['column1'] = [i*59 for i in gazePointADCS_Left_au['column1']]\n",
    "    gazePointADCS_Left_au['column2'] = [i*(34.5) for i in gazePointADCS_Left_au['column2']]\n",
    "    \n",
    "    gazePointADCS_Right_au['column1'] = [i*59 for i in gazePointADCS_Right_au['column1']]\n",
    "    gazePointADCS_Right_au['column2'] = [i*(34.5) for i in gazePointADCS_Right_au['column2']]\n",
    "    \n",
    "    gazePointADCS = dict()\n",
    "    gazePointADCS['x'] = [(v+gazePointADCS_Right_au['column1'][i])/2 for i, v in enumerate(gazePointADCS_Left_au['column1'])]\n",
    "    gazePointADCS['y'] = [(v+gazePointADCS_Right_au['column2'][i])/2 for i, v in enumerate(gazePointADCS_Left_au['column2'])]\n",
    "    \n",
    "    gazePointBetweenTrial_x, gazePointBetweenTrial_y = list(), list() \n",
    "    \n",
    "    \n",
    "    for ind, inBetweenTrialStart in enumerate(timeBetweenTrials['start']):\n",
    "        timeEyeDataStart, indEyeDataStart = nearestTimePoint(timeGazeLog, inBetweenTrialStart)\n",
    "        timeEyeDataEnd, indEyeDataEnd = nearestTimePoint(timeGazeLog, timeBetweenTrials['end'][ind]) \n",
    "        \n",
    "        print(timeEyeDataStart, timeEyeDataEnd)\n",
    "        \n",
    "        gazePointBetweenTrial_x = gazePointADCS['x'][indEyeDataStart:indEyeDataEnd]\n",
    "        gazePointBetweenTrial_y = gazePointADCS['y'][indEyeDataStart:indEyeDataEnd]\n",
    "        \n",
    "        \n",
    "        print('')\n",
    "        # Plot the image overlay\n",
    "        im = np.array(Image.open('keyboard_sleep.png'), dtype=np.uint8)\n",
    "        dpi = 80\n",
    "        fig, ax = plt.subplots(figsize = (20,15)) #, dpi = dpi)\n",
    "        plt.axis([min(min(gazePointBetweenTrial_x), 0), max(max(gazePointBetweenTrial_x), screenLength), \\\n",
    "                  max(max(gazePointBetweenTrial_y), 0), min(min(gazePointBetweenTrial_y), screenWidth)])  \n",
    "        \n",
    "        ax.imshow(im, extent=(0, screenLength, screenWidth, 0))\n",
    "        #ax.scatter(gazePointBetweenTrial_x, gazePointBetweenTrial_y)\n",
    "        ax=plt.gca()                            # get the axis\n",
    "        ax.set_ylim(ax.get_ylim()[::-1])        # invert the axis\n",
    "        ax.xaxis.tick_top()                     # and move the X-Axis      \n",
    "        ax.yaxis.tick_left()    \n",
    "        \n",
    "        print(len(gazePointBetweenTrial_x))\n",
    "        for line in range(0,len(gazePointBetweenTrial_x)):\n",
    "            if line%20 == 0:\n",
    "                \n",
    "                if not np.isnan(gazePointBetweenTrial_x[line]) and not np.isnan(gazePointBetweenTrial_y[line]):\n",
    "                    #ax = sns.scatterplot(gazePointBetweenTrial_x[line], gazePointBetweenTrial_y[line],s = 500)\n",
    "        \n",
    "                    ax.text(gazePointBetweenTrial_x[line], gazePointBetweenTrial_y[line], line+1, horizontalalignment='center',\\\n",
    "                    size='medium', color='yellow', weight='semibold')\n",
    "        \n",
    "        ax.plot(gazePointBetweenTrial_x, gazePointBetweenTrial_y)\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AOIs\n",
    "screenLength = 59\n",
    "screenWidth = 34.5\n",
    "columnWidth = screenLength/11\n",
    "rowHeight = screenWidth/6\n",
    "\n",
    "\n",
    "\n",
    "Suggestion_x = [0, screenLength]\n",
    "Suggestion_y = [0, rowHeight]\n",
    "\n",
    "PhraseText_x = [2*columnWidth, 9*columnWidth]\n",
    "PhraseText_y = [rowHeight, 1.5*rowHeight]\n",
    "\n",
    "ScratchPad_x = [2*columnWidth, 9*columnWidth]\n",
    "ScratchPad_y = [1.5*rowHeight, 2*rowHeight]\n",
    "\n",
    "Keyboard_x = [0, screenLength]\n",
    "Keyboard_y = [2*rowHeight, screenWidth]\n",
    "\n",
    "NextPhrase_x = [9*columnWidth, 10*columnWidth]\n",
    "NextPhrase_y = [rowHeight, 2*rowHeight]\n",
    "\n",
    "Sleep_x = [10*columnWidth, screenLength]\n",
    "Sleep_y = [rowHeight, 2*rowHeight]\n",
    "\n",
    "aoi_plot = {'Suggestion': [(Suggestion_x[0]+Suggestion_x[1])/2, (Suggestion_y[0]+Suggestion_y[1])/2], \\\n",
    "            'PhraseText': [(PhraseText_x[0]+PhraseText_x[1])/2, (PhraseText_y[0]+PhraseText_y[1])/2], \\\n",
    "            'ScratchPad': [(ScratchPad_x[0]+ScratchPad_x[1])/2, (ScratchPad_y[0]+ScratchPad_y[1])/2], \\\n",
    "            'Keyboard': [(Keyboard_x[0]+Keyboard_x[1])/2, (Keyboard_y[0]+Keyboard_y[1])/2], \\\n",
    "            'NextPhrase': [(NextPhrase_x[0]+NextPhrase_x[1])/2, (NextPhrase_y[0]+NextPhrase_y[1])/2], \\\n",
    "            'Sleep': [(Sleep_x[0]+Sleep_x[1])/2, (Sleep_y[0]+Sleep_y[1])/2], \\\n",
    "            'OutOfScreen': [59, 34.5]\n",
    "           }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeTimeBetweenTrials(userKeys):\n",
    "    \n",
    "    timeBetweenTrials = dict()\n",
    "    timeBetweenTrials['start'], timeBetweenTrials['end'] = list(), list()\n",
    "    \n",
    "    \n",
    "    \n",
    "    indLast = 0\n",
    "    for ind, userKey in enumerate(userKeys):\n",
    "        #if len(timeBetweenTrials['start']) == 12:\n",
    "        #    break\n",
    "        if userKey[1] == 'NextPhrase' and userKeys[ind-1][1] != 'NextPhrase':\n",
    "            if userKeys[ind-1][1] == 'Sleep' and float(userKeys[ind-1][2]) == 1:\n",
    "                print('SLEEP!!!')\n",
    "            #print('before next phrase')\n",
    "            #print(userKeys[ind-1])\n",
    "            #print(userKey)\n",
    "        \n",
    "        if userKey[1] == 'NextPhrase' and float(userKey[2]) == 1:\n",
    "            \n",
    "            time1, t1, t2 = userKey[0].partition('+')\n",
    "            timeBetweenTrials['start'].append(datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \\\n",
    "                                                                         \"%Y-%m-%d-%H-%M-%S-%f\"))\n",
    "            #print('start: ', timeBetweenTrials['start'][-1])\n",
    "            if ind < len(userKeys)-1:\n",
    "                indLast = ind\n",
    "                for ind2, userKey2 in enumerate(userKeys[ind:]):\n",
    "                    if userKey2[1] == 'Sleep':\n",
    "                        time1, t1, t2 = userKey2[0].partition('+')\n",
    "                        timeBetweenTrials['end'].append(datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \\\n",
    "                                                                         \"%Y-%m-%d-%H-%M-%S-%f\"))\n",
    "                        #print('end: ', timeBetweenTrials['end'][-1])\n",
    "                        #print('')\n",
    "                        break\n",
    "                        \n",
    "    if len(timeBetweenTrials['start']) > len(timeBetweenTrials['end']):\n",
    "        for ind3, userKey3 in enumerate(userKeys[indLast:]):\n",
    "            if userKey3[1] == 'Quit':\n",
    "                time1, t1, t2 = userKey3[0].partition('+')\n",
    "                timeBetweenTrials['end'].append(datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \\\n",
    "                                                                         \"%Y-%m-%d-%H-%M-%S-%f\"))\n",
    "                #print('end: ', timeBetweenTrials['end'][-1])\n",
    "                #print('')\n",
    "                break\n",
    "                \n",
    "    \n",
    "    print(len(timeBetweenTrials['start']), len(timeBetweenTrials['end']))\n",
    "    return timeBetweenTrials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeTimeOnKeys_test(userKeys):\n",
    "    \n",
    "    timeBetweenTrials = dict()\n",
    "    timeBetweenTrials['start'], timeBetweenTrials['end'] = list(), list()\n",
    "    \n",
    "    # first sleep selection:\n",
    "    time1, t1, t2 = userKeys[0][0].partition('+')\n",
    "    timeBetweenTrials['start'].append(datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \\\n",
    "                                                                         \"%Y-%m-%d-%H-%M-%S-%f\"))\n",
    "    \n",
    "    time1, t1, t2 = userKeys[73][0].partition('+')\n",
    "    timeBetweenTrials['end'].append(datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \\\n",
    "                                                                         \"%Y-%m-%d-%H-%M-%S-%f\"))\n",
    "    \n",
    "    # first letter selection:\n",
    "    time1, t1, t2 = userKeys[76][0].partition('+')\n",
    "    timeBetweenTrials['start'].append(datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \\\n",
    "                                                                         \"%Y-%m-%d-%H-%M-%S-%f\"))\n",
    "    \n",
    "    time1, t1, t2 = userKeys[148][0].partition('+')\n",
    "    timeBetweenTrials['end'].append(datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \\\n",
    "                                                                         \"%Y-%m-%d-%H-%M-%S-%f\"))\n",
    "    \n",
    "    \n",
    "    return timeBetweenTrials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EyeMovementBetweenAOI_Plot(timeBetweenTrials, GazeLog, EndPhrases, session_folder_name):\n",
    "    \n",
    "    # first create a list of times in gaze log\n",
    "    timeStrGazeLog = [item3[0] for item3 in GazeLog]\n",
    "    # convert the list of strings to datetime formats\n",
    "    timeGazeLog = timeConversion(timeStrGazeLog)\n",
    "    \n",
    "    \n",
    "    # Obtain gaze location data\n",
    "    # Location of eye gaze on screen in the ADCS by Tobii (in arbitrary units)\n",
    "    #print('gaze point on screen')\n",
    "    gazePointADCS_indWrtValidityL = [-4, -3, -2, -1]\n",
    "    gazePointADCS_validityL = 3\n",
    "    gazePointADCS_Left_au = gazeConvert2ColumnsTo1(GazeLog, gazePointADCS_indWrtValidityL, gazePointADCS_validityL)\n",
    "    \n",
    "    \n",
    "    gazePointADCS_indWrtValidityR = [-4, -3, -2, -1]\n",
    "    gazePointADCS_validityR = 4\n",
    "    gazePointADCS_Right_au = gazeConvert2ColumnsTo1(GazeLog, gazePointADCS_indWrtValidityR, gazePointADCS_validityR)\n",
    "    \n",
    "    \n",
    "    # gazePointADCS is in arbitrary units and needs to be converted to cm  \n",
    "    screenLength = 59\n",
    "    screenWidth = 34.5\n",
    "    \n",
    "    gazePointADCS_Left_au['column1'] = [i*screenLength for i in gazePointADCS_Left_au['column1']]\n",
    "    gazePointADCS_Left_au['column2'] = [i*screenWidth for i in gazePointADCS_Left_au['column2']]\n",
    "    \n",
    "    gazePointADCS_Right_au['column1'] = [i*screenLength for i in gazePointADCS_Right_au['column1']]\n",
    "    gazePointADCS_Right_au['column2'] = [i*screenWidth for i in gazePointADCS_Right_au['column2']]\n",
    "    \n",
    "    gazePointADCS = dict()\n",
    "    gazePointADCS['x'] = [(v+gazePointADCS_Right_au['column1'][i])/2 for i, v in enumerate(gazePointADCS_Left_au['column1'])]\n",
    "    gazePointADCS['y'] = [(v+gazePointADCS_Right_au['column2'][i])/2 for i, v in enumerate(gazePointADCS_Left_au['column2'])]\n",
    "    \n",
    "    gazePointBetweenTrial_x, gazePointBetweenTrial_y = list(), list() \n",
    "    \n",
    "    timeList = list()\n",
    "    \n",
    "    for ind, inBetweenTrialStart in enumerate(timeBetweenTrials['start']):\n",
    "        \n",
    "        # no session has more than 13 trials\n",
    "        if ind > 12:\n",
    "            break\n",
    "        \n",
    "        if session_folder_name in dict_TrialQuestionClean:\n",
    "            \n",
    "            if ind in dict_TrialQuestionClean[session_folder_name]:\n",
    "                #print(session_folder_name, ' has ', str(ind))\n",
    "                continue\n",
    "        #else:\n",
    "        #    print(session_folder_name, 'not in dict')\n",
    "            \n",
    "        timeEyeDataStart, indEyeDataStart = nearestTimePoint(timeGazeLog, inBetweenTrialStart)\n",
    "        timeEyeDataEnd, indEyeDataEnd = nearestTimePoint(timeGazeLog, timeBetweenTrials['end'][ind]) \n",
    "        \n",
    "        \n",
    "        gazePointBetweenTrial_x = gazePointADCS['x'][indEyeDataStart:indEyeDataEnd]\n",
    "        gazePointBetweenTrial_y = gazePointADCS['y'][indEyeDataStart:indEyeDataEnd]\n",
    "        \n",
    "        fixationLength = 1\n",
    "        aoi_previous = None\n",
    "        aoi_list, aoi_length = list(), list()\n",
    "        \n",
    "        flagFirst = 0\n",
    "        checkFixationLength = 0\n",
    "        \n",
    "        flagNextPhrase = 1\n",
    "        \n",
    "        aoi_point, aoi_pointList = list(), list()\n",
    "        \n",
    "        \n",
    "        for ind2 in range(0, len(gazePointBetweenTrial_x)):\n",
    "            \n",
    "            xPoint = gazePointBetweenTrial_x[ind2]\n",
    "            yPoint = gazePointBetweenTrial_y[ind2]\n",
    "            \n",
    "            if np.isnan(xPoint) or np.isnan(yPoint):\n",
    "                aoi_current = 'Blink'\n",
    "            \n",
    "            \n",
    "            \n",
    "            elif xPoint>ScratchPad_x[0] and xPoint<ScratchPad_x[1] and yPoint>ScratchPad_y[0] and yPoint<ScratchPad_y[1]:\n",
    "                aoi_current = 'ScratchPad'    \n",
    "            elif xPoint>PhraseText_x[0] and xPoint<PhraseText_x[1] and yPoint>PhraseText_y[0] and yPoint<PhraseText_y[1]:\n",
    "                aoi_current = 'PhraseText'\n",
    "                #print(ind2/90)\n",
    "                if ind2/90 >= 5:\n",
    "                    #print('New sentence appeared', ind2, ind2/90)\n",
    "                    flagNextPhrase = 0\n",
    "                    break\n",
    "                #else:\n",
    "                #    a = 1\n",
    "                #    print('New sentence not yet there', timeEyeDataStart + datetime.timedelta(seconds = ind2/90))\n",
    "            elif xPoint>Suggestion_x[0] and xPoint<Suggestion_x[1] and yPoint>Suggestion_y[0] and yPoint<Suggestion_y[1]:\n",
    "                aoi_current = 'Suggestion'\n",
    "            elif xPoint>Keyboard_x[0] and xPoint<Keyboard_x[1] and yPoint>Keyboard_y[0] and yPoint<Keyboard_y[1]:\n",
    "                aoi_current = 'Keyboard'\n",
    "            elif xPoint>Sleep_x[0] and xPoint<Sleep_x[1] and yPoint>Sleep_y[0] and yPoint<Sleep_y[1]:\n",
    "                aoi_current = 'Sleep'\n",
    "            elif xPoint>NextPhrase_x[0] and xPoint<NextPhrase_x[1] and yPoint>NextPhrase_y[0] and yPoint<NextPhrase_y[1]:\n",
    "                aoi_current = 'NextPhrase'                \n",
    "            else:\n",
    "                aoi_current = 'OutOfScreen'\n",
    "            \n",
    "            #print(aoi_current)\n",
    "            #if ind == 4:\n",
    "            #    print(ind2, xPoint, yPoint, aoi_current)\n",
    "            \n",
    "            #print(aoi_previous, flagFirst)\n",
    "            \n",
    "            if aoi_previous != aoi_current and flagFirst: # except for the first non-match, every time the aoi does not \n",
    "                # match the previous one, the previous list, aoi, fixation time are saved for later use\n",
    "                flagFirst = 1\n",
    "                \n",
    "                aoi_length.append(fixationLength)\n",
    "                aoi_list.append(aoi_previous)\n",
    "                checkFixationLength = checkFixationLength + fixationLength\n",
    "                fixationLength = 1\n",
    "                \n",
    "                aoi_pointList.append(aoi_point)\n",
    "                aoi_point = list()\n",
    "                aoi_previous = aoi_current\n",
    "                aoi_point.append([xPoint, yPoint])\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                aoi_previous = aoi_current\n",
    "                aoi_point.append([xPoint, yPoint])\n",
    "                fixationLength = fixationLength + 1\n",
    "                flagFirst = 1\n",
    "        \n",
    "        #print(ind, timeEyeDataStart, timeEyeDataStart + datetime.timedelta(seconds = ind2/90))\n",
    "        #print(datetime.timedelta(seconds=(ind2/90-5)))\n",
    "        timeExtra = datetime.timedelta(seconds=(ind2/90-5))     \n",
    "            \n",
    "        # the last aoi will not get added by the above procedure.\n",
    "        aoi_length.append(fixationLength)\n",
    "        aoi_list.append(aoi_previous)\n",
    "        checkFixationLength = checkFixationLength + fixationLength\n",
    "        aoi_pointList.append(aoi_point)\n",
    "                \n",
    "        \n",
    "                \n",
    "        \n",
    "        aoi_listCombine = [[aoi, aoi_length[i]] for i, aoi in enumerate(aoi_list)]\n",
    "        \n",
    "        timeRest = sum([aoi_length[ind] for ind, aoi in enumerate(aoi_list) if aoi == 'Blink' or aoi =='OutOfScreen'])\n",
    "        timeScratchPad = sum([aoi_length[ind] for ind, aoi in enumerate(aoi_list) if aoi == 'ScratchPad'])\n",
    "        timePhraseText = sum([aoi_length[ind] for ind, aoi in enumerate(aoi_list) if aoi == 'PhraseText'])\n",
    "        timeNextPhrase = sum([aoi_length[ind] for ind, aoi in enumerate(aoi_list) if aoi == 'NextPhrase'])\n",
    "        timeSleep = sum([aoi_length[ind] for ind, aoi in enumerate(aoi_list) if aoi == 'Sleep'])\n",
    "        timeTotal = len(gazePointBetweenTrial_x) \n",
    "        \n",
    "        timeList.append([timeExtra, timeRest/timeTotal, timeScratchPad/timeTotal, timePhraseText/timeTotal, timeNextPhrase/timeTotal,\\\n",
    "                         timeSleep/timeTotal])\n",
    "        \n",
    "        #print(timeRest/len(gazePointBetweenTrial_x), timeScratchPad/len(gazePointBetweenTrial_x), \\\n",
    "              #timeNextPhrase/len(gazePointBetweenTrial_x), timeSleep/len(gazePointBetweenTrial_x))\n",
    "        #print(EndPhrases[ind])\n",
    "        \n",
    "        #print('')\n",
    "        \n",
    "        title = EndPhrases[ind] + ': ' + str(timeRest/len(gazePointBetweenTrial_x)) + ',' +\\\n",
    "        str(timeScratchPad/len(gazePointBetweenTrial_x)) + ',' + str(timeNextPhrase/len(gazePointBetweenTrial_x)) + ',' + \\\n",
    "        str(timeSleep/len(gazePointBetweenTrial_x))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # plot \n",
    "        plt.style.use('dark_background')\n",
    "        \n",
    "        im = np.array(Image.open('keyboard_sleep.png'), dtype=np.uint8)\n",
    "        dpi = 80\n",
    "        fig, ax = plt.subplots(figsize = (20,15)) #, dpi = dpi)\n",
    "        #plt.axis([min(min(gazePointBetweenTrial_x), 0), max(max(gazePointBetweenTrial_x), screenLength), \\\n",
    "        #          max(max(gazePointBetweenTrial_y), 0), min(min(gazePointBetweenTrial_y), screenWidth)])  \n",
    "        \n",
    "        plt.axis([0, 60, 0, 40])\n",
    "        \n",
    "        ax.imshow(im, extent=(0, screenLength, screenWidth, 0))\n",
    "        #ax.scatter(gazePointBetweenTrial_x, gazePointBetweenTrial_y)\n",
    "        ax=plt.gca()                            # get the axis\n",
    "        ax.set_ylim(ax.get_ylim()[::-1])        # invert the axis\n",
    "        ax.xaxis.tick_top()                     # and move the X-Axis      \n",
    "        ax.yaxis.tick_left() \n",
    "        \n",
    "        plt.title(title)\n",
    "        \n",
    "        \n",
    "        xList, yList = list(), list()\n",
    "        \n",
    "        \n",
    "        #print('aoi: ', aoi_listCombine)\n",
    "        \n",
    "        # Create a Rectangle patch\n",
    "        for nNum, key in enumerate(aoi_listCombine):\n",
    "            \n",
    "            if key[0] == 'Blink':\n",
    "                continue\n",
    "            \n",
    "            #print(nNum, key)\n",
    "            \n",
    "            xPoint = np.nanmean(np.array(([aoi[0] for aoi in aoi_pointList[nNum]])))\n",
    "            yPoint = np.nanmean(np.array([aoi[1] for aoi in aoi_pointList[nNum]]))\n",
    "            \n",
    "            \n",
    "            xList.append(xPoint)\n",
    "            yList.append(yPoint)\n",
    "            rect = patches.Circle([xPoint, yPoint], min(key[1]/5, 2), linewidth=1, facecolor=(0,1,1), alpha = 0.25)\n",
    "            # Add the patch to the Axes\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(xPoint, yPoint, nNum, horizontalalignment='center',size='large', color='white', weight='semibold')\n",
    "            \n",
    "        \n",
    "        ax.plot(xList, yList, color='white', linewidth=2)\n",
    "        \n",
    "        #for i in aoi_listCombine:\n",
    "        #    print(i)\n",
    "        \n",
    "        \"\"\"\n",
    "         \n",
    "    return timeList   \n",
    "    \n",
    "            \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataForEveryTrial:\n",
    "    subjectID = ''\n",
    "    blockNumber = ''\n",
    "    sessionNumber = ''\n",
    "    variable = ''\n",
    "    dataForTrial = ''\n",
    "    resultPathName = ''\n",
    "   \n",
    "    \n",
    "    def printInfo(self):\n",
    "        dataFrame = pd.DataFrame(list(zip([self.subjectID]*len(self.dataForTrial), [self.blockNumber]*len(self.dataForTrial), [self.sessionNumber]*len(self.dataForTrial), range(0,len(self.dataForTrial)+1), self.dataForTrial)), columns=['subjectID', 'block', 'session', 'trial', self.variable])\n",
    "        \n",
    "        return dataFrame\n",
    "    \n",
    "    def AddToFile(self):\n",
    "        \n",
    "        dataFrame = pd.DataFrame(list(zip([self.subjectID]*len(self.dataForTrial), [self.blockNumber]*len(self.dataForTrial), [self.sessionNumber]*len(self.dataForTrial), range(0,len(self.dataForTrial)+1), self.dataForTrial)), columns=['subjectID', 'block', 'session', 'trial', self.variable])\n",
    "        book = load_workbook(self.resultPathName)\n",
    "        writer = pd.ExcelWriter(self.resultPathName, engine='openpyxl')\n",
    "        writer.book = book\n",
    "        writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "        startrow = writer.sheets['Sheet1'].max_row\n",
    "        dataFrame.to_excel(writer, startrow = startrow, index = False, header = False)\n",
    "        \n",
    "        writer.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metricComputed_time = 'TimeAfterTrials'\n",
    "metricComputed_timeResting = 'TimeRestingAfterTrials'\n",
    "\n",
    "resultFileName_time = r'C:\\DTU\\Data\\201901_JanuaryExpt\\DataExtracted\\IndividualTrials\\Performance\\Subject_Block_Session_Trial_' + metricComputed_time +  '.xlsx'\n",
    "resultFileName_timeResting = r'C:\\DTU\\Data\\201901_JanuaryExpt\\DataExtracted\\IndividualTrials\\Performance\\Subject_Block_Session_Trial_' + metricComputed_timeResting +  '.xlsx'\n",
    "\n",
    "dataFolderName = r'E:\\Data\\Data' # accessing external hard disk with the data\n",
    "a = re.compile('(?<=Data\\\\\\\\Data\\\\\\\\)(.*)(?=\\\\\\\\[1-9])')\n",
    "subjectName_listElement = 3\n",
    "\n",
    "#dataFolderName = r'C:\\DTU\\Data\\201901_JanuaryExpt' # accessing data saved in the computer\n",
    "#a = re.compile('(?<=Data\\\\\\\\201901_JanuaryExpt\\\\\\\\)(.*)(?=\\\\\\\\[1-9])')\n",
    "#subjectName_listElement = 4\n",
    "\n",
    "\n",
    "for root, dirs, subfolder in os.walk(dataFolderName):\n",
    "    \n",
    "    technique = 'dwell_time'\n",
    "    \n",
    "    if not dirs:\n",
    "        \n",
    "        #if 'notCompleted' in root or 'notInclude' in root: # Some subjects do not have gaze log and have been marked as \n",
    "        \n",
    "        if 'noData' in root or 'Trial' in root or 'trial' in root or 'Nothing' in root: # Some subjects do not have gaze log and have been marked as \n",
    "            #notInclude\n",
    "            continue\n",
    "        if 'Jonas' in root or 'Praktikant' in root or 'Villads' in root:\n",
    "            continue\n",
    "            \n",
    "        #if 'ac\\\\3_MS\\\\' not in root:\n",
    "        #    continue\n",
    "        if 'Picture' in root:\n",
    "            continue\n",
    "        #if '_MS' not in root:\n",
    "        #    continue\n",
    "        \n",
    "        #if '2019-02-06-11-25-41_1' not in root:\n",
    "        #    continue\n",
    "        \n",
    "        \n",
    "        #if 'ac\\\\1\\\\2019-02-11-11-18-30_1' not in root:\n",
    "        #    continue\n",
    "        \n",
    "        keysSelected = None\n",
    "        userKeys = None\n",
    "        phraseLog = None\n",
    "        \n",
    "        for file in subfolder:\n",
    "            \n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'KeySelection*'):\n",
    "                try:\n",
    "                    \n",
    "                    fKeysSelected = open(root + '\\\\' + file, encoding='utf-8', newline='')\n",
    "                    readerKeysSelected = csv.reader(fKeysSelected)\n",
    "                    keysSelected = list(readerKeysSelected)\n",
    "                    \n",
    "                    keysSelected.remove(keysSelected[0])\n",
    "                except:\n",
    "                    if fKeysSelected is not None:\n",
    "                        fKeysSelected.close()\n",
    "                    else:\n",
    "                        print('error in opening the KeySelection log file')\n",
    "                        \n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'user*'):\n",
    "                try:\n",
    "                    fUserKey = open(root + '\\\\' + file, encoding='utf-8',  newline='')\n",
    "                    readerUserKey = csv.reader(fUserKey, quotechar=None)\n",
    "                    userKeys = list(readerUserKey)\n",
    "                    userKeys.remove(userKeys[0])\n",
    "                except:\n",
    "                    if fUserKey is not None:\n",
    "                        fUserKey.close()\n",
    "                    else:\n",
    "                        print('error in opening the user key log file')\n",
    "                        \n",
    "            if fnmatch.fnmatch(file, 'ScratchPadLog*'):\n",
    "                try:\n",
    "                    fScratchPad = open(root + '\\\\' + file, encoding='utf-8', newline='')\n",
    "                    readerScratchPad = csv.reader(fScratchPad, quotechar=None)\n",
    "                    scratchPad = list(readerScratchPad)\n",
    "                    scratchPad.remove[scratchPad[0]]\n",
    "                    print(scratchPad)\n",
    "                except:\n",
    "                    if fScratchPad is not None:\n",
    "                        fScratchPad.close()\n",
    "                    else:\n",
    "                        print('error in opening the scratchpad log file')\n",
    "                        \n",
    "            if fnmatch.fnmatch(file, 'multiKey*'):\n",
    "                technique = 'multiKey_selection'\n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'tobiiGazeLog*'):\n",
    "                try:\n",
    "                    fGazeLog = open(root + '\\\\' + file, encoding='utf-8', newline='')\n",
    "                    readerGazeLog = csv.reader(fGazeLog, quotechar=None)\n",
    "                    gazeLog = list(readerGazeLog)\n",
    "                    gazeLog.remove(gazeLog[0])\n",
    "                    gazeLog.remove(gazeLog[-1])\n",
    "                except:\n",
    "                    if fGazeLog is not None:\n",
    "                        fGazeLog.close()\n",
    "                    else:\n",
    "                        print('error in opening the scratchpad log file')\n",
    "            \n",
    "                    \n",
    "                     \n",
    "        if keysSelected is None or userKeys is None or scratchPad is None or gazeLog is None:\n",
    "            continue\n",
    "        else:\n",
    "                 \n",
    "            print('subject path', root)\n",
    "            subjAndSessionName = '__'.join(root.split('\\\\')[subjectName_listElement:])\n",
    "            subjName = subjAndSessionName.split('__')[0]\n",
    "            print('subject and session name: ', subjAndSessionName)\n",
    "            sessionFolderName = root.split('\\\\')[-1]\n",
    "            \n",
    "            # fix phraselog due to comma related file changes\n",
    "            scratchPad_new = FixScratchPad(scratchPad)\n",
    "            \n",
    "            # fix userKeys due to comma related file changes\n",
    "            userKeys_new = FixUserKeys(userKeys)\n",
    "            \n",
    "            # trial times between NextPhrase and Sleep\n",
    "            timeBetweenTrials = ComputeTimeBetweenTrials(userKeys_new)\n",
    "            #timeBetweenTrials = ComputeTimeOnKeys_test(userKeys_new)\n",
    "            \n",
    "            timeList_scratchPadStr = [item3[0] for item3 in scratchPad_new][1:]\n",
    "            # convert the list of strings to datetime formats\n",
    "            timeList_scratchPad = timeConversion(timeList_scratchPadStr)\n",
    "            \n",
    "            endPhrase = list()\n",
    "            for i, timeStart in enumerate(timeBetweenTrials['start']):\n",
    "                timeNearest, indNearest = nearestTimePoint(timeList_scratchPad, timeStart)\n",
    "                endPhrase.append(scratchPad_new[indNearest+1][1])\n",
    "                #print(timeStart, timeNearest, scratchPad_new[indNearest+1][1])\n",
    "            #if 'Part' in root:\n",
    "            #    continue\n",
    "            \n",
    "            timeTrialSentences = list()\n",
    "            timeResting = list()\n",
    "            \n",
    "            if sessionFolderName in dict_noGazeData:\n",
    "                \n",
    "                print('no gaze data present')\n",
    "                timeTrialSentences = [np.nan]*5 # will check later in the file if it is correct or not \n",
    "                timeResting = [np.nan]*5\n",
    "                \n",
    "            else:\n",
    "                # filter the data\n",
    "                timeList = EyeMovementBetweenAOI_Plot(timeBetweenTrials, gazeLog, endPhrase, sessionFolderName)\n",
    "                \n",
    "                TrialStructure = ['Baseline', 'PictureSentence', 'PictureDifficulty', 'TrialSentence', 'TrialDifficulty', \\\n",
    "                 'TrialSentence', 'TrialDifficulty', 'TrialSentence', 'TrialDifficulty', 'TrialSentence', \\\n",
    "                  'TrialDifficulty', 'TrialSentence', 'TrialDifficulty']\n",
    "              \n",
    "                plt.figure()\n",
    "                xP = 1\n",
    "                colorList = ['blue', 'pink', 'green', 'red', 'orange']\n",
    "            \n",
    "                replacingList = []\n",
    "                #timeList = findAndRemoveTrials(sessionFolderName, dict_TrialQuestionClean, timeList, replacingList)\n",
    "                TrialStructure = findAndRemoveTrials(sessionFolderName, dict_TrialQuestionClean, TrialStructure, replacingList)\n",
    "                #print(TrialStructure)\n",
    "            \n",
    "                \n",
    "                for i, timeList2 in enumerate(timeList):\n",
    "                    \n",
    "                    if sessionFolderName not in dict_ChangeInTrials:\n",
    "                        TrialCurrent = TrialStructure[i]\n",
    "                    else:\n",
    "                        TrialCurrent = dict_ChangeInTrials[sessionFolderName][i]\n",
    "                    \n",
    "                    if TrialCurrent == 'Baseline':\n",
    "                        timeTrials = timeList2\n",
    "                    elif TrialCurrent == 'PictureSentence':\n",
    "                        if i+1 == len(TrialStructure):\n",
    "                            timeTrials = timeList2\n",
    "                        else:    \n",
    "                            if TrialStructure[i+1] == 'PictureDifficulty':\n",
    "                                timeTrials = list(np.array(timeList2) + np.array(timeList[i+1]))\n",
    "                            else:\n",
    "                                timeTrials = timeList2\n",
    "                    elif TrialCurrent == 'TrialSentence':\n",
    "                        if i+1 == len(TrialStructure):\n",
    "                            timeTrials = timeList2\n",
    "                        else:    \n",
    "                            if TrialStructure[i+1] == 'TrialDifficulty':\n",
    "                                timeTrials = list(np.array(timeList2) + np.array(timeList[i+1]))\n",
    "                            else:\n",
    "                                timeTrials = timeList2\n",
    "                    else:\n",
    "                        continue\n",
    "                        \n",
    "                        \n",
    "                    if TrialCurrent == 'TrialSentence':\n",
    "                        if sessionFolderName in dict_TrialToNan and i in dict_TrialToNan[sessionFolderName]:\n",
    "                            print(sessionFolderName, dict_TrialToNan[sessionFolderName])\n",
    "                            timeTrialSentences.append(np.nan)\n",
    "                            timeResting.append(np.nan)\n",
    "                        else:\n",
    "                            timeTrialSentences.append(timeTrials[0].total_seconds()) # total time \n",
    "                            timeResting.append((timeTrials[0]*timeTrials[1]).total_seconds())\n",
    "                            # second element of list is when people are blinking or\n",
    "                        # looking out of the screen, in short, resting\n",
    "                    print(i, TrialCurrent, ' : ', timeTrials[0])\n",
    "                    for i2, time_ in enumerate(timeTrials[1:]):\n",
    "                        #print(xP + i2, time_)\n",
    "                        plt.bar(xP+i2, time_, color = colorList[i2])\n",
    "                    xP = xP + 6\n",
    "                plt.ylim([0,1])\n",
    "                plt.close()\n",
    "                \n",
    "            if '1stPart' in root:\n",
    "                timeTrialSentences1 = timeTrialSentences\n",
    "                timeResting1 = timeResting\n",
    "                continue\n",
    "            if '2ndPart' in root:\n",
    "                timeTrialSentences2 = timeTrialSentences\n",
    "                timeResting2 = timeResting\n",
    "                \n",
    "                timeTrialSentences = timeTrialSentences1 + timeTrialSentences2\n",
    "                timeResting = timeResting1 + timeResting2\n",
    "                \n",
    "                timeTrialSentences1, timeResting1 = list(), list()\n",
    "                \n",
    "                \n",
    "            # save the total time\n",
    "            dataToSave_time = DataForEveryTrial()\n",
    "            dataToSave_time.subjectID = subjAndSessionName.split('__')[0]\n",
    "            dataToSave_time.blockNumber = subjAndSessionName.split('__')[1]\n",
    "            dataToSave_time.sessionNumber = subjAndSessionName[-1]\n",
    "            dataToSave_time.variable = metricComputed_time\n",
    "            dataToSave_time.dataForTrial = timeTrialSentences\n",
    "            dataToSave_time.resultPathName = resultFileName_time\n",
    "            \n",
    "            print(dataToSave_time.printInfo())\n",
    "            \n",
    "            \n",
    "            \n",
    "            # save the resting time\n",
    "            dataToSave_timeResting = DataForEveryTrial()\n",
    "            dataToSave_timeResting.subjectID = subjAndSessionName.split('__')[0]\n",
    "            dataToSave_timeResting.blockNumber = subjAndSessionName.split('__')[1]\n",
    "            dataToSave_timeResting.sessionNumber = subjAndSessionName[-1]\n",
    "            dataToSave_timeResting.variable = metricComputed_timeResting\n",
    "            dataToSave_timeResting.dataForTrial = timeResting\n",
    "            dataToSave_timeResting.resultPathName = resultFileName_timeResting\n",
    "            \n",
    "            print(dataToSave_timeResting.printInfo())\n",
    "            \n",
    "            \n",
    "            #dataToSave_time.AddToFile()\n",
    "            #dataToSave_timeResting.AddToFile()\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_TrialQuestionClean = {'2019-01-17-15-27-20_1stPart_2' : [11, 12], # af_2\n",
    "                           '2019-01-17-16-03-27_2ndPart_2' : [1,2,3,4,5,6,7,8], # af_2\n",
    "                           '2019-02-06-11-25-41_1' : [12], # aq_1\n",
    "                           '2019-02-08-11-33-53_1stPart_1' : [5,6] , # aq_3\n",
    "                           '2019-02-08-12-11-34_2ndPart_1' : [1,2,3,4,5,6,7,8,9,10], # aq_3\n",
    "                           '2019-01-31-09-22-49_1stPart_2' : [11,12], # bh1_4\n",
    "                           '2019-01-31-09-37-5_2ndPart_2' : [1,2,5,6,7,8,9,10,11,12], # bh1_4\n",
    "                           '2019-02-21-16-09-44_1stPart_1': [5, 6, 8], # bh2_1\n",
    "                           '2019-02-21-16-22-22_2ndPart_1': [1,2,7,8,9,10,11,12], # bh2_1\n",
    "                           '2019-02-28-17-03-53_1stPart_2' : [7,8], # bh2_3\n",
    "                           '2019-02-28-17-24-2_2ndPart_2': [1,2,3,4], # bh2_3\n",
    "                           '2019-02-14-13-28-20_1stPart_2': [7,8], # cw_3\n",
    "                           '2019-02-14-13-57-41_2ndPart_2': [1,2,3,4,7,8,9,10], # cw_3\n",
    "                           '2019-02-21-15-01-4_1stPart_1': [3,4], # le_3\n",
    "                           '2019-02-21-15-25-56_2ndPart_1': [1,2], # le_3\n",
    "                           '2019-02-18-10-28-35_2': [1,2], # ls2_4\n",
    "                           '2019-02-05-14-00-27_1stPart_2': [9], # mh_1\n",
    "                           '2019-02-05-14-10-39_2ndPart_2': [1,2,3,4,5,6,9,10] , # mh_2\n",
    "                           '2019-02-08-10-51-3_1stPart_1': [11,12], # mn_1\n",
    "                           '2019-02-08-11-05-7_2ndPart_1': [1,2,3,4,7,8,9,10,11,12], # mn_1\n",
    "                           '2019-02-19-10-34-7_1stPart_1': [9,10], # mn_3\n",
    "                           '2019-02-19-10-56-43_2ndPart_1': [1,2,5,6,7,8,9,10,11,12], # mn_3\n",
    "                           '2019-02-19-17-10-45_1': [9, 10], # ph_5\n",
    "                           '2019-01-16-15-18-0_1': [11,12], # no_1\n",
    "                           '2019-03-07-16-44-5_2': [5,6], #rh_1\n",
    "                           '2019-03-14-13-56-56_2' : [7,8], #rh_3\n",
    "                           '2019-01-14-15-07-21_1' : [11, 12], # ys_1\n",
    "                           '2019-01-16-15-18-50_1stPart_1': [6, 9, 10, 11], # ys_2\n",
    "                           '2019-01-16-15-42-51_2ndPart_1': [1, 2, 3, 4] # ys_2\n",
    "                          }\n",
    "\n",
    "\n",
    "\n",
    "dict_ChangeInTrials = {\n",
    "    '2019-01-17-15-05-1_1': ['Baseline', 'PictureSentence', 'PictureDifficulty', 'TrialSentence', \\\n",
    "                            'TrialDifficulty', 'TrialSentence', 'TrialDifficulty', 'TrialSentence', \\\n",
    "                            'TrialSentence', 'TrialSentence', 'TrialSentence', 'TrialSentence',\\\n",
    "                            'TrialSentence'], # ys_3\n",
    "    '2019-02-06-11-25-41_1': ['Baseline', 'PictureSentence', 'PictureDifficulty', 'TrialSentence', 'TrialDifficulty', \\\n",
    "                             'TrialSentence', 'TrialDifficulty', 'TrialSentence', 'TrialSentence', 'TrialSentence', \\\n",
    "                              'TrialSentence', 'TrialSentence'], # aq_1\n",
    "    '2019-01-28-14-30-44_1' : ['Baseline', 'PictureSentence', 'PictureDifficulty', 'TrialSentence', \\\n",
    "                            'TrialDifficulty', 'TrialSentence', 'TrialDifficulty', 'TrialSentence', \\\n",
    "                            'TrialSentence', 'TrialSentence', 'TrialSentence', 'TrialSentence',\\\n",
    "                            'TrialSentence'], # bh1_1\n",
    "    '2019-01-29-13-25-4_1' : ['Baseline', 'PictureSentence', 'PictureDifficulty', 'TrialSentence', \\\n",
    "                            'TrialDifficulty', 'TrialSentence', 'TrialDifficulty', 'TrialSentence', \\\n",
    "                            'TrialDifficulty', 'TrialSentence', 'TrialSentence', 'TrialSentence',\\\n",
    "                            'TrialSentence']\n",
    "                      }\n",
    "\n",
    "dict_ChangeInTrials_boolAddNextTrialData = {\n",
    "    '2019-01-17-15-05-1_1': [False, True, False, True, False, True, False, 0, 0, 0, 0, 0, 0], # ys_3\n",
    "    '2019-02-06-11-25-41_1': [False, True, False, True, False, True, False, False, False, False, False, False], # aq_1\n",
    "    '2019-01-28-14-30-44_1' : [False, True, False, True, False, True, False, False, False, False, False, False, False], # bh1_1\n",
    "    '2019-01-29-13-25-4_1' : [False, True, False, True, False, True, False, True, False, False, False, False, False]\n",
    "                      }\n",
    "                       \n",
    "dict_TrialToNan = {#'2019-02-12-15-27-37_2' : [0], # ac_2_2 --> Cannot be sure\n",
    "                   '2019-02-14-14-28-49_1': [7,8], # ac_3_MS_1 --> [7,8]\n",
    "                   #'2019-01-16-15-43-8_1': [0], # af_1_1 --> cannot be sure\n",
    "                   #'2019-01-17-15-27-20_1stPart_2' : [0], # af_2\n",
    "                   #'2019-01-17-16-03-27_2ndPart_2' : [0], # af_2\n",
    "                    '2019-02-19-13-31-29_2' : [5,6], # jp_5_2 --> [5,6]\n",
    "                    #'2019-03-04-11-20-5_1' : [0], # le_5_MS_1 --> is looking to the picture\n",
    "                    #'2019-03-04-12-00-15_2': [0], # le_5_MS_2 --> looking at the picture\n",
    "                    '2019-03-07-16-17-30_1': [11, 12], # rh_1_1 --> [11, 12]\n",
    "                    '2019-03-13-13-40-7_2': [3,4], # rh_2_2 --> [3,4] \n",
    "                    '2019-01-16-15-18-50_1stPart_1': [0, 6, 9, 10, 11] # ys_2 --> [0, 6, 9, 10, 11]\n",
    "                    #'2019-01-31-13-13-2_1': [0] # ys_5_1 --> cannot be sure\n",
    "}\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotPupilSizeWithEvents(PupilData_df, Event1_index, Event2_index, PlotTitle, SubjectAndSessionName, eventNumbers):\n",
    "    \n",
    "    subjectID = SubjectAndSessionName.split('__')[0]\n",
    "    \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    leftPlot = ax.plot(PupilData_df['timeStamp'], PupilData_df['pupilLeft'], 'b', label = 'Left')\n",
    "    rightPlot = ax.plot(PupilData_df['timeStamp'], PupilData_df['pupilRight'], 'r', label = 'Right')\n",
    "    \n",
    "    for start in Event1_index['start']:\n",
    "        event1_start = ax.plot([PupilData_df['timeStamp'][start], PupilData_df['timeStamp'][start]], [np.min(PupilData_df['pupilLeft']), np.max(PupilData_df['pupilLeft'])], color = 'orange')\n",
    "    \n",
    "    for end in Event1_index['end']:\n",
    "        event1_end = ax.plot([PupilData_df['timeStamp'][end], PupilData_df['timeStamp'][end]], [np.min(PupilData_df['pupilLeft']), np.max(PupilData_df['pupilLeft'])], color = 'pink')\n",
    "    \n",
    "    ax.set_ylabel('Absolute pupil size [in mm]')\n",
    "    ax.set_xlabel('Time [in s]')\n",
    "    \n",
    "    plt.title('plot {}  for subject  {}'.format(PlotTitle, SubjectAndSessionName))\n",
    "    \n",
    "    if eventNumbers > 1:\n",
    "        for start in Event2_index['start']:\n",
    "            event2_start = ax.plot([PupilData_df['timeStamp'][start], PupilData_df['timeStamp'][start]], [np.min(PupilData_df['pupilLeft']), np.max(PupilData_df['pupilLeft'])], color = 'green')\n",
    "    \n",
    "        for end in Event2_index['end']:\n",
    "            event2_end = ax.plot([PupilData_df['timeStamp'][end], PupilData_df['timeStamp'][end]], [np.min(PupilData_df['pupilLeft']), np.max(PupilData_df['pupilLeft'])], color = 'gray')\n",
    "    \n",
    "    #plt.legend((leftPlot, rightPlot, event1_start, event1_end, event2_start, event2_end), ('Left pupil', 'Right pupil', 'Reading start', 'Reading end', 'Writing start', 'Writing End'))\n",
    "        plt.legend([leftPlot[0], rightPlot[0], event1_start[0], event1_end[0], event2_start[0], event2_end[0]], ('Left pupil', 'Right pupil', 'Reading start', 'Reading end', 'Writing start', 'Writing End'))\n",
    "    else:\n",
    "        plt.legend([leftPlot[0], rightPlot[0], event1_start[0], event1_end[0]], ('Left pupil', 'Right pupil', 'Trial start', 'Trial end'))\n",
    "    \n",
    "    \n",
    "    pickle.dump(fig, open(r'C:\\DTU\\Results\\201901_Expt' + '\\\\Expt_w' + plotTitle + '\\\\' + subjectID + '\\\\' + 'pupilSize_CompleteExperiment_w' + PlotTitle + '_' + SubjectAndSessionName, 'wb'))\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindAndPlotPupilSizeForEpoch(GazeLog, TimeEpochTrial):\n",
    "    # function that uses the list of start and end trial times to find the pupil sizes for those trials and plots them\n",
    "    \n",
    "    # first create a list of times in gaze log\n",
    "    timeStrGazeLog = [item3[0] for item3 in GazeLog]\n",
    "    # convert the list of strings to datetime formats\n",
    "    timeGazeLog = timeConversion(timeStrGazeLog)\n",
    "    \n",
    "    # internal time, to depict seconds\n",
    "    timeInternalGazeLog = [float(item3[1]) for item3 in GazeLog]\n",
    "    \n",
    "    # extract pupil sizes in decimals from the strange 2 columns for every pupil\n",
    "    pupilLogL, pupilLogR = Convert2ColumnSizesTo1(GazeLog)\n",
    "    \n",
    "    timeOfGaze_TrialList = list()\n",
    "    \n",
    "    \n",
    "    blinkDurationAverageList = list()\n",
    "    blinkTimeList = list()\n",
    "    blinkFrequencyList = list()\n",
    "    timeInS_List = list()\n",
    "    pupilMean_Absolute = list()\n",
    "    pupilMean_Relative = list()\n",
    "    interBlinkDurationList = list()\n",
    "    \n",
    "    # for every epoch, plot the pupil size\n",
    "    for trialNr in range(0, len(TimeEpochTrial['start'])):\n",
    "        \n",
    "        # find pupil sizes for the trial\n",
    "        pupilSizeL_Trial, pupilSizeR_Trial, timeGaze_Trial, timeInternal_Trial = PupilSizeFromTrialTimes(\n",
    "            [TimeEpochTrial['start'][trialNr], TimeEpochTrial['end'][trialNr]], timeGazeLog, \n",
    "                                timeInternalGazeLog, pupilLogL, pupilLogR)\n",
    "        \n",
    "        pupilSize_Trial = dict()\n",
    "        pupilSize_Filter = dict()\n",
    "        pupilSize_woBlink = dict()\n",
    "        \n",
    "        # find difference in consecutive elements of internal time\n",
    "        timeInternalDifference = [t - s for s, t in zip(timeInternal_Trial, timeInternal_Trial[1:])]\n",
    "        # divide by 1000 to make it s\n",
    "        timeOfGaze_Trial = [sum(timeInternalDifference[:i])/1000000 for i in range(1,len(timeInternalDifference))]\n",
    "\n",
    "        \n",
    "        pupilSize_Trial['Left'] = pupilSizeL_Trial\n",
    "        pupilSize_Trial['Right'] = pupilSizeR_Trial\n",
    "        \n",
    "        \n",
    "        # filter the blinks\n",
    "        pupilSizeL_woBlink, time_filter, blinkDuration, blinkFrequency, interBlinkDuration, timeInS_filter = filterBlinks(pupilSizeL_Trial, timeGaze_Trial, timeOfGaze_Trial)\n",
    "        pupilSizeR_woBlink, time_filter, blinkDuration, blinkFrequency, interBlinkDuration, timeInS_filter = filterBlinks(pupilSizeR_Trial, timeGaze_Trial, timeOfGaze_Trial)\n",
    "        \n",
    "        # time of trial\n",
    "        timeInS_List.append(timeInS_filter)\n",
    "        \n",
    "        pupilSize_woBlink['Left'] = pupilSizeL_woBlink\n",
    "        pupilSize_woBlink['Right'] = pupilSizeR_woBlink\n",
    "        \n",
    "        # Hampel filter to remove the outliers\n",
    "        winSize = 25\n",
    "        pupilSizeL_filter = hampel(pupilSizeL_woBlink, winSize, 3, False)\n",
    "        pupilSizeR_filter = hampel(pupilSizeR_woBlink, winSize, 3, False)\n",
    "\n",
    "        pupilSize_Filter['Left'] = pupilSizeL_filter\n",
    "        pupilSize_Filter['Right'] = pupilSizeR_filter\n",
    "        \n",
    "        \n",
    "        RLCorrelation = np.corrcoef(pupilSizeL_filter, pupilSizeR_filter)\n",
    "        if RLCorrelation[0][1] < 0.8:\n",
    "            print('correlation between left and right:  ', RLCorrelation)\n",
    "        \n",
    "        timeOfGaze_TrialList.append(timeOfGaze_Trial[-1])\n",
    "        \n",
    "        timeInS_trialFilteredPlot = np.arange(0, len(pupilSize_Filter['Left'])/90, 1/90)\n",
    "        timeOfGaze_trialNonFilteredPlot = np.arange(0, len(pupilSizeL_Trial)/90, 1/90)\n",
    "        \n",
    "        #print(len(timeOfGaze_trialNonFilteredPlot), len(pupilSizeL_Trial))\n",
    "        \n",
    "        plotPupilSize_checkFilter(pupilSize_Filter['Left'], timeInS_trialFilteredPlot, pupilSizeL_Trial, timeOfGaze_trialNonFilteredPlot, trialNr)\n",
    "        \n",
    "    #return timeOfGaze_TrialList, timeInS_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotPupilSizeWithEvents_(PupilData_df, EventsTrials, PlotTitle, SubjectAndSessionName):\n",
    "    \n",
    "    subjectID = SubjectAndSessionName.split('__')[0]\n",
    "    \n",
    "    EventTrials_index = dict()\n",
    "    EventTrials_index['start'] = [i for i, x in enumerate(EventsTrials['start']) if x] \n",
    "    EventTrials_index['end'] = [i for i, x in enumerate(EventsTrials['end']) if x] \n",
    "    \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    ax.plot(PupilData_df['timeStamp'], PupilData_df['pupilLeft'], 'b', label = 'Left')\n",
    "    ax.plot(PupilData_df['timeStamp'], PupilData_df['pupilRight'], 'r', label = 'Right')\n",
    "    \n",
    "    for start in EventTrials_index['start']:\n",
    "        ax.plot([PupilData_df['timeStamp'][start], PupilData_df['timeStamp'][start]], [np.min(PupilData_df['pupilLeft']), np.max(PupilData_df['pupilLeft'])], color = 'orange')\n",
    "    \n",
    "    for end in EventTrials_index['end']:\n",
    "        ax.plot([PupilData_df['timeStamp'][end], PupilData_df['timeStamp'][end]], [np.min(PupilData_df['pupilLeft']), np.max(PupilData_df['pupilLeft'])], color = 'green')\n",
    "    \n",
    "    ax.set_ylabel('Absolute pupil size [in mm]')\n",
    "    ax.set_xlabel('Time [in s]')\n",
    "    plt.legend()\n",
    "    plt.title('plot {}  for subject  {}'.format(PlotTitle, SubjectAndSessionName))\n",
    "    \n",
    "    #pickle.dump(fig, open(r'C:\\DTU\\Results\\201901_Expt\\Expt_wTrialsMarked' + '\\\\' + subjectID + '\\\\' + 'pupilSize_CompleteExperiment_w' + PlotTitle + SubjectAndSessionName, 'wb'))\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
