{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckCoolDownTime(EventTrials_reading, PupilSize_df, NanValues, TimeBaseline, SubjectAndSessionName):\n",
    "\n",
    "    subjectID = SubjectAndSessionName.split('__')[0]\n",
    "    timeBaselineCheck = 5 # seconds\n",
    "    \n",
    "    pupilSize_baseline = dict()\n",
    "    pupilSize_baseline['pupilLeft'] = list()\n",
    "    pupilSize_baseline['pupilRight'] = list()\n",
    "    \n",
    "    coolDown = dict()\n",
    "    coolDown['start'] = list()\n",
    "    coolDown['end'] = list()\n",
    "    \n",
    "    baseline = dict()\n",
    "    baseline['start'] = list()\n",
    "    baseline['end'] = list()\n",
    "    \n",
    "    for ind, startTimeInd in enumerate(EventTrials_reading['start']):\n",
    "        startBaselineTime_NextPhraseEnds = PupilSize_df['timeStamp'][startTimeInd]\n",
    "        \n",
    "        CoolDownStartTime, CoolDownStartInd = nearestTimePoint(PupilSize_df['timeStamp'].tolist(), \\\n",
    "                startBaselineTime_NextPhraseEnds-datetime.timedelta(seconds=timeBaselineCheck))\n",
    "        CoolDownEndTime, CoolDownEndInd = nearestTimePoint(PupilSize_df['timeStamp'].tolist(), \\\n",
    "                                                          CoolDownStartTime + datetime.timedelta(seconds=timeBaselineCheck))\n",
    "        \n",
    "        StartBaselineTime, StartBaselineInd = nearestTimePoint(PupilSize_df['timeStamp'].tolist(), \\\n",
    "                startBaselineTime_NextPhraseEnds-datetime.timedelta(seconds=TimeBaseline))\n",
    "        \n",
    "        EndBaselineTime, EndBaselineInd = nearestTimePoint(PupilSize_df['timeStamp'].tolist(), StartBaselineTime + \\\n",
    "                                                           datetime.timedelta(seconds=timeBaselineCheck))\n",
    "        \n",
    "        \n",
    "        coolDown['start'].append(CoolDownStartInd)\n",
    "        coolDown['end'].append(CoolDownEndInd)\n",
    "        \n",
    "        \n",
    "        \n",
    "        trial_pupilSize = PupilSize_df['timeStamp'][StartBaselineInd:EndBaselineInd]\n",
    "        trial_nanValues = NanValues[StartBaselineInd:EndBaselineInd]\n",
    "        \n",
    "        # find baseline pupil size, for TimeBaseline \n",
    "        overlapping_time = 0.1 #s\n",
    "        sampling_frequency = 90\n",
    "        nIterations = int((timeBaselineCheck+TimeBaseline)/overlapping_time)+1\n",
    "        iteration = 0\n",
    "        done = 0\n",
    "        while iteration < nIterations:\n",
    "            NanValuesPresent = trial_nanValues[int(iteration*(TimeBaseline-overlapping_time)*sampling_frequency):\\\n",
    "                                     int((iteration*(TimeBaseline-overlapping_time) + TimeBaseline)*sampling_frequency)]\n",
    "            \n",
    "            if sum(NanValuesPresent) < 1 and len(NanValuesPresent)>1:\n",
    "                #print('done')\n",
    "                baselineStartInd = StartBaselineInd + int(iteration*(TimeBaseline-overlapping_time)*sampling_frequency)\n",
    "                baselineEndInd = StartBaselineInd + int((iteration*(TimeBaseline-overlapping_time) + TimeBaseline)*\\\n",
    "                                                        sampling_frequency)\n",
    "                done = 1\n",
    "                \n",
    "                #print(np.mean(PupilSize_df['pupilLeft'][baselineStartInd:baselineEndInd]))\n",
    "                #print(np.mean(PupilSize_df['pupilRight'][baselineStartInd:baselineEndInd]))\n",
    "                \n",
    "                pupilSize_baseline['pupilLeft'].append(np.mean(PupilSize_df['pupilLeft'][baselineStartInd:baselineEndInd]))\n",
    "                pupilSize_baseline['pupilRight'].append(np.mean(PupilSize_df['pupilRight'][baselineStartInd:baselineEndInd]))\n",
    "        \n",
    "                baseline['start'].append(StartBaselineInd)\n",
    "                baseline['end'].append(EndBaselineInd)\n",
    "                #plt.figure()\n",
    "                #plt.plot(PupilSize_df['timeStamp'][baselineStartInd:baselineEndInd], PupilSize_df['pupilLeft'][\\\n",
    "                #    baselineStartInd:baselineEndInd])\n",
    "                #plt.plot(PupilSize_df['timeStamp'][baselineStartInd:baselineEndInd], PupilSize_df['pupilRight'][\\\n",
    "                #    baselineStartInd:baselineEndInd])\n",
    "                \n",
    "                break\n",
    "            \n",
    "            iteration = iteration + 1\n",
    "            \n",
    "        if done < 1:\n",
    "            print('baseline not found')\n",
    "            # add another 5s to the baseline search\n",
    "            \n",
    "            extraBaseLineEndTime, extraBaseLineEndInd = nearestTimePoint(PupilSize_df['timeStamp'].tolist(), EndBaselineTime\\\n",
    "                    +datetime.timedelta(seconds=timeBaselineCheck))\n",
    "            \n",
    "            trial_nanValues = NanValues[EndBaselineInd:extraBaseLineEndInd]\n",
    "            \n",
    "            nIterations = int((timeBaselineCheck+TimeBaseline)/overlapping_time)+1\n",
    "            iteration = 0\n",
    "            done = 0\n",
    "            while iteration < nIterations:\n",
    "                NanValuesPresent = trial_nanValues[int(iteration*(TimeBaseline-overlapping_time)*sampling_frequency):\\\n",
    "                                     int((iteration*(TimeBaseline-overlapping_time) + TimeBaseline)*sampling_frequency)]\n",
    "            \n",
    "                if sum(NanValuesPresent) < 1 and len(NanValuesPresent)>1:\n",
    "                    #print('done')\n",
    "                    baselineStartInd = EndBaselineInd + int(iteration*(TimeBaseline-overlapping_time)*sampling_frequency)\n",
    "                    baselineEndInd = EndBaselineInd + int((iteration*(TimeBaseline-overlapping_time) + TimeBaseline)*\\\n",
    "                                                        sampling_frequency)\n",
    "                    done = 1\n",
    "                \n",
    "                    #print(np.mean(PupilSize_df['pupilLeft'][baselineStartInd:baselineEndInd]))\n",
    "                    #print(np.mean(PupilSize_df['pupilRight'][baselineStartInd:baselineEndInd]))\n",
    "                \n",
    "                    pupilSize_baseline['pupilLeft'].append(np.mean(PupilSize_df['pupilLeft'][baselineStartInd:baselineEndInd]))\n",
    "                    pupilSize_baseline['pupilRight'].append(np.mean(PupilSize_df['pupilRight'][baselineStartInd:baselineEndInd]))\n",
    "                    \n",
    "                    baseline['start'].append(StartBaselineInd)\n",
    "                    baseline['end'].append(EndBaselineInd)\n",
    "                \n",
    "                    #plt.figure()\n",
    "                    #plt.plot(PupilSize_df['timeStamp'][baselineStartInd:baselineEndInd], PupilSize_df['pupilLeft'][\\\n",
    "                    #    baselineStartInd:baselineEndInd])\n",
    "                    #plt.plot(PupilSize_df['timeStamp'][baselineStartInd:baselineEndInd], PupilSize_df['pupilRight'][\\\n",
    "                    #    baselineStartInd:baselineEndInd])\n",
    "                \n",
    "                    break\n",
    "            \n",
    "                iteration = iteration + 1\n",
    "            \n",
    "            if done < 1:\n",
    "                print('baseline not found -- again')\n",
    "              \n",
    "        \n",
    "    plt.figure()\n",
    "    plt.plot(PupilSize_df['timeStamp'], PupilSize_df['pupilLeft'], 'cyan')\n",
    "    \n",
    "    for i, coolDownStartInd in enumerate(coolDown['start']):\n",
    "        plt.plot([PupilSize_df['timeStamp'][coolDownStartInd],PupilSize_df['timeStamp'][coolDownStartInd]],[np.min(PupilSize_df['pupilLeft']), np.max(PupilSize_df['pupilLeft'])], color = 'green')\n",
    "        plt.plot([PupilSize_df['timeStamp'][coolDown['end'][i]],PupilSize_df['timeStamp'][coolDown['end'][i]]],[np.min(PupilSize_df['pupilLeft']), np.max(PupilSize_df['pupilLeft'])], color = 'gray')\n",
    "        \n",
    "        plt.plot(PupilSize_df['timeStamp'][baseline['start'][i]], pupilSize_baseline['pupilLeft'][i], '*')\n",
    "        \n",
    "        plt.plot([PupilSize_df['timeStamp'][baseline['start'][i]],PupilSize_df['timeStamp'][baseline['start'][i]]],[np.min(PupilSize_df['pupilLeft']), np.max(PupilSize_df['pupilLeft'])], '-.', color = 'green')\n",
    "        plt.plot([PupilSize_df['timeStamp'][baseline['end'][i]],PupilSize_df['timeStamp'][baseline['end'][i]]],[np.min(PupilSize_df['pupilLeft']), np.max(PupilSize_df['pupilLeft'])], '-.', color = 'gray')\n",
    "        \n",
    "    PlotTitle = 'CoolDownAndVaryingBaseline'\n",
    "    pickle.dump(fig, open(r'C:\\DTU\\Results\\201901_Expt\\PupilBaseline' + '\\\\' + subjectID + '\\\\' + 'pupilSize_CompleteExperiment_w' + PlotTitle + '_' + SubjectAndSessionName, 'wb'))\n",
    "    \n",
    "    \n",
    "    return pupilSize_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject path E:\\Data\\Data\\ac\\1\\2019-02-11-11-18-30_1\n",
      "subject and session name:  ac__1__2019-02-11-11-18-30_1\n",
      "2019-02-11 11:18:35.498852 2019-02-11 11:18:42.867362\n",
      "subject path E:\\Data\\Data\\ac\\1\\2019-02-11-11-33-32_2\n",
      "subject and session name:  ac__1__2019-02-11-11-33-32_2\n",
      "2019-02-11 11:33:43.254479 2019-02-11 11:33:54.564414\n",
      "subject path E:\\Data\\Data\\ac\\2\\2019-02-12-15-00-04_1\n",
      "subject and session name:  ac__2__2019-02-12-15-00-04_1\n",
      "2019-02-12 15:00:08.926311 2019-02-12 15:00:17.216577\n",
      "subject path E:\\Data\\Data\\ac\\2\\2019-02-12-15-27-37_2\n",
      "subject and session name:  ac__2__2019-02-12-15-27-37_2\n",
      "2019-02-12 15:27:42.679109 2019-02-12 15:27:49.581126\n",
      "subject path E:\\Data\\Data\\ac\\3_MS\\2019-02-14-14-28-49_1\n",
      "subject and session name:  ac__3_MS__2019-02-14-14-28-49_1\n",
      "2019-02-14 14:28:53.273463 2019-02-14 14:29:33.208768\n",
      "subject path E:\\Data\\Data\\ac\\3_MS\\2019-02-14-14-45-49_2\n",
      "subject and session name:  ac__3_MS__2019-02-14-14-45-49_2\n",
      "2019-02-14 14:45:53.753655 2019-02-14 14:46:44.590368\n",
      "subject path E:\\Data\\Data\\ac\\4\\2019-02-18-14-59-21_1\n",
      "subject and session name:  ac__4__2019-02-18-14-59-21_1\n",
      "2019-02-18 14:59:26.288707 2019-02-18 15:00:18.658878\n",
      "subject path E:\\Data\\Data\\ac\\4\\2019-2-18-15-23-54_2\n",
      "subject and session name:  ac__4__2019-2-18-15-23-54_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-af74efe17892>\", line 136, in <module>\n",
      "    userKeys_new = FixUserKeys(userKeys)\n",
      "  File \"C:\\DTU\\PythonScripts\\Analysis_Expt_201901\\Functions.py\", line 286, in FixUserKeys\n",
      "    range(0, len(UserKeys_ProgressPercent))]\n",
      "  File \"C:\\DTU\\PythonScripts\\Analysis_Expt_201901\\Functions.py\", line 285, in <listcomp>\n",
      "    UserKeys_New = [[UserKeys_Times[ind], UserKeys_Keys[ind], UserKeys_ProgressPercent[ind]] for ind in\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "AttributeError: module has no attribute '__name__'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "metricComputed_right = 'PupilSizeBaselineRight'\n",
    "metricComputed_left =  'PupilSizeBaselineLeft'\n",
    "\n",
    "dataFolderName = r'E:\\Data\\Data' # accessing external hard disk with the data\n",
    "a = re.compile('(?<=Data\\\\\\\\Data\\\\\\\\)(.*)(?=\\\\\\\\[1-9])')\n",
    "subjectName_listElement = 3\n",
    "\n",
    "#dataFolderName = r'C:\\DTU\\Data\\201901_JanuaryExpt' # accessing data saved in the computer\n",
    "#a = re.compile('(?<=Data\\\\\\\\201901_JanuaryExpt\\\\\\\\)(.*)(?=\\\\\\\\[1-9])')\n",
    "#subjectName_listElement = 4\n",
    "\n",
    "resultFileName_right = r'C:\\DTU\\Data\\201901_JanuaryExpt\\DataExtracted\\IndividualTrials\\Subject_Block_Session_Trial_' + metricComputed_right +  '.xlsx'\n",
    "resultFileName_left = r'C:\\DTU\\Data\\201901_JanuaryExpt\\DataExtracted\\IndividualTrials\\Subject_Block_Session_Trial_' + metricComputed_left +  '.xlsx'\n",
    "\n",
    "baselinePupilSize = dict()\n",
    "baselinePupilSize['pupilLeft'] = list()\n",
    "baselinePupilSize['pupilRight'] = list()\n",
    "\n",
    "baselinePupilSize1 = dict()\n",
    "baselinePupilSize1['pupilLeft'] = list()\n",
    "baselinePupilSize1['pupilRight'] = list()\n",
    "\n",
    "baselinePupilSize2 = dict()\n",
    "baselinePupilSize2['pupilLeft'] = list()\n",
    "baselinePupilSize2['pupilRight'] = list()\n",
    "\n",
    "for root, dirs, subfolder in os.walk(dataFolderName):\n",
    "    \n",
    "    technique = 'dwell_time'\n",
    "    \n",
    "    if not dirs:\n",
    "        \n",
    "        #if 'notCompleted' in root or 'notInclude' in root: # Some subjects do not have gaze log and have been marked as \n",
    "        \n",
    "        if 'noData' in root or 'Trial' in root or 'trial' in root or 'Nothing' in root: # Some subjects do not have gaze log and have been marked as \n",
    "            #notInclude\n",
    "            continue\n",
    "        if 'Jonas' in root or 'Praktikant' in root or 'Villads' in root:\n",
    "            continue\n",
    "            \n",
    "        if 'ac\\\\' not in root:\n",
    "            continue\n",
    "        if 'Picture' in root:\n",
    "            continue\n",
    "        #if '_MS' not in root:\n",
    "        #    continue\n",
    "        \n",
    "        #if 'bh2\\\\3\\\\2019-02-28-16-47-35_1' not in root:\n",
    "        #    continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        #if '2019-1-16-16-36-17_1stPart_2' not in root:\n",
    "        #    continue\n",
    "            \n",
    "        keysSelected = None\n",
    "        userKeys = None\n",
    "        phraseLog = None\n",
    "        \n",
    "        for file in subfolder:\n",
    "            \n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'KeySelection*'):\n",
    "                try:\n",
    "                    \n",
    "                    fKeysSelected = open(root + '\\\\' + file, encoding='utf-8', newline='')\n",
    "                    readerKeysSelected = csv.reader(fKeysSelected)\n",
    "                    keysSelected = list(readerKeysSelected)\n",
    "                    \n",
    "                    keysSelected.remove(keysSelected[0])\n",
    "                except:\n",
    "                    if fKeysSelected is not None:\n",
    "                        fKeysSelected.close()\n",
    "                    else:\n",
    "                        print('error in opening the KeySelection log file')\n",
    "                        \n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'user*'):\n",
    "                try:\n",
    "                    fUserKey = open(root + '\\\\' + file, encoding='utf-8',  newline='')\n",
    "                    readerUserKey = csv.reader(fUserKey, quotechar=None)\n",
    "                    userKeys = list(readerUserKey)\n",
    "                    userKeys.remove(userKeys[0])\n",
    "                except:\n",
    "                    if fUserKey is not None:\n",
    "                        fUserKey.close()\n",
    "                    else:\n",
    "                        print('error in opening the user key log file')\n",
    "                        \n",
    "            if fnmatch.fnmatch(file, 'phrase*'):\n",
    "                try:\n",
    "                    fPhraseLog = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerPhraseLog = csv.reader(fPhraseLog, quotechar=None)\n",
    "                    phraseLog = list(readerPhraseLog)\n",
    "                    \n",
    "                except:\n",
    "                    if fPhraseLog is not None:\n",
    "                        fPhraseLog.close()\n",
    "                    else:\n",
    "                        print('error in opening the phrase log file')\n",
    "                        \n",
    "            if fnmatch.fnmatch(file, 'multiKey*'):\n",
    "                technique = 'multiKey_selection'\n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'tobiiGazeLog*'):\n",
    "                try:\n",
    "                    fGazeLog = open(root + '\\\\' + file, encoding='utf-8', newline='')\n",
    "                    readerGazeLog = csv.reader(fGazeLog, quotechar=None)\n",
    "                    gazeLog = list(readerGazeLog)\n",
    "                    gazeLog.remove(gazeLog[0])\n",
    "                    gazeLog.remove(gazeLog[-1])\n",
    "                    \n",
    "                except:\n",
    "                    if fGazeLog is not None:\n",
    "                        fGazeLog.close()\n",
    "                    else:\n",
    "                        print('error in opening the scratchpad log file')\n",
    "            \n",
    "                    \n",
    "                     \n",
    "        if keysSelected is None or userKeys is None or phraseLog is None or gazeLog is None:\n",
    "            continue\n",
    "        else:\n",
    "                \n",
    "            print('subject path', root)\n",
    "            subjAndSessionName = '__'.join(root.split('\\\\')[subjectName_listElement:])\n",
    "            subjName = subjAndSessionName.split('__')[0]\n",
    "            print('subject and session name: ', subjAndSessionName)\n",
    "            sessionFolderName = root.split('\\\\')[-1]\n",
    "            \n",
    "            \n",
    "            # fix phraselog due to comma related file changes\n",
    "            phraseLog_new = FixScratchPad(phraseLog)\n",
    "            \n",
    "            # fix userKeys due to comma related file changes\n",
    "            userKeys_new = FixUserKeys(userKeys)\n",
    "            \n",
    "            \n",
    "            # need to fix keys selected, where rows get combined because of an inverted comma\n",
    "            keysSelected_new = FixKeysSelected(keysSelected)\n",
    "            \n",
    "            # find start time of typing\n",
    "            timeTyping = OptiKeyTypingTime(userKeys_new)\n",
    "            \n",
    "            timeBaselineQuestion = getBaselineQuestion(timeTyping, keysSelected_new)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            # divide complete data into epochs of phrases\n",
    "            timeStartEndDict_reading, timeStartEndDict_writing = FindTrialTimes(keysSelected_new, timeTyping, root)\n",
    "            \n",
    "            if sessionFolderName in dict_noGazeData:\n",
    "                print('no gaze data present')\n",
    "                baselinePupilSize['pupilRight'] = [np.nan]*len(timeStartEndDict_reading['start'])\n",
    "                baselinePupilSize['pupilLeft'] = [np.nan]*len(timeStartEndDict_writing['start'])\n",
    "                \n",
    "            else:\n",
    "            \n",
    "               # filter the data\n",
    "                pupilData_filtered, nanValues = FilterPupilSize(gazeLog, timeTyping, subjAndSessionName)\n",
    "            \n",
    "                # find a vector indicating True for the start and end of trials, False otherwise\n",
    "                eventTrials_reading, eventTrials_readingIndex = DivideTimeIntoTrials(pupilData_filtered, timeStartEndDict_reading)\n",
    "                eventTrials_writing, eventTrials_writingIndex = DivideTimeIntoTrials(pupilData_filtered, timeStartEndDict_writing)\n",
    "            \n",
    "                # baseline time extraction\n",
    "                #pupilSize_baseLine = GetBaseline(eventTrials_reading, pupilData_filtered)\n",
    "                timeBaseline = 0.3 # seconds\n",
    "                CheckCoolDownTime(eventTrials_readingIndex, pupilData_filtered, nanValues, timeBaseline, subjAndSessionName)\n",
    "            \n",
    "            \n",
    "            if '1stPart' in root:\n",
    "                print('1stPart')\n",
    "                baselinePupilSize1['pupilRight'] = baselinePupilSize['pupilRight']\n",
    "                baselinePupilSize1['pupilLeft'] = baselinePupilSize['pupilLeft']\n",
    "                \n",
    "                print(baselinePupilSize1)\n",
    "                \n",
    "                continue\n",
    "                \n",
    "            if '2ndPart' in root:\n",
    "                print('2ndPart')\n",
    "                baselinePupilSize2['pupilRight'] = baselinePupilSize1['pupilRight']\n",
    "                baselinePupilSize2['pupilLeft'] = baselinePupilSize1['pupilLeft']\n",
    "                \n",
    "                baselinePupilSize['pupilRight'] = baselinePupilSize1['pupilRight'] + baselinePupilSize2['pupilRight']\n",
    "                baselinePupilSize['pupilLeft'] = baselinePupilSize1['pupilLeft'] + baselinePupilSize2['pupilLeft']\n",
    "                \n",
    "                baselinePupilSize1['pupilLeft'] = list()\n",
    "                baselinePupilSize1['pupilRight'] = list()\n",
    "                \n",
    "             \n",
    "            \n",
    "            # save the ipa_reading\n",
    "            dataToSave_right = DataForEveryTrial()\n",
    "            dataToSave_right.subjectID = subjAndSessionName.split('__')[0]\n",
    "            dataToSave_right.blockNumber = subjAndSessionName.split('__')[1]\n",
    "            dataToSave_right.sessionNumber = subjAndSessionName[-1]\n",
    "            dataToSave_right.variable = metricComputed_right\n",
    "            dataToSave_right.dataForTrial = baselinePupilSize['pupilRight']\n",
    "            dataToSave_right.resultPathName = resultFileName_right\n",
    "            \n",
    "            print(dataToSave_right.printInfo())\n",
    "            dataToSave_right.AddToFile()\n",
    "            \n",
    "            \n",
    "            \n",
    "            # save the ipa_reading\n",
    "            dataToSave_left = DataForEveryTrial()\n",
    "            dataToSave_left.subjectID = subjAndSessionName.split('__')[0]\n",
    "            dataToSave_left.blockNumber = subjAndSessionName.split('__')[1]\n",
    "            dataToSave_left.sessionNumber = subjAndSessionName[-1]\n",
    "            dataToSave_left.variable = metricComputed_left\n",
    "            dataToSave_left.dataForTrial = baselinePupilSize['pupilLeft']\n",
    "            dataToSave_left.resultPathName = resultFileName_left\n",
    "            \n",
    "            print(dataToSave_left.printInfo())\n",
    "            dataToSave_left.AddToFile()\n",
    "            \n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
