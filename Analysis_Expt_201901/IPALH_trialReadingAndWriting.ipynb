{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "#%matplotlib inline\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "import fnmatch\n",
    "from pathlib import Path\n",
    "from itertools import groupby\n",
    "import copy\n",
    "import itertools\n",
    "#import distance\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pywt\n",
    "import math\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import snowball\n",
    "\n",
    "from itertools import *\n",
    "from operator import *\n",
    "\n",
    "# import other jupyter notebooks\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exceptional removal of particular extra sentences not typed by the user \n",
    "dict_phraseStim = {\n",
    "    #'2019-02-05-14-10-39_2ndPart_2' : [1, 2, 3, 4, 5, 6, 9, 10],\n",
    "    #'2019-01-14-14-58-30' : [0], # ys, session_trial ()\n",
    "    '2019-01-16-16-36-17_1stPart_2' : [-1], # af_session1\n",
    "    '2019-01-16-17-00-12_2ndPart_2': [1], # af_session1\n",
    "    '2019-01-17-15-27-20_1stPart_2' : [4], # Af session2\n",
    "    '2019-01-17-16-03-27_2ndPart_2' : [0, 1, 2], # Af session2\n",
    "    '2019-02-06-11-25-41_1' : [7],               # aq_session1    \n",
    "    '2019-02-08-11-33-53_1stPart_1' : [1],  # aq session3_1_part1\n",
    "    '2019-02-08-12-11-34_2ndPart_1' : [0, 1, 2, 3],  # aq session3_1_part2\n",
    "    '2019-01-31-09-37-5_2ndPart_2' : range(1,5), # bh1, session 4 , all sentences except the first one deleted\n",
    "    '2019-01-31-09-22-49_1stPart_2' : [4],  # bh1_session4_2_part1\n",
    "    '2019-02-21-16-09-44_1stPart_1' : [1], # bh2_session1\n",
    "    '2019-02-21-16-22-22_2ndPart_1' : [2, 3, 4],# bh2_session1\n",
    "    '2019-02-28-17-03-53_1stPart_2' : [2],       # bh2_session3\n",
    "    '2019-02-28-17-24-2_2ndPart_2' : [0, 2],     # bh2_session3\n",
    "    '2019-02-14-13-28-20_1stPart_2' : [2], # cw_session3_2_part1\n",
    "    '2019-02-14-13-57-41_2ndPart_2' : [0, 2, 3], # cw_session3_2_part2\n",
    "    '2019-02-21-15-01-4_1stPart_1' : [0],        # le_session3\n",
    "    '2019-02-21-15-25-56_2ndPart_1' : [1],        # le_session3\n",
    "    '2019-02-18-10-28-35_2' : [0],               # ls2_session4 # picture not described\n",
    "    '2019-02-05-14-00-27_1stPart_2' : [3],        # mh_session1\n",
    "    '2019-02-05-14-10-39_2ndPart_2' : [0, 1, 3],   # mh_session1\n",
    "    '2019-02-08-10-51-3_1stPart_1' : [4],        # mn_session1\n",
    "    '2019-02-08-11-05-7_2ndPart_1' : [0, 2, 3, 4], # mn_session1\n",
    "    '2019-02-19-10-34-7_1stPart_1' : [3],          # mn_session3\n",
    "    '2019-02-19-10-56-43_2ndPart_1' : [1, 2, 3, 4], # mn_session3\n",
    "    '2019-01-16-15-18-0_1' : [4],            # no_session1\n",
    "    '2019-02-19-17-10-45_1' : [3],                  # ph_session5\n",
    "    '2019-01-29-13-25-4_1' : [3],        # ph_session2\n",
    "    '2019-03-07-16-44-5_2' : [1],                   # rh_session1\n",
    "    '2019-03-14-13-56-56_2' : [2],                  # rh_session3\n",
    "    '2019-01-14-15-07-21_1' : [4], # ys_session1\n",
    "    '2019-01-16-15-18-50_1stPart_1' : [3, 4], # ys_session2\n",
    "    '2019-01-16-15-42-51_2ndPart_1' : [2], # ys_session2\n",
    "    '2019-01-30-11-22-25_1' : [3, 5, 7],          # ys_session4\n",
    "    '2019-01-30-11-22-25_1' : [4, 6, 7] # ys, session 4\n",
    "}\n",
    "\n",
    "# exceptional removal of sentences/words typed by the user, but then deleted everything to have a blank scratchpad\n",
    "\n",
    "dict_phraseUser = {\n",
    "    \"2019-02-06-15-44-15_1\" : [2, 3, 6], \n",
    "    \"2019-02-06-16-19-9_2\" : [1, 3, 6, 7],\n",
    "    \"2019-02-12-11-21-21_2\" : [0],\n",
    "    \"2019-02-14-14-28-49_1\" : [0, 2, 3], # ac_session3_1\n",
    "    \"2019-02-14-14-45-49_2\" : [0, 5, 6], # ac_session3_2\n",
    "    '2019-01-29-14-19-26_1' : [0, 3, 4], # bh1_session2_1\n",
    "    '2019-01-29-14-40-36_2' : [0, 1, 2], # bh1_session2_2\n",
    "    '2019-01-30-14-29-29_2' : [4],       # bh1_session3_2\n",
    "    '2019-01-31-09-12-2_1' : [3],         # bh1_session4_1\n",
    "    '2019-01-31-09-22-49_1stPart_2' : [4], # bh1_session4_2_part1\n",
    "    '2019-03-05-09-15-11_1' : [1],         # bh2_session5_1\n",
    "    '2019-03-05-09-15-11_2' : [1],        # bh2_session5_2\n",
    "    '2019-02-21-15-55-56_2' : [2],       # ch_session5_2\n",
    "    '2019-01-30-15-19-36_2' : [1],       # jm_session2_1\n",
    "    '2019-01-30-15-04-30_1' : [0],         # jm_session2_2\n",
    "    '2019-01-16-15-18-50_1stPart_1' : [1],  # ys_session2\n",
    "    '2019-01-16-15-42-51_2ndPart_1' : [0], # ys_session2\n",
    "    '2019-01-30-11-22-25_1' : [2, 4],       # ys_session4\n",
    "    '2019-01-30-11-57-3_2' : [0] ,          # ys_session4\n",
    "    '2019-01-31-13-13-2_1' : [4],           # ys_session5\n",
    "    '2019-01-30-10-20-32_1' : [0, 1, 2, 3, 4, 5], # no_session4\n",
    "    '2019-01-30-10-46-38_2' : [0],          # \n",
    "    '2019-02-28-17-03-53_1stPart_2' : [2],   # bh2_session3\n",
    "    '2019-03-12-09-30-5_1' : [0],            # kj_session3\n",
    "    '2019-02-13-15-20-38_1' : [0, 1, 2, 3, 6], # ls1_session3\n",
    "    '2019-02-18-10-25-52_1' : [1],              # ls2_session4\n",
    "    '2019-02-18-10-46-26_2' : [0],            # ls2_session4\n",
    "    '2019-01-29-13-25-4_1' : [0, 1, 7],        # ph_session2\n",
    "    '2019-01-29-13-43-50_2' : [0],              # ph_session2\n",
    "    '2019-03-07-16-17-30_1' : [0],              # rh_session1\n",
    "    '2019-03-07-16-44-5_2' : [0, 1],         # rh_session1\n",
    "    '2019-03-14-13-56-56_2' : [0, 1, 3]         # rh_session3\n",
    "}\n",
    "\n",
    "# key selection can have extra selections of NextPhrase at the end\n",
    "dict_keySelectionOfNextPhrase = {\n",
    "    \"2019-02-11-11-18-30_1\" : [12, 13], # ac_session1\n",
    "    \"2019-01-16-17-00-12_2ndPart_2\" : [12], # af_session1\n",
    "    \"2019-01-17-15-27-20_1stPart_2\" : [12], # af_session2\n",
    "    \"2019-02-06-16-19-9_2\" : [12], # af_session3\n",
    "    \"2019-02-12-11-07-43_1\" : [12], # af_session4\n",
    "    \"2019-02-27-15-08-32_1\" : [12], # af_session5\n",
    "    \"2019-01-28-14-30-44_1\" : [12], # bh1_session1\n",
    "    \"2019-02-21-16-22-22_2ndPart_1\" : [12], # bh2_session1\n",
    "    \"2019-02-18-14-02-56_2\" : [12], # le_session1\n",
    "    \"2019-02-19-10-03-14_1\" : [12], # le_session2\n",
    "    \"2019-02-08-11-05-7_2ndPart_1\" : [12], # mn_session1\n",
    "    \"2019-02-08-11-12-51_2\" : [12, 13], # mn_session1\n",
    "    \"2019-02-15-11-38-22_1\" : [12, 13], # mn_session2\n",
    "    \"2019-02-15-11-54-25_2\" : [12], # mn_session2\n",
    "    \"2019-01-16-15-18-0_1\" : [12], # no_session1\n",
    "    \"2019-01-28-13-31-51_1\" : [12], # ph_session1\n",
    "    \"2019-01-28-13-49-14_2\" : [12], # ph_session1\n",
    "    \"2019-01-14-15-07-21_1\" : [12], # ys_session1\n",
    "    \"2019-01-17-15-05-1_1\" : [12], # ys_session3\n",
    "    \"2019-01-30-11-22-25_1\" : [12], # ys_session4\n",
    "    \"2019-01-31-13-32-2_2\" : [12], # ys_session5\n",
    "}\n",
    "\n",
    "\n",
    "# key selection when participants skips some sentences\n",
    "dict_keySelectionNotCompleted = {\n",
    "    \"2019-01-16-16-36-17_1stPart_2\" : [0, 1, 3, 5, 7], # af_session1 ---- last sentence is not finished\n",
    "    \"2019-01-16-17-00-12_2ndPart_2\" : [0, 1, 3, 4, 5, 7, 9, 11], # af_session1\n",
    "    \"2019-01-17-15-27-20_1stPart_2\" : [0, 1, 3, 5, 7, 9, 11], # af_session2 \n",
    "    \"2019-01-17-16-03-27_2ndPart_2\" : [0, 1, 2, 3, 4, 5, 6, 7, 9, 11], # af_session2\n",
    "    \"2019-02-08-11-33-53_1stPart_1\" : [0, 1, 3, 4, 5, 7, 9, 11], # aq_session3\n",
    "    \"2019-02-08-12-11-34_2ndPart_1\" : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11], # aq_session3\n",
    "    \"2019-01-28-14-30-44_1\" : [0, 1, 3, 5], # bh1_session1\n",
    "    \"2019-01-31-09-22-49_1stPart_2\": [0, 1, 3, 5, 7, 9, 10, 11], # bh1_session4\n",
    "    \"2019-01-31-09-37-5_2ndPart_2\" : [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11], # bh1_session4\n",
    "    \"2019-02-21-16-09-44_1stPart_1\" : [0, 1, 3, 4, 5, 7, 9, 11], # bh2_session1\n",
    "    \"2019-02-21-16-22-22_2ndPart_1\" : [0, 1, 3, 5, 6, 7, 8, 9, 10, 11], # bh2_session1\n",
    "    \"2019-02-28-17-03-53_1stPart_2\" : [0, 1, 3, 5, 6, 7, 9, 11], # bh2_session3\n",
    "    \"2019-02-28-17-24-2_2ndPart_2\" : [0, 1, 2, 3, 5], # bh2_session3     ----\n",
    "    \"2019-02-14-13-28-20_1stPart_2\" : [0, 1, 3, 5, 6, 7, 9, 11], # cw_session3\n",
    "    \"2019-02-14-13-57-41_2ndPart_2\" : [0, 1, 2, 3, 5, 6, 7, 8, 9, 11], # cw_session3\n",
    "    \"2019-02-21-15-01-4_1stPart_1\" : [0, 1, 2, 3, 5, 7, 9, 11], # le_session3\n",
    "    \"2019-02-21-15-25-56_2ndPart_1\" : [0, 1, 3], # le_session3       ----\n",
    "    \"2019-02-05-14-00-27_1stPart_2\" : [0, 1, 3, 5, 7, 8], # mh_session1\n",
    "    \"2019-02-05-14-10-39_2ndPart_2\" : [0, 1, 2, 3, 4, 5, 7, 8, 9, 11], # mh_session1\n",
    "    \"2019-02-08-10-51-3_1stPart_1\" : [0, 1, 3, 5, 7, 9, 10, 11], # mn_session1\n",
    "    \"2019-02-08-11-05-7_2ndPart_1\" : [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11], # mn_session1\n",
    "    \"2019-02-19-10-34-7_1stPart_1\" : [0, 1, 3, 5, 7, 8, 9, 11], # mn_session3\n",
    "    \"2019-02-19-10-56-43_2ndPart_1\" : [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11], # mn_session3\n",
    "    \"2019-01-29-13-25-4_1\" : [0, 1, 3, 5, 7], # ph_session2  -- sessions where there are less score questions \n",
    "    # and more sentences typed\n",
    "    \"2019-01-16-15-18-50_1stPart_1\" : [0, 1, 3, 5, 7, 8, 9, 10], # ys_session2\n",
    "    \"2019-01-17-15-05-1_1\" : [0, 1, 3, 5],  # ys_session3  -- sessions where there are less score questions \n",
    "    # and more sentences typed\n",
    "    \"2019-02-06-11-25-41_1\" : [0, 1, 3, 5, 11], # aq_session1 -- sessions where there are less score questions \n",
    "    # and more sentences typed\n",
    "    \"2019-01-16-15-42-51_2ndPart_1\" : [0, 1, 2, 5], # ys_session2 -- different for reading and writing, this one is for\n",
    "    # writing\n",
    "    '2019-01-30-11-22-25_1' : [0, 1, 3, 5, 7, 9, 11]   # ys_session4 -- sessions where there are less score questions \n",
    "    # and more sentences typed\n",
    "   \n",
    "}\n",
    "\n",
    "# dictionary for phrase removal just like in the dict_phraseStim, but since not all participants require that, some that \n",
    "# do, are added to this new dictionary here\n",
    "dict_keySelection_phraseStim = {\n",
    "    '2019-01-17-15-27-20_1stPart_2' : [4], # Af session2\n",
    "    '2019-01-16-15-18-0_1' : [4],        # no_session1\n",
    "    '2019-02-19-17-10-45_1' : [3],                  # ph_session5\n",
    "    '2019-03-07-16-44-5_2' : [1],        # rh_session1\n",
    "    '2019-03-14-13-56-56_2' : [2],              # rh_session3\n",
    "    '2019-01-14-15-07-21_1' : [4]         # ys_session1\n",
    "}\n",
    "\n",
    "\n",
    "# in the beginning experiments, not everyone started with 800 initial dwell time\n",
    "\n",
    "dict_dwellTimeOrig_not800 = {\n",
    "    \"2019-01-16-15-51-13_2\" : 600, # no_session1\n",
    "    \"2019-01-16-15-18-0_1\" : 600, # no_session1\n",
    "    \"2019-01-16-15-43-8_1\" : 100, # af_session1\n",
    "    \"2019-01-16-16-36-17_1stPart_2\" : 100, # af_session1\n",
    "    \"2019-01-16-17-00-12_2ndPart_2\" : 100, # af_session1\n",
    "    \"2019-01-17-15-03-40_1\" : 100, # af_session2\n",
    "    \"2019-01-17-15-27-20_1stPart_2\" : 0, # af_session2\n",
    "    \"2019-01-17-16-03-27_2ndPart_2\" : 100, # af_session2\n",
    "    \"2019-01-14-15-07-21_1\" : 500, # ys_session1\n",
    "    \"2019-01-14-15-25-55_2\" : 300, # ys_session1\n",
    "    \"2019-01-16-15-18-50_1stpart_1\" : 200, # ys_session2\n",
    "    \"2019-01-16-15-42-51_2ndPart_1\" : 100, # ys_session2\n",
    "    \"2019-01-16-15-59-55_2\" : 100, # ys_session2\n",
    "    \"2019-01-17-15-05-1_1\" : 100, # ys_session3\n",
    "    \"2019-01-17-15-31-12_2\" : 100 # ys_session3\n",
    "}\n",
    "\n",
    "\n",
    "# list of all things that should be present when computing effective time\n",
    "list_keysToBeCounted = ['Comma', 'BackOne', 'BackMany', 'SpaceBar']\n",
    "\n",
    "# some sessions do not have gaze data\n",
    "dict_noGazeData = {\n",
    "    '2019-01-16-17-00-12_2ndPart_2' : 'no gaze data', # af_session2\n",
    "    '2019-01-17-15-31-12_2' : 'no gaze data', #ys_session2\n",
    "    '2019-01-30-11-57-3_2' : 'no gaze data' # ys_session4\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_keySelection_ReadingTrials = {\n",
    "    \"2019-01-16-15-42-51_2ndPart_1\" : [0, 1, 3, 5], # ys_session2 \n",
    "}\n",
    "\n",
    "dict_keySelection_WritingTrials = {\n",
    "    \"2019-01-16-15-42-51_2ndPart_1\" : [0, 1, 2, 5], # ys_session2   \n",
    "}\n",
    "\n",
    "# normally, reading part of trial ends when people look at the keyboardwithphrases. For some trials, this is not done,\n",
    "# as the reading is done, and the trial is accidentally skipped, and written in the next trial. Here, the trial number \n",
    "# given will have the reading time ending as sleep, and not keyboard with phrases. \n",
    "dict_keyboardNotChange_ReadingTrials = {\n",
    "    \"2019-01-16-15-42-51_2ndPart_1\" : 0, # ys_session2 \n",
    "}\n",
    "\n",
    "dict_keySelection_firstSleepNotCounted = {\n",
    "    \"2019-01-28-14-50-41_2\" : (0, 2), # bh1_session1 -- 3rd sleep activation to be counted\n",
    "    \"2019-02-19-10-56-43_2ndPart_1\" : 2  # mn_session3 -- 3rd sleep activation is to be counted\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TimeDwellOrig = 800\n",
    "TimeFixation = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FixUserKeys(UserKeys_Old):\n",
    "    # Fix the situation where comma has divided decimals into separate columns\n",
    "    \n",
    "    Column_beforeDecimal = [item[2] for item in UserKeys_Old]\n",
    "    Column_afterDecimal = [item[3] if len(item)>3 else '00' for item in UserKeys_Old]\n",
    "    \n",
    "    UserKeys_ProgressPercent = [float(Column_beforeDecimal[i]+'.'+ Column_afterDecimal[i]) for i in \n",
    "                                range(0, len(Column_beforeDecimal))]\n",
    "    UserKeys_Times = [item[0] for item in UserKeys_Old]\n",
    "    UserKeys_Keys = [item[1] for item in UserKeys_Old]\n",
    "    \n",
    "    UserKeys_New = [[UserKeys_Times[ind], UserKeys_Keys[ind], UserKeys_ProgressPercent[ind]] for ind in \n",
    "                    range(0, len(UserKeys_ProgressPercent))]\n",
    "    \n",
    "    #UserKeys_New = np.concatenate((UserKeys_Times, UserKeys_Keys, UserKeys_ProgressPercent), axis = 0)\n",
    "    \n",
    "    \n",
    "    return UserKeys_New\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FixScratchPad(ScratchPad_Old):\n",
    "    # Fix the situation where comma has divided decimals into separate columns\n",
    "    \n",
    "    ScratchPad_Times = [item[0] for item in ScratchPad_Old]\n",
    "    \n",
    "    ScratchPad_Phrases = list()\n",
    "    \n",
    "    # loop to combine phrases divided by commas\n",
    "    ScratchPadInd = -1 \n",
    "    while ScratchPadInd < len(ScratchPad_Old)-1:\n",
    "        ScratchPadInd = ScratchPadInd + 1\n",
    "        commasInPhrase = len(ScratchPad_Old[ScratchPadInd])-2\n",
    "        if commasInPhrase < 1:\n",
    "            #print(ScratchPad_Old[ScratchPadInd][1])\n",
    "            ScratchPad_Phrases.append(ScratchPad_Old[ScratchPadInd][1])\n",
    "            continue\n",
    "        scratchPadPhrase = ScratchPad_Old[ScratchPadInd][1]\n",
    "        for phraseJoinNr in range(1, commasInPhrase+1):\n",
    "            scratchPadPhrase = scratchPadPhrase + ', ' + ScratchPad_Old[ScratchPadInd][1+phraseJoinNr]\n",
    "        \n",
    "        ScratchPad_Phrases.append(scratchPadPhrase)\n",
    "            \n",
    "        \n",
    "    ScratchPad_New = [[ScratchPad_Times[ind], ScratchPad_Phrases[ind]] for ind in \n",
    "                    range(0, len(ScratchPad_Times))]\n",
    "    \n",
    "    #UserKeys_New = np.concatenate((UserKeys_Times, UserKeys_Keys, UserKeys_ProgressPercent), axis = 0)\n",
    "    \n",
    "    #print(ScratchPad_New)\n",
    "    return ScratchPad_New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FixKeysSelected(KeysSelected_Old):\n",
    "    # Fix the situation where comma has divided decimals into separate columns\n",
    "    \n",
    "    KeysSelected_New = list()\n",
    "    \n",
    "    # loop to combine phrases divided by commas\n",
    "    KeysSelectedInd = -1 \n",
    "    while KeysSelectedInd < len(KeysSelected_Old)-1:\n",
    "        KeysSelectedInd = KeysSelectedInd + 1\n",
    "        \n",
    "        if KeysSelected_Old[KeysSelectedInd][1].count(',') > 0:\n",
    "            \n",
    "            keys_split = KeysSelected_Old[KeysSelectedInd][1].split(\"\\r\\n\")\n",
    "            del keys_split[0]\n",
    "            del keys_split[-1]\n",
    "            \n",
    "            keys_split = [key.split(',') for key in keys_split]\n",
    "            \n",
    "            KeysSelected_New.extend(keys_split)\n",
    "        else:\n",
    "            KeysSelected_New.append(KeysSelected_Old[KeysSelectedInd])\n",
    "        \n",
    "    \n",
    "    return KeysSelected_New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeDwellTime(userKeys, full_path):\n",
    "    # modify userKeys to include a column of time instead of progress pct, which is dependent on the then dwell time\n",
    "    \n",
    "    TimeDwellOrig = 800\n",
    "    \n",
    "    # session name\n",
    "    session_folder_name = full_path.split('\\\\')[-1]\n",
    "    \n",
    "    if session_folder_name in dic_dwellTimeOrig_not800:\n",
    "        TimeDwellOrig = dic_dwellTimeOrig_not800[session_folder_name]\n",
    "    \n",
    "    #print(TimeDwellOrig)\n",
    "    \n",
    "    timeDwell = TimeDwellOrig\n",
    "    nKey = -1\n",
    "    for key in userKeys:\n",
    "        nKey = nKey + 1\n",
    "        #print(key[1])\n",
    "        if key[1] == 'IncreaseDwellTime':\n",
    "            if float(key[2]) == 1:\n",
    "                timeDwell = timeDwell + 100\n",
    "        elif key[1] == 'DecreaseDwellTime':\n",
    "            #print(key[2])\n",
    "            if float(key[2]) == 1:\n",
    "                timeDwell = timeDwell - 100\n",
    "        else:\n",
    "            userKeys[nKey].append(str(float(key[2])*timeDwell))\n",
    "    \n",
    "    return userKeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stimPhrasesEdit(PhraseLog, full_path):\n",
    "   \n",
    "    # Now extract phrases from the phrase file\n",
    "    phraseStim_Phrases = [item[1] for item in PhraseLog]\n",
    "    \n",
    "    # session name\n",
    "    session_folder_name = full_path.split('\\\\')[-1]\n",
    "        \n",
    "    phraseStim_PhrasesReduced, phraseStim_timeReduced = zip(*[(x[0], PhraseLog[phraseStim_Phrases.index(x[0])][0]) for x in groupby(phraseStim_Phrases)])\n",
    "    \n",
    "    PhraseLogReduced = [[phraseStim_timeReduced[i], phraseStim_PhrasesReduced[i]] for i in range(0, len(phraseStim_PhrasesReduced))]\n",
    "    \n",
    "    if PhraseLogReduced[-1][1] == 'THE EXPERIMENT IS NOW DONE':\n",
    "        del PhraseLogReduced[-1]\n",
    "        \n",
    "    if PhraseLogReduced[0][1] == 'phraseText':\n",
    "        del PhraseLogReduced[0]\n",
    "\n",
    "    # Here, we want only the sentences typed\n",
    "    notSentencesToType = list()\n",
    "    for index in range(0,len(PhraseLogReduced)):\n",
    "        sentence = PhraseLogReduced[index][1]\n",
    "        if 'Svar på følgende spørgsmål' in sentence or 'Answer the question:' in sentence or 'What is the complete name of your university?' in sentence or '(give a score between 1 and 7)' in sentence or sentence == '':\n",
    "            notSentencesToType.append(index)    \n",
    "    \n",
    "    for index in sorted(notSentencesToType, reverse=True):\n",
    "        del PhraseLogReduced[index]\n",
    "    \n",
    "    replacingList = []\n",
    "    PhraseLogReduced = findAndRemoveTrials(session_name, dict_phraseStim, PhraseLogReduced, replacingList)\n",
    "    \n",
    "    \n",
    "    return PhraseLogReduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will return the datetime in items which is the closest to the date pivot\n",
    "def nearestTimePoint(dates, date):\n",
    "    \n",
    "    for d in dates:\n",
    "        if d < date:\n",
    "            nearestTP = d\n",
    "        else:\n",
    "            continue\n",
    "    try: \n",
    "        nearestTP\n",
    "        nearestTPind = dates.index(nearestTP)\n",
    "    except:\n",
    "        nearestTP = 0\n",
    "        nearestTPind = -1\n",
    "        \n",
    "    return nearestTP, nearestTPind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert list of date and time into datetime format list\n",
    "def timeConversion(timeStrList):\n",
    "    timeList = list()\n",
    "    for time in timeStrList:\n",
    "        time1, t1, t2 = time.partition('+')\n",
    "        timeList.append(datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\"))\n",
    "    return timeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OptiKeyTypingTime(UserKeys):\n",
    "    \n",
    "    TimeTyping = dict()\n",
    "    \n",
    "    time1, t1, t2 = UserKeys[0][0].partition('+')\n",
    "    startTime = datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "    \n",
    "    time2, t1, t2 = UserKeys[-1][0].partition('+')\n",
    "    endTime = datetime.datetime.strptime(re.sub('[:.T]','-',time2[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "    \n",
    "    TimeTyping['startTime'] = startTime\n",
    "    TimeTyping['endTime'] = endTime\n",
    "    \n",
    "    return TimeTyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeTypingStart(userKeys):\n",
    "    # From the user keys, find when the user actually starts typing, after having looked at the phrase and all the other \n",
    "    # function keys\n",
    "    \n",
    "    timeTypingStartInd = 0\n",
    "    \n",
    "    timeTypingStartIndList = list()\n",
    "            \n",
    "    timeUserTimeInd = 0\n",
    "    \n",
    "    ind = 0\n",
    "    # Get start time of first trial\n",
    "    \n",
    "    while ind < len(userKeys):\n",
    "        #print(len(userKeys[ind][1]))\n",
    "        if len(userKeys[ind][1]) > 1:\n",
    "            ind = ind + 1\n",
    "        else:\n",
    "            timeTypingStartInd = ind\n",
    "            timeTypingStartIndList.append(ind)\n",
    "            break\n",
    "    \n",
    "    #print(timeTypingStartInd)\n",
    "    # Get every next phrase start timings\n",
    "    while ind < len(userKeys):\n",
    "        \n",
    "        if userKeys[ind][1] == 'NextPhrase' and float(userKeys[ind][2]) == 1:\n",
    "            \n",
    "            #timeTypingStartIndList.append(ind+1)\n",
    "            for ind2 in range(ind+1, len(userKeys)):\n",
    "                if len(userKeys[ind2][1]) > 1:\n",
    "                    ind = ind + 1\n",
    "                    continue\n",
    "                elif userKeys[ind2][1] == 'NextPhrase' and float(userKeys[ind][2]) == 1:\n",
    "                    ind = ind + 1\n",
    "                    continue\n",
    "                else:\n",
    "                    ind = ind2\n",
    "                    timeTypingStartIndList.append(ind)\n",
    "                    break\n",
    "                    \n",
    "        else:\n",
    "            ind = ind + 1\n",
    "            \n",
    "    #print(timeTypingStartIndList)\n",
    "    \n",
    "    return timeTypingStartIndList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAndRemoveTrials(session_name, dictionary_saved, trials, replacingList):\n",
    "    # function to check the session_name in the dictionary_saved and remove those trials from the dictionary_trial\n",
    "    \n",
    "    if session_name in dictionary_saved:\n",
    "        index_list = dictionary_saved[session_name]\n",
    "    else:\n",
    "        index_list = replacingList\n",
    "    \n",
    "    \n",
    "    if index_list:\n",
    "        if type(trials) == list:\n",
    "            for index in sorted(index_list, reverse=True):\n",
    "                del trials[index]\n",
    "                \n",
    "        else:\n",
    "            for index in sorted(index_list, reverse=True):\n",
    "                del trials['start'][index]\n",
    "                del trials['end'][index]\n",
    "        \n",
    "    return trials    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindExptStartEndTimes(KeysSelected, timeTyping, full_path):\n",
    "    # function to find start and end of tasks in experiments\n",
    "    \n",
    "    # session name\n",
    "    session_folder_name = full_path.split('\\\\')[-1]\n",
    "    \n",
    "    timeTrialDict = dict()\n",
    "    timeTrialDict = {'start': [],\n",
    "                    'end':[]}\n",
    "    \n",
    "    nTrial = -1\n",
    "    \n",
    "    \n",
    "    \n",
    "    for keys in KeysSelected:\n",
    "        \n",
    "            \n",
    "        \n",
    "        if keys[1] == 'NextPhrase':\n",
    "            nTrial = nTrial + 1\n",
    "            time1, t1, t2 = keys[0].partition('+')\n",
    "            endTimeTrial = datetime.datetime.strptime(re.sub('[:.T]','-',time1[:-1]), \"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "            \n",
    "            if nTrial != 0:\n",
    "                # print('end: ', endTimeTrial)\n",
    "                #print('')\n",
    "                timeTrialDict['end'].append(endTimeTrial)\n",
    "            \n",
    "            \n",
    "            # add 5s for the start time of the next phrase\n",
    "            startTimeTrial = endTimeTrial + datetime.timedelta(seconds=5)\n",
    "            \n",
    "            #print('start: ', startTimeTrial)\n",
    "            timeTrialDict['start'].append(startTimeTrial)\n",
    "        \n",
    "    del timeTrialDict['start'][-1]\n",
    "    \n",
    "    \n",
    "    # remove the extra selections of NewPhrase at the end of some sessions\n",
    "    replacingList = []\n",
    "    timeTrialDict = findAndRemoveTrials(session_folder_name, dict_keySelectionOfNextPhrase, timeTrialDict, replacingList)\n",
    "    \n",
    "    timeTrialDict_copy = copy.deepcopy(timeTrialDict)\n",
    "    \n",
    "    # separate the reading and writing trials for some participants who read in the actual trial, but write in the next\n",
    "    # trial\n",
    "    if session_folder_name in dict_keySelection_ReadingTrials:\n",
    "        # check the reading and writing separate dictionaries\n",
    "        print('reading and writing sessions are separate')\n",
    "        \n",
    "        #print(len(timeTrialDict['start']))\n",
    "        # writing trials - \n",
    "        timeTrialDict_writing = findAndRemoveTrials(session_folder_name, dict_keySelection_WritingTrials, timeTrialDict, replacingList)\n",
    "        #print(len(timeTrialDict_copy['start']))\n",
    "        \n",
    "        # reading trials\n",
    "        timeTrialDict_reading = findAndRemoveTrials(session_folder_name, dict_keySelection_ReadingTrials, timeTrialDict_copy, replacingList)\n",
    "    else:\n",
    "        # some participants skip some sentences, and then it affects the scoreQuestions too. Remove the skipped sentences or \n",
    "        # remove the score questions \n",
    "        # for these participants, reading and writing trials are the same\n",
    "        \n",
    "        #print('same reading and writing trials')\n",
    "        scoreQuestions = [0, 1, 3, 5, 7, 9, 11]\n",
    "        timeTrialDict = findAndRemoveTrials(session_folder_name, dict_keySelectionNotCompleted, timeTrialDict, scoreQuestions)\n",
    "        \n",
    "        # most of the skipped sentences are removed, but for those that are not removed\n",
    "        timeTrialDict_writing = findAndRemoveTrials(session_folder_name, dict_keySelection_phraseStim, timeTrialDict, replacingList)\n",
    "        \n",
    "        timeTrialDict_reading = timeTrialDict_writing \n",
    "        \n",
    "    \n",
    "          \n",
    "    return timeTrialDict_reading, timeTrialDict_writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindReadingPartsOfTrial_inKeysSelected(EventTrials_reading, KeysSelected_new, full_path):\n",
    "    # find the reading end in the pupil size data\n",
    "    \n",
    "    # session name\n",
    "    session_folder_name = full_path.split('\\\\')[-1]\n",
    "    \n",
    "    KeysSelected_timeStr = [key[0] for key in KeysSelected_new]\n",
    "    KeysSelected_time = timeConversion(KeysSelected_timeStr)\n",
    "    \n",
    "    KeysSelected_keys = [key[1] for key in KeysSelected_new]\n",
    "    \n",
    "    EventReading = dict()    \n",
    "    EventReading['start'] = list()\n",
    "    EventReading['end'] = list()\n",
    "    \n",
    "    EventReading_index = dict()    \n",
    "    EventReading_index['start'] = list()\n",
    "    EventReading_index['end'] = list()\n",
    "    \n",
    "    for ind, startTrialTime_afterCoolDown in enumerate(EventTrials_reading['start']):\n",
    "        \n",
    "        startTrialTime, startTrialInd = nearestTimePoint(KeysSelected_time, startTrialTime_afterCoolDown)\n",
    "        \n",
    "        EventReading['start'].append(startTrialTime)\n",
    "        EventReading_index['start'].append(startTrialInd)\n",
    "        \n",
    "        endTrialTime = EventTrials_reading['end'][ind]\n",
    "        endTrialInd = KeysSelected_time.index(endTrialTime)\n",
    "        \n",
    "        keysSelected_trial = KeysSelected_keys[startTrialInd:endTrialInd]\n",
    "        \n",
    "        # compute the end of reading time -- which is taken when the keyboard with phrases key is pressed\n",
    "        if session_folder_name not in dict_keyboardNotChange_ReadingTrials:\n",
    "            \n",
    "            endReading_keyInd = startTrialInd + keysSelected_trial.index('KeyboardWithPhrases')\n",
    "            endReading_keyTime = KeysSelected_time[endReading_keyInd]\n",
    "            \n",
    "        else:\n",
    "            if ind == dict_keyboardNotChange_ReadingTrials[session_folder_name]:\n",
    "                endReading_keyInd = startTrialInd + keysSelected_trial.index('Sleep')\n",
    "                endReading_keyTime = KeysSelected_time[endReading_keyInd]\n",
    "                \n",
    "            else:\n",
    "                endReading_keyInd = startTrialInd + keysSelected_trial.index('KeyboardWithPhrases')\n",
    "                endReading_keyTime = KeysSelected_time[endReading_keyInd]\n",
    "                \n",
    "                \n",
    "        EventReading['end'].append(KeysSelected_time[endReading_keyInd+1])\n",
    "        EventReading_index['end'].append(endReading_keyInd+1)\n",
    "        \n",
    "        #print(ind)\n",
    "        #print('reading: ', EventReading['start'][ind], EventReading['end'][ind])\n",
    "        \n",
    "    \n",
    "    \n",
    "    return EventReading, EventReading_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindWritingPartsOfTrial_inKeysSelected(EventTrials_writing, KeysSelected_new, EventReading):\n",
    "    \n",
    "    KeysSelected_timeStr = [key[0] for key in KeysSelected_new]\n",
    "    KeysSelected_time = timeConversion(KeysSelected_timeStr)\n",
    "    \n",
    "    KeysSelected_keys = [key[1] for key in KeysSelected_new]\n",
    "    \n",
    "    EventWriting = dict()    \n",
    "    EventWriting['start'] = list()\n",
    "    EventWriting['end'] = list()\n",
    "    \n",
    "    EventWriting_index = dict()    \n",
    "    EventWriting_index['start'] = list()\n",
    "    EventWriting_index['end'] = list()\n",
    "    \n",
    "    for ind, startTrialTime_afterCoolDown in enumerate(EventTrials_writing['start']):\n",
    "        \n",
    "        startTrialTime, startTrialInd = nearestTimePoint(KeysSelected_time, startTrialTime_afterCoolDown)\n",
    "        \n",
    "        endTrialTime = EventTrials_writing['end'][ind]\n",
    "        endTimeReading = EventReading['end'][ind]\n",
    "        \n",
    "        \n",
    "        # for some participants, reading and writing trials are different. So their writing times will not be the end of \n",
    "        # the reading time.\n",
    "        # Regardless, the writing time should start later than when the reading time ends.\n",
    "        # We choose the starting time for writing as the one that is later than the start time from writing trials\n",
    "        # and end time from reading trials\n",
    "        \n",
    "        if startTrialTime > endTimeReading:\n",
    "            EventWriting['start'].append(startTrialTime)\n",
    "            EventWriting_index['start'].append(startTrialInd)\n",
    "        else:\n",
    "            EventWriting['start'].append(endTimeReading)\n",
    "            EventWriting_index['start'].append(KeysSelected_time.index(endTimeReading))\n",
    "        \n",
    "        EventWriting['end'].append(endTrialTime)\n",
    "        EventWriting_index['end'].append(KeysSelected_time.index(endTrialTime))\n",
    "        \n",
    "        #print(ind)\n",
    "        #print('writing: ', EventWriting['start'][ind], EventWriting['end'][ind])\n",
    "        \n",
    "    \n",
    "    \n",
    "    return EventWriting, EventWriting_index     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gazeConvert2ColumnsTo1(GazeLog, columnIndwValidity_list, indValidity):\n",
    "    # function to convert pupilsizes from 2 columns for every pupil due to comma use instead of decimal, \n",
    "    # to proper pupil sizes\n",
    "    \n",
    "    #columnInd_list = [joinColumn1_1, joinColumn1_2, joinColumn2_1, joinColumn2_2]\n",
    "    \n",
    "    # number of columns in the final dictionary\n",
    "    nColumns = int(len(columnIndwValidity_list)/2)\n",
    "    \n",
    "    # dictionary of columns that are to be joined later\n",
    "    columns_beforeDecimal = dict()\n",
    "    columns_afterDecimal = dict()\n",
    "    \n",
    "    # dictionary of joined columns\n",
    "    columnsFinal = dict()\n",
    "    \n",
    "    # dictionary to find and equalize missing values in every column\n",
    "    missingVal_column = dict()\n",
    "    missingVal = list()\n",
    "    \n",
    "    # find correct index of validity column to be used, to find the actual columns relative to that\n",
    "    columnsValidity_inUse = list()\n",
    "    \n",
    "    for ind, row in enumerate(GazeLog):\n",
    "        #print(ind)\n",
    "        #print(sorted(list(np.where(np.array(row) == 'Valid')[0])+list(np.where(np.array(row)=='Invalid')[0]))[indValidity])\n",
    "\n",
    "        columnsValidity = (sorted(list(np.where(np.array(row) == 'Valid')[0])+list(np.where(np.array(row)=='Invalid')[0]))[indValidity])\n",
    "        columnsValidity_inUse.append(int(columnsValidity))\n",
    "    \n",
    "    columnsValidity_inUse = np.array(columnsValidity_inUse)\n",
    "    \n",
    "    columnInd_list = [[columnsValidity_inUse+i] for i in columnIndwValidity_list]\n",
    "    \n",
    "    \n",
    "    for ind in range(0, nColumns):\n",
    "        \n",
    "        dict_name = 'column' + str(ind+1)\n",
    "        columnsFinal[dict_name] = list()\n",
    "        columns_afterDecimal[dict_name] = list()\n",
    "                \n",
    "        #for indItem, item4 in enumerate(GazeLog):\n",
    "        #    if 'Invalid' not in item4:\n",
    "        #        if columnInd_list[2*ind+1][0][indItem] < len(item4):\n",
    "        #            columns_afterDecimal[dict_name].append(item4[columnInd_list[2*ind+1][0][indItem]])\n",
    "        #        else:\n",
    "        #            columns_afterDecimal[dict_name].append('0')\n",
    "        #    else:\n",
    "        #        columns_afterDecimal[dict_name].append('nan')\n",
    "        \n",
    "                \n",
    "        columns_beforeDecimal[dict_name] = [item4[columnInd_list[2*ind][0][indItem]] if 'Invalid' not in item4 else 'nan' for indItem, item4 in enumerate(GazeLog)]\n",
    "        columns_afterDecimal[dict_name] = [item4[columnInd_list[2*ind+1][0][indItem]] if 'Invalid' not in item4 and columnInd_list[2*ind+1][0][indItem] < len(item4) else 'nan' for indItem, item4 in enumerate(GazeLog)]\n",
    "\n",
    "        \n",
    "        for i in range(0, len(columns_beforeDecimal[dict_name])):\n",
    "            if 'Valid' not in columns_beforeDecimal[dict_name][i] and 'Valid' not in columns_afterDecimal[dict_name][i]:\n",
    "                if 'nan' not in columns_beforeDecimal[dict_name][i] and 'nan' not in columns_afterDecimal[dict_name][i]:\n",
    "                    if float(columns_afterDecimal[dict_name][i]) > 0: \n",
    "                        columnsFinal[dict_name].append(float(columns_beforeDecimal[dict_name][i]+'.'+columns_afterDecimal[dict_name][i]))\n",
    "                    else:\n",
    "                        columnsFinal[dict_name].append(np.nan)\n",
    "                else:\n",
    "                    columnsFinal[dict_name].append(np.nan)\n",
    "            else:\n",
    "                # Rarely, the pupil size is a whole number\n",
    "                columnsFinal[dict_name].append(np.nan) # we will ignore the row, since there is no way of automatically knowing which - \n",
    "                # right or left eye has whole number pupil size\n",
    "    \n",
    "        missingVal_column[dict_name] = np.argwhere(np.isnan(columnsFinal[dict_name]))\n",
    "        missingVal_column[dict_name] = list(itertools.chain.from_iterable(missingVal_column[dict_name])) # flatten the list\n",
    "        \n",
    "        missingVal.extend(missingVal_column[dict_name])\n",
    "        \n",
    "        \n",
    "    \n",
    "    missingVal = sorted(set(missingVal))\n",
    "    \n",
    "    # if one of the columns are nan, the other one is converted too\n",
    "    for column in range(0, nColumns):\n",
    "        dict_name = 'column' + str(column+1)\n",
    "        for ind in missingVal:\n",
    "            if ind < len(columnsFinal[dict_name]):\n",
    "                columnsFinal[dict_name][ind] = np.nan\n",
    "                \n",
    "    \n",
    "    \n",
    "    \n",
    "    #print(len(columnsFinal['column1']), len(columnsFinal['column2']))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    return columnsFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterBlinks(pupilDataL, pupilDataR, timeInDatetime):\n",
    "    # filter any blinks and nan values lasting around 250ms (on average)\n",
    "    # first the single nan occurances are replaced with mean of the values on either sides, \n",
    "    # as they are assumed to be from hardware problems\n",
    "    # for the rest of the blinks, 250ms before and after the nan values are interpolated with a linear function\n",
    "    # returns a dataframe with pupil size, and timestamp\n",
    "    # http://faculty.washington.edu/chudler/facts.html\n",
    "   \n",
    "    \n",
    "    # create a dataframe from the pupilsize and time\n",
    "    pupilData_df = pd.DataFrame(list(zip(timeInDatetime, pupilDataL, pupilDataR)), columns=['timeStamp', 'pupilLeft', 'pupilRight'])\n",
    "    \n",
    "    # blink is every nan value in the range of 100-400ms \n",
    "    # 250 ms (22 samples) before and after the blink will also be removed\n",
    "    extraBlinkSamples = 22   \n",
    "    \n",
    "    \n",
    "    #pupilData_woSingleMissingData = pupilData.copy()\n",
    "    #timeList_woSingleMissingData = timeInDatetime.copy()\n",
    "    #timeInS_woSingleMissingData = timeInS_Trial[-1]\n",
    "    \n",
    "    # in case of single missing data, that are due to hardware error, replace with the mean of the pupil size before and\n",
    "    # after the nan value\n",
    "    # missing values will be the same for left and right pupil\n",
    "    missingVal_Single = np.argwhere(np.isnan(pupilDataL))\n",
    "    missingVal_Single = list(itertools.chain.from_iterable(missingVal_Single)) # flatten the list \n",
    "    \n",
    "    # if no blinks present, return the data\n",
    "    if len(missingVal_Single) == 0:\n",
    "        interpolatedNan = np.array([False]*len(pupilData_df))\n",
    "        return pupilData_df, interpolatedNan\n",
    "    \n",
    "    # find the index and values to replace for single nan values\n",
    "    pupilData_tuples_replaceSingleNan_left = [(val, np.mean([pupilDataL[val-1], pupilDataL[val+1]])) for i, val in enumerate(missingVal_Single) if (val != 0 and val != (len(pupilDataL)-1)) if not np.isnan(pupilDataL[val-1]) and not np.isnan(pupilDataL[val+1])]\n",
    "    pupilData_tuples_replaceSingleNan_right = [(val, np.mean([pupilDataR[val-1], pupilDataR[val+1]])) for i, val in enumerate(missingVal_Single) if (val != 0 and val != (len(pupilDataR)-1)) if not np.isnan(pupilDataR[val-1]) and not np.isnan(pupilDataR[val+1])]\n",
    "    \n",
    "    \n",
    "    interpolatedNan = np.array([True if ind in dict(pupilData_tuples_replaceSingleNan_left) else False for ind, val in enumerate(pupilDataL)])\n",
    "    \n",
    "    \n",
    "    # replace the single nan values with the mean of the pupil size on either sides\n",
    "    indList = -1\n",
    "    for ind, val in pupilData_tuples_replaceSingleNan_left:\n",
    "        indList = indList + 1\n",
    "        pupilData_df.iloc[ind, pupilData_df.columns.get_loc('pupilLeft')] = val\n",
    "        pupilData_df.iloc[ind, pupilData_df.columns.get_loc('pupilRight')] = pupilData_tuples_replaceSingleNan_right[indList][1]\n",
    "        \n",
    "    \n",
    "    # again, find the nan values in the pupil size\n",
    "    # the list missingVal_SingleDifference contains the index of the first blink, followed by the difference in the index\n",
    "    # to the next nan value\n",
    "    \n",
    "    \n",
    "    \n",
    "    # find the nan values again from pupilData['pupilLeft']\n",
    "    missingVal_Rest_trueFalse = pupilData_df['pupilLeft'].isnull()\n",
    "    missingVal_Rest = [i for i, x in enumerate(missingVal_Rest_trueFalse) if x]\n",
    "    \n",
    "    # if no blinks left, return the current pupilData\n",
    "    if len(missingVal_Rest) == 0:\n",
    "        return pupilData_df, interpolatedNan\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    # in the blinks left, find when the blinks start by finding a difference in the consecutive values of the indices\n",
    "    missingVal_RestDifference = [t - s for s, t in zip(missingVal_Rest, missingVal_Rest[1:])]\n",
    "    missingVal_RestDifference.insert(0, missingVal_Rest[0])\n",
    "    \n",
    "    blinkStart_tupleList = [(ind, sum(missingVal_RestDifference[0:ind+1])) for ind, val in enumerate(missingVal_RestDifference) if val != 1]\n",
    "    \n",
    "    blinkStart_tupleList_wLength = list()\n",
    "    \n",
    "    # create a list of tuples of blink start index and the length of the blink\n",
    "    ind = -1\n",
    "    blinkLengthSum = 0\n",
    "    for blink_ind, blinkStartInd in blinkStart_tupleList:\n",
    "        ind = ind + 1\n",
    "        if ind != len(blinkStart_tupleList) - 1:\n",
    "            \n",
    "            blinkLength = blinkStart_tupleList[ind+1][0]-blink_ind\n",
    "            blinkLengthSum = blinkLengthSum + blinkLength\n",
    "            \n",
    "            blinkStart_tupleList_wLength.append(tuple((blinkStartInd, blinkLength)))\n",
    "        else:\n",
    "            # for the last blink -- all blink lengths summed and subtracted from the length of the list\n",
    "            # missingVal_RestDifference \n",
    "            blinkLength = len(missingVal_RestDifference)-blinkLengthSum\n",
    "            blinkStart_tupleList_wLength.append(tuple((blinkStartInd, blinkLength)))\n",
    "     \n",
    "    # add to vector with start and end of tuple\n",
    "    #beforeAfterNan = [False]*len(pupilData_df['pupilLeft'])\n",
    "    #for blinkStart, blinkLength in blinkStart_tupleList_wLength:\n",
    "    #    beforeAfterNan[blinkStart] = True\n",
    "    #    beforeAfterNan[blinkStart+blinkLength] = True\n",
    "    #    #print('start and end points: ', pupilData_df['timeStamp'][blinkStart], pupilData_df['timeStamp'][blinkStart + blinkLength])\n",
    "    \n",
    "    \n",
    "    # create lists with start and end values for the blinks, based on blinkStart_tupleList_wLength, regardless of the blink length\n",
    "    blink_missingData_startList = [blinkStartInd - extraBlinkSamples if (blinkStartInd - extraBlinkSamples) > 0 else 0 for blinkStartInd, blinkLength in blinkStart_tupleList_wLength]\n",
    "    blink_missingData_endList = [blinkStartInd + blinkLength + extraBlinkSamples if (blinkStartInd + blinkLength + extraBlinkSamples) < (len(pupilData_df['pupilLeft'])-1) else (len(pupilData_df['pupilLeft'])-1) for blinkStartInd, blinkLength in blinkStart_tupleList_wLength]\n",
    "    # create a list of tuples from the start and end points of the blink\n",
    "    blink_missingData_startEndTuple = [(blinkStart, blink_missingData_endList[ind]) for ind, blinkStart in enumerate(blink_missingData_startList)] \n",
    "    \n",
    "    \n",
    "    # check if blinks need to be combined - blinksCombine is a list of list of 2 elements, the index of the blinks that should be combined\n",
    "    blinksCombine = [[ind, ind+1] for ind, blink in enumerate(blink_missingData_startEndTuple[0:-1]) if blink[1] > blink_missingData_startEndTuple[ind+1][0]]\n",
    "        \n",
    "    if blinksCombine:\n",
    "        # combine blinks that need to be combined - if multiple consecutive blinks need to be removed: eg - [1, 2], [2, 3] \n",
    "        # are included in the blinksCombine, the combined version should be [1, 3] \n",
    "        blinksCombineFinal = list()\n",
    "        ind = -1\n",
    "        while ind < len(blinksCombine)-2:\n",
    "            \n",
    "            ind = ind + 1\n",
    "            blinkCombining = blinksCombine[ind]\n",
    "            blinksCombineFinal.append(blinkCombining)\n",
    "            while ind < len(blinksCombine)-2 and blinkCombining[1] == blinksCombine[ind+1][0]:\n",
    "                # change the ending of the last added blink of blinksCombineFinal\n",
    "                blinksCombineFinal[-1][1] = blinksCombine[ind+1][1]\n",
    "                ind = ind + 1\n",
    "            \n",
    "            \n",
    "        if len(blinksCombine) == 1:\n",
    "            blinksCombineFinal = blinksCombine.copy()\n",
    "            \n",
    "        \n",
    "        if blinksCombine[-1][1] != blinksCombineFinal[-1][1]:\n",
    "            if blinksCombine[-1][0] == blinksCombineFinal[-1][1]:\n",
    "                blinksCombineFinal[-1][1] = blinksCombine[-1][1]\n",
    "            else:\n",
    "                blinksCombineFinal.append(blinksCombine[-1])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    #    for w, z in groupby(sorted(list(blinksCombine)), lambda x, y=itertools.count(): next(y)-x):\n",
    "    #        group = list(z)\n",
    "    #        blinksCombineFinal.append(tuple((group[0], group[-1])))\n",
    "        \n",
    "        for x in sorted(blinksCombineFinal, reverse=True):\n",
    "            new_start = blink_missingData_startEndTuple[x[0]][0] \n",
    "            new_end = blink_missingData_startEndTuple[x[1]][1] \n",
    "            \n",
    "            x_start = x[0]\n",
    "            x_end = x[1]\n",
    "            \n",
    "            # delete also the blinkStart_tupleList_wLength, since it is going to be used to compute other metrics\n",
    "            for blinkRemove in range(x[1], x[0]-1, -1):\n",
    "                del blink_missingData_startEndTuple[blinkRemove]\n",
    "            \n",
    "            blink_missingData_startEndTuple.insert(x[0], tuple((new_start, new_end)))\n",
    "    \n",
    "    \n",
    "    #blinkAndNonBlinkDurationList = [length/90 for start, length in blinkStart_tupleList_wLength]\n",
    "    #timeInS_Trial_filter = timeInS_Trial[-1] - sum(blinkAndNonBlinkDurationList) \n",
    "    \n",
    "    \n",
    "    # remove blinks from data\n",
    "    for blinkStart, blinkEnd in blink_missingData_startEndTuple:\n",
    "        pupilData_df.loc[blinkStart:blinkEnd,'pupilLeft'] = np.nan\n",
    "        pupilData_df.loc[blinkStart:blinkEnd,'pupilRight'] = np.nan\n",
    "        replaceTrueList = range(blinkStart, blinkEnd+1, 1)\n",
    "        interpolatedNan[replaceTrueList] = True\n",
    "    \n",
    "    \n",
    "    \n",
    "    pupilData_df['pupilLeft'] = pupilData_df['pupilLeft'].astype(float).interpolate('linear', limit_direction = 'both')\n",
    "    pupilData_df['pupilRight'] = pupilData_df['pupilRight'].astype(float).interpolate('linear', limit_direction = 'both')\n",
    "    \n",
    "    if pupilData_df.isnull().any().any():\n",
    "        print('nan values in filtered data')\n",
    "        #for i,val in enumerate(pupilData_filter[0:5000]):\n",
    "        #    print(i, val, pupilData_woSingleMissingData[i])\n",
    "        \n",
    "    \n",
    "    return pupilData_df, interpolatedNan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hampel(dvec, radius=5, nsigma=3, rem_nomed=False):\n",
    "\n",
    "    # replace outliers with median values (hampel filter)\n",
    "    \n",
    "    mvec = pd.Series(dvec).rolling(radius*2+1, center=True, min_periods=radius).median()\n",
    "    svec = 1.4862 * np.abs(dvec-mvec).rolling(radius*2+1, center=True, min_periods=radius).median()\n",
    "    plonk = np.abs(dvec-mvec) > nsigma*svec\n",
    "    dvec = np.array(dvec)\n",
    "    dvec[plonk.tolist()] = mvec[plonk.tolist()]\n",
    "\n",
    "    # remove \"bad data\" where we cannot calculate a median value due to already missing values\n",
    "    if (rem_nomed):\n",
    "        dvec[np.isnan(mvec)] = np.nan\n",
    "    return dvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FilterPupilSize(GazeLog, TimeTyping, subjectAndSessionName):\n",
    "    # function that uses the list of start and end trial times to find the pupil sizes for those trials and plots them\n",
    "    \n",
    "    # first create a list of times in gaze log\n",
    "    timeStrGazeLog = [item3[0] for item3 in GazeLog]\n",
    "    # convert the list of strings to datetime formats\n",
    "    timeGazeLog = timeConversion(timeStrGazeLog)\n",
    "    \n",
    "    # internal time, to depict seconds\n",
    "    timeInternalGazeLog = [float(item3[1]) for item3 in GazeLog]\n",
    "    \n",
    "    # extract pupil sizes in decimals from the strange 2 columns for every pupil\n",
    "    pupil_indWrtValidityL = [1, 2]\n",
    "    pupil_validityL = 4\n",
    "    pupilLogL_raw = gazeConvert2ColumnsTo1(GazeLog, pupil_indWrtValidityL, pupil_validityL)\n",
    "    \n",
    "    pupil_indWrtValidityR = [1, 2]\n",
    "    pupil_validityR = 5\n",
    "    pupilLogR_raw = gazeConvert2ColumnsTo1(GazeLog, pupil_indWrtValidityR, pupil_validityR)\n",
    "    \n",
    "    \n",
    "    # reduce the data to start and end of typing time\n",
    "    timeTyping_start, timeTyping_startInd = nearestTimePoint(timeGazeLog, TimeTyping['startTime'])\n",
    "    timeTyping_end, timeTyping_endInd = nearestTimePoint(timeGazeLog, TimeTyping['endTime'])\n",
    "    \n",
    "    pupilLogL_wDefinedTime = pupilLogL_raw['column1'][timeTyping_startInd:timeTyping_endInd+1]\n",
    "    pupilLogR_wDefinedTime = pupilLogR_raw['column1'][timeTyping_startInd:timeTyping_endInd+1]\n",
    "    \n",
    "    timeGazeLog_wDefinedTime = timeGazeLog[timeTyping_startInd:timeTyping_endInd+1]\n",
    "    \n",
    "    timeInS_GazeLog_wDefinedTime = timeInternalGazeLog[timeTyping_startInd:timeTyping_endInd+1]\n",
    "    timeInS_Difference = [(t - s)/1000000 for s, t in zip(timeInS_GazeLog_wDefinedTime, timeInS_GazeLog_wDefinedTime[1:])]\n",
    "    timeInS_Difference.insert(0, 0)\n",
    "    \n",
    "    \n",
    "    #timeInS = [sum(timeInS_Difference[:i]) for i, v in enumerate(timeInS_Difference)]\n",
    "    \n",
    "    pupilData_df, interpolated_items = filterBlinks(pupilLogL_wDefinedTime, pupilLogR_wDefinedTime, timeGazeLog_wDefinedTime)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #timeGazeLog_plot = np.arange(0, timeInS[-1], 1/90)\n",
    "    \n",
    "    #plotPupilSize_checkFilter(pupilData_df, pupilLogL_wDefinedTime, blinkStartAndEnd, 'blink removal', subjectAndSessionName)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    pupilData_df_hampel = dict()\n",
    "    \n",
    "    pupilData_df_hampel = pupilData_df.copy()\n",
    "    pupilData_df_hampel['pupilLeft'] = hampel(pupilData_df['pupilLeft'], 25, 3, False)\n",
    "    pupilData_df_hampel['pupilRight'] = hampel(pupilData_df['pupilRight'], 25, 3, False)\n",
    "        \n",
    "    \n",
    "        \n",
    "    return pupilData_df_hampel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EventPartsFromPupilData(EventTimeInKeys, PupilSize_df, full_path):\n",
    "    \n",
    "    # session name\n",
    "    session_folder_name = full_path.split('\\\\')[-1]\n",
    "    \n",
    "    EventTime = dict()    \n",
    "    EventTime['start'] = list()\n",
    "    EventTime['end'] = list()\n",
    "    \n",
    "    EventIndex = dict()    \n",
    "    EventIndex['start'] = list()\n",
    "    EventIndex['end'] = list()\n",
    "    \n",
    "    EventBaseline_startKeyTime = list()\n",
    "    \n",
    "    for ind, eventStartInKeys in enumerate(EventTimeInKeys['start']):\n",
    "        \n",
    "        eventStartTime, eventStartInd = nearestTimePoint(PupilSize_df['timeStamp'].tolist(), eventStartInKeys)\n",
    "        eventEndTime, eventEndInd = nearestTimePoint(PupilSize_df['timeStamp'].tolist(), EventTimeInKeys['end'][ind])\n",
    "        \n",
    "        # reading start is the same as trial start\n",
    "        EventTime['start'].append(eventStartTime)\n",
    "        EventIndex['start'].append(eventStartInd)\n",
    "        \n",
    "        EventTime['end'].append(eventEndTime)\n",
    "        EventIndex['end'].append(eventEndInd)\n",
    "        \n",
    "        \n",
    "    return EventTime, EventIndex    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modmax(d):\n",
    "    # modulus maxima detection\n",
    "    \n",
    "    # compute signal modulus\n",
    "    m = [0.0]*len(d)\n",
    "    for i in range(0, len(d)):\n",
    "        m[i] = math.fabs(d[i])\n",
    "    \n",
    "    # if value is larger than both neighbours , and strictly\n",
    "    # larger than either , then it is a local maximum\n",
    "    t = [0.0]*len(d)\n",
    "    for i in range(0, len(d)):\n",
    "        ll = m[i-1] if i >= 1 else m[i]\n",
    "        oo = m[i]\n",
    "        rr = m[i+1] if i < len(d)-2 else m[i]\n",
    "        if (ll <= oo and oo >= rr) and (ll < oo or oo > rr):\n",
    "            # compute magnitude\n",
    "            t[i] = math.sqrt(d[i]**2)\n",
    "        else:\n",
    "            t[i] = 0.0\n",
    "    #print(len(t))\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdwtlevel(pupilData,dwtlvl):\n",
    "    \n",
    "    d = pupilData.pupilSize.tolist()\n",
    "    \n",
    "    cA = pywt.downcoef('a',d,'sym16','per',level=dwtlvl)\n",
    "    cD = pywt.downcoef('d',d,'sym16','per',level=dwtlvl)\n",
    "\n",
    "    cA[:] = [x / math.sqrt(2**dwtlvl) for x in cA]\n",
    "    cD[:] = [x / math.sqrt(2**dwtlvl) for x in cD]\n",
    "\n",
    "    cDm = modmax(cD)\n",
    "    cDt = cDm\n",
    "    \n",
    "    lambda_univ = np.std(cDm) * math.sqrt(2.0*np.log2(len(cDm)))\n",
    "    cDt = pywt.threshold(cDm,lambda_univ,mode=\"hard\")\n",
    "\n",
    "    \n",
    "    return cDt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pIPAlevel(pupilData, cDt):\n",
    "\n",
    "    # this function computes Sandra P. Marshall's Index of Cognitive Activity\n",
    "    # using the DWT of the pupil diamter: pwdt (above) must be run first!\n",
    "\n",
    "    ts = pupilData.timeStamp.iloc[0]\n",
    "    te = pupilData.timeStamp.iloc[-1]\n",
    "    tt = (te - ts).total_seconds()\n",
    "#   print \"ts: \", ts\n",
    "#   print \"te: \", te\n",
    "#   print \"total time: \", tt\n",
    "    ctr = 0\n",
    "    for i in range(len(cDt)):\n",
    "        if math.fabs(cDt[i]) > 0:\n",
    "            ctr += 1\n",
    "    ICA = float(ctr)/tt\n",
    "\n",
    "    return ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdwtLH(pupilData, lof, hif):\n",
    "    \n",
    "    d = pupilData.pupilSize.tolist()\n",
    "    d.insert(0, 0)\n",
    "\n",
    "    # lof, hif are low frequency band, high frequency band, resp.\n",
    "    # maxlevel = \\floor{\\log_2{\\left(\\frac{n_d}{n_f-1}\\right)}}\n",
    "    w = pywt.Wavelet('sym16')\n",
    "    maxlevel = pywt.dwt_max_level(len(d), filter_len=w.dec_len)\n",
    "    #print(\"max DWT level: \", maxlevel)\n",
    "\n",
    "    hif = 1\n",
    "    lof = int(maxlevel/2)\n",
    "\n",
    "    # get the wavelet detail coefficients for high and low frequenices\n",
    "    cD_H = pywt.downcoef('d',d,'sym16','per',level=hif)\n",
    "    cD_L = pywt.downcoef('d',d,'sym16','per',level=lof)\n",
    "\n",
    "    # normalize\n",
    "    cD_H[:] = [x / math.sqrt(2**hif) for x in cD_H]\n",
    "    cD_L[:] = [x / math.sqrt(2**lof) for x in cD_L]\n",
    "\n",
    "    cD_LH = cD_L\n",
    "\n",
    "    # obtain the LH ratio (HF:LH in this case)\n",
    "    #\n",
    "    # note that I am artificially extending the signal by using the 2*i\n",
    "    # index into the original data's timeline\n",
    "#   print \"len(cD_L): \", len(cD_L)\n",
    "#   print \"len(cD_H): \", len(cD_H)\n",
    "    # length of lower frequency detail coefficients will be shorter than\n",
    "    # the high frequency octaves, hence we should iterate over the low\n",
    "    # frequency octave and then use those inndices to index to the high\n",
    "    # frequency octave\n",
    "    for i in range(len(cD_L)):\n",
    "#     print \"cD_L: \", cD_L[i]\n",
    "#     print \"cD_H: \", cD_H[((2**lof)/(2**hif))*i]\n",
    "      # does low:high ratio really make sense?\n",
    "        cD_LH[i] = cD_L[i] / cD_H[int(((2**lof)/(2**hif))*i)]\n",
    "      # why not high:low signal ratio\n",
    "#     cD_LH[i] = cD_H[((2**lof)/(2**hif))*i] / cD_L[i]\n",
    "\n",
    "    \n",
    "    # the rest of the algorithm proceeds like the original IPA:\n",
    "    # find the modmax spikes in the LH signal and threshold\n",
    "    cD_LHm = modmax(cD_LH)\n",
    "    cD_LHt = cD_LHm\n",
    "    lambda_univ = np.std(cD_LHm) * math.sqrt(2.0*np.log2(len(cD_LHm)))\n",
    "    #cD_LHt = pywt.threshold(cD_LHm,lambda_univ,mode=\"hard\")\n",
    "    cD_LHt = pywt.threshold(cD_LHm,lambda_univ,mode=\"less\")\n",
    "    \n",
    "    return cD_LHt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pIPALH(pupilData, cD_LHt):\n",
    "\n",
    "    # this function computes Sandra P. Marshall's Index of Cognitive Activity\n",
    "    # using the DWT of the pupil diamter: pwdt (above) must be run first!\n",
    "\n",
    "    ts = pupilData.timeStamp.iloc[0]\n",
    "    te = pupilData.timeStamp.iloc[-1]\n",
    "    tt = (te - ts).total_seconds()\n",
    "#   print \"ts: \", ts\n",
    "#   print \"te: \", te\n",
    "#   print \"total time: \", tt\n",
    "    ctr = 0\n",
    "    for i in range(len(cD_LHt)):\n",
    "        if math.fabs(cD_LHt[i]) > 0:\n",
    "            ctr += 1\n",
    "    ICA_LH = float(ctr)/tt\n",
    "\n",
    "    return ICA_LH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ipaComputeForTrials(Events, PupilData):\n",
    "    \n",
    "    ipaNew_list = list()\n",
    "    for ind, eventStart in enumerate(Events['start']):\n",
    "        \n",
    "        eventStartTime, eventStartInd = nearestTimePoint(PupilData['timeStamp'].tolist(), eventStart)\n",
    "        eventEndTime, eventEndInd = nearestTimePoint(PupilData['timeStamp'].tolist(), Events['end'][ind])\n",
    "        \n",
    "        trialPupilSize = PupilData.iloc[eventStartInd:eventEndInd,:]\n",
    "        \n",
    "        pupilMean = (np.array(trialPupilSize['pupilLeft']) + np.array(trialPupilSize['pupilRight']))/2 \n",
    "        df = pd.DataFrame(list(zip(trialPupilSize['timeStamp'], pupilMean)), columns=['timeStamp', 'pupilSize'])\n",
    "        \n",
    "        #herz = 90\n",
    "        #sfdegree = 3\n",
    "        #sfcutoff = 1.0/herz\n",
    "        dwtlvl = 2\n",
    "        lof = 4\n",
    "        hif = 1\n",
    "        \n",
    "        #cDt = pdwtlevel(df,dwtlvl)\n",
    "        #ICA = pIPAlevel(df, cDt)\n",
    "        \n",
    "        cD_LHt = pdwtLH(df, lof, hif)\n",
    "        ICA_LH = pIPALH(df, cD_LHt)        \n",
    "        \n",
    "        ipaNew_list.append(ICA_LH)\n",
    "\n",
    "    return ipaNew_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataForEveryTrial:\n",
    "    subjectID = ''\n",
    "    blockNumber = ''\n",
    "    sessionNumber = ''\n",
    "    variable = ''\n",
    "    dataForTrial = ''\n",
    "    resultPathName = ''\n",
    "   \n",
    "    \n",
    "    def printInfo(self):\n",
    "        dataFrame = pd.DataFrame(list(zip([self.subjectID]*len(self.dataForTrial), [self.blockNumber]*len(self.dataForTrial), [self.sessionNumber]*len(self.dataForTrial), range(0,len(self.dataForTrial)+1), self.dataForTrial)), columns=['subjectID', 'block', 'session', 'trial', self.variable])\n",
    "        \n",
    "        return dataFrame\n",
    "    \n",
    "    def AddToFile(self):\n",
    "        \n",
    "        dataFrame = pd.DataFrame(list(zip([self.subjectID]*len(self.dataForTrial), [self.blockNumber]*len(self.dataForTrial), [self.sessionNumber]*len(self.dataForTrial), range(0,len(self.dataForTrial)+1), self.dataForTrial)), columns=['subjectID', 'block', 'session', 'trial', self.variable])\n",
    "        book = load_workbook(self.resultPathName)\n",
    "        writer = pd.ExcelWriter(self.resultPathName, engine='openpyxl')\n",
    "        writer.book = book\n",
    "        writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "        startrow = writer.sheets['Sheet1'].max_row\n",
    "        dataFrame.to_excel(writer, startrow = startrow, index = False, header = False)\n",
    "        \n",
    "        writer.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CombineReadingWriting(EventReading, EventWriting):\n",
    "    \n",
    "    EventTrial = copy.deepcopy(EventReading)\n",
    "    EventTrialEnd = [endTime for endTime in EventWriting['end']]\n",
    "    EventTrial['end'] = EventTrialEnd\n",
    "    \n",
    "    return EventTrial       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject path E:\\Data\\Data\\ac\\1\\2019-02-11-11-18-30_1\n",
      "subject and session name:  ac__1__2019-02-11-11-18-30_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ac     1       1      0          2.861466\n",
      "1        ac     1       1      1          2.697956\n",
      "2        ac     1       1      2          5.823699\n",
      "3        ac     1       1      3          2.293707\n",
      "4        ac     1       1      4          6.626967\n",
      "subject path E:\\Data\\Data\\ac\\1\\2019-02-11-11-33-32_2\n",
      "subject and session name:  ac__1__2019-02-11-11-33-32_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ac     1       2      0          2.803969\n",
      "1        ac     1       2      1          1.418728\n",
      "2        ac     1       2      2          1.375262\n",
      "3        ac     1       2      3          2.792472\n",
      "4        ac     1       2      4          2.852096\n",
      "subject path E:\\Data\\Data\\ac\\2\\2019-02-12-15-00-04_1\n",
      "subject and session name:  ac__2__2019-02-12-15-00-04_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ac     2       1      0          1.558531\n",
      "1        ac     2       1      1          5.643036\n",
      "2        ac     2       1      2          1.378528\n",
      "3        ac     2       1      3          2.830331\n",
      "4        ac     2       1      4          3.136958\n",
      "subject path E:\\Data\\Data\\ac\\2\\2019-02-12-15-27-37_2\n",
      "subject and session name:  ac__2__2019-02-12-15-27-37_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ac     2       2      0          5.664637\n",
      "1        ac     2       2      1          2.956475\n",
      "2        ac     2       2      2          6.175262\n",
      "3        ac     2       2      3          0.000000\n",
      "4        ac     2       2      4          2.523809\n",
      "subject path E:\\Data\\Data\\ac\\3_MS\\2019-02-14-14-28-49_1\n",
      "subject and session name:  ac__3_MS__2019-02-14-14-28-49_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ac  3_MS       1      0          5.873411\n",
      "1        ac  3_MS       1      1          7.201105\n",
      "2        ac  3_MS       1      2          6.238993\n",
      "3        ac  3_MS       1      3          3.218480\n",
      "4        ac  3_MS       1      4          2.851521\n",
      "subject path E:\\Data\\Data\\ac\\3_MS\\2019-02-14-14-45-49_2\n",
      "subject and session name:  ac__3_MS__2019-02-14-14-45-49_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ac  3_MS       2      0          1.457736\n",
      "1        ac  3_MS       2      1          1.405621\n",
      "2        ac  3_MS       2      2          6.646994\n",
      "3        ac  3_MS       2      3          3.476484\n",
      "4        ac  3_MS       2      4          6.196608\n",
      "subject path E:\\Data\\Data\\ac\\4\\2019-02-18-14-59-21_1\n",
      "subject and session name:  ac__4__2019-02-18-14-59-21_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ac     4       1      0          3.216730\n",
      "1        ac     4       1      1          1.543111\n",
      "2        ac     4       1      2          2.854876\n",
      "3        ac     4       1      3          1.405559\n",
      "4        ac     4       1      4          3.039824\n",
      "subject path E:\\Data\\Data\\ac\\4\\2019-2-18-15-23-54_2\n",
      "subject and session name:  ac__4__2019-2-18-15-23-54_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ac     4       2      0          0.000000\n",
      "1        ac     4       2      1          6.164309\n",
      "2        ac     4       2      2          0.000000\n",
      "3        ac     4       2      3          3.081250\n",
      "4        ac     4       2      4          2.853956\n",
      "subject path E:\\Data\\Data\\ac\\5\\2019-02-19-15-07-5_1\n",
      "subject and session name:  ac__5__2019-02-19-15-07-5_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ac     5       1      0          6.740797\n",
      "1        ac     5       1      1          5.836468\n",
      "2        ac     5       1      2          5.948077\n",
      "3        ac     5       1      3          2.221322\n",
      "4        ac     5       1      4          6.638166\n",
      "subject path E:\\Data\\Data\\ac\\5\\2019-02-19-15-18-20_2\n",
      "subject and session name:  ac__5__2019-02-19-15-18-20_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ac     5       2      0          2.667882\n",
      "1        ac     5       2      1          2.618284\n",
      "2        ac     5       2      2          1.407686\n",
      "3        ac     5       2      3          1.273605\n",
      "4        ac     5       2      4          2.755452\n",
      "subject path E:\\Data\\Data\\af\\1\\2019-01-16-15-43-8_1\n",
      "subject and session name:  af__1__2019-01-16-15-43-8_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        af     1       1      0          0.634690\n",
      "1        af     1       1      1          1.413793\n",
      "2        af     1       1      2          1.198672\n",
      "3        af     1       1      3          1.361006\n",
      "4        af     1       1      4          6.661797\n",
      "subject path E:\\Data\\Data\\af\\1\\2019-01-16-16-36-17_1stPart_2\n",
      "subject and session name:  af__1__2019-01-16-16-36-17_1stPart_2\n",
      "same reading and writing trials\n",
      "1stPart\n",
      "subject path E:\\Data\\Data\\af\\1\\2019-01-16-17-00-12_2ndPart_2\n",
      "subject and session name:  af__1__2019-01-16-17-00-12_2ndPart_2\n",
      "same reading and writing trials\n",
      "no gaze data present\n",
      "2ndPart\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        af     1       2      0          3.595377\n",
      "1        af     1       2      1          6.825205\n",
      "2        af     1       2      2          6.973567\n",
      "3        af     1       2      3               NaN\n",
      "4        af     1       2      4               NaN\n",
      "5        af     1       2      5               NaN\n",
      "6        af     1       2      6               NaN\n",
      "subject path E:\\Data\\Data\\af\\2\\2019-01-17-15-03-40_1\n",
      "subject and session name:  af__2__2019-01-17-15-03-40_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        af     2       1      0          6.802818\n",
      "1        af     2       1      1          5.803426\n",
      "2        af     2       1      2          6.088156\n",
      "3        af     2       1      3          2.881421\n",
      "4        af     2       1      4          1.336114\n",
      "subject path E:\\Data\\Data\\af\\2\\2019-01-17-15-27-20_1stPart_2\n",
      "subject and session name:  af__2__2019-01-17-15-27-20_1stPart_2\n",
      "same reading and writing trials\n",
      "1stPart\n",
      "subject path E:\\Data\\Data\\af\\2\\2019-01-17-16-03-27_2ndPart_2\n",
      "subject and session name:  af__2__2019-01-17-16-03-27_2ndPart_2\n",
      "same reading and writing trials\n",
      "2ndPart\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        af     2       2      0          7.211656\n",
      "1        af     2       2      1          1.309164\n",
      "2        af     2       2      2          1.293738\n",
      "3        af     2       2      3          1.711469\n",
      "4        af     2       2      4          1.417762\n",
      "5        af     2       2      5          6.129899\n",
      "subject path E:\\Data\\Data\\af\\3_MS\\2019-02-06-15-44-15_1\n",
      "subject and session name:  af__3_MS__2019-02-06-15-44-15_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        af  3_MS       1      0          1.400847\n",
      "1        af  3_MS       1      1          3.238510\n",
      "2        af  3_MS       1      2          3.371364\n",
      "3        af  3_MS       1      3          3.049047\n",
      "4        af  3_MS       1      4          3.591468\n",
      "subject path E:\\Data\\Data\\af\\3_MS\\2019-02-06-16-19-9_2\n",
      "subject and session name:  af__3_MS__2019-02-06-16-19-9_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        af  3_MS       2      0          5.799876\n",
      "1        af  3_MS       2      1          6.904592\n",
      "2        af  3_MS       2      2          6.644190\n",
      "3        af  3_MS       2      3          6.236959\n",
      "4        af  3_MS       2      4          5.838548\n",
      "subject path E:\\Data\\Data\\af\\4\\2019-02-12-11-07-43_1\n",
      "subject and session name:  af__4__2019-02-12-11-07-43_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        af     4       1      0          0.000000\n",
      "1        af     4       1      1          6.802336\n",
      "2        af     4       1      2          6.745660\n",
      "3        af     4       1      3          7.234697\n",
      "4        af     4       1      4          0.000000\n",
      "subject path E:\\Data\\Data\\af\\4\\2019-02-12-11-21-21_2\n",
      "subject and session name:  af__4__2019-02-12-11-21-21_2\n",
      "same reading and writing trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        af     4       2      0          1.269394\n",
      "1        af     4       2      1          6.724797\n",
      "2        af     4       2      2          3.221206\n",
      "3        af     4       2      3          2.839739\n",
      "4        af     4       2      4          3.446965\n",
      "subject path E:\\Data\\Data\\af\\5\\2019-02-27-15-08-32_1\n",
      "subject and session name:  af__5__2019-02-27-15-08-32_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        af     5       1      0          3.543908\n",
      "1        af     5       1      1          3.098381\n",
      "2        af     5       1      2          3.300027\n",
      "3        af     5       1      3          3.331703\n",
      "4        af     5       1      4          3.713585\n",
      "subject path E:\\Data\\Data\\af\\5\\2019-02-27-15-40-6_2\n",
      "subject and session name:  af__5__2019-02-27-15-40-6_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        af     5       2      0          6.813367\n",
      "1        af     5       2      1          6.585490\n",
      "2        af     5       2      2          7.046681\n",
      "3        af     5       2      3          6.758026\n",
      "4        af     5       2      4          6.961980\n",
      "subject path E:\\Data\\Data\\aq\\1\\2019-02-06-11-25-41_1\n",
      "subject and session name:  aq__1__2019-02-06-11-25-41_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        aq     1       1      0          3.048076\n",
      "1        aq     1       1      1          3.265388\n",
      "2        aq     1       1      2          2.478286\n",
      "3        aq     1       1      3          1.295430\n",
      "4        aq     1       1      4          2.763977\n",
      "5        aq     1       1      5          2.579325\n",
      "6        aq     1       1      6          1.205146\n",
      "subject path E:\\Data\\Data\\aq\\1\\2019-02-06-12-37-45_2\n",
      "subject and session name:  aq__1__2019-02-06-12-37-45_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        aq     1       2      0          6.666731\n",
      "1        aq     1       2      1          6.308988\n",
      "2        aq     1       2      2          5.572337\n",
      "3        aq     1       2      3          5.872150\n",
      "4        aq     1       2      4          2.827073\n",
      "subject path E:\\Data\\Data\\aq\\2\\2019-02-07-11-01-57_1\n",
      "subject and session name:  aq__2__2019-02-07-11-01-57_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        aq     2       1      0          7.026390\n",
      "1        aq     2       1      1          3.229649\n",
      "2        aq     2       1      2          2.826801\n",
      "3        aq     2       1      3          2.604501\n",
      "4        aq     2       1      4          3.474164\n",
      "subject path E:\\Data\\Data\\aq\\2\\2019-02-07-11-24-49_2\n",
      "subject and session name:  aq__2__2019-02-07-11-24-49_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        aq     2       2      0          2.857915\n",
      "1        aq     2       2      1          6.705090\n",
      "2        aq     2       2      2          1.280892\n",
      "3        aq     2       2      3          2.631144\n",
      "4        aq     2       2      4          1.370582\n",
      "subject path E:\\Data\\Data\\aq\\3\\2019-02-08-11-33-53_1stPart_1\n",
      "subject and session name:  aq__3__2019-02-08-11-33-53_1stPart_1\n",
      "same reading and writing trials\n",
      "1stPart\n",
      "subject path E:\\Data\\Data\\aq\\3\\2019-02-08-12-11-34_2ndPart_1\n",
      "subject and session name:  aq__3__2019-02-08-12-11-34_2ndPart_1\n",
      "same reading and writing trials\n",
      "2ndPart\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        aq     3       1      0          1.451792\n",
      "1        aq     3       1      1          1.488714\n",
      "2        aq     3       1      2          1.593772\n",
      "3        aq     3       1      3          3.055903\n",
      "4        aq     3       1      4          2.731075\n",
      "subject path E:\\Data\\Data\\aq\\3\\2019-02-08-12-22-35_2\n",
      "subject and session name:  aq__3__2019-02-08-12-22-35_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        aq     3       2      0          3.161203\n",
      "1        aq     3       2      1          6.673273\n",
      "2        aq     3       2      2          3.201376\n",
      "3        aq     3       2      3          2.756055\n",
      "4        aq     3       2      4          2.947318\n",
      "subject path E:\\Data\\Data\\aq\\4\\2019-02-13-11-05-20_1\n",
      "subject and session name:  aq__4__2019-02-13-11-05-20_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        aq     4       1      0          3.014778\n",
      "1        aq     4       1      1          6.478900\n",
      "2        aq     4       1      2          2.773057\n",
      "3        aq     4       1      3          6.700435\n",
      "4        aq     4       1      4          2.985846\n",
      "subject path E:\\Data\\Data\\aq\\4\\2019-02-13-11-22-4_2\n",
      "subject and session name:  aq__4__2019-02-13-11-22-4_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        aq     4       2      0          1.449398\n",
      "1        aq     4       2      1          1.334230\n",
      "2        aq     4       2      2          5.629084\n",
      "3        aq     4       2      3          1.188889\n",
      "4        aq     4       2      4          1.339765\n",
      "subject path E:\\Data\\Data\\aq\\5_MS\\2019-02-15-16-03-19_1\n",
      "subject and session name:  aq__5_MS__2019-02-15-16-03-19_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        aq  5_MS       1      0          1.395589\n",
      "1        aq  5_MS       1      1          1.277895\n",
      "2        aq  5_MS       1      2          2.949594\n",
      "3        aq  5_MS       1      3          1.417136\n",
      "4        aq  5_MS       1      4          1.186286\n",
      "subject path E:\\Data\\Data\\aq\\5_MS\\2019-02-15-16-35-40_2\n",
      "subject and session name:  aq__5_MS__2019-02-15-16-35-40_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        aq  5_MS       2      0          6.228209\n",
      "1        aq  5_MS       2      1          3.116947\n",
      "2        aq  5_MS       2      2          6.261935\n",
      "3        aq  5_MS       2      3          2.942772\n",
      "4        aq  5_MS       2      4          3.010836\n",
      "subject path E:\\Data\\Data\\bh1\\1\\2019-01-28-14-30-44_1\n",
      "subject and session name:  bh1__1__2019-01-28-14-30-44_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       bh1     1       1      0          6.862109\n",
      "1       bh1     1       1      1          3.660201\n",
      "2       bh1     1       1      2          3.082586\n",
      "3       bh1     1       1      3          7.013350\n",
      "4       bh1     1       1      4          3.119987\n",
      "5       bh1     1       1      5          6.200358\n",
      "6       bh1     1       1      6          6.604005\n",
      "7       bh1     1       1      7          6.383442\n",
      "subject path E:\\Data\\Data\\bh1\\1\\2019-01-28-14-50-41_2\n",
      "subject and session name:  bh1__1__2019-01-28-14-50-41_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       bh1     1       2      0          3.434396\n",
      "1       bh1     1       2      1          2.954952\n",
      "2       bh1     1       2      2          3.193144\n",
      "3       bh1     1       2      3          6.440398\n",
      "4       bh1     1       2      4          3.264454\n",
      "subject path E:\\Data\\Data\\bh1\\2_MS\\2019-01-29-14-19-26_1\n",
      "subject and session name:  bh1__2_MS__2019-01-29-14-19-26_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       bh1  2_MS       1      0          6.607611\n",
      "1       bh1  2_MS       1      1          6.695360\n",
      "2       bh1  2_MS       1      2          6.945709\n",
      "3       bh1  2_MS       1      3          3.111784\n",
      "4       bh1  2_MS       1      4          7.060572\n",
      "subject path E:\\Data\\Data\\bh1\\2_MS\\2019-01-29-14-40-36_2\n",
      "subject and session name:  bh1__2_MS__2019-01-29-14-40-36_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       bh1  2_MS       2      0          6.823402\n",
      "1       bh1  2_MS       2      1          7.505427\n",
      "2       bh1  2_MS       2      2          7.338136\n",
      "3       bh1  2_MS       2      3          5.932505\n",
      "4       bh1  2_MS       2      4          6.764343\n",
      "subject path E:\\Data\\Data\\bh1\\3\\2019-01-30-14-13-37_1\n",
      "subject and session name:  bh1__3__2019-01-30-14-13-37_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       bh1     3       1      0          3.606885\n",
      "1       bh1     3       1      1          3.762550\n",
      "2       bh1     3       1      2          6.349427\n",
      "3       bh1     3       1      3          6.932778\n",
      "4       bh1     3       1      4          6.572691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject path E:\\Data\\Data\\bh1\\3\\2019-01-30-14-29-29_2\n",
      "subject and session name:  bh1__3__2019-01-30-14-29-29_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       bh1     3       2      0          3.054559\n",
      "1       bh1     3       2      1          6.729216\n",
      "2       bh1     3       2      2          0.000000\n",
      "3       bh1     3       2      3          6.622697\n",
      "4       bh1     3       2      4          6.864207\n",
      "subject path E:\\Data\\Data\\bh1\\4\\2019-01-31-09-12-2_1\n",
      "subject and session name:  bh1__4__2019-01-31-09-12-2_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       bh1     4       1      0          6.635599\n",
      "1       bh1     4       1      1          6.174628\n",
      "2       bh1     4       1      2          6.611657\n",
      "3       bh1     4       1      3          7.127899\n",
      "4       bh1     4       1      4          6.104073\n",
      "subject path E:\\Data\\Data\\bh1\\4\\2019-01-31-09-22-49_1stPart_2\n",
      "subject and session name:  bh1__4__2019-01-31-09-22-49_1stPart_2\n",
      "same reading and writing trials\n",
      "1stPart\n",
      "subject path E:\\Data\\Data\\bh1\\4\\2019-01-31-09-37-5_2ndPart_2\n",
      "subject and session name:  bh1__4__2019-01-31-09-37-5_2ndPart_2\n",
      "same reading and writing trials\n",
      "2ndPart\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       bh1     4       2      0          3.044340\n",
      "1       bh1     4       2      1          0.000000\n",
      "2       bh1     4       2      2          3.290377\n",
      "3       bh1     4       2      3          2.859641\n",
      "4       bh1     4       2      4          3.069448\n",
      "subject path E:\\Data\\Data\\bh1\\5\\2019-02-05-14-04-11_1\n",
      "subject and session name:  bh1__5__2019-02-05-14-04-11_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       bh1     5       1      0          3.300165\n",
      "1       bh1     5       1      1          3.425191\n",
      "2       bh1     5       1      2          3.101830\n",
      "3       bh1     5       1      3          7.064328\n",
      "4       bh1     5       1      4          6.502151\n",
      "subject path E:\\Data\\Data\\bh1\\5\\2019-02-05-14-20-6_2\n",
      "subject and session name:  bh1__5__2019-02-05-14-20-6_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       bh1     5       2      0          6.414465\n",
      "1       bh1     5       2      1          0.000000\n",
      "2       bh1     5       2      2          6.798707\n",
      "3       bh1     5       2      3          0.000000\n",
      "4       bh1     5       2      4          7.030436\n",
      "subject path E:\\Data\\Data\\bh2\\1\\2019-02-21-16-09-44_1stPart_1\n",
      "subject and session name:  bh2__1__2019-02-21-16-09-44_1stPart_1\n",
      "same reading and writing trials\n",
      "1stPart\n",
      "subject path E:\\Data\\Data\\bh2\\1\\2019-02-21-16-22-22_2ndPart_1\n",
      "subject and session name:  bh2__1__2019-02-21-16-22-22_2ndPart_1\n",
      "same reading and writing trials\n",
      "2ndPart\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       bh2     1       1      0          7.355274\n",
      "1       bh2     1       1      1          7.307280\n",
      "2       bh2     1       1      2          7.144668\n",
      "3       bh2     1       1      3          6.979719\n",
      "4       bh2     1       1      4          7.289165\n",
      "5       bh2     1       1      5          7.510793\n",
      "subject path E:\\Data\\Data\\bh2\\1\\2019-02-21-16-33-19_2\n",
      "subject and session name:  bh2__1__2019-02-21-16-33-19_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       bh2     1       2      0          3.537565\n",
      "1       bh2     1       2      1          7.531780\n",
      "2       bh2     1       2      2          3.671533\n",
      "3       bh2     1       2      3          3.336792\n",
      "4       bh2     1       2      4          3.235857\n",
      "subject path E:\\Data\\Data\\bh2\\2\\2019-02-27-13-19-57_1\n",
      "subject and session name:  bh2__2__2019-02-27-13-19-57_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       bh2     2       1      0          3.070221\n",
      "1       bh2     2       1      1          2.960884\n",
      "2       bh2     2       1      2          6.766960\n",
      "3       bh2     2       1      3          3.180669\n",
      "4       bh2     2       1      4          2.991249\n",
      "subject path E:\\Data\\Data\\bh2\\2\\2019-02-27-13-45-4_2\n",
      "subject and session name:  bh2__2__2019-02-27-13-45-4_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       bh2     2       2      0          6.357025\n",
      "1       bh2     2       2      1          6.487157\n",
      "2       bh2     2       2      2          3.149148\n",
      "3       bh2     2       2      3          2.617872\n",
      "4       bh2     2       2      4          6.854684\n",
      "subject path E:\\Data\\Data\\bh2\\3\\2019-02-28-16-47-35_1\n",
      "subject and session name:  bh2__3__2019-02-28-16-47-35_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       bh2     3       1      0          3.286042\n",
      "1       bh2     3       1      1          6.605601\n",
      "2       bh2     3       1      2          3.453462\n",
      "3       bh2     3       1      3          3.670915\n",
      "4       bh2     3       1      4          2.959512\n",
      "subject path E:\\Data\\Data\\bh2\\3\\2019-02-28-17-03-53_1stPart_2\n",
      "subject and session name:  bh2__3__2019-02-28-17-03-53_1stPart_2\n",
      "same reading and writing trials\n",
      "1stPart\n",
      "subject path E:\\Data\\Data\\bh2\\3\\2019-02-28-17-24-2_2ndPart_2\n",
      "subject and session name:  bh2__3__2019-02-28-17-24-2_2ndPart_2\n",
      "same reading and writing trials\n",
      "2ndPart\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       bh2     3       2      0          3.234275\n",
      "1       bh2     3       2      1          7.637988\n",
      "2       bh2     3       2      2          3.614539\n",
      "3       bh2     3       2      3          7.000934\n",
      "4       bh2     3       2      4          3.610670\n",
      "subject path E:\\Data\\Data\\bh2\\4\\2019-03-04-10-14-44_1\n",
      "subject and session name:  bh2__4__2019-03-04-10-14-44_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       bh2     4       1      0          3.458768\n",
      "1       bh2     4       1      1          3.757864\n",
      "2       bh2     4       1      2          3.492668\n",
      "3       bh2     4       1      3          3.637300\n",
      "4       bh2     4       1      4          3.614790\n",
      "subject path E:\\Data\\Data\\bh2\\4\\2019-03-04-10-38-49_2\n",
      "subject and session name:  bh2__4__2019-03-04-10-38-49_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       bh2     4       2      0          6.918662\n",
      "1       bh2     4       2      1          7.135609\n",
      "2       bh2     4       2      2          7.302832\n",
      "3       bh2     4       2      3          7.299262\n",
      "4       bh2     4       2      4          6.504402\n",
      "subject path E:\\Data\\Data\\bh2\\5_MS\\2019-03-05-09-00-21_1\n",
      "subject and session name:  bh2__5_MS__2019-03-05-09-00-21_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       bh2  5_MS       1      0          6.991889\n",
      "1       bh2  5_MS       1      1          6.497994\n",
      "2       bh2  5_MS       1      2          6.755100\n",
      "3       bh2  5_MS       1      3          7.225816\n",
      "4       bh2  5_MS       1      4          6.772894\n",
      "subject path E:\\Data\\Data\\bh2\\5_MS\\2019-03-05-09-15-11_2\n",
      "subject and session name:  bh2__5_MS__2019-03-05-09-15-11_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       bh2  5_MS       2      0          3.435476\n",
      "1       bh2  5_MS       2      1          3.545549\n",
      "2       bh2  5_MS       2      2          6.989982\n",
      "3       bh2  5_MS       2      3          3.254619\n",
      "4       bh2  5_MS       2      4          7.505362\n",
      "subject path E:\\Data\\Data\\cw\\1\\2019-02-07-13-20-50_1\n",
      "subject and session name:  cw__1__2019-02-07-13-20-50_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        cw     1       1      0          3.664298\n",
      "1        cw     1       1      1          7.218336\n",
      "2        cw     1       1      2          3.601202\n",
      "3        cw     1       1      3          6.705860\n",
      "4        cw     1       1      4          3.065606\n",
      "subject path E:\\Data\\Data\\cw\\1\\2019-02-07-13-50-26_2\n",
      "subject and session name:  cw__1__2019-02-07-13-50-26_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        cw     1       2      0          1.447537\n",
      "1        cw     1       2      1          6.851989\n",
      "2        cw     1       2      2          3.296300\n",
      "3        cw     1       2      3          3.108893\n",
      "4        cw     1       2      4          6.695195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject path E:\\Data\\Data\\cw\\2\\2019-02-13-13-02-13_1\n",
      "subject and session name:  cw__2__2019-02-13-13-02-13_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        cw     2       1      0          3.184370\n",
      "1        cw     2       1      1          3.088240\n",
      "2        cw     2       1      2          3.379782\n",
      "3        cw     2       1      3          7.072974\n",
      "4        cw     2       1      4          3.224153\n",
      "subject path E:\\Data\\Data\\cw\\2\\2019-02-13-13-38-31_2\n",
      "subject and session name:  cw__2__2019-02-13-13-38-31_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        cw     2       2      0          5.052025\n",
      "1        cw     2       2      1          6.087085\n",
      "2        cw     2       2      2          6.615070\n",
      "3        cw     2       2      3          6.721120\n",
      "4        cw     2       2      4          6.642655\n",
      "subject path E:\\Data\\Data\\cw\\3\\2019-02-14-13-04-42_1\n",
      "subject and session name:  cw__3__2019-02-14-13-04-42_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        cw     3       1      0          2.933663\n",
      "1        cw     3       1      1          6.710631\n",
      "2        cw     3       1      2          3.441014\n",
      "3        cw     3       1      3          3.500541\n",
      "4        cw     3       1      4          7.137368\n",
      "subject path E:\\Data\\Data\\cw\\3\\2019-02-14-13-28-20_1stPart_2\n",
      "subject and session name:  cw__3__2019-02-14-13-28-20_1stPart_2\n",
      "same reading and writing trials\n",
      "1stPart\n",
      "subject path E:\\Data\\Data\\cw\\3\\2019-02-14-13-57-41_2ndPart_2\n",
      "subject and session name:  cw__3__2019-02-14-13-57-41_2ndPart_2\n",
      "same reading and writing trials\n",
      "2ndPart\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        cw     3       2      0          3.600189\n",
      "1        cw     3       2      1          3.515917\n",
      "2        cw     3       2      2          7.044279\n",
      "3        cw     3       2      3          1.607971\n",
      "4        cw     3       2      4          3.341323\n",
      "5        cw     3       2      5          1.708478\n",
      "subject path E:\\Data\\Data\\cw\\4\\2019-02-18-11-01-34_1\n",
      "subject and session name:  cw__4__2019-02-18-11-01-34_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        cw     4       1      0          3.177658\n",
      "1        cw     4       1      1          6.366065\n",
      "2        cw     4       1      2          1.726403\n",
      "3        cw     4       1      3          1.668392\n",
      "4        cw     4       1      4          3.438541\n",
      "subject path E:\\Data\\Data\\cw\\4\\2019-02-18-11-35-13_2\n",
      "subject and session name:  cw__4__2019-02-18-11-35-13_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        cw     4       2      0          3.509813\n",
      "1        cw     4       2      1          6.521566\n",
      "2        cw     4       2      2          7.036112\n",
      "3        cw     4       2      3          7.183543\n",
      "4        cw     4       2      4          6.894950\n",
      "subject path E:\\Data\\Data\\cw\\5_MS\\2019-02-21-15-32-15_1\n",
      "subject and session name:  cw__5_MS__2019-02-21-15-32-15_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        cw  5_MS       1      0          6.332767\n",
      "1        cw  5_MS       1      1          6.434783\n",
      "2        cw  5_MS       1      2          6.882018\n",
      "3        cw  5_MS       1      3          3.377015\n",
      "4        cw  5_MS       1      4          3.280941\n",
      "subject path E:\\Data\\Data\\cw\\5_MS\\2019-02-21-15-55-56_2\n",
      "subject and session name:  cw__5_MS__2019-02-21-15-55-56_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        cw  5_MS       2      0          3.216073\n",
      "1        cw  5_MS       2      1          3.203035\n",
      "2        cw  5_MS       2      2          6.378309\n",
      "3        cw  5_MS       2      3          3.437895\n",
      "4        cw  5_MS       2      4          3.347595\n",
      "subject path E:\\Data\\Data\\jm\\1\\2019-01-29-15-15-59_1\n",
      "subject and session name:  jm__1__2019-01-29-15-15-59_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        jm     1       1      0          6.625940\n",
      "1        jm     1       1      1          3.156881\n",
      "2        jm     1       1      2          3.101554\n",
      "3        jm     1       1      3          6.432190\n",
      "4        jm     1       1      4          3.205323\n",
      "subject path E:\\Data\\Data\\jm\\1\\2019-01-29-15-33-22_2\n",
      "subject and session name:  jm__1__2019-01-29-15-33-22_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        jm     1       2      0          3.130035\n",
      "1        jm     1       2      1          3.169794\n",
      "2        jm     1       2      2          2.882479\n",
      "3        jm     1       2      3          1.565029\n",
      "4        jm     1       2      4          3.147466\n",
      "subject path E:\\Data\\Data\\jm\\2_MS\\2019-01-30-15-04-30_1\n",
      "subject and session name:  jm__2_MS__2019-01-30-15-04-30_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        jm  2_MS       1      0          3.093224\n",
      "1        jm  2_MS       1      1          6.767057\n",
      "2        jm  2_MS       1      2          2.935042\n",
      "3        jm  2_MS       1      3          3.237439\n",
      "4        jm  2_MS       1      4          6.206349\n",
      "subject path E:\\Data\\Data\\jm\\2_MS\\2019-01-30-15-19-36_2\n",
      "subject and session name:  jm__2_MS__2019-01-30-15-19-36_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        jm  2_MS       2      0          2.899279\n",
      "1        jm  2_MS       2      1          5.488936\n",
      "2        jm  2_MS       2      2          3.093477\n",
      "3        jm  2_MS       2      3          3.150417\n",
      "4        jm  2_MS       2      4          1.491678\n",
      "subject path E:\\Data\\Data\\jm\\3\\2019-02-01-15-17-37_1\n",
      "subject and session name:  jm__3__2019-02-01-15-17-37_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        jm     3       1      0          2.879306\n",
      "1        jm     3       1      1          3.203110\n",
      "2        jm     3       1      2          3.155614\n",
      "3        jm     3       1      3          1.610615\n",
      "4        jm     3       1      4          6.997010\n",
      "subject path E:\\Data\\Data\\jm\\3\\2019-02-01-15-40-18_2\n",
      "subject and session name:  jm__3__2019-02-01-15-40-18_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        jm     3       2      0          6.999543\n",
      "1        jm     3       2      1          2.984574\n",
      "2        jm     3       2      2          3.003078\n",
      "3        jm     3       2      3          6.774579\n",
      "4        jm     3       2      4          5.503817\n",
      "subject path E:\\Data\\Data\\jm\\4\\2019-02-05-14-49-17_1\n",
      "subject and session name:  jm__4__2019-02-05-14-49-17_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        jm     4       1      0          2.938398\n",
      "1        jm     4       1      1          2.923006\n",
      "2        jm     4       1      2          3.145241\n",
      "3        jm     4       1      3          6.411976\n",
      "4        jm     4       1      4          6.470699\n",
      "subject path E:\\Data\\Data\\jm\\4\\2019-02-05-15-01-43_2\n",
      "subject and session name:  jm__4__2019-02-05-15-01-43_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        jm     4       2      0          3.010443\n",
      "1        jm     4       2      1          1.463449\n",
      "2        jm     4       2      2          3.149346\n",
      "3        jm     4       2      3          1.440392\n",
      "4        jm     4       2      4          1.502473\n",
      "subject path E:\\Data\\Data\\jm\\5\\2019-02-06-15-32-48_1\n",
      "subject and session name:  jm__5__2019-02-06-15-32-48_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        jm     5       1      0          1.506042\n",
      "1        jm     5       1      1          1.575547\n",
      "2        jm     5       1      2          2.914801\n",
      "3        jm     5       1      3          1.609507\n",
      "4        jm     5       1      4          3.190559\n",
      "subject path E:\\Data\\Data\\jm\\5\\2019-02-06-16-10-7_2\n",
      "subject and session name:  jm__5__2019-02-06-16-10-7_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        jm     5       2      0          0.000000\n",
      "1        jm     5       2      1          6.298507\n",
      "2        jm     5       2      2          6.692509\n",
      "3        jm     5       2      3          6.078433\n",
      "4        jm     5       2      4          5.556278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject path E:\\Data\\Data\\jp\\1\\2019-02-11-14-23-27_1\n",
      "subject and session name:  jp__1__2019-02-11-14-23-27_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        jp     1       1      0          3.175949\n",
      "1        jp     1       1      1          6.685254\n",
      "2        jp     1       1      2          3.332733\n",
      "3        jp     1       1      3          3.258386\n",
      "4        jp     1       1      4          7.292929\n",
      "subject path E:\\Data\\Data\\jp\\1\\2019-02-11-14-46-36_2\n",
      "subject and session name:  jp__1__2019-02-11-14-46-36_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        jp     1       2      0          6.683780\n",
      "1        jp     1       2      1          3.317948\n",
      "2        jp     1       2      2          3.153799\n",
      "3        jp     1       2      3          3.271303\n",
      "4        jp     1       2      4          3.343303\n",
      "subject path E:\\Data\\Data\\jp\\2_MS\\2019-02-12-10-18-24_1\n",
      "subject and session name:  jp__2_MS__2019-02-12-10-18-24_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        jp  2_MS       1      0          3.407482\n",
      "1        jp  2_MS       1      1          3.360349\n",
      "2        jp  2_MS       1      2          3.464823\n",
      "3        jp  2_MS       1      3          3.376389\n",
      "4        jp  2_MS       1      4          3.335529\n",
      "subject path E:\\Data\\Data\\jp\\2_MS\\2019-02-12-10-46-29_2\n",
      "subject and session name:  jp__2_MS__2019-02-12-10-46-29_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        jp  2_MS       2      0          6.936971\n",
      "1        jp  2_MS       2      1          7.080840\n",
      "2        jp  2_MS       2      2          7.022748\n",
      "3        jp  2_MS       2      3          6.308759\n",
      "4        jp  2_MS       2      4          6.973771\n",
      "subject path E:\\Data\\Data\\jp\\3\\2019-02-13-15-03-15_1\n",
      "subject and session name:  jp__3__2019-02-13-15-03-15_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        jp     3       1      0          6.239761\n",
      "1        jp     3       1      1          7.180329\n",
      "2        jp     3       1      2          3.211909\n",
      "3        jp     3       1      3          3.437380\n",
      "4        jp     3       1      4          6.873890\n",
      "subject path E:\\Data\\Data\\jp\\3\\2019-02-13-15-24-33_2\n",
      "subject and session name:  jp__3__2019-02-13-15-24-33_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        jp     3       2      0          3.221617\n",
      "1        jp     3       2      1          3.238287\n",
      "2        jp     3       2      2          3.177434\n",
      "3        jp     3       2      3          3.506396\n",
      "4        jp     3       2      4          6.984237\n",
      "subject path E:\\Data\\Data\\jp\\4\\2019-02-18-10-00-56_1\n",
      "subject and session name:  jp__4__2019-02-18-10-00-56_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        jp     4       1      0          6.567187\n",
      "1        jp     4       1      1          2.929223\n",
      "2        jp     4       1      2          7.012488\n",
      "3        jp     4       1      3          3.261478\n",
      "4        jp     4       1      4          3.255923\n",
      "subject path E:\\Data\\Data\\jp\\4\\2019-02-18-10-21-1_2\n",
      "subject and session name:  jp__4__2019-02-18-10-21-1_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        jp     4       2      0          6.675258\n",
      "1        jp     4       2      1          3.182460\n",
      "2        jp     4       2      2          6.880810\n",
      "3        jp     4       2      3          7.137219\n",
      "4        jp     4       2      4          7.395051\n",
      "subject path E:\\Data\\Data\\jp\\5\\2019-02-19-13-08-1_1\n",
      "subject and session name:  jp__5__2019-02-19-13-08-1_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        jp     5       1      0          3.387858\n",
      "1        jp     5       1      1          3.286064\n",
      "2        jp     5       1      2          3.299666\n",
      "3        jp     5       1      3          3.463984\n",
      "4        jp     5       1      4          6.512996\n",
      "subject path E:\\Data\\Data\\jp\\5\\2019-02-19-13-31-29_2\n",
      "subject and session name:  jp__5__2019-02-19-13-31-29_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        jp     5       2      0          3.345253\n",
      "1        jp     5       2      1          6.912896\n",
      "2        jp     5       2      2          3.442033\n",
      "3        jp     5       2      3          6.815644\n",
      "4        jp     5       2      4          6.908056\n",
      "subject path E:\\Data\\Data\\kj\\1\\2019-03-01-15-13-20_1\n",
      "subject and session name:  kj__1__2019-03-01-15-13-20_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        kj     1       1      0          3.369783\n",
      "1        kj     1       1      1          3.183249\n",
      "2        kj     1       1      2          7.226159\n",
      "3        kj     1       1      3          3.340027\n",
      "4        kj     1       1      4          3.776264\n",
      "subject path E:\\Data\\Data\\kj\\1\\2019-03-01-15-35-0_2\n",
      "subject and session name:  kj__1__2019-03-01-15-35-0_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        kj     1       2      0          7.148518\n",
      "1        kj     1       2      1          6.495756\n",
      "2        kj     1       2      2          6.610452\n",
      "3        kj     1       2      3          6.826805\n",
      "4        kj     1       2      4          6.305170\n",
      "subject path E:\\Data\\Data\\kj\\2_MS\\2019-03-07-12-28-7_1\n",
      "subject and session name:  kj__2_MS__2019-03-07-12-28-7_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        kj  2_MS       1      0          3.397790\n",
      "1        kj  2_MS       1      1          6.543142\n",
      "2        kj  2_MS       1      2          6.896223\n",
      "3        kj  2_MS       1      3          3.257033\n",
      "4        kj  2_MS       1      4          2.758853\n",
      "subject path E:\\Data\\Data\\kj\\2_MS\\2019-03-07-12-44-13_2\n",
      "subject and session name:  kj__2_MS__2019-03-07-12-44-13_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        kj  2_MS       2      0          6.464974\n",
      "1        kj  2_MS       2      1          6.193534\n",
      "2        kj  2_MS       2      2          6.324428\n",
      "3        kj  2_MS       2      3          6.536610\n",
      "4        kj  2_MS       2      4          6.327762\n",
      "subject path E:\\Data\\Data\\kj\\3\\2019-03-12-09-30-5_1\n",
      "subject and session name:  kj__3__2019-03-12-09-30-5_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        kj     3       1      0          6.817321\n",
      "1        kj     3       1      1          3.322849\n",
      "2        kj     3       1      2          3.492631\n",
      "3        kj     3       1      3          6.901940\n",
      "4        kj     3       1      4          7.063251\n",
      "subject path E:\\Data\\Data\\kj\\3\\2019-03-12-09-47-44_2\n",
      "subject and session name:  kj__3__2019-03-12-09-47-44_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        kj     3       2      0          6.797255\n",
      "1        kj     3       2      1          7.015602\n",
      "2        kj     3       2      2          6.655913\n",
      "3        kj     3       2      3          5.873448\n",
      "4        kj     3       2      4          7.321689\n",
      "subject path E:\\Data\\Data\\kj\\4\\2019-03-13-10-04-6_1\n",
      "subject and session name:  kj__4__2019-03-13-10-04-6_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        kj     4       1      0          6.827749\n",
      "1        kj     4       1      1          6.540097\n",
      "2        kj     4       1      2          6.226623\n",
      "3        kj     4       1      3          6.872782\n",
      "4        kj     4       1      4          7.318576\n",
      "subject path E:\\Data\\Data\\kj\\4\\2019-03-13-10-15-45_2\n",
      "subject and session name:  kj__4__2019-03-13-10-15-45_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        kj     4       2      0          3.776912\n",
      "1        kj     4       2      1          3.329794\n",
      "2        kj     4       2      2          6.516262\n",
      "3        kj     4       2      3          2.738563\n",
      "4        kj     4       2      4          6.257172\n",
      "subject path E:\\Data\\Data\\kj\\5\\2019-03-14-13-53-54_1\n",
      "subject and session name:  kj__5__2019-03-14-13-53-54_1\n",
      "same reading and writing trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        kj     5       1      0          6.617480\n",
      "1        kj     5       1      1          5.715277\n",
      "2        kj     5       1      2          7.417013\n",
      "3        kj     5       1      3          6.794710\n",
      "4        kj     5       1      4          6.674027\n",
      "subject path E:\\Data\\Data\\kj\\5\\2019-03-14-14-08-11_2\n",
      "subject and session name:  kj__5__2019-03-14-14-08-11_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        kj     5       2      0          3.237231\n",
      "1        kj     5       2      1          2.940853\n",
      "2        kj     5       2      2          2.884734\n",
      "3        kj     5       2      3          3.102106\n",
      "4        kj     5       2      4          2.832541\n",
      "subject path E:\\Data\\Data\\le\\1\\2019-02-18-13-20-38_1\n",
      "subject and session name:  le__1__2019-02-18-13-20-38_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        le     1       1      0          1.566266\n",
      "1        le     1       1      1          1.431995\n",
      "2        le     1       1      2          1.575195\n",
      "3        le     1       1      3          3.364982\n",
      "4        le     1       1      4          1.458461\n",
      "subject path E:\\Data\\Data\\le\\1\\2019-02-18-14-02-56_2\n",
      "subject and session name:  le__1__2019-02-18-14-02-56_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        le     1       2      0          3.170001\n",
      "1        le     1       2      1          7.213373\n",
      "2        le     1       2      2          6.909088\n",
      "3        le     1       2      3          2.908688\n",
      "4        le     1       2      4          3.263347\n",
      "subject path E:\\Data\\Data\\le\\2\\2019-02-19-10-03-14_1\n",
      "subject and session name:  le__2__2019-02-19-10-03-14_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        le     2       1      0          2.846701\n",
      "1        le     2       1      1          3.594868\n",
      "2        le     2       1      2          7.022316\n",
      "3        le     2       1      3          6.889292\n",
      "4        le     2       1      4          3.319777\n",
      "subject path E:\\Data\\Data\\le\\2\\2019-02-19-10-22-45_2\n",
      "subject and session name:  le__2__2019-02-19-10-22-45_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        le     2       2      0          1.430628\n",
      "1        le     2       2      1          1.438982\n",
      "2        le     2       2      2          1.519922\n",
      "3        le     2       2      3          1.325651\n",
      "4        le     2       2      4          6.542186\n",
      "subject path E:\\Data\\Data\\le\\3\\2019-02-21-15-01-4_1stPart_1\n",
      "subject and session name:  le__3__2019-02-21-15-01-4_1stPart_1\n",
      "same reading and writing trials\n",
      "1stPart\n",
      "subject path E:\\Data\\Data\\le\\3\\2019-02-21-15-25-56_2ndPart_1\n",
      "subject and session name:  le__3__2019-02-21-15-25-56_2ndPart_1\n",
      "same reading and writing trials\n",
      "2ndPart\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        le     3       1      0          1.455135\n",
      "1        le     3       1      1          3.264783\n",
      "2        le     3       1      2          6.871108\n",
      "3        le     3       1      3          3.262488\n",
      "4        le     3       1      4          3.191901\n",
      "subject path E:\\Data\\Data\\le\\3\\2019-02-21-15-36-13_2\n",
      "subject and session name:  le__3__2019-02-21-15-36-13_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        le     3       2      0          3.328722\n",
      "1        le     3       2      1          6.593070\n",
      "2        le     3       2      2          7.322862\n",
      "3        le     3       2      3          2.947348\n",
      "4        le     3       2      4          7.046579\n",
      "subject path E:\\Data\\Data\\le\\4\\2019-02-27-13-58-47_1\n",
      "subject and session name:  le__4__2019-02-27-13-58-47_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        le     4       1      0          6.658721\n",
      "1        le     4       1      1          3.467840\n",
      "2        le     4       1      2          3.229424\n",
      "3        le     4       1      3          3.074032\n",
      "4        le     4       1      4          6.945122\n",
      "subject path E:\\Data\\Data\\le\\4\\2019-02-27-14-15-48_2\n",
      "subject and session name:  le__4__2019-02-27-14-15-48_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        le     4       2      0          1.457168\n",
      "1        le     4       2      1          3.219982\n",
      "2        le     4       2      2          7.082395\n",
      "3        le     4       2      3          3.262484\n",
      "4        le     4       2      4          3.109418\n",
      "subject path E:\\Data\\Data\\le\\5_MS\\2019-03-04-11-20-5_1\n",
      "subject and session name:  le__5_MS__2019-03-04-11-20-5_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        le  5_MS       1      0          3.279711\n",
      "1        le  5_MS       1      1          1.387022\n",
      "2        le  5_MS       1      2          1.413580\n",
      "3        le  5_MS       1      3          1.474964\n",
      "4        le  5_MS       1      4          1.470564\n",
      "subject path E:\\Data\\Data\\le\\5_MS\\2019-03-04-12-00-15_2\n",
      "subject and session name:  le__5_MS__2019-03-04-12-00-15_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        le  5_MS       2      0          6.915363\n",
      "1        le  5_MS       2      1          6.280856\n",
      "2        le  5_MS       2      2          6.977175\n",
      "3        le  5_MS       2      3          3.132633\n",
      "4        le  5_MS       2      4          6.330584\n",
      "subject path E:\\Data\\Data\\ls1\\1\\2019-02-11-10-18-57_1\n",
      "subject and session name:  ls1__1__2019-02-11-10-18-57_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       ls1     1       1      0          6.065668\n",
      "1       ls1     1       1      1          5.777401\n",
      "2       ls1     1       1      2          3.279107\n",
      "3       ls1     1       1      3          6.571880\n",
      "4       ls1     1       1      4          5.488608\n",
      "subject path E:\\Data\\Data\\ls1\\1\\2019-02-11-10-37-37_2\n",
      "subject and session name:  ls1__1__2019-02-11-10-37-37_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       ls1     1       2      0          3.373058\n",
      "1       ls1     1       2      1          3.123117\n",
      "2       ls1     1       2      2          6.470230\n",
      "3       ls1     1       2      3          5.695554\n",
      "4       ls1     1       2      4          3.327879\n",
      "subject path E:\\Data\\Data\\ls1\\2\\2019-02-12-13-58-2_1\n",
      "subject and session name:  ls1__2__2019-02-12-13-58-2_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       ls1     2       1      0          6.280517\n",
      "1       ls1     2       1      1          6.411724\n",
      "2       ls1     2       1      2          4.833604\n",
      "3       ls1     2       1      3          5.003514\n",
      "4       ls1     2       1      4          5.902823\n",
      "subject path E:\\Data\\Data\\ls1\\2\\2019-02-12-14-14-31_2\n",
      "subject and session name:  ls1__2__2019-02-12-14-14-31_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       ls1     2       2      0          3.074175\n",
      "1       ls1     2       2      1          3.251346\n",
      "2       ls1     2       2      2          2.809182\n",
      "3       ls1     2       2      3          6.075466\n",
      "4       ls1     2       2      4          2.993765\n",
      "subject path E:\\Data\\Data\\ls1\\3\\2019-02-13-15-58-26_1\n",
      "subject and session name:  ls1__3__2019-02-13-15-58-26_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       ls1     3       1      0          2.973507\n",
      "1       ls1     3       1      1          6.087444\n",
      "2       ls1     3       1      2          5.949782\n",
      "3       ls1     3       1      3          3.430766\n",
      "4       ls1     3       1      4          3.165043\n",
      "subject path E:\\Data\\Data\\ls1\\3\\2019-02-13-16-30-57_2\n",
      "subject and session name:  ls1__3__2019-02-13-16-30-57_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       ls1     3       2      0          6.363140\n",
      "1       ls1     3       2      1          7.446084\n",
      "2       ls1     3       2      2          6.441014\n",
      "3       ls1     3       2      3          7.302068\n",
      "4       ls1     3       2      4          7.432766\n",
      "subject path E:\\Data\\Data\\ls1\\4_MS\\2019-02-18-10-25-52_1\n",
      "subject and session name:  ls1__4_MS__2019-02-18-10-25-52_1\n",
      "same reading and writing trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       ls1  4_MS       1      0          6.975591\n",
      "1       ls1  4_MS       1      1          0.000000\n",
      "2       ls1  4_MS       1      2          7.527938\n",
      "3       ls1  4_MS       1      3          7.491236\n",
      "4       ls1  4_MS       1      4          3.279113\n",
      "subject path E:\\Data\\Data\\ls1\\4_MS\\2019-02-18-10-46-26_2\n",
      "subject and session name:  ls1__4_MS__2019-02-18-10-46-26_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       ls1  4_MS       2      0          3.357794\n",
      "1       ls1  4_MS       2      1          3.436741\n",
      "2       ls1  4_MS       2      2          3.181144\n",
      "3       ls1  4_MS       2      3          6.962198\n",
      "4       ls1  4_MS       2      4          3.563839\n",
      "subject path E:\\Data\\Data\\ls1\\5\\2019-02-21-17-11-42_1\n",
      "subject and session name:  ls1__5__2019-02-21-17-11-42_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       ls1     5       1      0          3.050397\n",
      "1       ls1     5       1      1          1.392499\n",
      "2       ls1     5       1      2          3.100107\n",
      "3       ls1     5       1      3          2.941481\n",
      "4       ls1     5       1      4          2.849406\n",
      "subject path E:\\Data\\Data\\ls1\\5\\2019-02-21-17-40-46_2\n",
      "subject and session name:  ls1__5__2019-02-21-17-40-46_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       ls1     5       2      0          6.593441\n",
      "1       ls1     5       2      1          6.429418\n",
      "2       ls1     5       2      2          6.671003\n",
      "3       ls1     5       2      3          5.581503\n",
      "4       ls1     5       2      4          5.438796\n",
      "subject path E:\\Data\\Data\\ls2\\1\\2019-02-11-14-24-40_1\n",
      "subject and session name:  ls2__1__2019-02-11-14-24-40_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       ls2     1       1      0          3.471385\n",
      "1       ls2     1       1      1          3.710453\n",
      "2       ls2     1       1      2          3.358594\n",
      "3       ls2     1       1      3          3.545376\n",
      "4       ls2     1       1      4          3.436532\n",
      "subject path E:\\Data\\Data\\ls2\\1\\2019-02-11-14-53-55_2\n",
      "subject and session name:  ls2__1__2019-02-11-14-53-55_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       ls2     1       2      0          7.264334\n",
      "1       ls2     1       2      1          6.968092\n",
      "2       ls2     1       2      2          6.870924\n",
      "3       ls2     1       2      3          6.585132\n",
      "4       ls2     1       2      4          3.374635\n",
      "subject path E:\\Data\\Data\\ls2\\2\\2019-02-12-10-02-45_1\n",
      "subject and session name:  ls2__2__2019-02-12-10-02-45_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       ls2     2       1      0          3.516824\n",
      "1       ls2     2       1      1          3.259570\n",
      "2       ls2     2       1      2          3.447657\n",
      "3       ls2     2       1      3          6.281006\n",
      "4       ls2     2       1      4          6.609305\n",
      "subject path E:\\Data\\Data\\ls2\\2\\2019-02-12-10-23-24_2\n",
      "subject and session name:  ls2__2__2019-02-12-10-23-24_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       ls2     2       2      0          3.502348\n",
      "1       ls2     2       2      1          3.580387\n",
      "2       ls2     2       2      2          3.572982\n",
      "3       ls2     2       2      3          6.810248\n",
      "4       ls2     2       2      4          3.552697\n",
      "subject path E:\\Data\\Data\\ls2\\3_MS\\2019-02-13-15-20-38_1\n",
      "subject and session name:  ls2__3_MS__2019-02-13-15-20-38_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       ls2  3_MS       1      0          6.958186\n",
      "1       ls2  3_MS       1      1          3.706842\n",
      "2       ls2  3_MS       1      2          3.544313\n",
      "3       ls2  3_MS       1      3          3.477133\n",
      "4       ls2  3_MS       1      4          3.471669\n",
      "subject path E:\\Data\\Data\\ls2\\3_MS\\2019-02-13-15-55-28_2\n",
      "subject and session name:  ls2__3_MS__2019-02-13-15-55-28_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       ls2  3_MS       2      0          6.368610\n",
      "1       ls2  3_MS       2      1          7.086898\n",
      "2       ls2  3_MS       2      2          3.702239\n",
      "3       ls2  3_MS       2      3          7.355451\n",
      "4       ls2  3_MS       2      4          7.253395\n",
      "subject path E:\\Data\\Data\\ls2\\4\\2019-02-18-10-09-22_1\n",
      "subject and session name:  ls2__4__2019-02-18-10-09-22_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       ls2     4       1      0          6.641215\n",
      "1       ls2     4       1      1          6.775433\n",
      "2       ls2     4       1      2          7.044961\n",
      "3       ls2     4       1      3          7.007131\n",
      "4       ls2     4       1      4          3.343105\n",
      "subject path E:\\Data\\Data\\ls2\\4\\2019-02-18-10-28-35_2\n",
      "subject and session name:  ls2__4__2019-02-18-10-28-35_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       ls2     4       2      0          3.659481\n",
      "1       ls2     4       2      1          7.119278\n",
      "2       ls2     4       2      2          3.592069\n",
      "3       ls2     4       2      3          3.635868\n",
      "4       ls2     4       2      4          3.599839\n",
      "subject path E:\\Data\\Data\\ls2\\5\\2019-02-19-13-08-35_1\n",
      "subject and session name:  ls2__5__2019-02-19-13-08-35_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       ls2     5       1      0          3.409930\n",
      "1       ls2     5       1      1          3.304741\n",
      "2       ls2     5       1      2          3.257116\n",
      "3       ls2     5       1      3          7.276763\n",
      "4       ls2     5       1      4          3.485423\n",
      "subject path E:\\Data\\Data\\ls2\\5\\2019-02-19-13-34-31_2\n",
      "subject and session name:  ls2__5__2019-02-19-13-34-31_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0       ls2     5       2      0          7.180122\n",
      "1       ls2     5       2      1          3.445349\n",
      "2       ls2     5       2      2          6.600746\n",
      "3       ls2     5       2      3          7.075184\n",
      "4       ls2     5       2      4          3.027363\n",
      "subject path E:\\Data\\Data\\mh\\1\\2019-02-05-13-21-12_1\n",
      "subject and session name:  mh__1__2019-02-05-13-21-12_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        mh     1       1      0          3.153322\n",
      "1        mh     1       1      1          1.762707\n",
      "2        mh     1       1      2          1.412779\n",
      "3        mh     1       1      3          1.715523\n",
      "4        mh     1       1      4          3.300561\n",
      "subject path E:\\Data\\Data\\mh\\1\\2019-02-05-14-00-27_1stPart_2\n",
      "subject and session name:  mh__1__2019-02-05-14-00-27_1stPart_2\n",
      "same reading and writing trials\n",
      "1stPart\n",
      "subject path E:\\Data\\Data\\mh\\1\\2019-02-05-14-10-39_2ndPart_2\n",
      "subject and session name:  mh__1__2019-02-05-14-10-39_2ndPart_2\n",
      "same reading and writing trials\n",
      "2ndPart\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        mh     1       2      0          3.378734\n",
      "1        mh     1       2      1          5.935635\n",
      "2        mh     1       2      2          2.915047\n",
      "3        mh     1       2      3          3.088007\n",
      "4        mh     1       2      4          3.131654\n",
      "subject path E:\\Data\\Data\\mh\\2_MS\\2019-02-06-10-22-56_1\n",
      "subject and session name:  mh__2_MS__2019-02-06-10-22-56_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        mh  2_MS       1      0          2.841523\n",
      "1        mh  2_MS       1      1          1.332656\n",
      "2        mh  2_MS       1      2          1.357336\n",
      "3        mh  2_MS       1      3          1.474519\n",
      "4        mh  2_MS       1      4          1.456996\n",
      "subject path E:\\Data\\Data\\mh\\2_MS\\2019-02-06-11-01-44_2\n",
      "subject and session name:  mh__2_MS__2019-02-06-11-01-44_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        mh  2_MS       2      0          2.874283\n",
      "1        mh  2_MS       2      1          6.894843\n",
      "2        mh  2_MS       2      2          7.456445\n",
      "3        mh  2_MS       2      3          6.518271\n",
      "4        mh  2_MS       2      4          7.124713\n",
      "subject path E:\\Data\\Data\\mh\\3\\2019-02-11-13-01-52_1\n",
      "subject and session name:  mh__3__2019-02-11-13-01-52_1\n",
      "same reading and writing trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        mh     3       1      0          1.674007\n",
      "1        mh     3       1      1          1.418267\n",
      "2        mh     3       1      2          3.247328\n",
      "3        mh     3       1      3          3.043869\n",
      "4        mh     3       1      4          1.586645\n",
      "subject path E:\\Data\\Data\\mh\\3\\2019-02-11-13-34-42_2\n",
      "subject and session name:  mh__3__2019-02-11-13-34-42_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        mh     3       2      0          7.379290\n",
      "1        mh     3       2      1          7.086610\n",
      "2        mh     3       2      2          7.113604\n",
      "3        mh     3       2      3          3.403336\n",
      "4        mh     3       2      4          7.085331\n",
      "subject path E:\\Data\\Data\\mh\\4\\2019-02-12-13-03-58_1\n",
      "subject and session name:  mh__4__2019-02-12-13-03-58_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        mh     4       1      0          3.434097\n",
      "1        mh     4       1      1          6.867479\n",
      "2        mh     4       1      2          7.459365\n",
      "3        mh     4       1      3          7.472596\n",
      "4        mh     4       1      4          3.163355\n",
      "subject path E:\\Data\\Data\\mh\\4\\2019-02-12-13-15-54_2\n",
      "subject and session name:  mh__4__2019-02-12-13-15-54_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        mh     4       2      0          1.465208\n",
      "1        mh     4       2      1          6.537282\n",
      "2        mh     4       2      2          1.400538\n",
      "3        mh     4       2      3          1.630522\n",
      "4        mh     4       2      4          1.490117\n",
      "subject path E:\\Data\\Data\\mh\\5\\2019-02-13-09-59-37_1\n",
      "subject and session name:  mh__5__2019-02-13-09-59-37_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        mh     5       1      0          3.340003\n",
      "1        mh     5       1      1          7.252163\n",
      "2        mh     5       1      2          3.375340\n",
      "3        mh     5       1      3          7.063209\n",
      "4        mh     5       1      4          3.563614\n",
      "subject path E:\\Data\\Data\\mh\\5\\2019-02-13-10-11-26_2\n",
      "subject and session name:  mh__5__2019-02-13-10-11-26_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        mh     5       2      0          1.391105\n",
      "1        mh     5       2      1          1.451702\n",
      "2        mh     5       2      2          3.377028\n",
      "3        mh     5       2      3          1.384718\n",
      "4        mh     5       2      4          6.131535\n",
      "subject path E:\\Data\\Data\\mn\\1\\2019-02-08-10-51-3_1stPart_1\n",
      "subject and session name:  mn__1__2019-02-08-10-51-3_1stPart_1\n",
      "same reading and writing trials\n",
      "1stPart\n",
      "subject path E:\\Data\\Data\\mn\\1\\2019-02-08-11-05-7_2ndPart_1\n",
      "subject and session name:  mn__1__2019-02-08-11-05-7_2ndPart_1\n",
      "same reading and writing trials\n",
      "2ndPart\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        mn     1       1      0          6.261192\n",
      "1        mn     1       1      1          3.370654\n",
      "2        mn     1       1      2          6.514591\n",
      "3        mn     1       1      3          3.164053\n",
      "4        mn     1       1      4          7.277624\n",
      "subject path E:\\Data\\Data\\mn\\1\\2019-02-08-11-12-51_2\n",
      "subject and session name:  mn__1__2019-02-08-11-12-51_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        mn     1       2      0          3.403294\n",
      "1        mn     1       2      1          3.145281\n",
      "2        mn     1       2      2          1.425640\n",
      "3        mn     1       2      3          3.157435\n",
      "4        mn     1       2      4          3.425111\n",
      "subject path E:\\Data\\Data\\mn\\2\\2019-02-15-11-38-22_1\n",
      "subject and session name:  mn__2__2019-02-15-11-38-22_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        mn     2       1      0          6.323841\n",
      "1        mn     2       1      1          2.875691\n",
      "2        mn     2       1      2          2.996263\n",
      "3        mn     2       1      3          7.111436\n",
      "4        mn     2       1      4          6.386990\n",
      "subject path E:\\Data\\Data\\mn\\2\\2019-02-15-11-54-25_2\n",
      "subject and session name:  mn__2__2019-02-15-11-54-25_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        mn     2       2      0          1.417812\n",
      "1        mn     2       2      1          2.967052\n",
      "2        mn     2       2      2          3.154176\n",
      "3        mn     2       2      3          3.211172\n",
      "4        mn     2       2      4          1.500726\n",
      "subject path E:\\Data\\Data\\mn\\3\\2019-02-19-10-34-7_1stPart_1\n",
      "subject and session name:  mn__3__2019-02-19-10-34-7_1stPart_1\n",
      "same reading and writing trials\n",
      "1stPart\n",
      "subject path E:\\Data\\Data\\mn\\3\\2019-02-19-10-56-43_2ndPart_1\n",
      "subject and session name:  mn__3__2019-02-19-10-56-43_2ndPart_1\n",
      "same reading and writing trials\n",
      "2ndPart\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        mn     3       1      0          6.464173\n",
      "1        mn     3       1      1          3.257194\n",
      "2        mn     3       1      2          1.549700\n",
      "3        mn     3       1      3          1.507702\n",
      "4        mn     3       1      4          1.370582\n",
      "subject path E:\\Data\\Data\\mn\\3\\2019-02-19-11-08-43_2\n",
      "subject and session name:  mn__3__2019-02-19-11-08-43_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        mn     3       2      0          3.357092\n",
      "1        mn     3       2      1          7.205215\n",
      "2        mn     3       2      2          3.347661\n",
      "3        mn     3       2      3          2.886798\n",
      "4        mn     3       2      4          3.202667\n",
      "subject path E:\\Data\\Data\\mn\\4_MS\\2019-02-21-17-26-10_1\n",
      "subject and session name:  mn__4_MS__2019-02-21-17-26-10_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        mn  4_MS       1      0          6.932567\n",
      "1        mn  4_MS       1      1          3.223780\n",
      "2        mn  4_MS       1      2          7.165014\n",
      "3        mn  4_MS       1      3          6.485394\n",
      "4        mn  4_MS       1      4          3.119945\n",
      "subject path E:\\Data\\Data\\mn\\4_MS\\2019-02-21-17-45-11_2\n",
      "subject and session name:  mn__4_MS__2019-02-21-17-45-11_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        mn  4_MS       2      0          3.568221\n",
      "1        mn  4_MS       2      1          3.301398\n",
      "2        mn  4_MS       2      2          1.457183\n",
      "3        mn  4_MS       2      3          3.082376\n",
      "4        mn  4_MS       2      4          2.979970\n",
      "subject path E:\\Data\\Data\\mn\\5\\2019-02-22-10-41-37_1\n",
      "subject and session name:  mn__5__2019-02-22-10-41-37_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        mn     5       1      0          3.169124\n",
      "1        mn     5       1      1          7.094963\n",
      "2        mn     5       1      2          2.982705\n",
      "3        mn     5       1      3          6.613169\n",
      "4        mn     5       1      4          7.098683\n",
      "subject path E:\\Data\\Data\\mn\\5\\2019-02-22-11-03-32_2\n",
      "subject and session name:  mn__5__2019-02-22-11-03-32_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        mn     5       2      0          1.442598\n",
      "1        mn     5       2      1          1.358968\n",
      "2        mn     5       2      2          3.276674\n",
      "3        mn     5       2      3          2.842139\n",
      "4        mn     5       2      4          3.392167\n",
      "subject path E:\\Data\\Data\\no\\1\\2019-01-16-15-18-0_1\n",
      "subject and session name:  no__1__2019-01-16-15-18-0_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        no     1       1      0          3.418500\n",
      "1        no     1       1      1          1.700393\n",
      "2        no     1       1      2          1.607313\n",
      "3        no     1       1      3          1.569251\n",
      "subject path E:\\Data\\Data\\no\\1\\2019-01-16-15-51-13_2\n",
      "subject and session name:  no__1__2019-01-16-15-51-13_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        no     1       2      0          3.352337\n",
      "1        no     1       2      1          3.179950\n",
      "2        no     1       2      2          3.370168\n",
      "3        no     1       2      3          3.131376\n",
      "4        no     1       2      4          2.993076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject path E:\\Data\\Data\\no\\2\\2019-01-28-10-01-27_1\n",
      "subject and session name:  no__2__2019-01-28-10-01-27_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        no     2       1      0          7.030225\n",
      "1        no     2       1      1          6.558991\n",
      "2        no     2       1      2          3.181006\n",
      "3        no     2       1      3          3.239875\n",
      "4        no     2       1      4          3.361193\n",
      "subject path E:\\Data\\Data\\no\\2\\2019-01-28-10-17-12_2\n",
      "subject and session name:  no__2__2019-01-28-10-17-12_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        no     2       2      0          1.642532\n",
      "1        no     2       2      1          1.676824\n",
      "2        no     2       2      2          3.405861\n",
      "3        no     2       2      3          3.179204\n",
      "4        no     2       2      4          1.730360\n",
      "subject path E:\\Data\\Data\\no\\3\\2019-01-29-10-08-10_1\n",
      "subject and session name:  no__3__2019-01-29-10-08-10_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        no     3       1      0          3.384249\n",
      "1        no     3       1      1          3.362626\n",
      "2        no     3       1      2          7.488599\n",
      "3        no     3       1      3          3.145858\n",
      "4        no     3       1      4          6.445755\n",
      "subject path E:\\Data\\Data\\no\\3\\2019-01-29-10-23-27_2\n",
      "subject and session name:  no__3__2019-01-29-10-23-27_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        no     3       2      0          1.627098\n",
      "1        no     3       2      1          1.514041\n",
      "2        no     3       2      2          1.674350\n",
      "3        no     3       2      3          1.616383\n",
      "4        no     3       2      4          3.190452\n",
      "subject path E:\\Data\\Data\\no\\4_MS\\2019-01-30-10-20-32_1\n",
      "subject and session name:  no__4_MS__2019-01-30-10-20-32_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        no  4_MS       1      0          3.142803\n",
      "1        no  4_MS       1      1          6.720798\n",
      "2        no  4_MS       1      2          3.469946\n",
      "3        no  4_MS       1      3          3.280782\n",
      "4        no  4_MS       1      4          3.360677\n",
      "subject path E:\\Data\\Data\\no\\4_MS\\2019-01-30-10-46-38_2\n",
      "subject and session name:  no__4_MS__2019-01-30-10-46-38_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        no  4_MS       2      0          1.540636\n",
      "1        no  4_MS       2      1          1.626699\n",
      "2        no  4_MS       2      2          1.550882\n",
      "3        no  4_MS       2      3          6.440752\n",
      "4        no  4_MS       2      4          2.836425\n",
      "subject path E:\\Data\\Data\\no\\5\\2019-01-31-10-09-21_1\n",
      "subject and session name:  no__5__2019-01-31-10-09-21_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        no     5       1      0          3.415639\n",
      "1        no     5       1      1          3.332399\n",
      "2        no     5       1      2          1.590686\n",
      "3        no     5       1      3          1.564021\n",
      "4        no     5       1      4          6.967310\n",
      "subject path E:\\Data\\Data\\no\\5\\2019-01-31-10-35-17_2\n",
      "subject and session name:  no__5__2019-01-31-10-35-17_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        no     5       2      0          7.020310\n",
      "1        no     5       2      1          7.557895\n",
      "2        no     5       2      2          7.461981\n",
      "3        no     5       2      3          6.767615\n",
      "4        no     5       2      4          7.060242\n",
      "subject path E:\\Data\\Data\\ph\\1\\2019-01-28-13-31-51_1\n",
      "subject and session name:  ph__1__2019-01-28-13-31-51_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ph     1       1      0          3.411239\n",
      "1        ph     1       1      1          3.575875\n",
      "2        ph     1       1      2          3.216061\n",
      "3        ph     1       1      3          3.244770\n",
      "4        ph     1       1      4          6.884591\n",
      "subject path E:\\Data\\Data\\ph\\1\\2019-01-28-13-49-14_2\n",
      "subject and session name:  ph__1__2019-01-28-13-49-14_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ph     1       2      0          3.196048\n",
      "1        ph     1       2      1          3.141429\n",
      "2        ph     1       2      2          3.385817\n",
      "3        ph     1       2      3          3.292152\n",
      "4        ph     1       2      4          3.244302\n",
      "subject path E:\\Data\\Data\\ph\\2_MS\\2019-01-29-13-25-4_1\n",
      "subject and session name:  ph__2_MS__2019-01-29-13-25-4_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ph  2_MS       1      0          5.841822\n",
      "1        ph  2_MS       1      1          3.042386\n",
      "2        ph  2_MS       1      2          3.416967\n",
      "3        ph  2_MS       1      3          6.567810\n",
      "4        ph  2_MS       1      4          6.079948\n",
      "5        ph  2_MS       1      5          3.023444\n",
      "6        ph  2_MS       1      6          3.146779\n",
      "subject path E:\\Data\\Data\\ph\\2_MS\\2019-01-29-13-43-50_2\n",
      "subject and session name:  ph__2_MS__2019-01-29-13-43-50_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ph  2_MS       2      0          5.794963\n",
      "1        ph  2_MS       2      1          3.247066\n",
      "2        ph  2_MS       2      2          6.684984\n",
      "3        ph  2_MS       2      3          6.885079\n",
      "4        ph  2_MS       2      4          6.161038\n",
      "subject path E:\\Data\\Data\\ph\\3\\2019-02-07-16-11-24_1\n",
      "subject and session name:  ph__3__2019-02-07-16-11-24_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ph     3       1      0          6.317287\n",
      "1        ph     3       1      1          5.993757\n",
      "2        ph     3       1      2          2.780501\n",
      "3        ph     3       1      3          6.582765\n",
      "4        ph     3       1      4          5.296579\n",
      "subject path E:\\Data\\Data\\ph\\3\\2019-02-07-16-26-56_2\n",
      "subject and session name:  ph__3__2019-02-07-16-26-56_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ph     3       2      0          6.139227\n",
      "1        ph     3       2      1          5.853675\n",
      "2        ph     3       2      2          3.018091\n",
      "3        ph     3       2      3          6.251781\n",
      "4        ph     3       2      4          5.716260\n",
      "subject path E:\\Data\\Data\\ph\\4\\2019-02-18-16-04-48_1\n",
      "subject and session name:  ph__4__2019-02-18-16-04-48_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ph     4       1      0          6.211408\n",
      "1        ph     4       1      1          5.732710\n",
      "2        ph     4       1      2          6.111907\n",
      "3        ph     4       1      3          3.103043\n",
      "4        ph     4       1      4          6.122272\n",
      "subject path E:\\Data\\Data\\ph\\4\\2019-02-18-16-19-28_2\n",
      "subject and session name:  ph__4__2019-02-18-16-19-28_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ph     4       2      0          6.668916\n",
      "1        ph     4       2      1          6.202225\n",
      "2        ph     4       2      2          6.938003\n",
      "3        ph     4       2      3          6.536466\n",
      "4        ph     4       2      4          6.049774\n",
      "subject path E:\\Data\\Data\\ph\\5\\2019-02-19-17-10-45_1\n",
      "subject and session name:  ph__5__2019-02-19-17-10-45_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ph     5       1      0          6.570619\n",
      "1        ph     5       1      1          6.422564\n",
      "2        ph     5       1      2          3.168236\n",
      "3        ph     5       1      3          6.467764\n",
      "subject path E:\\Data\\Data\\ph\\5\\2019-02-19-17-24-20_2\n",
      "subject and session name:  ph__5__2019-02-19-17-24-20_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ph     5       2      0          6.763637\n",
      "1        ph     5       2      1          6.449615\n",
      "2        ph     5       2      2          6.041822\n",
      "3        ph     5       2      3          6.933182\n",
      "4        ph     5       2      4          6.661456\n",
      "subject path E:\\Data\\Data\\rh\\1\\2019-03-07-16-17-30_1\n",
      "subject and session name:  rh__1__2019-03-07-16-17-30_1\n",
      "same reading and writing trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        rh     1       1      0          6.194260\n",
      "1        rh     1       1      1          6.286430\n",
      "2        rh     1       1      2          6.041807\n",
      "3        rh     1       1      3          3.013691\n",
      "4        rh     1       1      4          5.353781\n",
      "subject path E:\\Data\\Data\\rh\\1\\2019-03-07-16-44-5_2\n",
      "subject and session name:  rh__1__2019-03-07-16-44-5_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        rh     1       2      0          2.827054\n",
      "1        rh     1       2      1          1.313359\n",
      "2        rh     1       2      2          2.952204\n",
      "3        rh     1       2      3          3.231550\n",
      "subject path E:\\Data\\Data\\rh\\2\\2019-03-13-13-03-17_1\n",
      "subject and session name:  rh__2__2019-03-13-13-03-17_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        rh     2       1      0          5.606619\n",
      "1        rh     2       1      1          1.282573\n",
      "2        rh     2       1      2          1.446886\n",
      "3        rh     2       1      3          1.451068\n",
      "4        rh     2       1      4          3.207574\n",
      "subject path E:\\Data\\Data\\rh\\2\\2019-03-13-13-40-7_2\n",
      "subject and session name:  rh__2__2019-03-13-13-40-7_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        rh     2       2      0          6.275150\n",
      "1        rh     2       2      1          1.563998\n",
      "2        rh     2       2      2          5.943514\n",
      "3        rh     2       2      3          5.558697\n",
      "4        rh     2       2      4          6.137033\n",
      "subject path E:\\Data\\Data\\rh\\3_MS\\2019-03-14-13-30-35_1\n",
      "subject and session name:  rh__3_MS__2019-03-14-13-30-35_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        rh  3_MS       1      0          3.363504\n",
      "1        rh  3_MS       1      1          6.301694\n",
      "2        rh  3_MS       1      2          5.859400\n",
      "3        rh  3_MS       1      3          2.731324\n",
      "4        rh  3_MS       1      4          2.872242\n",
      "subject path E:\\Data\\Data\\rh\\3_MS\\2019-03-14-13-56-56_2\n",
      "subject and session name:  rh__3_MS__2019-03-14-13-56-56_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        rh  3_MS       2      0          2.728601\n",
      "1        rh  3_MS       2      1          3.039616\n",
      "2        rh  3_MS       2      2          2.970074\n",
      "3        rh  3_MS       2      3          2.955881\n",
      "subject path E:\\Data\\Data\\rh\\4\\2019-04-11-13-03-50_1\n",
      "subject and session name:  rh__4__2019-04-11-13-03-50_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        rh     4       1      0          2.931895\n",
      "1        rh     4       1      1          2.807432\n",
      "2        rh     4       1      2          1.189075\n",
      "3        rh     4       1      3          1.434261\n",
      "4        rh     4       1      4          3.292249\n",
      "subject path E:\\Data\\Data\\rh\\4\\2019-04-11-13-40-31_2\n",
      "subject and session name:  rh__4__2019-04-11-13-40-31_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        rh     4       2      0          5.740550\n",
      "1        rh     4       2      1          6.312360\n",
      "2        rh     4       2      2          5.878078\n",
      "3        rh     4       2      3          6.693476\n",
      "4        rh     4       2      4          5.785153\n",
      "subject path E:\\Data\\Data\\rh\\5\\2019-04-15-14-24-43_1\n",
      "subject and session name:  rh__5__2019-04-15-14-24-43_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        rh     5       1      0          6.148173\n",
      "1        rh     5       1      1          6.323228\n",
      "2        rh     5       1      2          3.035294\n",
      "3        rh     5       1      3          6.121302\n",
      "4        rh     5       1      4          2.860685\n",
      "subject path E:\\Data\\Data\\rh\\5\\2019-04-15-14-49-27_2\n",
      "subject and session name:  rh__5__2019-04-15-14-49-27_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        rh     5       2      0          1.252839\n",
      "1        rh     5       2      1          2.972548\n",
      "2        rh     5       2      2          1.570969\n",
      "3        rh     5       2      3          1.598870\n",
      "4        rh     5       2      4          1.397546\n",
      "subject path E:\\Data\\Data\\ys\\1\\2019-01-14-15-07-21_1\n",
      "subject and session name:  ys__1__2019-01-14-15-07-21_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ys     1       1      0          6.845441\n",
      "1        ys     1       1      1          6.651428\n",
      "2        ys     1       1      2          3.581195\n",
      "3        ys     1       1      3          3.474211\n",
      "subject path E:\\Data\\Data\\ys\\1\\2019-01-14-15-25-55_2\n",
      "subject and session name:  ys__1__2019-01-14-15-25-55_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ys     1       2      0          3.174563\n",
      "1        ys     1       2      1          6.627700\n",
      "2        ys     1       2      2          6.131356\n",
      "3        ys     1       2      3          6.799783\n",
      "4        ys     1       2      4          6.619877\n",
      "subject path E:\\Data\\Data\\ys\\2\\2019-01-16-15-18-50_1stPart_1\n",
      "subject and session name:  ys__2__2019-01-16-15-18-50_1stPart_1\n",
      "same reading and writing trials\n",
      "1stPart\n",
      "subject path E:\\Data\\Data\\ys\\2\\2019-01-16-15-42-51_2ndPart_1\n",
      "subject and session name:  ys__2__2019-01-16-15-42-51_2ndPart_1\n",
      "reading and writing sessions are separate\n",
      "2ndPart\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ys     2       1      0          3.094529\n",
      "1        ys     2       1      1          1.409094\n",
      "2        ys     2       1      2          3.226434\n",
      "3        ys     2       1      3          6.413914\n",
      "4        ys     2       1      4          3.057785\n",
      "subject path E:\\Data\\Data\\ys\\2\\2019-01-16-15-59-55_2\n",
      "subject and session name:  ys__2__2019-01-16-15-59-55_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ys     2       2      0          7.235627\n",
      "1        ys     2       2      1          6.257048\n",
      "2        ys     2       2      2          3.131141\n",
      "3        ys     2       2      3          6.093638\n",
      "4        ys     2       2      4          5.194919\n",
      "subject path E:\\Data\\Data\\ys\\3\\2019-01-17-15-05-1_1\n",
      "subject and session name:  ys__3__2019-01-17-15-05-1_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ys     3       1      0          1.322791\n",
      "1        ys     3       1      1          5.433409\n",
      "2        ys     3       1      2          2.651638\n",
      "3        ys     3       1      3          2.688568\n",
      "4        ys     3       1      4          6.629468\n",
      "5        ys     3       1      5          2.816610\n",
      "6        ys     3       1      6          2.741800\n",
      "7        ys     3       1      7          3.013114\n",
      "subject path E:\\Data\\Data\\ys\\3\\2019-01-17-15-31-12_2\n",
      "subject and session name:  ys__3__2019-01-17-15-31-12_2\n",
      "same reading and writing trials\n",
      "no gaze data present\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ys     3       2      0               NaN\n",
      "1        ys     3       2      1               NaN\n",
      "2        ys     3       2      2               NaN\n",
      "3        ys     3       2      3               NaN\n",
      "4        ys     3       2      4               NaN\n",
      "subject path E:\\Data\\Data\\ys\\4_MS\\2019-01-30-11-22-25_1\n",
      "subject and session name:  ys__4_MS__2019-01-30-11-22-25_1\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ys  4_MS       1      0          3.759835\n",
      "1        ys  4_MS       1      1          6.903033\n",
      "2        ys  4_MS       1      2          3.057354\n",
      "3        ys  4_MS       1      3          2.920657\n",
      "4        ys  4_MS       1      4          3.649403\n",
      "subject path E:\\Data\\Data\\ys\\4_MS\\2019-01-30-11-57-3_2\n",
      "subject and session name:  ys__4_MS__2019-01-30-11-57-3_2\n",
      "same reading and writing trials\n",
      "no gaze data present\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ys  4_MS       2      0               NaN\n",
      "1        ys  4_MS       2      1               NaN\n",
      "2        ys  4_MS       2      2               NaN\n",
      "3        ys  4_MS       2      3               NaN\n",
      "4        ys  4_MS       2      4               NaN\n",
      "subject path E:\\Data\\Data\\ys\\5\\2019-01-31-13-13-2_1\n",
      "subject and session name:  ys__5__2019-01-31-13-13-2_1\n",
      "same reading and writing trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ys     5       1      0          2.997913\n",
      "1        ys     5       1      1          6.650268\n",
      "2        ys     5       1      2          6.003848\n",
      "3        ys     5       1      3          6.163935\n",
      "4        ys     5       1      4          6.319482\n",
      "subject path E:\\Data\\Data\\ys\\5\\2019-01-31-13-32-2_2\n",
      "subject and session name:  ys__5__2019-01-31-13-32-2_2\n",
      "same reading and writing trials\n",
      "  subjectID block session  trial  IpaNewNewReading\n",
      "0        ys     5       2      0          3.205827\n",
      "1        ys     5       2      1          6.111788\n",
      "2        ys     5       2      2          3.177337\n",
      "3        ys     5       2      3          3.231806\n",
      "4        ys     5       2      4          3.269885\n"
     ]
    }
   ],
   "source": [
    "metricComputed_read = 'IpaLHReading'\n",
    "metricComputed_write = 'IpaLHWriting'\n",
    "metricComputed_trial = 'IpaLHTrial'\n",
    "\n",
    "dataFolderName = r'E:\\Data\\Data' # accessing external hard disk with the data\n",
    "a = re.compile('(?<=Data\\\\\\\\Data\\\\\\\\)(.*)(?=\\\\\\\\[1-9])')\n",
    "subjectName_listElement = 3\n",
    "\n",
    "#dataFolderName = r'C:\\DTU\\Data\\201901_JanuaryExpt' # accessing data saved in the computer\n",
    "#a = re.compile('(?<=Data\\\\\\\\201901_JanuaryExpt\\\\\\\\)(.*)(?=\\\\\\\\[1-9])')\n",
    "#subjectName_listElement = 4\n",
    "\n",
    "resultFileName_read = r'C:\\DTU\\Data\\201901_JanuaryExpt\\DataExtracted\\IndividualTrials\\Subject_Block_Session_Trial_' + metricComputed_read +  '.xlsx'\n",
    "resultFileName_write = r'C:\\DTU\\Data\\201901_JanuaryExpt\\DataExtracted\\IndividualTrials\\Subject_Block_Session_Trial_' + metricComputed_write +  '.xlsx'\n",
    "resultFileName_trial = r'C:\\DTU\\Data\\201901_JanuaryExpt\\DataExtracted\\IndividualTrials\\Subject_Block_Session_Trial_' + metricComputed_trial +  '.xlsx'\n",
    "\n",
    "\n",
    "\n",
    "for root, dirs, subfolder in os.walk(dataFolderName):\n",
    "    \n",
    "    technique = 'dwell_time'\n",
    "    \n",
    "    if not dirs:\n",
    "        \n",
    "        #if 'notCompleted' in root or 'notInclude' in root: # Some subjects do not have gaze log and have been marked as \n",
    "        \n",
    "        if 'noData' in root or 'Trial' in root or 'trial' in root or 'Nothing' in root: # Some subjects do not have gaze log and have been marked as \n",
    "            #notInclude\n",
    "            continue\n",
    "        if 'Jonas' in root or 'Praktikant' in root or 'Villads' in root:\n",
    "            continue\n",
    "            \n",
    "        #if 'ac\\\\1\\\\' not in root:\n",
    "        #    continue\n",
    "        if 'Picture' in root:\n",
    "            continue\n",
    "        #if '_MS' not in root:\n",
    "        #    continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        #if '2019-1-16-16-36-17_1stPart_2' not in root:\n",
    "        #    continue\n",
    "            \n",
    "        keysSelected = None\n",
    "        userKeys = None\n",
    "        phraseLog = None\n",
    "        \n",
    "        for file in subfolder:\n",
    "            \n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'KeySelection*'):\n",
    "                try:\n",
    "                    \n",
    "                    fKeysSelected = open(root + '\\\\' + file, encoding='utf-8', newline='')\n",
    "                    readerKeysSelected = csv.reader(fKeysSelected)\n",
    "                    keysSelected = list(readerKeysSelected)\n",
    "                    \n",
    "                    keysSelected.remove(keysSelected[0])\n",
    "                except:\n",
    "                    if fKeysSelected is not None:\n",
    "                        fKeysSelected.close()\n",
    "                    else:\n",
    "                        print('error in opening the KeySelection log file')\n",
    "                        \n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'user*'):\n",
    "                try:\n",
    "                    fUserKey = open(root + '\\\\' + file, encoding='utf-8',  newline='')\n",
    "                    readerUserKey = csv.reader(fUserKey, quotechar=None)\n",
    "                    userKeys = list(readerUserKey)\n",
    "                    userKeys.remove(userKeys[0])\n",
    "                except:\n",
    "                    if fUserKey is not None:\n",
    "                        fUserKey.close()\n",
    "                    else:\n",
    "                        print('error in opening the user key log file')\n",
    "                        \n",
    "            if fnmatch.fnmatch(file, 'phrase*'):\n",
    "                try:\n",
    "                    fPhraseLog = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerPhraseLog = csv.reader(fPhraseLog, quotechar=None)\n",
    "                    phraseLog = list(readerPhraseLog)\n",
    "                    \n",
    "                except:\n",
    "                    if fPhraseLog is not None:\n",
    "                        fPhraseLog.close()\n",
    "                    else:\n",
    "                        print('error in opening the phrase log file')\n",
    "                        \n",
    "            if fnmatch.fnmatch(file, 'multiKey*'):\n",
    "                technique = 'multiKey_selection'\n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'tobiiGazeLog*'):\n",
    "                try:\n",
    "                    fGazeLog = open(root + '\\\\' + file, encoding='utf-8', newline='')\n",
    "                    readerGazeLog = csv.reader(fGazeLog, quotechar=None)\n",
    "                    gazeLog = list(readerGazeLog)\n",
    "                    gazeLog.remove(gazeLog[0])\n",
    "                    gazeLog.remove(gazeLog[-1])\n",
    "                    \n",
    "                except:\n",
    "                    if fGazeLog is not None:\n",
    "                        fGazeLog.close()\n",
    "                    else:\n",
    "                        print('error in opening the scratchpad log file')\n",
    "            \n",
    "                    \n",
    "                     \n",
    "        if keysSelected is None or userKeys is None or phraseLog is None or gazeLog is None:\n",
    "            continue\n",
    "        else:\n",
    "                \n",
    "            print('subject path', root)\n",
    "            subjAndSessionName = '__'.join(root.split('\\\\')[subjectName_listElement:])\n",
    "            subjName = subjAndSessionName.split('__')[0]\n",
    "            print('subject and session name: ', subjAndSessionName)\n",
    "            sessionFolderName = root.split('\\\\')[-1]\n",
    "            \n",
    "            \n",
    "            # fix phraselog due to comma related file changes\n",
    "            phraseLog_new = FixScratchPad(phraseLog)\n",
    "            \n",
    "            # fix userKeys due to comma related file changes\n",
    "            userKeys_new = FixUserKeys(userKeys)\n",
    "            \n",
    "            \n",
    "            # need to fix keys selected, where rows get combined because of an inverted comma\n",
    "            keysSelected_new = FixKeysSelected(keysSelected)\n",
    "            \n",
    "            # find start time of typing\n",
    "            timeTyping = OptiKeyTypingTime(userKeys_new)\n",
    "            \n",
    "            # divide complete data into epochs of phrases\n",
    "            timeStartEndKeys_reading, timeStartEndKeys_writing = FindExptStartEndTimes(keysSelected_new, timeTyping, root)\n",
    "            \n",
    "            # use the times of trial start and end, to divide the time of trial into reading and writing\n",
    "            eventTrialsInKeysSelected_reading, eventTrialsInKeysSelected_readingIndex = FindReadingPartsOfTrial_inKeysSelected(timeStartEndKeys_reading, keysSelected_new, root)\n",
    "            eventTrialsInKeysSelected_writing, eventTrialsInKeysSelected_writingIndex = FindWritingPartsOfTrial_inKeysSelected(timeStartEndKeys_writing, keysSelected_new, eventTrialsInKeysSelected_reading)\n",
    "            \n",
    "            if sessionFolderName in dict_noGazeData:\n",
    "                print('no gaze data present')\n",
    "                ipa_reading = [np.nan]*len(eventTrialsInKeysSelected_writing['start'])\n",
    "                ipa_writing = [np.nan]*len(eventTrialsInKeysSelected_writing['start'])\n",
    "                ipa_trial = [np.nan]*len(eventTrialsInKeysSelected_writing['start'])\n",
    "                \n",
    "            else:\n",
    "                \n",
    "            \n",
    "               # filter the data\n",
    "                pupilData_filtered = FilterPupilSize(gazeLog, timeTyping, subjAndSessionName)\n",
    "            \n",
    "                # divide trials into reading and writing\n",
    "                eventReading, eventReading_index = EventPartsFromPupilData(eventTrialsInKeysSelected_reading, pupilData_filtered, root)\n",
    "                eventWriting, eventWriting_index = EventPartsFromPupilData(eventTrialsInKeysSelected_writing, pupilData_filtered, root)\n",
    "                eventTrial = CombineReadingWriting(eventReading, eventWriting)\n",
    "                \n",
    "                ipa_reading = ipaComputeForTrials(eventReading, pupilData_filtered)\n",
    "                ipa_writing = ipaComputeForTrials(eventWriting, pupilData_filtered)\n",
    "                ipa_trial = ipaComputeForTrials(eventTrial, pupilData_filtered)\n",
    "                \n",
    "                \n",
    "            if '1stPart' in root:\n",
    "                print('1stPart')\n",
    "                ipa_reading1 = ipa_reading\n",
    "                ipa_writing1 = ipa_writing\n",
    "                ipa_trial1 = ipa_trial\n",
    "                continue\n",
    "            \n",
    "            if '2ndPart' in root:\n",
    "                print('2ndPart')\n",
    "                ipa_reading2 = ipa_reading\n",
    "                ipa_writing2 = ipa_writing\n",
    "                ipa_trial2 = ipa_trial\n",
    "                \n",
    "                ipa_reading = ipa_reading1 + ipa_reading2\n",
    "                ipa_writing = ipa_writing1 + ipa_writing2\n",
    "                ipa_trial = ipa_trial1 + ipa_trial2\n",
    "                \n",
    "                ipa_reading1 = list()\n",
    "                ipa_writing1 = list()\n",
    "                ipa_trial1 = list()\n",
    "            \n",
    "            \n",
    "            # save the ipa_reading\n",
    "            dataToSave_read = DataForEveryTrial()\n",
    "            dataToSave_read.subjectID = subjAndSessionName.split('__')[0]\n",
    "            dataToSave_read.blockNumber = subjAndSessionName.split('__')[1]\n",
    "            dataToSave_read.sessionNumber = subjAndSessionName[-1]\n",
    "            dataToSave_read.variable = metricComputed_read\n",
    "            dataToSave_read.dataForTrial = ipa_reading\n",
    "            dataToSave_read.resultPathName = resultFileName_read\n",
    "            \n",
    "            print(dataToSave_read.printInfo())\n",
    "            dataToSave_read.AddToFile()\n",
    "            \n",
    "            \n",
    "            # save the ipa_writing\n",
    "            dataToSave_write = DataForEveryTrial()\n",
    "            dataToSave_write.subjectID = subjAndSessionName.split('__')[0]\n",
    "            dataToSave_write.blockNumber = subjAndSessionName.split('__')[1]\n",
    "            dataToSave_write.sessionNumber = subjAndSessionName[-1]\n",
    "            dataToSave_write.variable = metricComputed_write\n",
    "            dataToSave_write.dataForTrial = ipa_writing\n",
    "            dataToSave_write.resultPathName = resultFileName_write\n",
    "            \n",
    "            #print(dataToSave_write.printInfo())\n",
    "            dataToSave_write.AddToFile()\n",
    "            \n",
    "            # save the ipa_trial\n",
    "            dataToSave_trial = DataForEveryTrial()\n",
    "            dataToSave_trial.subjectID = subjAndSessionName.split('__')[0]\n",
    "            dataToSave_trial.blockNumber = subjAndSessionName.split('__')[1]\n",
    "            dataToSave_trial.sessionNumber = subjAndSessionName[-1]\n",
    "            dataToSave_trial.variable = metricComputed_trial\n",
    "            dataToSave_trial.dataForTrial = ipa_trial\n",
    "            dataToSave_trial.resultPathName = resultFileName_trial\n",
    "            \n",
    "            #print(dataToSave_trial.printInfo())\n",
    "            dataToSave_trial.AddToFile()\n",
    "            \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
