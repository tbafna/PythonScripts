{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject path E:\\Data\\Data\\ac\\1\\2019-02-11-11-18-30_1\n",
      "subject and session name:  ac__1__2019-02-11-11-18-30_1\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-b8a0404c790b>\", line 150, in <module>\n",
      "    timeBaselineQuestion = getBaselineQuestion(timeTyping, keysSelected_new)\n",
      "NameError: name 'getBaselineQuestion' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "AttributeError: module has no attribute '__name__'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'getBaselineQuestion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "metricComputed_baseline = 'PupilRelativeBaseline_300ms'\n",
    "metricComputed_readingStart = 'PupilRelative_readingStarting_300ms'\n",
    "metricComputed_readingEnd = 'PupilRelative_readingEnding_300ms'\n",
    "metricComputed_writingStart = 'PupilRelative_writingStarting_300ms'\n",
    "metricComputed_writingEnd = 'PupilRelative_writingEnding_300ms'\n",
    "#metricComputed_correlation = 'PupilSizeCorrelation_300ms'\n",
    "\n",
    "\n",
    "dataFolderName = r'E:\\Data\\Data' # accessing external hard disk with the data\n",
    "a = re.compile('(?<=Data\\\\\\\\Data\\\\\\\\)(.*)(?=\\\\\\\\[1-9])')\n",
    "subjectName_listElement = 3\n",
    "\n",
    "#dataFolderName = r'C:\\DTU\\Data\\201901_JanuaryExpt' # accessing data saved in the computer\n",
    "#a = re.compile('(?<=Data\\\\\\\\201901_JanuaryExpt\\\\\\\\)(.*)(?=\\\\\\\\[1-9])')\n",
    "#subjectName_listElement = 4\n",
    "\n",
    "resultFileName_baseline = r'C:\\DTU\\Data\\201901_JanuaryExpt\\DataExtracted\\IndividualTrials\\Pupils\\Subject_Block_Session_Trial_' \\\n",
    "+ metricComputed_baseline +  '.xlsx'\n",
    "\n",
    "resultFileName_readingStart = r'C:\\DTU\\Data\\201901_JanuaryExpt\\DataExtracted\\IndividualTrials\\Pupils\\Subject_Block_Session_Trial_' \\\n",
    "+ metricComputed_readingStart +  '.xlsx'\n",
    "resultFileName_readingEnd = r'C:\\DTU\\Data\\201901_JanuaryExpt\\DataExtracted\\IndividualTrials\\Pupils\\Subject_Block_Session_Trial_' \\\n",
    "+ metricComputed_readingEnd +  '.xlsx'\n",
    "\n",
    "resultFileName_writingStart = r'C:\\DTU\\Data\\201901_JanuaryExpt\\DataExtracted\\IndividualTrials\\Pupils\\Subject_Block_Session_Trial_' \\\n",
    "+ metricComputed_writingStart +  '.xlsx'\n",
    "resultFileName_writingEnd = r'C:\\DTU\\Data\\201901_JanuaryExpt\\DataExtracted\\IndividualTrials\\Pupils\\Subject_Block_Session_Trial_' \\\n",
    "+ metricComputed_writingEnd +  '.xlsx'\n",
    "\n",
    "#resultFileName_correlation = r'C:\\DTU\\Data\\201901_JanuaryExpt\\DataExtracted\\IndividualSessions_TrialAvg\\Subject_Block_Session_' \\\n",
    "#+ metricComputed_correlation +  '.xlsx'\n",
    "\n",
    "\n",
    "for root, dirs, subfolder in os.walk(dataFolderName):\n",
    "    \n",
    "    technique = 'dwell_time'\n",
    "    \n",
    "    if not dirs:\n",
    "        \n",
    "        #if 'notCompleted' in root or 'notInclude' in root: # Some subjects do not have gaze log and have been marked as \n",
    "        \n",
    "        if 'noData' in root or 'Trial' in root or 'trial' in root or 'Nothing' in root: # Some subjects do not have gaze \n",
    "            # log and have been marked as notInclude\n",
    "            continue\n",
    "        if 'Jonas' in root or 'Praktikant' in root or 'Villads' in root:\n",
    "            continue\n",
    "            \n",
    "        #if 'ac\\\\3_MS\\\\' not in root:\n",
    "        #    continue\n",
    "        if 'Picture' in root:\n",
    "            continue\n",
    "        #if '_MS' not in root:\n",
    "        #    continue\n",
    "        \n",
    "        #if 'bh2\\\\3\\\\2019-02-28-16-47-35_1' not in root:\n",
    "        #    continue\n",
    "        \n",
    "        #if '2019-1-16-16-36-17_1stPart_2' not in root:\n",
    "        #    continue\n",
    "            \n",
    "        keysSelected = None\n",
    "        userKeys = None\n",
    "        phraseLog = None\n",
    "        \n",
    "        for file in subfolder:\n",
    "            \n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'KeySelection*'):\n",
    "                try:\n",
    "                    \n",
    "                    fKeysSelected = open(root + '\\\\' + file, encoding='utf-8', newline='')\n",
    "                    readerKeysSelected = csv.reader(fKeysSelected)\n",
    "                    keysSelected = list(readerKeysSelected)\n",
    "                    \n",
    "                    keysSelected.remove(keysSelected[0])\n",
    "                except:\n",
    "                    if fKeysSelected is not None:\n",
    "                        fKeysSelected.close()\n",
    "                    else:\n",
    "                        print('error in opening the KeySelection log file')\n",
    "                        \n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'user*'):\n",
    "                try:\n",
    "                    fUserKey = open(root + '\\\\' + file, encoding='utf-8',  newline='')\n",
    "                    readerUserKey = csv.reader(fUserKey, quotechar=None)\n",
    "                    userKeys = list(readerUserKey)\n",
    "                    userKeys.remove(userKeys[0])\n",
    "                except:\n",
    "                    if fUserKey is not None:\n",
    "                        fUserKey.close()\n",
    "                    else:\n",
    "                        print('error in opening the user key log file')\n",
    "                        \n",
    "            if fnmatch.fnmatch(file, 'phrase*'):\n",
    "                try:\n",
    "                    fPhraseLog = open(root + '\\\\' + file, encoding='utf-8')\n",
    "                    readerPhraseLog = csv.reader(fPhraseLog, quotechar=None)\n",
    "                    phraseLog = list(readerPhraseLog)\n",
    "                    \n",
    "                except:\n",
    "                    if fPhraseLog is not None:\n",
    "                        fPhraseLog.close()\n",
    "                    else:\n",
    "                        print('error in opening the phrase log file')\n",
    "                        \n",
    "            if fnmatch.fnmatch(file, 'multiKey*'):\n",
    "                technique = 'multiKey_selection'\n",
    "            \n",
    "            if fnmatch.fnmatch(file, 'tobiiGazeLog*'):\n",
    "                try:\n",
    "                    fGazeLog = open(root + '\\\\' + file, encoding='utf-8', newline='')\n",
    "                    readerGazeLog = csv.reader(fGazeLog, quotechar=None)\n",
    "                    gazeLog = list(readerGazeLog)\n",
    "                    gazeLog.remove(gazeLog[0])\n",
    "                    gazeLog.remove(gazeLog[-1])\n",
    "                    \n",
    "                except:\n",
    "                    if fGazeLog is not None:\n",
    "                        fGazeLog.close()\n",
    "                    else:\n",
    "                        print('error in opening the scratchpad log file')\n",
    "            \n",
    "                    \n",
    "                     \n",
    "        if keysSelected is None or userKeys is None or phraseLog is None or gazeLog is None:\n",
    "            continue\n",
    "        else:\n",
    "                \n",
    "            print('subject path', root)\n",
    "            subjAndSessionName = '__'.join(root.split('\\\\')[subjectName_listElement:])\n",
    "            subjName = subjAndSessionName.split('__')[0]\n",
    "            print('subject and session name: ', subjAndSessionName)\n",
    "            sessionFolderName = root.split('\\\\')[-1]\n",
    "            \n",
    "            \n",
    "            # fix phraselog due to comma related file changes\n",
    "            phraseLog_new = FixScratchPad(phraseLog)\n",
    "            \n",
    "            # fix userKeys due to comma related file changes\n",
    "            userKeys_new = FixUserKeys(userKeys)\n",
    "            \n",
    "            \n",
    "            # need to fix keys selected, where rows get combined because of an inverted comma\n",
    "            keysSelected_new = FixKeysSelected(keysSelected)\n",
    "            \n",
    "            # find start time of typing\n",
    "            timeTyping = OptiKeyTypingTime(userKeys_new)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # divide complete data into epochs of phrases\n",
    "            timeStartEndKeys_reading, timeStartEndKeys_writing = FindExptStartEndTimes(keysSelected_new, timeTyping, root)\n",
    "            \n",
    "            userKeys_new_wDwellTime = ComputeDwellTime(userKeys_new, root)\n",
    "            \n",
    "            # use the times of trial start and end, to divide the time of trial into reading and writing\n",
    "            eventTrialsInKeysSelected_reading, eventTrialsInKeysSelected_readingIndex = \\\n",
    "            FindReadingPartsOfTrial_inKeysSelected(timeStartEndKeys_reading, keysSelected_new, root, \\\n",
    "                                                   userKeys_new_wDwellTime)\n",
    "            eventTrialsInKeysSelected_writing, eventTrialsInKeysSelected_writingIndex = FindWritingPartsOfTrial_inKeysSelected(timeStartEndKeys_writing, keysSelected_new, eventTrialsInKeysSelected_reading)\n",
    "            \n",
    "            if sessionFolderName in dict_noGazeData:\n",
    "                print('no gaze data present')\n",
    "                pupilSize_baseline = [np.nan]*len(eventTrialsInKeysSelected_writing['start'])\n",
    "                \n",
    "                pupilSize_starting_reading = [np.nan]*len(eventTrialsInKeysSelected_writing['start'])\n",
    "                pupilSize_ending_reading = [np.nan]*len(eventTrialsInKeysSelected_writing['start'])\n",
    "                pupilSize_starting_writing = [np.nan]*len(eventTrialsInKeysSelected_writing['start'])\n",
    "                pupilSize_ending_writing = [np.nan]*len(eventTrialsInKeysSelected_writing['start'])\n",
    "                \n",
    "            else:\n",
    "            \n",
    "                # filter the data\n",
    "                pupilMean_df, nanValues, correlationRL = FilterPupilSize_wWeightedMean(gazeLog, timeTyping, subjAndSessionName)\n",
    "            \n",
    "                # divide trials into reading and writing\n",
    "                eventReading, eventReading_index = EventPartsFromPupilData(eventTrialsInKeysSelected_reading, pupilMean_df, root)\n",
    "                eventWriting, eventWriting_index = EventPartsFromPupilData(eventTrialsInKeysSelected_writing, pupilMean_df, root)\n",
    "                \n",
    "                \n",
    "                # baseline time extraction\n",
    "                #pupilSize_baseLine = GetBaseline(eventTrials_reading, pupilData_filtered)\n",
    "                timeBaseline = 0.3 # seconds\n",
    "                pupilSize_baseline = GetBaselineForEveryTrial(eventReading_index, pupilMean_df, nanValues, timeBaseline, \\\n",
    "                                  subjAndSessionName)\n",
    "                \n",
    "                #print(pupilSize_baseline)\n",
    "                # compute the pupil size for the trialComputationTime for reading and writing, at the beginning and end\n",
    "                # of the parts\n",
    "                trialComputationTime = 0.3                \n",
    "                \n",
    "                #print('reading')\n",
    "                pupilSize_starting_reading, pupilSize_ending_reading = GetRelativePupilSize_startingAndEnding(\\\n",
    "                                eventReading_index, pupilMean_df, pupilSize_baseline, trialComputationTime, nanValues)\n",
    "                \n",
    "                #print('writing')\n",
    "                pupilSize_starting_writing, pupilSize_ending_writing = GetRelativePupilSize_startingAndEnding(\\\n",
    "                                eventWriting_index, pupilMean_df, pupilSize_baseline, trialComputationTime, nanValues)\n",
    "                \n",
    "            \n",
    "                \n",
    "            if '1stPart' in root:\n",
    "                print('1stPart')\n",
    "                pupilSize_baseline1 = pupilSize_baseline\n",
    "                pupilSize_starting_reading1 = pupilSize_starting_reading\n",
    "                pupilSize_ending_reading1 = pupilSize_ending_reading\n",
    "                pupilSize_starting_writing1 = pupilSize_starting_writing\n",
    "                pupilSize_ending_writing1 = pupilSize_ending_writing\n",
    "                \n",
    "                \"\"\"\n",
    "                dataToSave_correlationRL = DataForEverySession()\n",
    "                dataToSave_correlationRL.subjectID = subjAndSessionName.split('__')[0]\n",
    "                dataToSave_correlationRL.blockNumber = subjAndSessionName.split('__')[1]\n",
    "                dataToSave_correlationRL.sessionNumber = subjAndSessionName[-1]\n",
    "                dataToSave_correlationRL.variable = metricComputed_correlation\n",
    "                dataToSave_correlationRL.dataForTrial = correlationRL\n",
    "                dataToSave_correlationRL.resultPathName = resultFileName_correlation\n",
    "            \n",
    "                print(dataToSave_correlationRL.printInfo())\n",
    "                dataToSave_correlationRL.AddToFile()\n",
    "                \"\"\"\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            if '2ndPart' in root:\n",
    "                print('2ndPart')\n",
    "                pupilSize_baseline2 = pupilSize_baseline\n",
    "                \n",
    "                pupilSize_starting_reading2 = pupilSize_starting_reading\n",
    "                pupilSize_ending_reading2 = pupilSize_ending_reading\n",
    "                pupilSize_starting_writing2 = pupilSize_starting_writing\n",
    "                pupilSize_ending_writing2 = pupilSize_ending_writing\n",
    "                \n",
    "                pupilSize_baseline = pupilSize_baseline1 + pupilSize_baseline2\n",
    "                \n",
    "                pupilSize_starting_reading = pupilSize_starting_reading1 + pupilSize_starting_reading2\n",
    "                pupilSize_ending_reading = pupilSize_ending_reading1 + pupilSize_ending_reading2\n",
    "                pupilSize_starting_writing = pupilSize_starting_writing1 + pupilSize_starting_writing2\n",
    "                pupilSize_ending_writing = pupilSize_ending_writing1 + pupilSize_ending_writing2\n",
    "                \n",
    "                pupilSize_baseline1 = list()\n",
    "                pupilSize_starting_reading1 = list()\n",
    "                pupilSize_ending_reading1 = list()\n",
    "                pupilSize_starting_writing1 = list()\n",
    "                pupilSize_ending_writing1 = list()\n",
    "                \n",
    "                \n",
    "            print('')\n",
    "            # save the baseline pupil size for every \n",
    "            dataToSave_baseline = DataForEveryTrial()\n",
    "            dataToSave_baseline.subjectID = subjAndSessionName.split('__')[0]\n",
    "            dataToSave_baseline.blockNumber = subjAndSessionName.split('__')[1]\n",
    "            dataToSave_baseline.sessionNumber = subjAndSessionName[-1]\n",
    "            dataToSave_baseline.variable = metricComputed_baseline\n",
    "            dataToSave_baseline.dataForTrial = pupilSize_baseline\n",
    "            dataToSave_baseline.resultPathName = resultFileName_baseline\n",
    "            \n",
    "            print(dataToSave_baseline.printInfo())\n",
    "            \n",
    "            \n",
    "            # save the reading start\n",
    "            dataToSave_readingStart = DataForEveryTrial()\n",
    "            dataToSave_readingStart.subjectID = subjAndSessionName.split('__')[0]\n",
    "            dataToSave_readingStart.blockNumber = subjAndSessionName.split('__')[1]\n",
    "            dataToSave_readingStart.sessionNumber = subjAndSessionName[-1]\n",
    "            dataToSave_readingStart.variable = metricComputed_readingStart\n",
    "            dataToSave_readingStart.dataForTrial = pupilSize_starting_reading\n",
    "            dataToSave_readingStart.resultPathName = resultFileName_readingStart\n",
    "            \n",
    "            print(dataToSave_readingStart.printInfo())\n",
    "            \n",
    "            \n",
    "            # save the reading end\n",
    "            dataToSave_readingEnd = DataForEveryTrial()\n",
    "            dataToSave_readingEnd.subjectID = subjAndSessionName.split('__')[0]\n",
    "            dataToSave_readingEnd.blockNumber = subjAndSessionName.split('__')[1]\n",
    "            dataToSave_readingEnd.sessionNumber = subjAndSessionName[-1]\n",
    "            dataToSave_readingEnd.variable = metricComputed_readingEnd\n",
    "            dataToSave_readingEnd.dataForTrial = pupilSize_ending_reading\n",
    "            dataToSave_readingEnd.resultPathName = resultFileName_readingEnd\n",
    "            \n",
    "            print(dataToSave_readingEnd.printInfo())\n",
    "            \n",
    "            \n",
    "            # save the writing start\n",
    "            dataToSave_writingStart = DataForEveryTrial()\n",
    "            dataToSave_writingStart.subjectID = subjAndSessionName.split('__')[0]\n",
    "            dataToSave_writingStart.blockNumber = subjAndSessionName.split('__')[1]\n",
    "            dataToSave_writingStart.sessionNumber = subjAndSessionName[-1]\n",
    "            dataToSave_writingStart.variable = metricComputed_writingStart\n",
    "            dataToSave_writingStart.dataForTrial = pupilSize_starting_writing\n",
    "            dataToSave_writingStart.resultPathName = resultFileName_writingStart\n",
    "            \n",
    "            print(dataToSave_writingStart.printInfo())\n",
    "            \n",
    "            \n",
    "            # save the writing start\n",
    "            dataToSave_writingEnd = DataForEveryTrial()\n",
    "            dataToSave_writingEnd.subjectID = subjAndSessionName.split('__')[0]\n",
    "            dataToSave_writingEnd.blockNumber = subjAndSessionName.split('__')[1]\n",
    "            dataToSave_writingEnd.sessionNumber = subjAndSessionName[-1]\n",
    "            dataToSave_writingEnd.variable = metricComputed_writingEnd\n",
    "            dataToSave_writingEnd.dataForTrial = pupilSize_ending_writing\n",
    "            dataToSave_writingEnd.resultPathName = resultFileName_writingEnd\n",
    "            \n",
    "            print(dataToSave_writingEnd.printInfo())\n",
    "            \n",
    "            \n",
    "        \n",
    "            \"\"\"\n",
    "            dataToSave_baseline.AddToFile()\n",
    "            dataToSave_readingStart.AddToFile()\n",
    "            dataToSave_readingEnd.AddToFile()\n",
    "            dataToSave_writingStart.AddToFile()\n",
    "            dataToSave_writingEnd.AddToFile()\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            dataToSave_correlationRL = DataForEverySession()\n",
    "            dataToSave_correlationRL.subjectID = subjAndSessionName.split('__')[0]\n",
    "            dataToSave_correlationRL.blockNumber = subjAndSessionName.split('__')[1]\n",
    "            dataToSave_correlationRL.sessionNumber = subjAndSessionName[-1]\n",
    "            dataToSave_correlationRL.variable = metricComputed_correlation\n",
    "            dataToSave_correlationRL.dataForTrial = correlationRL\n",
    "            dataToSave_correlationRL.resultPathName = resultFileName_correlation\n",
    "            \n",
    "            print(dataToSave_correlationRL.printInfo())\n",
    "            dataToSave_correlationRL.AddToFile()\n",
    "            \"\"\"\n",
    "            \n",
    "            \n",
    "            print('')\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
